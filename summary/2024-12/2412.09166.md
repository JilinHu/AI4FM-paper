#### 背景
随着大型语言模型 (LLM) 在软件开发中的广泛应用，人们越来越担心 LLM 生成代码的安全性。现有的研究表明，LLM 生成代码中可能存在漏洞，这可能导致软件安全风险。
#### 核心贡献
本文的主要贡献是：

FormAI 数据集： 这是第一个包含 112,000 个由 AI 生成并可编译的独立 C 程序的大型数据集，每个程序都根据形式验证结果进行了漏洞标记。

漏洞分析： 本文对 GPT-3.5 生成的 C 程序中的漏洞进行了全面分析，确定了最常见的漏洞类型，并与通用弱点枚举 (CWE) 编号相关联。

#### 部署实现
本文使用 GPT-3.5-turbo 生成 C 程序，并使用 ESBMC 对生成的程序进行形式验证和漏洞标记。为了确保数据集的多样性，本文开发了一种动态零样本提示技术，并使用多种编程场景和编程风格来引导 LLM 生成代码。

#### 总结
本文的研究结果表明，GPT-3.5 生成的代码中存在漏洞，这给软件安全带来了风险。FormAI 数据集为研究人员和开发人员提供了宝贵的资源，可用于训练 LLM 生成更安全的代码，并改进漏洞检测工具。