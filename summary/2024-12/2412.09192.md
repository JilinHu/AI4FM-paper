#### 背景：
- 交互式定理证明器（ITP）如 Coq 可以确保软件正确性，但需要大量人工努力。
- 大型语言模型（LLM）在生成非正式证明方面表现出潜力，但在生成形式化证明方面效果较差。
- 现有的形式化证明自动化方法存在局限性，例如符号方法难以进行高阶和归纳推理，而机器学习方法需要大量训练数据。
#### 核心贡献：
- 形成性研究： 分析了 GPT-3.5 在 Coq 中证明定理时犯的常见错误，发现 LLM 通常可以识别出证明的正确高级结构，但在获取这些证明的较低级细节方面却很困难。
- PALM 方法： 提出了 PALM，这是一种新颖的“生成然后修复”方法，它首先提示 LLM 生成一个初始证明，然后利用针对单个证明步骤的低级别问题的有针对性的符号方法进行迭代修复。
- 评估： 在包含超过 10K 定理的大型数据集上评估了 PALM，结果表明它显著优于其他最先进的解决方案，成功证明了更多定理。
#### 部署实现：
- 前提检索： 使用 TF-IDF 和 KNN 算法从环境中检索与待证明定理相关的定理和定义。
- 提示设计： 设计了用于优化 LLM 生成的初始证明质量的提示，包括示例、前提和待证明定理。
- 修复机制： 开发了一系列修复机制来处理常见的错误类型，例如：

- 参考替换： 将未定义的引用替换为局部或全局上下文中具有相似名称的定理或假设。
- 重命名： 修改重复的变量名称或删除不必要的引入操作。
- 子弹转换： 修正子弹使用错误，确保正确地处理子目标。
- 前提增强： 使用 CoqHammer 确定如何正确使用被错误使用的定理。
- 回溯： 当修复机制无法解决问题时，使用 CoqHammer 重新证明之前的证明步骤，并尝试修复高级结构中的错误。
#### 总结：
PALM 是一种结合 LLM 和符号方法的证明自动化方法，可以有效证明更多定理，并具有泛化到不同 LLM 的能力。未来可以进一步改进 PALM，例如利用 LLM 修复不正确的证明、采用更强大的检索器和优化提示设计。