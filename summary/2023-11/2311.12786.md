#### 背景
- **背景**       
    文章研究了微调对预定义过程性任务效果的影响，以了解能力的相关性如何影响微调。作者使用两种设置：首先是使用Tracr编译具有事先定义能力的模型，其次是使用PCFG（Probabilistic Context-Free Grammars）对模型进行能力预训练。

- **已有的工作**
    当前关于微调对能力影响的研究不足，现有工具往往单一，有缺陷，且无法提供跨多个工具一致性的证据，使得结论抗性较弱。

#### 核心贡献
- **提出了一个评估微调影响的实验设定**
    - **挑战1：如何在微调过程中嵌入与预训练能力相关的特征**
        要评估能力相关性对微调的影响，文章通过在微调数据集中随机嵌入与预训练能力相关的虚假特征。这种设计挑战在于确保嵌入的特征足够简单，以使模型倾向于利用它来降低后续的损失，而这种嵌入方法需微妙构造，以保持特征的有效性。

    - **挑战2：确保评估方法能够深入揭示微调的影响**
        为了避免单个工具的局限性影响评估结果的稳健性，文章提出了一个称为逆向微调（reverse fine-tuning, reFT）的方法。这种方法包括将一个预训练模型微调在一个下游数据集上，然后再次微调它，即在原始预训练分布的数据集上。这样做的目的是检验微调是否真正显著地改变了相关的预训练能力。

#### 实现与部署
实验结果表明，微调很少引起预训练能力的有意义变化。分析工具包括网络剪枝、注意力图可视化和探测分类器等，旨在各个方面深入理解微调的效果。文章还利用reFT来探究模型在微调之后对预训练任务的恢复能力，形成对传统方法的补充和验证。结果表明，微调通常生成“封装能力”，而通过使用逆向微调和网络剪枝，研究人员可以"复活"模型原有的能力，即模型再次在预训练任务上表现良好。总之，文章的实验结果在多个工具上一致地表明微调对预训练模型的核心能力影响有限。

#### 总结
本文针对微调对预定义能力的影响开展了一项全面的分析和评估。通过Tracr编译式的能力设计和基于PCFG的学习式能力设计，文章详细探讨了微调过程中嵌入特征的相关性，提出了reFT来强化分析微调影响的深度。本研究的发现改进了对微调影响机理的理解，并为后续的模型设计和微调策略提供了实证支持。