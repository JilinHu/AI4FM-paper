#### 背景
- **背景**       
    文章介绍了人类有能力从单张图片或简短描述中直观了解人体姿态的背景，并指出了传统的基于图像或文本的人体姿态估计方法常常缺乏对整个场景的全面理解和微妙推理，导致视觉数据与其现实世界的含义之间存在脱节。

- **已有的工作**
    已有的工作通常是通过检测图像中的个体，将其从图像中分离出来，然后使用神经网络来预测三维姿态和形状。然而，这种方法没有全面理解场景，例如怎样从2D关键点估计出3D人体姿态，这些关键点不包含上下文信息。对于文本驱动的姿态生成方法，尽管发展迅速，但通常受限于文本指令是具体的，比如描述一个或多个动作，可能连续发生或一起发生，这些模型受到其训练数据的限制，数据通常包括运动捕捉数据集的文字描述，如AMASS，表达了非常有限的人类行为、情感和互动范围。针对此，现有的专用系统对于三维姿态的估计和生成受约束于狭窄的任务，与大型语言模型表现出的通用推理能力形成鲜明对比。

#### 核心贡献
- **提出了一个称为PoseGPT的框架**
    - **挑战1：解决新型姿态生成与推理问题**
        已有的系统受限于受训数据和具体指令，PoseGPT框架通过在多模态大型语言模型中嵌入SMPL姿态作为独特信号标记，从而可以直接从文本和视觉输入生成三维人体姿态。这种方法简化了姿态预测，并赋予大型语言模型利用其世界知识推理有关人类姿态的能力。这种能力产生了两项先进任务：投机性姿态生成（Speculative Pose Generation， SPG）和对姿态估计的推理。

    - **挑战2：通过交互式答疑对LLM进行微调**
        LLM必须能够理解和解释三维人体姿态，PoseGPT通过微调多模态大型语言模型来预测SMPL代表的人体姿态参数达成这一点。该方法嵌入SMPL姿态作为一个独特的<POSE>标记，促使LLM在被询问SMPL姿态相关问题时输出这些信息。作者还采取了新的训练策略，构造了来自姿态估计和文本驱动姿态生成任务的图像到SMPL和文本到SMPL姿态配对的问题和答案对。

#### 实现与部署
PoseGPT在多种不同任务上进行了评估，包括传统的单图像三维人体姿态估计任务和基于文本描述的姿态生成任务。尽管在这些传统任务的度量精度上还不及专用方法，但作者认为这是一个概念的证明。更重要的是，一旦LLMs可以理解SMPL姿态，它们就可以利用其固有的世界知识来关联和推理人类姿态，而不需要大量额外数据或训练。这种能力使得人类姿态分析领域出现了创新的任务。

#### 总结
PoseGPT是一个新型框架，它通过在LLM中嵌入SMPL姿态标记，使模型可以直接从文本和视觉输入生成三维人体姿态，并在解释三维人体姿态方面实现了一定程度的创新。