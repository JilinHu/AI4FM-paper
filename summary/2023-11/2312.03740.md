#### 背景
- **背景**       
    论文介绍了自回归大型语言模型（LLMs）如何改变自然语言处理（NLP）的格局。目前，预训练加提示（prompting）的范式已经取代了传统的预训练加微调方法，用于许多下游NLP任务。这一转变很大程度上得益于LLMs和创新的提示技术的发展。LLMs由于其庞大的参数数量和它们被预训练的巨大数据集展现出对多种下游任务的巨大潜力。然而，为了充分发挥这些模型的潜力，需要引导它们的输出朝着期望的结果发展。提示技术是实现这一目标的工具，它通过提供特定的输入或指令来引导LLMs实现预期的输出。

- **已有的工作**
    尽管提示技术在引导LLMs输出方面起到了重要作用，它并没有被完全利用，仍有许多开放问题有待解决。传统的预训练加微调方法不能适应LLMs庞大的规模，在面对每一个任务时进行微调变得不现实，而提示技术为LLMs带来了新的方法，使其无需额外培训即可实现有效指导，但如何详尽和系统地利用提示技术，尚无定论。

#### 核心贡献
- **提出了一个LLMs提示技术的分类和简要调查**
    - **挑战1：引导LLMs实现预期结果的准确性与效率**
        论文指出尽管提示技术能够有效地指导LLMs达到预期输出，现有的许多技术还是存在局限性。文章通过对现有文献的分类和调查，揭示出当前提示技术的多样性，并分析了如何更好地利用这些技术来提高LLMs在多种任务中的表现。

    - **挑战2：提示技术的创新与优化**
        论文认为尽管提示技术已经取得了一些进展，但其完全潜力尚未实现，并识别了推动技术领域中的一些开放问题，这些问题将成为未来研究的重要方向，需要进一步的创新和探索。

#### 实现与部署
尽管论文对当前LLMs的提示技术进行了总结和分类，但它未提供具体的实验结果或与其他工作的比较。论文的主要贡献是概括了当前的研究，并指出了该领域的开放问题和未来的研究方向。

#### 总结
本论文为自回归大型语言模型的提示技术领域提供了一个紧凑的文献综述，并指出了一些尚未解决的挑战和开放性问题，为未来研究提供了方向。