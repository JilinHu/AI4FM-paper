#### 背景
- **背景**       
    文章涉及了大型语言模型预训练语料库的数据整理与评估问题。研究人员对如何评估预训练语料库并未形成共识。存在用于探索文本困惑度分布和主题多样性的方法，也有侧重于语言正确性的人类标注比较以及针对高质量和低质量文本的审查，但缺少一个全面、多维度、易于使用的数据评估系统。

- **已有的工作**
    现有方法主要基于单一维度或具体任务来评估数据集的品质，而且许多高效的去重复方法对大规模部署的内存需求成为障碍。

#### 核心贡献
- **提出了一个名为Oasis的系统**
    - **挑战1：自定义数据整理**
        当前的语料库从不同来源收集而来，存在质量、风格、格式、模板和元信息的差异。传统的规则过滤器在不同数据源和语言上并不总是适用，从而需要针对性地构建和改进筛选规则，基于样本判决高质量文本与低质量文本的差异。Oasis提出了交互式模块化规则过滤器，允许用户交互式地编辑和连接规则单元，以构建自定义的规则过滤管道并自动生成脚本在后台运行。

    - **挑战2：偏差模型过滤器**
        现有的神经过滤器可能因所依赖的高质量源标准而导致对当前数据源的质量评估产生偏见，影响所筛选数据的数量和多样性。Oasis提出了以负面样本为中心的数据集构建方法，该方法从当前来源规则过滤的文本中收集大多数正样本，并通过启发式污染正样本来获取大多数负样本，以此减少偏见。此外，还通过神经过滤器对自定义文本污染规则的应用，强化了模型过滤器的泛化能力。

#### 实现与部署
Oasis系统包含不同的模块以解决自定义数据整理的挑战，如利用动态文档去重复来提高训练集的多样性并减少内存需求。它还包括一个全面的数据评估系统，该系统通过局部质量和全局分布的双重视角，结合人类评估、启发式指标和GPT-4来量化数据质量。通过对数据集进行定量的质量评估，支持数据整理过程的优化。Oasis系统通过其多模块功能和评估方法，展示了在控制资源消耗的同时改善预训练数据集质量的潜力。

#### 总结
本文提出的Oasis系统是针对大型语言模型预训练的数据整理和评估问题的解决方案。Oasis通过其交互式的自定义数据整理模块、针对偏差的模型过滤器和全面的数据评估系统，旨在提高数据集的质量和多样性，同时降低内存需求和资源消耗。系统的实现立足于提升数据处理的灵活性和评估的准确性，填补了现有工作在全面性和多维度评估方面的空白。通过综合使用人类评估、启发式度量和最新的大型语言模型如GPT-4进行质量评估，Oasis展现了对预训练数据集进行全方位优化的能力。