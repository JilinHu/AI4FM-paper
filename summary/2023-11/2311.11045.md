#### 背景
- **背景**       
    文章介绍了如何通过引导训练来教授小型语言模型进行推理。通过改进前一版本的Orca，提出了Orca 2，以提高小型语言模型在各种推理任务上的性能。

- **已有的工作**
    当前模型即使在数据较少的情况下也能够学习如何处理具体任务，但这些模型在综合推理方面常常表现不佳，特别是在任务没有明确指导时的性能。以往的工作虽然提高了一些性能，但大部分提升是通过规模的扩大实现的，并没有针对中小型模型在推理任务中的挑战提出解决方案。

#### 核心贡献
- **提出了一个新的小型语言模型Orca 2**
    - **挑战1：小型模型在推理方面的表现**
        小型模型在复杂任务上通常表现不佳，尤其在没有清晰指导下完成任务时。Orca 2 使用新的数据集和训练方法，改进了模型的推理能力和教育方法，允许它在任务指导不明确时也能展现出卓越的性能。

    - **挑战2：保证模型表现的同时减少模型尺寸**
        现有的模型往往需要通过扩大规模来提升性能，这不仅增加了部署的成本，也限制了模型的普及性。Orca 2证明了即使是小型模型，通过精心设计的训练数据和策略也能达到或超越更大模型的性能水平。

#### 实现与部署
在实现和部署方面，Orca 2 利用了大约817K的训练实例，并通过包括原始FLAN集合、Orca 1数据集以及Orca 2数据集的组合进行分阶段学习。Orca 2的数据集来源于FLAN-v2集合，包括Cot、NiV2、T0和Flan 2021四个子集合，这些子集中包含1913个任务。此外，还构建了一个Few-Shot数据集，该集包含55K个样本，用于鼓励模型学习如何使用示例数据。除此之外，Orca 2还用到了Deepmind的数学数据集，以及其他一些已有的数学问题数据集。此外，Orca 2 还包含了通过GPT-4合成创建的2000个医患对话生成的完全合成数据。这些工作为Orca 2的成功部署奠定了基础。训练过程包括使用LLaMA Byte Pair Encoding (BPE) 分词器和填充技术，以及有效地使用packaging技术优化训练过程，最大化计算资源的利用。

在评估结果方面，如图1所示，Orca 2的模型在一系列基准测试中，包括语言理解、常识推理、多步骤推理和数学问题解决等，与其他大型模型相比，能够匹敌或超越它们的性能，这些测试在零样本设置下完成。值得注意的是，尽管Orca 2的尺寸小得多，但在这些基准测试中仍然显示出卓越的性能。

#### 总结
文章通过介绍一个新的小型语言模型Orca 2，并展示其在多种推理任务上能够与更大的模型相匹敌或超越它们的性能，对当前小型语言模型在复杂推理任务中表现不佳的问题提出了有效的解决方案。Orca 2的开发依赖于对训练数据和训练策略的精心设计，证明了即使是小型模型，也可以通过改进训练方法来增强其理解和推理能力。文章还提供了Orca 2在各种标准测试中的卓越性能结果，验证了其方法论在实际应用中的有效性。