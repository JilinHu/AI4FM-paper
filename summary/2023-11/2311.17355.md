#### 背景
- **背景**       
    文章介绍了事实核查的重要性及其面临的挑战。事实核查意在评估值得核查的说法是否属实。事实核查可以细分为四个子任务：报告重点追踪（check-worthiness detection）、证据获取（evidence retrieval）、事实核实（fact verification）和解释生成（explanation generation）。当前研究提出了大量自动化的事实核查框架和模型来处理这些任务，这些方法主要利用预训练的语言模型提取文本特征并使用深度学习方法融合以预测说法的真实性。然而，这些方法因训练数据的规模限制以及领域敏感性而面临挑战，且这些方法通常要求大量的注释数据，这是耗时且费力的。

- **已有的工作**
    现有研究已经开始尝试利用如GPT-4和LLaMa2等大型语言模型（LLMs）处理自然语言处理（NLP）任务，并展示出卓越性能。对于事实核查的子任务之一——事实核实，已有研究显示LLMs有一定的潜力，但目前尚无系统性地评估LLMs在全部事实核查子任务中的表现。此外，关于LLMs是否能解决事实核查的全部子任务也缺乏研究。这篇文章旨在系统评估LLMs对事实核查任务的可能性，并提供未来研究方向。

#### 核心贡献
- **提出了一个事实核查的整体评估框架**
    - **挑战1：0-shot 设置中LLMs是否能在事实核查任务中表现优异**
        研究表明，即使使用不同方法增强提示（prompt），LLMs在0-shot设置中解决事实核查任务仍然困难。此外，LLMs能够同时进行事实核查和合理解释生成，但是当LLMs只处理事实核实任务时，性能会下降。
        
    - **挑战2：缺乏可以处理事实核查整个流程的集成模型，LLMs是否能同时解决所有子任务**
        该研究探讨了提示调整（prompt tuning）是否有助于提升LLMs的事实核查能力，以及LLMs是否能使用其知识作为知识库来提供需要核实的说法的证据。结果显示，提示的增强对于改善性能有一定效用，但LLMs作为知识库时仍需努力消除幻觉效应和不实信息的影响。

#### 实现与部署
研究者在3个事实核查数据集上进行了多项实验，以阐明LLMs在每个子任务和整个事实核查流程中的表现。结果表明LLMs难以在0-shot设置中解决事实核查任务，即便使用不同方法增强提示也是如此。尽管LLMs可以同时进行事实核查和解释生成，但它们在只处理事实核实任务时性能较差。尽管LLMs能够灵活地使用其知识检索相关证据并对标签进行预测，但在作为知识库时仍面临挑战。实验结果表明，需要更多尝试和研究才能提高LLMs在事实核查任务上的性能，使其成为优秀的事实核查者。

#### 总结
这篇文章通过系统评估LLMs在整个事实核查流程中的潜力，发现尽管LLMs在某些方面表现出潜力，但依然需要更多研究和尝试来提升它们在事实核查任务上的表现。