#### 背景
- **背景**       
    文章提出了答案推理问题的一种新框架——归纳增强生成（IAG），旨在解决现有基于检索的方法在为生成器提供充足知识、用于回答隐性推理问题时的不足。

- **已有的工作**
    已有研究利用大型语言模型（LLMs, 如GPT-3）进行问答任务，因其储存事实知识和进行推理的能力吸引了研究兴趣。然而，LLM从自由形式的文本中提取知识时容易出现事实错误，影响下游任务效果。已有方法要么专注于算数或常识推理任务，要么难于适用于开放域场景。

#### 核心贡献
- **提出了一个归纳增强生成框架（IAG）**
    - **挑战1：如何提高LLMs中知识陈述的真实性**
        现有LLMs在问答任务中虽然展现出能力，但其生成的知识陈述容易包含事实错误。论文通过归纳提示法加强LLMs知识表述的真实性，该方法利用类比和归纳推理来完成。

    - **挑战2：如何克服随机错误和过多噪声信息的问题**
        在实现IAG时，需要平衡知识陈述的数量。过少的陈述数量使得模型易于受到随机错误的影响；过多的陈述则可能引入误导预测的噪声信息。论文通过提供多个知识陈述给生成器，以增强其对于证据的多样性和鲁棒性。

#### 实现与部署
IAG在两个开放域问答基准上进行了评估，结果表明，IAG在回答隐性推理问题上超越了基于检索的生成（RAG）框架。通过在多个知识陈述中融合生成预测，相比于明确投票不同推理路径的自洽方法（self-consistency approach），IAG采用知识融合机制，使得模型在推理时能处理由多个知识陈述组成的证据集。优化了学生归纳模型，包括两步训练机制和不同的知识陈述数量，其中5到7之间的陈述数量被证实可以为IAG-Student实现最佳性能。

#### 总结
IAG框架通过归纳提示法加强知识陈述的真实性，并且优化了知识融合机制和学生归纳模型，以解决现有基于检索的方法在隐性推理问答任务上的不足。研究成果表明，IAG在回答涉及隐性推理的问答任务上表现更优。