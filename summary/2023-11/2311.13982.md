#### 背景
- **背景**       
    文章介绍了大型语言模型（LLM）在使用思维链条（CoT）推理回答知识密集型复杂问题时的能力。然而，当所需知识在模型的参数中不存在或不是最新的时，LLM倾向于生成事实上不正确的推理步骤。为了缓解这个问题，近期的作品转向检索外部知识来增强CoT推理，尽管有前景，但这些链式方法由于负面检索和有限视野（不能向前和后看而导致错误传播）的问题而不尽人意。

- **已有的工作**
    现有工作中的检索增强LLM通常采用一次性检索，也就是只使用输入问题进行一次知识检索，这对于需要多跳推理的复杂问题来说是不够的。针对这种需求，另一种采用在生成过程中进行多次检索的工作出现了，但这些方法仍然存在负面检索和有限视野的问题，即它们忽略了不必要或错误的外部知识可能误导LLM推理，且在推理步骤中的一个局部错误会沿着链传播，恶化整个推理过程。

#### 核心贡献
- **提出了一个新颖的方法**
    - **挑战1：负面检索**
        在对树叶节点进行推理时，文章提出的方法（ProbTree）将关闭书本式QA（采用参数知识）和开放书本式QA（利用检索到的外部知识）同时进行，并基于自我评估选择更有信心的答案，从而消除了负面检索问题。

    - **挑战2：有限视野**
        文章提出的树状思维框架使得LLM具有更广阔的视野，并能够全局地利用来自子节点的信息进行推理，从而在非叶节点上恢复局部错误，并缓解错误传播问题。
    - ...

#### 实现与部署
ProbTree在三个开放性复杂QA数据集上的评估结果显示，与现有SOTA方法相比，我们的方法在HotpotQA、MusiQue和2WikiMultihopQA上分别提高了F1分数的3.9％、7.3％和5.2％，展示了ProbTree推理的效果。

#### 总结
文章提出了一种新颖的概率树状推理（ProbTree）方法，通过探索LLM在回答知识密集型复杂问题时的能力，并将不确定性引入推理过程，在统一框架中整合了外部和参数知识。