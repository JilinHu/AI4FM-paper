#### 背景
- **背景**       
    文章介绍了在大型语言模型（LLMs）展现了在自然语言处理任务中的卓越一体化能力这一背景下，人体运动理解领域的研究人员仍然在对每个任务开发孤立的模型。由此研究人员受到InstructGPT和Gato背后的通用概念的启发，提出了AvatarGPT框架，一个针对运动理解、规划、生成和其他任务（如运动之间合成）的全能一体化框架。

- **已有的工作**
    现有文本到人体运动生成的方法在从端到端角度观察时，表现出两个局限性：其一，它们主要有效于生成短时运动序列，而将这些方法扩展到更长时间持续呈现出相当的挑战；其二，这些方法依赖于为每个运动序列手动制作的详细文本输入，这限制了它们在现实世界场景中的应用。

#### 核心贡献
- **提出了一个全能一体化框架AvatarGPT**
    - **挑战1：实现长期运动合成的无限可能。**
        这是一个挑战，因为现有技术主要有效于生成短时序列。AvatarGPT实现了通过闭环内的任务迭代遍历，对于长时间运动合成采用了原则性的方法，超越以往任何工作的能力范围。

    - **挑战2：避免手动干预而从实际视频中构建数据集。**
        这在以往是困难的，因为通常需要人工干预来生成训练数据集。AvatarGPT开发了一个创新的从野生视频中生成人体动作序列自然语言描述的无监督管道，并精心策划了一个专门用于调整高级人类行动规划的数据集。

    - ...

#### 实现与部署
AvatarGPT框架代表连续移动序列作为离散代币，并将其作为LLMs的扩展词汇库。该框架围绕四个高级别子任务（任务规划、分解、概括，以及场景估计）以及三个低级别子任务（文本驱动的动作生成、动作理解和动作之间的生成）。使用专门的提示为每个子任务，结合指令微调策略对模型进行训练。通过模型在低层级任务上取得的新的最先进水准，以及对高层级任务展示了有前途的结果，该框架显示了的有效性。

#### 总结
研究提出了一个创新的，一体化的框架AvatarGPT，用于处理理解、规划以及生成人类动作相关的高级和低级任务，展现出长时间运动合成的能力和减少手动干预的可能性。