#### 背景
- **背景**       
    文章介绍了最小贝叶斯风险（MBR）解码问题，尤其是在神经机器翻译（NMT）的领域。与更常用的最大后验概率（MAP）决策规则相比，MBR通过选择具有最高预期效用的序列作为输出，并已在多种任务中表现出更好的性能。然而，标准的基于采样的MBR算法比较昂贵，需要大量样本以及呈二次数量级的用户函数调用，限制了其适用性。

- **已有的工作**
    现有的MBR算法在计算效率方面存在限制，它需要大量的样本和用户函数调用。即使已有研究致力于寻找更准确和高效的生成方法，以及在执行标准MBR之前通过更快的方法将假设集H剪枝到较小的大小，现有方法仍不足以克服计算成本问题。

#### 核心贡献
- **提出了一个基于置信度的假设剪枝算法**
    - **挑战1：计算效率不足**
        挑战说明：由于MBR解码需要成千上万的样本和二次数量级的用户函数调用，因此在许多情况下变得过于昂贵，特别是当用户函数本身是一个深度神经模型时。论文的方法通过在预期效用的估计中逐步增加样本数量的同时剪除表现不佳的假设来解决该挑战。这依据通过自举采样得到的置信估计，剪除那些不太可能是最终预测的假设，进而显著减少用户函数的调用次数。

    - **挑战2：保持准确性**
        挑战说明：尽管需要减少计算成本，但仍需保持解码的准确性。论文提出的迭代剪枝算法能够在降低用户函数调用的同时，保持与标准MBR在准确度方面统计上不可区分的水平。这被三种语言对上的NMT实验所验证，实验中使用chrF++和COMET作为效用/评估指标。

#### 实现与部署
作者提出的基于置信度的算法不仅减少了适用于MBR的样本数量，而且在chrF++上至少减少了7倍，在COMET上至少减少了15倍的用户函数调用。通过提前终止预测，该算法还能比标准MBR算法使用更少的样本。实验在三种语言对上展示了该方法的有效性，证明了其能够在降低计算成本的同时保持准确性。

#### 总结
论文提出了一个用于MBR解码的算法，该算法通过在样本估计中逐渐增加样本数量并使用置信度剪枝来减少用户函数调用。在保持准确度的同时，该算法显著降低了计算成本，并通过三种语言对的NMT实验得到了验证。