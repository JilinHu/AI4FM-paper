#### 背景
- **背景**       
    文章研究了当下任务性文本（如问答数据集）被混淆后，最新的大型语言模型（LLMs）如何在恢复原文和回答问题任务中的表现。

- **已有的工作**
    以往研究在测试LLMs的能力时可能面临数据污染的问题，即测试集中的数据无意中被包含在了训练集中。此外，已有的评估方法没有明确区分LLMs是否确实理解了原始或变形后的文本，或是仅仅记忆了内容。

#### 核心贡献
- **提出了一个基于混淆语句的评估方法**
    - **挑战1：混淆文本识别**
        为了模拟自然语言的真实混乱，并确保评估过程中不出现数据污染，研究团队采用了最新的RealtimeQA数据集，并构建了多种混淆类型（随机混淆、保留首字母、保留首尾字母），以此来评估模型在不同混淆场景下恢复文本和回答问题的能力。挑战在于，如何确保评价系统是在评估语言模型真正的解决问题能力，而非其记忆能力。
        
    - **挑战2：测量性能**
        该研究定义了两项指标：恢复成功率（Recovery Rate, RR）和相对性能增益（Relative Performance Gain, RPG）。RR用于量化模型在恢复文本时减少的编辑距离比例，而RPG用于衡量模型在解析混淆文本相对原始文本的性能。挑战在于创建一个公正的比较基准，不受模型在原始问题上能力差异的影响。

#### 实现与部署
文章中的实验评估了包括最新版的text-davinci-003、GPT-3.5-turbo和GPT-4等在内的多种闭源和开源LLMs。主要的实验结果表明GPT-4在不同类型的混淆文本处理任务中均保持了超过95%的恢复成功率，即使在混淆比率增加时，它的性能也显著优于其他模型。这些成果证明了GPT-4在处理非自然混乱文本方面的卓越性能。

#### 总结
研究展示了GPT-4处理混淆文本的强大能力，设置了两项新指标RR和RPG，并通过它们验证了GPT-4在不同混淆场景和比率下的稳定表现。