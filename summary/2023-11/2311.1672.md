#### 背景
- **背景**       
    文章介绍了如何通过大型语言模型（LLM）以一种非监督的方式，提高文本排序任务的性能。在现有的信息检索领域，文本排序是一个核心的问题，其中涉及到按照相关性对候选文档集合进行排序。过去的研究已经开始利用LLMs的生成能力来估计文档生成给定查询的概率，以此作为相关性的指标。然而，这样的方法尚不完美，因为它没有能够显式地处理查询与文档之间的相关性。

- **已有的工作**
    已有研究尝试通过无监督方式使用大型语言模型进行文本排序，但这些方法通常没有显式地包含查询与文档间相关性的信号。这限制了模型理解文本间微妙关联性的能力，导致预训练阶段在细化训练迁移时可能会损失累积的益处。

#### 核心贡献
- **提出了一个综合性的二阶段训练模型**
    - **挑战1：如何保持持续预训练的优势**
        传统LLMs的预训练不包括查询和文档相关性的显式信号，而论文提出的持续预训练阶段结合了弱监督数据源的使用，训练了模型以更精致地理解查询与文档之间的关系。生成式的预训练任务专门针对提升模型在查询-文档空间理解灵活性相关信号的能力。

    - **挑战2：如何在细化训练时避免损失预训练期间的好处**
        论文提出了监督细化训练(SFT)，通过增强模型区分正负文本对的能力来提高性能。然而，连续预训练的目标与细化训练的离散性质之间存在不一致性，可能会损害预训练的益处。为此，论文设计了保持预训练益处的策略，包括差异惩罚（DP），它将细化训练的过程正规化以保持忠于预训练分布同时适应新的任务特定目标。
    - ...

#### 实现与部署
在实验部分，通过在MS MARCO、TREC 2019和TREC 2020数据集上的性能评估，来验证所提出的方法的有效性，这些数据集是信息检索领域公认的基准。论文还使用BEIR基准进行了域外评估，涉及金融、医药等多个领域和多种检索任务，如问答和事实核查。在这些基准上，论文提出的模型表现出了高于现有技术的有效性。特别是在≤3B参数的模型中，BLOOM-560M在平均得分上超过MonoBERT-340M、MonoT5-220M和MonoT5-770M达2.0、3.7和2.1的间隔。在7B参数的模型中，论文的模型在所有数据集上保持了更好的性能，仅在DL20例外。论文还针对不同类型和大小的LLMs进行了一致的优化和测试，以证明方法的普适性。

#### 总结
本研究提出了一种用于文本排序的二阶段训练模型，结合了弱监督预训练和监督细化训练，通过在不损害预训练益处的基础上增强模型细化训练性能，完成了从预训练到细化训练的平滑过渡，并在实验中显著优于现有技术。