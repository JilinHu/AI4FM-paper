#### 背景
- **背景**       
    文章主要导航了涵盖三个研究主题的内容：（一）探究链式思考（CoT）技术的基本机制，特别关注于何时何故CoT会有效；（二）识别CoT范式中的转变；（三）研究由CoT技术所能力化的语言代理（Language Agents）的出现【9†源】。

- **已有的工作**
    已有许多研究聚焦于CoT在极大语言模型（LLMs）中的应用，并探讨了CoT如何促进这些模型解决问题的能力。然而，尽管已有研究展示了CoT在提升LLMs性能方面的潜力，但关于当CoT有效时的特定条件及其内在原因仍存在一些不明确之处【11†源】【16†源】。

#### 核心贡献
- **提出了一个系统探索CoT的工作**
    - **挑战1：确定CoT何时有效**
        CoT虽然展示出潜在的优势，但并非所有条件下均适用。例如，CoT在小模型或简单任务上可能不太有效，而在大型模型和需要多步推理的复杂任务上效果较佳。此外，训练数据之中的局部知识（即LLMs中的参数知识）如果是与任务紧密相关并且互联性强，则有助于CoT的成功实施【16†源】。

    - **挑战2：理解CoT之所以有效的原因**
        从经验和理论角度分析，CoT的成功可能涉及到多方面的能力，如语义理解、符号映射、主题连贯性、算术能力等。理论上，当训练数据显示变量之间极度依赖的局部结构时，CoT更为有效。LLMs必须具备与任务相关的知识，而CoT有助于识别用于推理的基本知识单元，并通过中间推理步骤连接这些知识单元【16†源】。

#### 实现与部署
论文展示了通过对七个非常具有代表性的推理任务的分析，来总结CoT在LLMs推理能力增强中的作用。这些任务跨越算术推理、常识推理和符号推理等类别。通过将这些任务中使用CoT的最佳性能与未使用CoT的性能进行比较，可以清晰看到CoT如何显著影响了LLMs在所有七个任务上的推理能力。“直接提示”对照组使用未经CoT优化的基准性能，而最佳的CoT结果展示了多种优化技术的共同贡献，包括自洽（SC）等手段。文章展示了CoT在改进LLMs性能、解释性、可控性和灵活性方面的优势。研究发现，CoT有助于逐步推进LLMs的思考过程，并且在性能对比中表现出CoT的重要作用【15†源】【17†源】。

#### 总结
本文作为首篇系统性探讨CoT基步机制、范式转变，以及CoT与代理间复杂交互的工作，提供了一些关键见解。文章揭示了CoT在特定条件下显示出的有效性，指出了使CoT工作的多个条件，以及理论和实证研究为其成功提供了何种解释。文章还对CoT理论进行了深入分析，提出了CoT对于LLMs在多个领域的优化和革新可能具有重要的贡献，并指出尽管LLMs、CoT推理和语言代理快速发展，但仍存在未解决的挑战，如对未见领域的泛化、提高交互效率、代理定制化、代理扩展及代理安全性等【10†源】。