#### 背景
- **背景**       
    文章讨论了如何使用一组可验证的指令来评估大型语言模型（LLMs）的指令遵循能力。

- **已有的工作**
    已有的方法通常缺乏一种简便、无偏见且自动化的方式来评估LLMs的指令遵循能力，因此需要一个可以简易复制、无偏见且自动化的评估方法，本文提出的IFEval方法便是为了解决这个需求。

#### 核心贡献
- **提出了一个IFEval评估方法**
    - **挑战1：如何合成符合逻辑的指令**
        当前存在的挑战是生成一个能够让LLMs正确解释和执行的指令提示。生成提示的最直接方式会导致指令之间的潜在冲突，如一个要求段落数限制，另一个要求字数限制，从而削弱多样性。IFEval通过几个步骤合成提示，比如随机选择指令、去除逻辑不通的提示、重构表述方式来增加多样性，以及最后的手动检查和编辑。

    - **挑战2：如何量化遵循指令的准确性**
        另一个挑战是准确判断和量化LLMs对指令的遵循情况。即便使用编程和简单启发式规则，依然存在误判，IFEval方法提供了严格的和宽松的两种评价准则来计算指令遵循的准确性，减少误判，解决这个挑战。

#### 实现与部署
评估了GPT-4和PaLM 2 Small (S)模型，并分别在四个准确性指标上计算得分。这四个准确性指标包括：严格的提示级准确性、指令级准确性，以及宽松的提示级和指令级准确性。宽松准则通过多种变换函数来变换响应，比如移除markdown语法中的字体修饰符号和响应的首尾行，以减少误判。但宽松准则可能同时引入误报，为此作为补充，它与原始标准一同使用。GPT-4和PaLM 2 Small (S)的评估结果显示，两种模型在指令遵循能力上的差异，例如严格的指令级准确性分别为83.57%和55.76%。

#### 总结
本文提出了一种评估大型语言模型的指令遵循能力的新方法——IFEval，它通过合成逻辑一致的指令和计算指令遵循准确性的新准则来解决评估过程中的挑战。此方法为自动化且无偏见，它通过多步骤过程避免指令间的潜在冲突，并引入了严格和宽松的准确性评价标准来减少误判，同时认为未来可以通过增加多样化和使用多模态指令来改进该方法。