#### 背景
- **背景**       
    文章考察开源大型语言模型（Open-source Large Language Models, 简称LLMs）自ChatGPT一年发布之际的进展和性能。ChatGPT自推出以来，以其能力在多种任务领域中提供有帮助的、安全且详细的回答，快速吸引了公众的注意并吸引了商业投资。然而，由于其技术细节不开源，导致无法充分评估其潜在风险和对社会的影响，并且难以实现可重复的研究结果。而开源LLMs作为一个有希望的方向，可以解决或规避前述问题，但普遍被认为在性能上落后于如OpenAI的GPT-3.5（ChatGPT）和GPT-4这样的闭源对应物。尽管如此，开源LLMs正迅速缩小与闭源模型之间的差距，并在某些基准测试中已经超越了GPT-3.5-turbo。

- **已有的工作**
    目前，大部分高性能LLMs都采用大规模自监督预训练，并通过精细调整（Fine-tuning）来适应下游任务。尽管社区积极推动开源高性能LLMs的进程，但仍普遍认为，如Llama-2和Falcon这样的开源LLMs在性能上落后于他们的闭源对应物。评估LLMs的能力也是一个活跃的研究领域，因为需要执行多种多样的评估。文中详细地复习了开源LLMs已经赶上甚至在某些领域超越了ChatGPT的性能，并详细地讨论了可能会出现的潜在问题。

#### 核心贡献
- **提出了一个针对开源大型语言模型的系统回顾**
    - **挑战1：在众多任务领域中与ChatGPT持平或超越**
        文章列出和分析了多个开源LLMs在不同的任务领域相比ChatGPT所取得的进展，包括长输入任务、特定应用任务的能力以及信赖度等。例如，Llama-2-long-chat-70B在ZeroSCROLLS基准测试中超越了GPT-3.5-turbo-16k。这表明，在长输入任务中，通过预训练时使用更长的上下文窗口和数据来推动开源LLMs的性能非常有效。

    - **挑战2：培训LLMs的最佳实践以促进减少与闭源模型的性能差距**
        文章还讨论了构建高性能LLMs的最佳实践，包括数据收集和处理、模型设计和训练过程。例如，使用数量少但质量高的精细调整数据，利用decoder-only transformer架构以及重视模型与人类偏好和指令遵循的一致性等等。文章还指出了目前开源LLMs发展中的一些漏洞和潜在问题，如数据污染问题、对齐开发的闭源化以及在基本能力上的持续改进困难等。

#### 实现与部署
在评价开源LLMs对比ChatGPT的性能时，文章使用了大量的基准测试和评价指标，并在多项任务中展示了开源LLMs的崭露头角。举例来说，Llama-2-long提升了长输入任务的处理效率，Lemur-70B-chat在代码任务中的环境探索和反馈跟进方面表现优异，Gorilla则在编写API调用方面超越了GPT-4。同时，许多开源模型在特定任务上经过任务特定的精细调整后，如心理健康分析和放射学报告解读领域，展现了超越GPT-3.5-turbo的能力。这些比较表明，通过针对性的改进，开源LLMs正逐渐在质量和性能上赶超ChatGPT。

#### 总结
这篇综述文章提供了对开源LLMs在多任务领域相较ChatGPT的性能评估的考察，突出了目前开源LLMs的强项和潜在问题，并为未来的研究和开发提供了启示。此外，文章还总结了众多的最佳实践和挑战，显示出开源领域在一定程度上有望缩小与商业模型之间的差距。