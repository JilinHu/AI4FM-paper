#### 背景
- **背景**       
    文章介绍了在视觉问题回答（Visual Question Answering, VQA）的领域内，当前的视觉语言模型（Vision Language Models, VLMs）往往将VQA任务视为感知任务，使用黑盒模型，忽视了对同一视觉场景中不同问题之间关系的显式建模。此外，这些方法中依赖知识库（Knowledge Bases, KBs）的VQA方法可能会因为数据有限和信息索引的挑战面临偏见。为了克服这些限制，文章引入了一个多代理协作框架，该框林通过对大规模语料库进行训练的大型语言模型（Large Language Models, LLMs）中嵌入的知识的挖掘，实现了可解释性。

- **已有的工作**
    已有的研究尝试从外部知识库中增加模型的先验知识，以加强模型处理现实世界中复杂图像的能力，但通常无法为多样的视觉任务提供适应性强、无偏见的先验信息。同时，现有的一些需要结合LLMs的方法在利用LLMs的知识时缺乏可解释性和鲁棒性，并且与人类推理过程不同。

#### 核心贡献
- **提出了一个名为SIRI的多代理合作框架**
    - **挑战1：弥合LLMs与VLMs之间巨大的语言领域差距** 
        对于由LLMs学习的具体问题内实体间的关联显式地加以利用是一大挑战。文章通过创新性地结合了三个代理——搜索问题相关问题的Seeker代理、处理简单VQA任务的Responder代理和整合前两者信息以生成最终答案的Integrator代理——来模仿人类的认知过程，其中代理之间的协作模拟了人类认知中的自顶向下推理过程。这解决了现有方法中由于代理间的语言领域差异导致的局限。

    - **挑战2：增强VQA模型的解释能力和泛化能力** 
        这个框架引入了名为多视角知识库（Multi-view Knowledge Base）的模块，它使用LLMs的潜力，通过将Seeker代理生成的每个假设作为节点组织起来，实现了与问题和图像都密切相关的高效模块。此外，Integrator代理能使用该知识库和LLMs给假设赋予的真实世界发生概率，来衡量并最终确定给定原始问题的答案。这种结构使得模型在提供VQA答案的同时，也能够提供足够的解释。

#### 实现与部署
SIRI框架通过三个并行工作的代理来实现教学化的人类推理：Responder代理生成问题的候选答案，Seeker代理基于问题和答案候选生成相关问题并获取相应回答，Integrator代理结合前两者的信息产出最终答案。实验显示，在多个VQA数据集和不同VLMs上的评估展现了该方法的有效性和广泛适用性。

#### 总结
这项工作通过创新性地结合三个代理来模拟人类认知中的自顶向下推理过程，并引入了多视角知识库的概念，显著提升了VQA模型的表现力和解释能力。