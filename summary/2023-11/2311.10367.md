#### 背景
- **背景**       
    论文在探索大型语言模型（LLM）的两大主流学习范式：上下文内学习（ICL）和指令调优（IT）。ICL 通过在推断时提供示例来指导模型的响应而不更新模型参数，而 IT 指的是在有监督的情况下继续训练 LLM，提高其在未见任务上的泛化能力。目前对这两种方法的研究大多是分开进行的，本文意在探索二者之间的联系。

- **已有的工作**
    在现有研究中，ICL 和 IT 被视作提升大型语言模型能力的两种主要方法，分别通过提供示例或基于示例进一步练习模型来实现。然而，关于这两种方法之间的关系和互动的研究却很少，这也构成了本文探索的研究问题。

#### 核心贡献
- **提出了一个分析框架**
    - **挑战1：如何量化ICL和IT的效果**
        本研究尝试通过比较输入序列最后一个 token 的隐藏状态来量化ICL和IT的效果。论文分析了三种情境下的隐藏状态：基础情况下的零次学习、ICL中提供示例与推断样本的情景，以及在IT情景中使用示例进行模型调整。这允许研究人员通过隐藏状态的相似度来评估ICL和IT的效果。

    - **挑战2：确定ICL与IT之间的相关性**
        研究发现，ICL 和 IT 导致了相似的模型状态，这表明虽然在ICL中模型参数没有更新，在IT中模型参数经过调整，但两者都导向了相似的状态。此外，实验也表明，示例与推断样本之间的语义相似度提高了ICL和IT之间的一致性。这一结果有助于理解示例对ICL和IT效果的影响，并警示设计有效示例数据集和任务的重要性。

#### 实现与部署
研究选择了LLaMA-2 (7B)作为基础LLM，并设计了一个情感分析的示例数据集进行ICL和IT的测试。通过比较hanchor、hICL 和 hIT 三种隐藏状态的相似度，结果显示ICL和IT在隐藏状态上具有高度相似性，而与hanchor的相似度较低，这表明ICL和IT虽然在方法上有差异，但在引导LLM前往相似状态方面具有内在联系。论文进一步探讨了不同的示例变量如示例数量（从一次性ICL到少次性ICL），示例与推断样本间的语义相似度，以及使用错误标签的示例或不同任务的示例等，这些结果持续支持了ICL和IT所产生效果的相似性。

#### 总结
论文提供了ICL与IT之间密切相关的实证证据，即使ICL中不更改模型参数，二者所使用的指令和示例都驱动模型朝着收敛的隐藏状态前进。这一发现对于如何设计高效的数据集和任务以推进基础模型在下游应用的发展和对齐具有启示作用。研究结果还可以帮助理解示例在ICL和IT中的作用，以及如何利用这些见解来设计有效的示例任务和数据集，从而提升LLM的性能。论文中申明将会提供实验代码以供复现。