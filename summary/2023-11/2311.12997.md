#### 背景
- **背景**       
    文章介绍了大型Transformer模型如何在近年来通过预训练在大量文本数据上彻底改变了机器学习领域，如ChatGPT等模型展现出了将原始能力进行组合的迹象。由于这些模型的黑箱性质，目前尚不清楚这些模型是真正学会了组合能力，还是仅仅记住了训练数据中相关的样本。

- **已有的工作**
    已有的研究主要关注于评估大型预训练模型在实际任务中的“原始”能力，例如文本生成、代码生成和调试以及解决多模态问题等。然而，这种评估可能导致低估模型的能力，因为如果模型能够组合其原始能力，它可能能够执行我们从未明确训练它的任务。另一方面，如果模型未学会组合，则可以确定仅评估原始能力是足以表征模型的。这种情况可能导致在实际使用过程中无法确认模型是否真正地学会了复合不同的能力，或者是否能够在适当的上下文中使用它们。

#### 核心贡献
- **提出了一个用于评估Transformer模型能力的合成数据生成过程**
    - **挑战1：评估Transformer的组合性能力**
        挑战在于确定通过常规训练流程在合成数据上训练的Transformer是否能够学习组合其原始能力。这一挑战难在要区别模型是真的学会了复合能力，还是仅仅记住了训练样本。通过在合成、可解释的任务上训练自回归Transformer模型，文中的方法绕过了这一挑战，并通过实验系统性地证明了模型的组合能力。

    - **挑战2：理解Transformer的组合学习机制**
        另一个挑战是理解Transformer模型如何组合学习其能力。困难在于Transformer模型作为一个黑箱系统，很难直观地理解其内部学习和决策过程。文中的实验揭示了在模型后半部分的注意力层对于学习组合结构至关重要。

#### 实现与部署
通过在合成数据生成过程上训练自回归Transformer模型，文中展示了这样的模型能够从训练数据中学习组合结构，并概括到指数级甚至组合性地许多函数。实验结果表明，通过生成中间输出的方式来组合函数比直接输出方式更有效地推广到未见过的组合。同时，训练数据对模型组合未见过的函数组合的能力有显著影响。结果还发现，在模型的后半部分注意力层对于学习组合结构至关重要。这些发现与现有工作相比，深入探讨了Transformer训练数据的组合性质以及模型在没有中间输出的情况下组合能力的限制。

#### 总结
本文通过设计合成数据生成过程和系统性实验，以评估和理解自回归Transformer模型在组合其原始能力方面的潜力。研究结果突显了模型学习组合结构的能力，揭示了训练数据对此能力的影响以及模型内部注意力层在组合学习过程中的重要性。这或许为评估和提高现代神经网络对真实世界数据的理解和应用，特别是在其可能面临前所未见的任务时，提供了新的见解。