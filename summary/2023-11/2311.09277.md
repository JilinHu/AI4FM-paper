#### 背景
- **背景**       
    文章介绍了大型语言模型（LLMs）通过增大模型规模来提高泛化能力和自新任务的能力。尽管如此，单纯增加模型规模无法解决复杂的推理任务。因此，提出了链式思维提示（chain-of-thought prompting）来激发LLMs的推理能力，这通过生成中间推理步骤来实现。

- **已有的工作**
    现有的链式思维方法挖掘了文本示例中的中间思维链和输出，但对链式思维的理解尚不完全。先前的研究发现，即使使用逻辑上不合理的示例也能达到与合理示例相似的性能。此外，传统的链式思维没有告知语言模型应避免哪些错误，这可能导致更多错误。此外，中间步骤的错误可能会累积，从而破坏推理过程。因此，还需要减少中间推理步骤中的错误。

#### 核心贡献
- **提出了一个对比式链式思维（contrastive chain-of-thought）**
    - **挑战1：推理效果不明确**
        先前研究表明，即使是无效的推理示例，也可以达到与有效示例相似的性能，这导致我们不清楚语言模型如何基于链式思维示例有效学习。论文借鉴人类同时学习正面和负面示例的能力，提出了对比式链式思维，通过提供有效和无效的推理示例来引导模型一步步进行推理，同时减少推理错误。

    - **挑战2：有效应用到不同任务**
        如何设计有效的负面示例，并且是否可以泛化到不同的任务是一个挑战。论文通过分析多种无效推理类型，设计了一种简单有效的自动方法来从现有的有效推理链中生成对比式示例。此外，由于对比式链式思维与任务无关，并且与自洽性（self-consistency）等方法兼容，因此可以作为通用的链式思维增强方法。

#### 实现与部署
论文的实验评估表明，和传统的链式思维相比，对比式链式思维在多个推理基准测试中展示了显著的优势。具体而言，在使用广泛应用的LLM GPT-3.5-Turbo时，对比式链式思维分别在GSM-8K和Bamboogle任务上实现了9.8和16.0个百分点的提升。通过进一步分析从对比式方法生成的推理链，也显示出在减少错误方面的显著效果。总之，该方法不仅结合了正面和负面示例来提升链式思维的有效性，而且提出了一个自动构建对比示例的方法，其实验结果证明了这种方法与传统链式思维相比具有显著的改进。

#### 总结
本论文提出了对比式链式思维方法，以解决传统链式思维中存在的问题，即缺乏对错误避免的指导以及实现推理效果的不确定性。通过提供有效和无效的推理示例，新方法旨在引导模型减少推理错误并一步步推理，同时该方法提供了自动化构建对比示例的技术以便泛化到各种任务。实验结果证实，该方法能够作为一种通用增强手段，显著提升链式思维的性能。