#### 背景
- **背景**       
    文章介绍了在与大型语言模型（Large Language Models, LLMs）交互时，用户通常面临验证模型生成文本的真实性与可靠性的挑战。尤其在长文本生成的场景中，人工检验模型的输出存在显著的困难，因为需要从复杂的生成文本中评估事实一致性，这不仅耗时而且易错。

- **已有的工作**
    已有的研究提出了如链式思考（chain-of-thought）等策略来提升操作LLMs执行复杂任务的可控性，并构建了模块化的流水线来逐步解决子任务。然而，这些策略并未能有效提供对LLMs生成文本的事实一致性的直观评价与交互操作。

#### 核心贡献
- **提出了一个名为RELIC的交互系统**
    - **挑战1：使用户能够验证并指导语言模型生成的自然语言生成（NLG）文本的事实一致性**
        RELIC系统设计的**响应视图（Response View）**部分提供关键词标注、提问画笔和编辑功能，通过这些可视化手段帮助用户检查和编辑生成文本。

    - **挑战2：提高用户检验和编辑生成文本的效率**
        通过集成问题解答（question-answering）的流水线和交互技术，RELIC系统允许用户交互式地检索支持与反驳某些声明的词语和句子（即证据），并为用户提供了进行what-if分析和编辑生成文本的能力，以得到新的自我一致性判断。

#### 实现与部署
关键特性如关键词标注（Keyword Annotation）通过小型词级别的可视化显示不同样本中不同选项的比例。用户可以点击关键词注释查看详细的替代选项列表。RELIC通过用户研究评估了系统的可用性和有用性，十名参与者从多个角度提供了定量和定性反馈，确认了系统的可用性和提出的方法的有效性，并为未来人与LLM交互研究提供了见解。用户可以通过关键词注释、提问画笔互动和编辑功能来与LLMs的生成进行更积极的交互。

#### 总结
RELIC是一个交互式系统，它通过多样本的事实一致性检验，帮助用户验证和指导LLMs生成的文本。