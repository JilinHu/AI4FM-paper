#### 背景
- **背景**       
    文章介绍了目前大型语言模型（LLMs）在创建通用型智能体方面取得显著成就，这些智能体能够在多个领域内完成广泛任务，包括自然语言处理、计算机视觉和机器人技术。然而，它们在理解和互动3D世界方面的能力有限，这限制了模型执行现实世界任务和实现通用智能的能力。

- **已有的工作**
    已有工作在多模态（例如图像与文本）和通用型模型上取得了进展，尽管如此，由于3D数据集规模有限和手工标签的问题，这些模型在3D场景级理解上进展缓慢。此外，过去的模型经常被设计为具有强先验，且对基于LLMs的大规模统一预训练和有效微调进行探索的尝试有限。即使一些工作利用统一的Transformer或LLMs增强模型在固定3D场景理解上的能力，这些模型仍然缺乏在3D环境中行动的能力，以及释放LLMs用于3D视觉-语言-行动（VLA）学习的努力。

#### 核心贡献
- **提出了一个新的通用型智能体LEO**
    - **挑战1：缺乏与3D世界的深度理解和互动能力**
        目前的智能体模型在与3D世界的深入理解和交互方面存在局限性。这主要是由于3D数据集的规模有限和手工标注的问题导致的。文章通过开发LEO智能体，并且用细致研究和生成的包含对象级和场景级多模态任务的大型数据集来解决这一挑战，使得LEO可以在3D环境中实现包括3D字幕、问题回答、身体推理、身体导航和机器人操纵等广泛任务的显著效能。

    - **挑战2：设计统一模型和有效的学习策略**
        以前的3D机器学习模型依赖强先验设计，缺乏基于LLMs的大规模统一预训练和有效微调方法。文章中提出的LEO采用了简单统一的架构和有效的学习策略，通过一个专注于解码器的LLM来处理任务，把所有任务作为序列预测问题来重新格式化。

#### 实现与部署
LEO的实现有两个阶段，第一个阶段是3D视觉-语言对齐，第二阶段是3D视觉-语言-动作指令调优。LEO是一个统一模型，它将自我中心的2D图像、3D点云和文本作为输入，并将综合性3D任务构建为自回归序列预测。通过对LEO进行细化调整，将LLMs的能力扩展到包括视觉-语言-行动在内的多模态任务。通过实验，证明了LEO在多种任务上的显著熟练度，包括3D字幕、问题回答、身体推理、身体导航和机器人操作。此外，LEO的训练利用自回归训练目标对基于任务的输入和输出进行了任务不可知的训练，通过这种方法来适应预测动作标记的具体任务。

#### 总结
LEO是一个新型的身体化、多模态、多任务的通用型智能体，专注于在3D世界中的感知、基础、推理、规划和行动。通过对3D视觉-语言对齐和视觉-语言-动作指令调优的训练，LEO能在3D世界中执行一系列任务。文章通过一系列严格实验和消融实验的结果，证实了LEO在一系列任务上的高效性能，并为未来身体化通用型智能体的发展提供了宝贵洞见。