#### 背景
- **背景**       
    文章针对自然语言处理（NLP）中的文本分类问题，探讨了在数据受限的领域，如金融行业，现有的全数据分类方法因其需要成千上万的标记样本而变得不切实际。尽管近期基于少量样本（few-shot）的方法，如对比学习，已提出为改善这一问题提供帮助，可通过每个类别仅使用20个样本左右来取得有效结果，同时，如GPT-4这样的大型语言模型（LLM）仅需每类1-5个样本即可有效执行。然而，这些方法在性能与成本之间的权衡尚未得到充分探索，这对预算有限的组织来说是一个关键问题。

- **已有的工作**
    针对上述问题，该论文中的研究使用银行意图检测数据集Banking77，对OpenAI、Cohere和Anthropic等前沿LLM进行了综合评估，同时涉及了少量样本的各种场景。Banking77是一个真实世界的数据集，含有77个具有语义重叠的标签，使其适合探索方法论观点的同时解决商业用例。

#### 核心贡献
- **提出了一个应用于银行领域的资源受限文本分类方法**
    - **挑战1：成本有效的LLM查询方法**
        当前文献中缺乏对LLM在操作成本和性能之间权衡的探索。文章提出了基于检索增强生成（Retrieval-Augmented Generation, RAG）的方法，这种方法能够显著降低与传统few-shot方法相比的运营成本。通过这种方法，只需检索一小部分（2.2%）的案例，就能在测试集中以更低的成本（节约700美元）超越GPT-4的性能1.5个百分点。这对于经费有限的小型组织来说是一个重要的贡献。

    - **挑战2：低资源设置下的数据生成**
        论文还模拟了一个低资源数据场景，并利用GPT-4进行了数据增强，以此来展示了在数据受限情形下提高性能的可能性。该方法改进了性能，并且分析了数据增强失效的阈值，为AI从业者在决策时提供辅助。

#### 实现与部署
研究者首先采用MPNet进行微调，将其与完整数据集结合使用，再应用SetFit这种对比学习技术，展示在只有20个样例时也能取得类似的结果。此外，研究者还利用多种流行的LLM（如GPT-3.5、GPT-4）进行了上下文学习，证明了经过专家筛选的样例比随机选择的样例性能要好。研究结果表明，上下文学习配合LLM在金融领域的少样本文本分类任务中，即使示例更少，也能超越经过微调的MLM模型。

#### 总结
论文首次将多种在资源受限环境下的方法进行了全面评估，包括成本分析、RAG方法和利用GPT-4的数据增强，为金融行业提供了新的方法用以应对数据和预算限制的挑战。