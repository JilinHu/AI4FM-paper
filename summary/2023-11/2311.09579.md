#### 背景
- **背景**       
    文章探讨了如何根据语言模型（LM）的参数知识有效地制作上下文示例，为了提高大型语言模型（LLM）的输出精度。

- **已有的工作**
    已有研究表明，在上下文示例集中，标签分布影响LM的表现，但这些工作并未解决有效选择和排序上下文示例的问题，特别是在考虑LM的参数知识的情况下。

#### 核心贡献
- **提出了一个上下文示例检索器**
    - **挑战1：选择最有效的上下文示例**
        选择对LM来说“已知”与“未知”上下文示例的挑战在于，需要在提高LM输出精度的同时避免过拟合。通过度量示例候选与查询的平均相似性，并选择中值附近值的示例，研究表明"已知"示例能够提高LLM的表现。

    - **挑战2：优化上下文示例的排序**
        在每个上下文示例内部答案排序对LM性能有显著影响，方法是探究基于LM参数知识的答案排序是否改善性能。文章通过计算答案的长度标准化困惑度（perplexity）来决定答案的顺序，并采用贪心解码方法进行排序。

#### 实现与部署
在AmbigQA、QAMPARI和QUEST数据集上进行了实验，通过比较已知示例与未知示例的性能来验证该方法。结果表明，使用“半已知”的示例（即模型对答案有一半的知识）比其他设置表现更好，这可能促使LM利用参数知识并进行有根据的推测。

对于答案排序策略，研究表明，基于模型知识排序答案的策略（即“知识感知”排序），能够真实地反映在上下文示例中的答案排序，并且随着模型对答案排序的忠实度（ϕ值）增加，模型生成的答案数量也随之增加。

答案排序研究结果显示，GREEDY排序（以参数知识降序排列答案）在模仿上下文示例答案排序方面，其生成的答案排序与上下文示例的答案排序匹配的比例达到了平均74.1%。而相反的GREEDY排序（即REVERSE GREEDY，答案顺序相反，以参数知识升序排列）只有平均43.5%的匹配率。而在RANDOM和ALPHABET排序策略下，GREEDY排序具有显著的优势，说明了排序策略对于模型复现上下文例示答案的准确顺序具有重要作用。

#### 总结
本文的重点研究是如何根据LM的参数知识有效地创建上下文示例：选择最优的示例（已知与未知的比较）以及在上下文示例中如何排序答案。实验结果支持了半已知示例的有效性以及基于参数知识的答案排序方法，这些发现为提高大型语言模型在多答案生成任务中的性能提供了可行的技术途径。