#### 背景
- **背景**       
    论文介绍了多模态大型语言模型（MLLMs）在自动驾驶领域的应用和研究进展。

- **已有的工作**
    尽管言语模型已经在自动驾驶领域取得了一定的进展，但依然存在如何更好地融合不同模态（如视觉、语言等）以提高自动驾驶系统的决策和交互能力的挑战。

#### 核心贡献
- **提出了一个全面回顾**
    - **挑战1：环境感知能力**
        MLLMs通过整合视觉、语言、驾驶数据等多种信息源，提高了对交通场景理解的能力并且有望达到类似人类直觉的决策过程。
    - **挑战2：多模态融合与生成模型**
        论文探讨了如何将MLLMs用于更广泛的应用，例如生成真实驾驶场景的模拟以及驾驶任务的规划和控制，以适应现实世界的动态变化。

#### 实现与部署
MLLMs表现在分析图像和点云等非文本数据方面的熟练能力，通过文本分析进行学习，这一进展大幅改善了零样本（zero-shot）和少样本（few-shot）的图像分类，分割，以及物体检测等任务。领先的模型如CLIP展示了训练过匹配图像和标题可以有效地创建图像表示。针对多模态感知的进步，像SurrealDriver这样的模拟模型，可以生成驾驶行为，展示了MLLMs在感知复杂交通场景并生成相应驾驶操控的能力。研究也提出了将MLLMs作为语言模型转换为可执行动作计划的可能性，这既展示了它们理解自然语言命令的能力，也显示了在自动驾驶规划中深入推理的潜力。

#### 总结
该论文全面回顾了MLLMs在自动驾驶领域的应用，表明MLLMs具备解析非文本数据和融合多种模态（如视觉、语言）的能力，这些能力对于行为预测和动作规划尤为重要。通过在不同的自动驾驶环节中部署MLLMs（如理解交通场景、规划控制、模式生成），可以改善决策流程，并实现类似人类的驾驶直觉和决策模式，同时提高车辆导航和规划的效率和安全性。此外，模型通过为多个任务的预训练提供了一种新的可能性，这可能会推动把智能系统推向人工普遍智能（AGI）的发展路径。