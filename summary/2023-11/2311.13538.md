#### 背景
- **背景**       
    文章主要探讨了在使用大型语言模型(LLMs)进行高水平和坚实的复杂推理(如数学推理、常识推理)方面的挑战。目前，LLMs在提示词汇和风格上很精细且易变，而且存在LLM理解与人类编写提示之间的差距。

- **已有的工作**
    目前的研究在如何选择有效的示例方面做了很多尝试，提出了链式思综(Chain of Thought, CoT)提示等技术，并构建了基于此的各种提升模型。然而，CoT在文本风格上，特别是LLMs在思考时所熟悉和擅长的语言使用的规律及其对LLM进行复杂推理表现的影响，仍然没有得到充分的研究。

#### 核心贡献
- **提出了一个AlignedCoT技术**
    - **挑战1：文本风格差异导致LLMs推理能力不稳定**
        此技术可以通过逐步探测，细化和格式化LLM的思维链，以零样本情景下生成正确且连贯的步骤提示，消除了手工制作的少数样本示范的需求，同时保持了提示的质量。

    - **挑战2：训练与推理之间存在差异**
        通过对传统的少数样本CoT文本风格与LLMs的“本土风格”进行对齐，该方法减少了模型在训练和推理之间差异，降低了对模型广泛泛化能力的需求，从而提升了性能。

#### 实现与部署
通过在数学推理和常识推理任务的实验中，证明了使用AlignedCoT的LLMs显著超越了使用人工制定的示范的LLMs。此外，作者还将AlignedCoT应用于重写GSM8K训练集，得出一个GSM8K-Align数据集，并证实GSM8K-Align能有效提升检索增强方法的表现。

#### 总结
本文提出的AlignedCoT技术，旨在通过对齐LLMs的CoT文本风格与其“本土风格”，来提高LLMs的推理能力，并通过实验证明了其有效性。