#### 背景
- **背景**       
    论文讨论了大型语言模型(LLMs)在处理和生成自然语言时展现出显著的能力。然而，存在一个问题：这些模型可能会无意中记住隐私信息，从而构成重大的隐私风险。

- **已有的工作**
    已有的工作尝试通过机器遗忘（Machine Unlearning, MU）技术解决隐私问题，这种技术目标是在不重新训练模型的情况下，消除不需要数据的影响和相关模型能力。但目前的研究缺乏在真实世界场景下保护个人隐私数据的MU方法的评估，即目标个体在现实中存在且被LLMs记住。

#### 核心贡献
- **提出了一个名为RETURN的数据集**
    - **挑战1：真实世界个人数据保护**
        目前没有针对真实个体并且考虑到了模型已有记忆的个人数据保护评估的数据集。RETURN数据集包含来自维基百科的2,492个个体及其相关的QA对，用以在真实场景中评估MU方法在保护个人数据上的表现。

    - **挑战2：区分需要遗忘集和保留集**
        现有的MU方法通常对超参数选择敏感，或者不能有效区分遗忘集和保留集。为了克服这些缺陷，作者提出了一个简单而新颖的遗忘方法——“Name-Aware Unlearning Framework”（NAUF），用于隐私保护。这个框架由两个关键部分组成：Name-Aware Refusal Answer和Contrastive Data Augmentation。Name-Aware Refusal Answer旨在帮助模型学习哪些个人信息应被保护，而Contrastive Data Augmentation则旨在扩大遗忘集和保留集的分布，以增强该方法的泛化能力。

#### 实现与部署
在RETURN数据集上的实验展示了NAUF方法的有效性；与基线方法相比，NAUF获得了全球最佳的平均遗忘得分，优于最好的基线方法5.65分。实验证明，NAUF能有效地保护目标个体的个人数据，同时维持模型对其他不相关个体信息的处理能力。

#### 总结
论文提出了一种新的机器学习框架NAUF和与之配套的真实世界个人数据遗忘数据集RETURN，用于评估和改善LLMs在隐私保护方面的表现。