#### 背景
- **背景**       
    文章讨论了大型语言模型（LLMs）的知识机制对于推动值得信赖的通用人工智能（AGI）的发展的重要性。人类的知识发展历史悠久，并致力于利用现有知识和探索未知知识领域来培养更高级的智能。相较之下，LLMs对于学习、存储、使用和知识演化的机制仍然是一个谜。

- **已有的工作**
    尽管已有许多工作试图通过知识神经元和电路来解析LLMs中不同类型的知识，但这些努力散布在各种任务中，缺乏一个全面的回顾和分析。

#### 核心贡献
- **提出了一个新分类体系和对LLMs知识机制的全面回顾**
    - **挑战1：跨时间的知识演化**
        提出了一个包含特定时间点的知识使用和跨所有时期的知识演化的新分类体系。论文通过对知识利用的三个层面进行新的角度分析：记忆、理解与应用、以及创造。
    - **挑战2：参数化知识的脆弱性与潜在的“暗知识”**
        讨论了个体和群体LLMs中的知识演化，并分析了这一过程中固有的冲突与整合。同时猜想变压器架构可能阻碍创造力，数据分布和数量可能贡献了参数化知识的脆弱性，导致幻觉和知识冲突。此外，"暗知识"将长期存在。

#### 实现与部署
本文以一种新的视角去探讨和操纵LLMs中的高级知识，检查当前的局限性，并通过知识演化的历史鼓励未来更有效和可信赖的架构和学习策略。文章推测了大部分假设是基于基于Transformer的LLMs，并验证了这些建议在其他架构模型上的普适性。此外，提供了面向未来研究的方向和工具。

#### 总结
本论文认为深入了解LLMs的知识机制对于培养强大且可靠的AI至关重要。论文提出了一个评估此类系统的新框架，集中在知识的利用和演化，并为未来的研究方向提供了愿景和工具。