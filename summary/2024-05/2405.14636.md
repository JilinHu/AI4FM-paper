#### 背景
- **背景**       
    隨著大语言模型（Large Language Models, LLMs）用户数量的迅速增长，带宽受限的云服务器难以在实时处理大量LLMs服务需求。尽管边缘-云基础设施提高了大规模LLM服务处理的效率，但任务需求的多样性和资源的动态性对推理调度提出了巨大挑战，导致许多资源浪费。

- **已有的工作**
    边缘-云计算已被用来处理大规模数据传输因带宽受限导致的实时推理性能限制，以及高参数模型推理带来的高能源成本问题。然而，边缘计算仅能支持一些简单任务，在处理复杂任务时服务质量可能会受到妥协。

#### 核心贡献
- **提出了一个名为PerLLM的个性化推理调度框架**
    - **挑战1：多样化服务和推理调度的复杂性**
        PerLLM针对边缘-云协作环境下多样化LLMs服务的复杂约束和决策过程，整合了基于约束满足机制的置信上限算法，优化服务调度和资源分配解决方案，以满足处理时间要求的同时最小化能源成本。

    - **挑战2：提高吞吐量和降低能源成本**
        相较于其他方法，实验结果表明PerLLM能有效满足个性化服务的处理时间要求，同时实现了比传统方法2.2倍、2.1倍和1.6倍的吞吐量，并降低了超过50%的能源成本。

#### 实现与部署
PerLLM将边缘-云协作架构中的复杂决策过程建模为组合多臂老虎机问题，并提出了一个有效的服务调度和资源分配算法。实验结果显示，PerLLM在处理时间需求多样化的服务时，能显著增加吞吐量、减少处理时间和能源成本。与基线方法相比，PerLLM能更有效地满足推理服务的个性化需求，吞吐量提高了1.6倍以上，能源成本降低了50%以上。

#### 总结
本论文提出了PerLLM框架，通过边缘-云协作来处理大量推理服务，不仅优化了服务调度和资源分配，还显著提高了吞吐量并降低了能源成本，具有突出的应用价值。