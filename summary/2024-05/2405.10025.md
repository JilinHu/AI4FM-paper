#### 背景
- **背景**       
    文章介绍了自动语音识别（ASR）中存在的问题，尤其是在使用大型语言模型（LLM）进行生成错误修正（GER）时，虽然能有效增强ASR结果，但仍存在不考虑源语音内容和输入信息冗余的问题。

- **已有的工作为什么解决不了**
    现有研究没有整合源语音作为输入，导致可能出现语法正确但与源语音内容不符的情况。此外，N最佳假设列表中的项目往往只在几个词汇上有所变化，这在进行修正时造成信息冗余，LLM难以确定应 focus 的词汇。

#### 核心贡献
- **提出了一个名为ClozeGER的新范式**
    - **挑战1：模型在修正时忽视了源语音内容**
        现有的模型在进行文本生成错误修正时，未能考虑到原始语音的内容，可能导致输出与真实语音内容不符。为此，作者引入了一个多模态LLM“SpeechGPT”，该模型通过接收源语音作为额外输入，提高了修正输出的准确性。

    - **挑战2：输入信息冗余**
        在GER中使用全N最佳假设导致输入冗余，模型难以精确进行错误修正。论文通过重新格式化GER为填空题和对数标定来移除输入冗余，并通过清晰指令简化修正过程。

#### 实现与部署
ClozeGER在九个流行的ASR数据集上实现了新的突破，并通过实验表明其有效性。与传统GER相比，ClozeGER通过减少输入冗余和提升修正的目标明确性，实现了更精确的错误修正。

#### 总结
本论文成功提出并验证了结合多模态LLM的新ASR错误修正范式，不仅解决了源语音忽视和输入冗余的问题，还在实际应用中取得了显著效果。