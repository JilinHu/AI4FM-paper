#### 背景
- **背景**       
    大型语言模型（LLMs）已经显示出在解决各种任务方面的强大能力。然而，它们仍然面临着幻觉的挑战或过时知识的问题。最近，检索增强生成（RAG）技术已成为通过结合外部知识来增强LLM能力的重要技术。例如，在开放域问答（QA）中，LLMs首先检索相关文档然后生成答案。然而，直接用原始查询检索不总是能够获得正确和相关的文档。因此，查询重写已被广泛用于改写查询以扩展检索文档，以获得更好的响应。

- **已有的工作**
    已有工作尝试利用成本较高的LLMs直接生成重写内容或采用特定的小型查询重写模型以及基于反馈的强化学习来改进查询重写性能。然而，这些方法通常需要注释（例如，标记相关文档或下游答案）或为特定领域量身定制的奖励，这缺乏普遍性，且未能使用针对查询重写任务的有效信号。

#### 核心贡献
- **提出了一个名为RaFe的新框架**
    - **挑战1：注释成本与信号对齐问题**
        RaFe利用来自重排序器（reranker）的反馈来训练查询重写模型，减少了对注释的需求，这一反馈与查询重写的目标非常吻合。重排序器能够在不需要额外标签的情况下对文档进行评分，因此用于提供查询重写模型的反馈。

    - **挑战2：训练框架的普适性**
        RaFe不需要经过标注的标签或特别设计的分数，确保了训练框架的普适性。该框架经过直观的设计，很好地与查询重写的目标（检索与原查询相关的文档）对齐，并支持离线和在线的RL反馈训练。

#### 实现与部署
RaFe包含两个阶段的过程。首先通过标准的监督式微调来训练一个初始的查询重写模型。随后，使用来自重排序器的排名得分对查询重写模型进行反馈训练。在实验中，RaFe利用一个通用、公开可用的重排序器来推动查询重写模型的训练，表明了所提方法的有效性和潜在的普适性。该框架在跨语言数据集上验证了所提方法的有效性，进一步对更好的查询重写是什么以及排名反馈如何工作进行了全面探讨。

#### 总结
RaFe是一个新颖的查询重写框架，利用重排序器反馈来训练模型，无需注释，支持离线和在线反馈训练，具有良好的普适性和有效性。