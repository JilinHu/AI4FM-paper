#### 背景
- **背景**       
    随着语言模型（LMs）输出涵盖极其多样化的文本和复杂任务，评估它们产生的质量变得日益困难。目前，以LMs为基础的评估被视为一种可扩展且低成本的范式，用来评估由LMs生成的文本。然而，现有的开源评估模型存在缺陷：与人类评分的相关性不高，且它们通常只针对直接评估或成对排名的某一种方式进行训练，缺乏灵活性。

- **已有的工作**
    现有开源评估LMs通常无法与人类的评分做出足够相关的评分决策，无法很好地模拟专有LMs（如GPT-4），并且在评估时缺乏透明度、可控性和可承受性。此外，现有的模型在不同的评价体系下功能不够灵活，限制了它们在现实场景中的应用。

#### 核心贡献
- **提出了PROMETHEUS 2**
    - **挑战1：评估准确性与灵活性**
        现有模型通常无法同时执行直接评估和成对排名两种格式，也没能在特定评价标准（例如可帮助性和无害性之外的标准）上有效评估。PROMETHEUS 2可以处理直接评估和成对排名格式，并且在自定义评价标准上具有更高的准确性。

    - **挑战2：性能与专有模型的对比**
        开源评估模型与专有模型（如GPT-4）相比，通常在评估性能上存在显著差距。通过权重合并方法，训练的PROMETHEUS 2能够在直接评估和成对排名上取得很好的效果，其与人类评分的相关性和专有LMs的评分一致性均得到显著提高。
        
    - **额外贡献**
        还包括引入了一个包含1,000个自定义评估标准的成对排名反馈数据集，即PREFERENCE COLLECTION。

#### 实现与部署
在四个直接评估基准（如Vicuna Bench、MT Bench等）和四个成对排名基准（如HHH Alignment、MT Bench Human Judgment等）上，与其他开源评估LMs相比，PROMETHEUS 2在相关性和一致性方面取得了最高得分。特别是在全部数据集的皮尔森相关系数上超过其他基线0.2个单位，而在成对排名基准上，比人类评估的一致性几乎提高了一半，从而减小了与GPT-4性能差距的一半。

#### 总结
PROMETHEUS 2是一个新型的开源评估LM，能在直接评估和成对排名两种格式下工作，并且在自定义评价标准上与人类评分和专有LMs的判断密切相关。该模型采用权重合并的方式训练，性能显著超过其他开源模型和某些专有模型。