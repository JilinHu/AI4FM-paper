#### 背景
- **背景**       
    文章讨论了大型语言模型（LLM）在信息提取（IE）任务中常见的挑战，特别指出现有的LLM在遵循IE任务复杂指令方面表现不佳，这主要是由于LLM与人类的对齐不充分，因为主流的对齐数据集通常不包括IE数据。

- **已有的工作**
    现有研究主要探索了三个方面：提示工程、使用代码LLM和多任务微调。但这些工作没有充分对齐LLM在IE任务上的需求，提示工程方法没有调整模型参数就不能本质上对齐LLM，使用代码LLM和多任务微调的工作通常只在同质数据上微调模型，缺乏多样化的对齐数据，导致微调模型在IE任务上的泛化能力有限。

#### 核心贡献
- **提出了一个名为ADELIE的对齐大型语言模型**
    - **挑战1：数据多样性和质量**
        现有的对齐数据集不包括复杂的IE任务数据。ADELIE项目通过构建高质量的指令调整数据集IEInstruct，包括83,585个各种IE任务的实例，来解决这一挑战。IEInstruct包括多样化的指令和输入输出格式，增加了数据集的多样性和质量。

    - **挑战2：模型泛化能力和维持通用能力**
        传统的微调方法可能导致模型在特定任务上表现良好，但通用能力下降。ADELIE通过在LLAMA 2基础上使用监督式微调（SFT）结合广泛的对齐数据进行训练，并进一步使用直接偏好优化（DPO）目标进行训练，这样可以在保证任务特定性能的同时维护模型的通用能力。

#### 实现与部署
通过在多种保留的IE数据集上的广泛实验，ADELIE模型（ADELIESFT和ADELIEDPO）展示了优于其他开源模型包括GPT-3.5的顶尖性能。这些模型在封闭IE、开放IE和按需IE任务上的表现评估显示了它们的优势，证明了其模型对齐和指令调整的有效性，同时保持了在更广泛的任务（如自然语言理解等）中的通用性能。

#### 总结
本文提出的ADELIE模型有效地解决了LLM在信息提取任务中的对齐问题，并通过创新的数据集和训练方法提升了模型在这些任务上的性能，同时维护了良好的通用能力，为未来相关研究提供了有价值的见解和基础。