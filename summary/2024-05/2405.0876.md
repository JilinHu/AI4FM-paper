#### 背景
- **背景**       
    人类经常以间接或非字面意义的方式表达自己的交流意图，这要求交流者（无论是人类还是人工智能）理解超出字面意义的内容。然而已有的研究大多集中在区分性评估上，很少有工作探讨生成性回应的评估方法。

- **已有的工作**
    现有工作通过多选分类方法评估意图理解，这对于检测意图可能有效，但不一定能反映出LLMs在生成与交流意图相关的合适回应的能力。

#### 核心贡献
- **提出了一个新的生成性评估框架**
    - **挑战1：理解并适当回应非字面语言**
        现有方法通常无法正确处理非字面表达的含义。本研究通过创建一个框架，使得模型能够展示其在理解和生成与真实意图一致的回应方面的能力，尤其是在处理非直接表达的场景中。
    
    - **挑战2：改进语言模型的意图使用**
        即使是在给定明确意图的情况下，LLMs也往往难以有效地使用这些意图生成合适的回应。论文通过链式思考方法促使模型在生成回应前明确表达其意图，以期提升模型的表现。

#### 实现与部署
通过评估几种最新的开源LLMs在处理各种非字面语言时的表现，研究发现这些模型常常无法生成与上下文相关的适当回应。使用真实意图的准确性平均在50-55%之间，表明大型语言模型在理解和使用交流意图方面存在显著的障碍。链式思考的应用虽然提升了性能，但仍有限。这突出显示了在实践中如何更有效地捕捉和运用交流意图的需要。

#### 总结
本研究通过引入一个全新的生成性评估框架，探索了LLMs在理解和生成与意图对齐的回应方面的潜力和挑战，揭示了当前模型在语用理解方面的不足，并指出了未来提升方向。