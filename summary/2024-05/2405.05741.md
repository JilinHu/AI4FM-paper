#### 背景
- **背景**       
    文章介绍了大型语言模型（LLMs）如ChatGPT在自然语言理解（NLU）任务上的显著进展。尽管如此，现有的研究主要集中在表面级的NLU，忽略了细粒度探索。细粒度探索对于理解其独特的理解机制、与人类认知对齐，最终提高LLMs的通用NLU能力至关重要。

- **已有的工作**
    现有工作未能解决的问题是它们主要关注表面层次的语义理解，而忽略了言语交流中词义的深层次共享和理解，这限制了对模型理解能力的全面评估和提升。

#### 核心贡献
- **提出了一个Lexical Semantic Comprehension (LeSC)数据集与新的评估方法**
    - **挑战1：精细的语义理解**
        现有的LLMs在理解常见词汇的非常见含义方面表现不佳。研究通过构建LeSC数据集，提出了包括细粒度和跨语言维度的首个基准，检验模型在这一基础词义理解任务上的性能。

    - **挑战2：跨语言的语义转移能力**
        大多数现有模型在跨语言语义理解上存在缺陷。通过LeSC数据集的跨语言测试，文章进一步探究了模型的理解能力，并通过实验突显了当前LLMs在语言能力转移方面的不足。

#### 实现与部署
 LeSC数据集的实验结果显示，即便是最先进的LLMs如GPT-4和GPT-3.5在词义理解任务上也未能达到人类的水平，分别落后于16岁人类3.9%和22.3%。此外，尽管引入了多种先进的提示技术和检索增强生成来帮助解决这一问题，限制仍然存在。

#### 总结
本研究通过建立新的评估体系和数据集，揭示了大型语言模型在理解常见词汇的罕见含义方面存在的重大不足，为提高模型的NLU能力提供了新的研究方向。