#### 背景
- **背景**       
    文章介绍了在使用大模型进行域特定微调的情况，虽然提升了大语言模型（LLMs）在特定任务域中的表现，但巨大的内存消耗已经成为大规模训练的重大障碍。尽管提出了有效的微调方法，例如低秩适应（LoRA）来降低内存消耗，但它们的性能在大多数大规模微调设置中仍然不能匹敌全部参数训练。

- **已有的工作**
    LoRA 在域特定的微调中虽然是广泛采用的范例，但是在大规模数据集上持续的预训练中的表现让人怀疑其在这些环境下的有效性。LoRA 相比于基本模型有更少的可训练参数，限制了其表示能力和训练性能。

#### 核心贡献
- **提出了一个 LISA (Layerwise Importance Sampled AdamW)**
    - **挑战1：参数效率微调技术（PEFT）的内存效率与性能**
        挑战是要在保持内存效率的同时，提升大语言模型在微调任务中的性能。论文通过在各层中分析LoRA的训练统计数据，发现不同层的权重规范（weight norms）分布存在偏斜，意味着不同层在更新时的重要性不同。基于这一观察，论文提出了一个简单的训练策略 LISA，它采用重要性抽样的思想，选择性地只更新关键的大语言模型层次，而保留其他层次不变，解决了性能与内存效率之间的矛盾。

#### 实现与部署
在类似或更低的GPU内存消耗下，LISA在下游微调任务中优于LoRA甚至全部参数调整，在MT-Bench分数方面超过LoRA 11%-37%。在特定的大型模型如LLaMA-2-70B上，LISA在MT-Bench、GSM8K和PubMedQA上达到或超过LoRA的性能，证明了其在不同领域中的有效性。

#### 总结
这篇论文提出的LISA策略，通过分层权重重要性采样，实现了在保持类似于LoRA的内存效率的同时，提升了大型语言模型的微调效率和性能。