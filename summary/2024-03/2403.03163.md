#### 背景
- **背景**       
    文章讨论了前端开发中将视觉设计自动转换为代码的问题。这一任务要求理解视觉元素及其布局，并将它们翻译成结构化代码。尽管近年来自然语言生成代码的进步迅速，但从用户界面设计生成代码却由于视觉和文本信号的多样性以及结果代码的广泛搜索空间而受到限制 。虽然过去有尝试，但通常限于简单或合成示例。

- **已有的工作**
    尽管最近多模态LLMs的开发开启了一个全新的范式，能够处理视觉和文本输入并为各种视觉基础任务生成文本输出，但是目前的多模态LLMs尚未能够很好地处理这个任务，因为缺乏系统地评估和优化它们在此任务上的表现。

#### 核心贡献
- **提出了一项用于前端生成的Design2Code任务**
    - **挑战1：多样性和代码搜索空间**
        设计了一个包含484个多样化的真实世界网页测试案例的基准，开发了一套自动评估度量标准，以评估多模态LLMs如何将输入的屏幕截图直接生成渲染给定参考网页的代码实现。结合了自动度量和全面的人工评估来解决视觉和文本信号多样性和代码生成搜索空间广泛的挑战。

    - **挑战2：提升生成质量**
        进行了多模态提示方法的开发，并证明了这些方法在GPT-4V和Gemini Pro Vision上的有效性，进一步微调了开源的Design2Code-18B模型以达到与Gemini Pro Vision相媲美的性能。这些方法能够显著提升生成的网页在视觉外观和内容方面的质量，以及在一些度量上能达到比原始参考网页更好的表现。

#### 实现与部署
文章的评估展示了GPT-4V在该任务上相较于其他模型的卓越表现。人工评估和自动度量都显示，GPT-4V生成的网页可以在49%的案例中在视觉外观和内容方面替代原始参考网页；更令人惊讶的是，在64%的案例中，评估者认为GPT-4V生成的网页比原始参考网页更好。文章还提出了自动度量标准，包括高级视觉相似度和低级别元素匹配，这些指标能够针对生成质量的不同方面提供评价，是多模态LLMs生成能力的综合体现。

#### 总结
本文通过对Design2Code任务的形式化和基准测试，评估了当前多模态LLMs在将视觉设计转换为代码的能力，并发现GPT-4V表现最佳，为自动化前端开发提供了一种新的范式。