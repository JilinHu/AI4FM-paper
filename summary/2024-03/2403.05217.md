#### 背景
- **背景**       
    文章介绍了开放域问答（Open-domain question answering, ODQA）领域，目前的方法主要通过两种范式来搜集信息：一是从外部语料库检索相关文档的“检索-然后-阅读”范式，二是利用大型语言模型（Large Language Models, LLMs）生成相关文档的“生成-然后-阅读”范式。但这两个范式都无法完全解决证据的多方面要求。

- **已有的工作**
    现有范式无法满足证据的多元化和全面性要求，因此需要一个既能提供事实可靠性，又能拓展证据多样性的解决方案。

#### 核心贡献
- **提出了一个名为LLMQA的通用框架**
    - **挑战1：证据的多方面要求**
        现有方法无法全面满足开放域问答对证据的多样性需求，LLMQA通过结合检索和生成范式，将开放域问答过程分类为查询拓展、文档选择和答案生成三个基本步骤，综合两种范式的优势，提高了证据搜集的质量。

    - **挑战2：如何指导LLMs在框架中发挥多重角色**
        LLMs在不同任务中展现了出色的能力，论文让LLMs在框架中担任生成器、重排器和评估器多重角色，在开放域问答过程中进行合作，提高了整体性能。此外，通过引入一种新的提示优化算法，进一步提高了LLMs生成高质量证据和答案的能力。
    
#### 实现与部署
通过在NQ、WebQ和TriviaQA这些广泛使用的基准上进行实验，实验结果表明LLMQA在答案准确性和证据质量方面都达到了最佳性能，展示其推进ODQA研究和应用的潜力。与基线相比，LLMQA在EM分数上取得了显著的提高（TriviaQA上提高了4.0点，WebQ上提高了2.7点，NQ上提高了3.1点），展示了多角色LLMs在ODQA上的有效性。查询扩展生成器在生成拓展中的答案召回率达到了73%-87%，重排器角色提高了约8.1%的答案覆盖率。

#### 总结
LLMQA是一个新的通用框架模型，通过结合检索和生成范式搜集更高质量的证据，并让LLMs在框架中发挥多重角色，提高了开放域问答系统的整体性能，实验结果也证明了其超越现有方法的有效性。