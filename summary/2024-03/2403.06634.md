#### 背景
- **背景**       
    文章介绍了在对语言模型了解的范围内，一个敌手通过对语言模型API进行查询能够学习到多少信息。这是模型窃取领域中的一个问题，涉及到能够通过对API进行查询来提取模型权重的能力。

- **已有的工作为什么解决不了**
    之前的工作重点在从底层到顶层逐层重建模型，而没有一种直接从上至下提取模型最后一层的有效方式。

#### 核心贡献
- **提出了一个攻击方法**
    - **挑战1：如何恢复一个黑盒Transformer语言模型的完整嵌入投影层？**
        已有的攻击方法是自下而上的重构模型，从输入层开始。不同于前者，论文提出的攻击操作是自顶向下直接提取模型的最后一层。通过有针对性的查询，能够提取出嵌入维数或最终的权重矩阵。
    - **挑战2：如何使用窃取的层及其意义？**
        该层的窃取对多方面有意义：首先，它展示了Transformer模型的宽度，通常与其总参数数量相关；其次，它减少了模型作为一个完全黑盒的程度；第三，尽管攻击只恢复了整个模型的一小部分，但能窃取任何生产模型的参数本身就令人吃惊，并引发了对攻击的扩展可能恢复更多信息的担忧；最后，恢复模型的最后一层（即隐藏的尺寸）可能会揭示有关模型的更多全局信息，如不同模型之间的相对大小差异。
#### 实现与部署
评估结果显示，本文介绍的攻击方式可以以低于20美元的成本从OpenAI的ada和babbage语言模型中提取出完整的投影矩阵。这证实了这些黑盒模型分别具有1024和2048的隐藏维度。文章还恢复了gpt-3.5-turbo模型的确切隐藏维度大小，并估计需要不到2000美元的查询成本来恢复整个投影矩阵。为了负责任地披露，作者将他们的攻击与所有可能受此攻击影响的服务方分享，并与其中的一些服务（包括OpenAI）合作确认了攻击方法的有效性。之后，受影响的公司已经对其API进行了修改，引入了防御措施，使得执行此类攻击变得更加困难、成本更高。

#### 总结
本文提出了一项对生产语言模型进行模型窃取的新攻击方法，该方法能够有效地提取Transformer模型的最后一层，并能用于解密黑盒模型的细节信息、参数和尺寸。文章还讨论了可能的防御措施，并指出了修改API以防止未来此类攻击的必要性。