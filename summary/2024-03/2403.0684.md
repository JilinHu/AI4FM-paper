#### 背景
- **背景**       
    论文指出，大型语言模型（LLMs）在处理多种任务方面表现出色，但仍然严重依赖于其参数中存储的知识。此外，更新这些知识需要高昂的训练成本，而当前的检索增强生成（Retrieval-Augmented Generation, RAG）方法尽管能够通过整合外部知识来解决这一问题，但如果检索到不相关的文本可能会降低模型性能。

- **已有的工作**
    现有的RAG框架面临两个主要问题：检索到不相关的知识文本会损害LLMs解决任务的能力；模型现有知识与检索到的知识的融合可能会遇到困难。虽然已有的方法在考虑模型的解题能力和检索过来的段落是否与问题相关等方面进行了研究，但解决知识密集型问题和不同层级子问题方面仍存在不足。

#### 核心贡献
- **提出了一个创新的检索增强框架RA-ISF**
    - **挑战1：整合irrelevant text导致性能下降**
        为了应对由irrelevant text干扰导致的问题，RA-ISF采用了一个迭代问题分解的方法，这是在检索增强框架中首次被使用的，可以减少不相关文本干扰的影响。

    - **挑战2：缺乏有效的task decomposition策略**
        RA-ISF利用任务分解来缓解不相关提示文本对模型的影响，通过迭代回答子问题并将文本相关性与自知识解答能力整合到框架中，从而提高了解决整个问题的表现。

#### 实现与部署
RA-ISF首先使用自知识模块确定当前问题是否可以依靠自身知识解答。然后，当采用检索策略时，通过段落相关性模块评估每个检索段落与问题的相关性。相关段落会合并到提示中并用于预测。当所有段落与问题不相关时，问题分解模块会将问题分解为子问题并重复之前的步骤。最终，模型会综合子问题的答案来回答原始问题。实验表明，RA-ISF在处理复杂问题方面的表现优于现有方法，这表明了我们框架的潜力和鲁棒性。

#### 总结
RA-ISF是一个创新的检索增强框架，通过迭代问题分解和三个子模块的迭代处理来提高LLMs的问题解决能力，并有效降低不相关文本的干扰，显著提升知识检索的性能。