#### 背景
- **背景**       
    本论文研究的是在特定领域情境下，如何通过提取辅助文档来提高大型语言模型（LLM）的问题回答能力。当前的大型语言模型在面对开卷式（open-book）问题时，有时会受到无关文档的干扰，这影响了模型的回答质量和推理能力。

- **已有的工作**
    已有的工作通过标准的检索增强生成（RAG）设置来训练模型，让模型在回答问题时除了依赖其在预训练或者微调训练阶段获得的知识之外，还能引入额外的文档来提供帮助。然而，在这种设置下，模型可能会在不应该使用的文档中寻找答案，即遭受到“干扰文档”的负面影响。

#### 核心贡献
- **提出了一个名为‘RAFT’的训练配方**
    - **挑战1：如何让模型忽视干扰文档而专注于相关文档**
        RAFT 通过训练模型识别并引用相关文档中的正确序列来回答问题，这样可以提高模型的回答和推理能力。为了应对干扰文档的挑战，RAFT在某些训练样本中移除了可用于直接推断答案的“神谕文档”，强迫模型在没有明确解答文档的情况下自行记忆答案。

    - **挑战2：如何增强模型解答问题时的推理过程**
        为了提升训练质量，作者采用了生成链式推理（Chain-of-Thought）来解释给定的答案。通过创建完整的推理链，并清晰地引用源头文档，实验证明可以增强模型在问题回答中的准确性。

#### 实现与部署
RAFT的实验结果显示，它在处理特定领域文档时比专门进行领域微调的模型和具有RAG功能的通用模型表现得更好。尤其在特定的数据集上，如HotpotQA和HuggingFace数据集，RAFT的表现优势明显。此外，论文还研究了模型学习链式推理（CoT）反应的重要性，结果表明包含CoT的模型显著优于基线模型。RAFT实验还包括定性分析与对模型在top-K RAG环境中的鲁棒性的探讨。

#### 总结
本论文提出的RAFT方法针对训练大型语言模型在特定领域内以“开卷”模式回答问题进行了创新，强化了模型的推理能力和对干扰文档的抵抗力，同时通过链式推理方式改进了模型生成解答的准确性。