#### 背景
- **背景**       
    文章介绍了目前音乐领域缺乏可公开获取的自然语言处理相关数据集，从而限制了语言模型在音乐理解和生成方面的能力。

- **已有的工作**
    已有的研究无法解决此问题，主要是因为缺少专门针对音乐语料的预训练数据集，导致模型在音乐领域的应用受限。

#### 核心贡献
- **提出了一个名为MusicPile的预训练数据集**
    - **挑战1：缺少音乐相关的语料**
        研究者通过筛选现有大规模语料库，使用音乐相关的术语和话题，创建了MusicPile数据集来注入音乐能力到LLMs中。
        
    - **挑战2：理解和生成音乐方面性能有限**
        研究者建立了称为MusicTheoryBench的基准测试，用于评估LLMs的音乐理解和推理能力。同时展示了如何使用ABC音乐符号系统来有效压缩和编码音乐结构。

#### 实现与部署
评估结果显示，新提出的方法和数据集可以显著提升音乐理解能力和生成性能。理解能力方面的测试，所有系统都超过了随机基线，其中GPT-4在音乐知识指标上达到了最高分58.2。而在音乐推理上，尽管表现不佳，但ChatMusician-Base和ChatMusician在零样本环境下分别达到27.1和26.3，超过了GPT-4。在音乐生成方面，提出的ABC符号压缩方法实现了更高的压缩比，并通过人类评估证明了其生成音乐的音乐性更优。

#### 总结
本文通过创造首个针对语言模型的音乐预训练数据集和评估基准，提升了LLMs在音乐理解和生成方面的表现，并在这一未被深入研究的领域取得了实质性进展。