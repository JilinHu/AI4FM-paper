#### 背景
- **背景**       
    当前的大型语言模型（LLM）在读取长文本时存在局限性，不仅有最大上下文长度的限制，且在处理长输入时性能不稳定。与此相对，人类可以阅读和理解非常长的文本。人类阅读和处理长文本的方式与LLM不同，更注重理解上下文的大致意思，而不是精确词汇，并且在需要时会通过交互式的方式回顾原文。

- **已有的工作**
    尽管有尝试通过训练或微调LLM使其能处理更长的上下文窗口，或者通过探索新的架构来减少长上下文微调的需求，但LLM在处理有挑战性的长文本上依然存在局限。之前的工作显示LLM在输入过长时性能会下降，且对于上下文中的干扰信息非常敏感，因此有效上下文长度有时甚至低于 modelos界限。
  
#### 核心贡献
- **提出了一个Human-Inspired Reading Agent:** ReadAgent
    - **挑战1：半仿人类阅读方式处理长文本**
        当模型需要回忆相关细节以完成任务时，通过模仿人类阅读长文本的方式，ReadAgent 创建了“gist memories”来压缩每一页的摘要，并与相应的上下文联系起来。这使得模型能够在决定查阅哪些页面时使用全局上下文。

    - **挑战2：有效地扩展处理长文本的能力**
        通过与其他基线方法进行比较，ReadAgent 在三种长文档阅读理解任务上显示出优势，有效上下文长度增加了3到20倍。这些任务包括 QuALITY, NarrativeQA 和 QMSum。它能在合理的计算开销下实现性能提升。

#### 实现与部署
在与使用全文或仅使用gist内存而不进行交互查找以及页面检索的方法进行比较中，ReadAgent 能够在所有任务上超过基线方法，并在相对原始LLM的情况下显著地增加了有效上下文长度，同时计算开销合理。例如，在 NarrativeQA 的 Gutenberg 测试集上，ReadAgent 在保持有效上下文长度增加∼20倍的同时，将 LLM评级提高了12.97％，ROUGE-L提高了31.98％，超过了最佳检索基线。

#### 总结
ReadAgent 是一个受人类阅读方式启发的LLM代理系统，通过创建摘要记忆并根据需要检索信息来解决长文本任务，显著提高了模型的表现和伸缩性。