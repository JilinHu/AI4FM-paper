#### 背景
- **背景**       
    论文指出大型语言模型（LLMs）的训练代价高昂，针对这个问题，研究者们探讨了一些数据高效的预训练方法。这些方法旨在优化模型质量与训练资源/数据消费之间的帕累托前沿。

- **已有的工作**
    传统的LLMs训练方法并不专注于数据选择的最优化，这导致在数据和模型尺寸的线性增长下收益递减，并且面对数据和模型规模扩展的边界，现有的策略可能因为计算代价过大而难以持续。

#### 核心贡献
- **提出了ASK-LLM和DENSITY采样技术**
    - **挑战1：数据选择和质量评估的代价问题**
        论文提出了ASK-LLM技术，它利用指令调优的LLMs的零样本推理能力直接评估训练样本的质量。这种方法解决了传统数据质量评估成本高的问题，因为它依赖LLM的推理能力而非其他昂贵的评估技术。

    - **挑战2：数据覆盖率和多样性优化问题**
        为了目标覆盖率，论文提出了DENSITY采样技术，这种方法通过建模数据分布来选择样本，确保样本的多样性。它解决了确保训练数据覆盖范围广泛和多样的问题。

#### 实现与部署
在比较19种不同的采样器，涉及数百个评估任务和预训练运行的过程中发现，ASK-LLM和DENSITY分别在它们的类别中表现最佳。覆盖率采样可以恢复全数据的性能，而使用ASK-LLM数据训练的模型一致性能优于全数据训练，即使在拒绝了原始数据集90％的情况下，也能够比全数据训练快70％收敛。

#### 总结
论文提出的ASK-LLM和DENSITY技术优化了大型语言模型的数据效率，有效提升了模型训练的速度和质量，并在资源限制下表现出色。