#### 背景
- **背景**       
    文章指出，在进行推理任务时，前提的顺序对大型语言模型（LLMs）的性能有重大影响，即使这个顺序并未改变任务本身。研究者通过全面的评估发现，LLMs在处理这些问题时，倾向性与人类对前提顺序的偏好相似；也就是说，当前提的顺序遵循解决问题所需的中间步骤时，模型性能最佳。相反地，当问题的解答需要模型来回阅读问题描述时，LLMs的性能会下降超过30%。此外，研究者还对数学推理问题进行了扩展研究，并提出了R-GSM基准测试，实验性地确认了顺序的影响。

- **已有的工作**
    现有的研究尚未全面地研究LLMs在面对前提顺序调整时的性能变化，以及这种顺序变化如何显著影响模型的推理能力。

#### 核心贡献
- **提出了一个全面评估**
    - **挑战1：前提顺序对LLMs性能的影响**
        挑战在于前提顺序即便没有改变实质性任务，却仍然对LLMs的推理性能产生显著影响。研究者通过设计评估方法展示了LLMs与人类类似，倾向于"前向"（顺着问题解决步骤）的前提顺序，当需要模型来回阅读问题描述时表现出下降。

    - **挑战2：适应不同类型的推理任务**
        第二个挑战是如何在不同类型的推理任务（如逻辑推理和数学推理）中考察前提顺序的影响。通过创建新的R-GSM基准测试和对模型的详尽评估，研究者证实了不同推理任务中前提顺序调整的影响。
  
#### 实现与部署
研究者提出的R-GSM基准测试包含了220个问题，并对LLMs性能进行了详尽的评估。例如，在有5个或10个分散注意力的规则下，研究者展示了不同前提顺序配置的精确度对比，包括"前向"、"后向"以及"随机"（shuffled）。这些结果从根本上展示了LLMs如何在不同的前提顺序下性能有明显不同，尤其是当顺序与解题步骤的自然顺序不一致时，模型的正确率会有所下降。

#### 总结
这篇论文关注于大型语言模型在处理推理任务时，前提顺序的影响，并通过创建R-GSM基准测试来评估这一现象。研究揭示了LLMs对前提顺序极为敏感，性能受顺序影响显著。