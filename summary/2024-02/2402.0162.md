#### 背景
- **背景**       
    大型语言模型（LLM）之间的多代理交互已经在各种推理任务中显示出了显著的改进。然而，这些交互涉及到在多轮交互过程中多个模型之间的长文本生成，因此过程十分昂贵。此外，这些多代理方法无法提供一个有效推断的最终单一模型。

- **已有的工作**
    现有的多代理交互框架通常构建在如GPT-4、Bard、Claude等专有模型之上，它们可以作为通用的对话代理，处理长文本并遵循指令。然而，当在多轮交互中使用时，这些模型也计算和金钱上都特别昂贵，需要多次长令牌长度的推断调用底层的LLM。此外，这些框架最终并未产生一个可以直接用于推断的联合模型，而是在测试时需要调用所有参与交互的LLM。

#### 核心贡献
- **提出了一个名为MAGDI的方法**
    - **挑战1：结构化的特点（结构差异）**
        为了克服高成本和缺乏高效单一模型的挑战，作者介绍了MAGDI，这是一种新的方法，用于将多个LLM之间的推理交互结构化地蒸馏到较小的语言模型（LM）中。MAGDI通过将多代理交互表示为图形，通过一个图形编码器增强基础学生模型，并使用三个目标函数进行知识蒸馏：下一个令牌预测、正确和错误推理之间的对比损失，以及用于模拟交互结构的基于图的目标。

    - **挑战2：提升效率和泛化能力**
        MAGDI在广泛使用的七个常识和数学推理基准上进行实验，结果表明MAGDI提高了小模型的推理能力，超过了多个从单一教师和多个教师蒸馏的方法。此外，MAGDI还展示了比其老师高一个数量级的效率。通过广泛的分析，作者展示了MAGDI如何增强对领域外任务的泛化能力，随着基础学生模型的大小和实力的增加而正面规模化，并且在应用自洽性（一种依赖模型多样性的推理技术）时通过多教师训练获得了更大的改善。

#### 实现与部署
研究人员提出了一种通过多轮讨论产生多代理交互图（MAG）的方法，MAGDI将这些图中的推理知识蒸馏到基础学生模型中。实验结果表明，使用MAGDI的方法，基于图的学生模型在数学推理问题上比基本模型提高了10.71%。MAGDI不仅提高了模型的推理能力，而且相比于原始大模型，提高了一个数量级的效率，这显著降低了计算和金钱上的花费，并且提升了模型对新任务的泛化能力。

#### 总结
本论文介绍了名为MAGDI的新方法，它通过结构化蒸馏方式将多LLM之间的推理交互蒸馏到更小的模型中，显著提升小模型的推理能力和泛化能力，同时降低了成本。