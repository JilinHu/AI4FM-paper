#### 背景
- **背景**
    文章指出，尽管大型语言模型（LLMs）在代码生成上取得了显著进步，但它们在特定场景下的代码生成任务仍然面临挑战。这些特定场景通常需要调整LLMs以满足具体需求，但实际中可用的训练数据有限，导致代码生成性能不佳。如何高效地使用少量训练样本来适应新场景是当前代码生成领域的一个主要挑战。

- **已有的工作**
    目前的方法大多使用大量特定场景下收集的样本来进行训练，使模型能够全面学习这些样本中的特征，从而适应特定场景。然而，这种方法存在两个缺点：一是迫使LLMs重新学习这些新场景的整个代码数据效率不高；二是在数据量不足或数据漂移的情况下，模型可能会学习到一些不希望的特征（如不准确或不相关的编程知识和模式），进而影响学习效率并对最终性能产生负面影响。

#### 核心贡献
- **提出了一个名为SEED的方法**
    - **挑战1：有效适应特定场景的样本不足问题**
        SEED方法解决了传统微调方法在数据有限条件下性能下降的问题。通过错误驱动学习，SEED使用由模型生成的错误代码作为学习机会，并采用错误修正来克服模型自身的缺点。SEED通过错误代码收集、自动代码修订、模型优化和迭代适应等步骤使LLMs高效学习。

    - **挑战2：保持模型优化的持续性和泛化性**
        实验结果表明，SEED在使用更少的训练样本时比传统微调方法有更好的性能，显示了27.2%-325.0%的相对改进。SEED不仅在不同的LLMs上都显示出强大的性能，而且通过连续优化，SEED实现了持续改进和泛化。

#### 实现与部署
在MBPP数据集上的实验结果显示，与传统的直接微调方法相比，SEED在使用更少的训练样本时取得了优越的性能，具有27.2%-325.0%的相对改进率。此外，SEED在两个公共基准测试上超越了传统微调方法，并且在各种LLMs上均取得了更好的性能，从而验证了SEED的泛化性能。

#### 总结
本文提出了一个名为SEED的适应方法，它利用错误驱动学习来使LLMs更少样本地高效学习，针对代码生成任务实现了更佳的性能和泛化性。