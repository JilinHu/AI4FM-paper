#### 背景
- **背景**       
    文章介绍了近年来多模态大型语言模型（MultiModal Large Language Models，MM-LLMs）取得了显著发展，将现成的LLMs扩展以支持多模态输入或输出，并通过成本有效的训练策略实现。这些模型不仅保留了LLMs的推理和决策能力，还赋能于多种多模态任务。

- **已有的工作**
    已有的工作包括利用GPT-4(Vision)等模型在多模态理解和生成能力上取得了令人印象深刻的效果，促使了MM-LLMs研究的热潮。最初的研究主要集中在多模态内容理解和文本生成等领域。此外，也有研究在探索如何将LLMs与外部工具结合起来。

#### 核心贡献
- **提出了一个xxx**
    - **挑战1：xxx**
        挑战1是如何有效地将LLM与其他模态的模型连接起来，实现协同推理。为了解决这一挑战，论文首先概述了模型架构和训练流程的通用设计表述，然后介绍了26个现有的MM-LLM的特定表述。

    - **挑战2：xxx**
        挑战2是如何通过两个阶段的训练，即多模态预训练（MM PT）和多模态指令微调（MM IT），增强一个预训练的仅文本LLM以支持多模态输入或输出。这一挑战所采取的方法是设计一个包含五个组件的模型架构（Modality Encoder, Input Projector, LLM Backbone, Output Projector, 和 Modality Generator），并总结了MM PT和MM IT的主流数据集。

#### 实现与部署
论文深入讨论了26个最新的MM-LLMs，每个模型都有其具体的表述，并概述了它们的发展趋势。此外，论文全面回顾了主流基准测试上MM-LLMs的性能，并提炼了增强MM-LLMs效能的关键训练配方。

#### 总结
本文是一项关于MM-LLMs的综合性调研，旨在进一步推动MM-LLMs领域的研究工作。