#### 背景
- **背景**       
    论文介绍了大模型（Large Language Models，LLMs）在数学推理上的能力可以通过提示它们表达解决问题的中间步骤来增强，这一见解引发了多项提升推理路径的进展。

- **已有的工作**
    论文提到现有工作通过不同方式为LLMs生成可执行的代码、使用多个推理路径并结合投票机制、让LLMs在推理前制定计划、或者采用多样化的推理提示来解决问题。尽管这些方法在某种程度上改善了模型的推理能力，但在转换数学问题到可解的方程组的能力方面仍有提升空间，同时需要减少计算错误和提升处理未定义变量的能力。

#### 核心贡献
- **提出了一个名为Equation-of-Thought Distillation (EoTD)的新框架**
    - **挑战1：数学推理转换为方程**
        EoTD将数学推理转换为方程，用于微调小模型（Small Language Models，SLMs）。不同于Chain-of-Thought Distillation和Program-of-Thought Distillation，EoTD通过生成可解的方程系统并使用确定性求解器来减少计算错误，并有效提升数学推理性能。

    - **挑战2：相关数据集与实验设计**
        研究者使用ChatGPT作为教师模型来构建训练数据集，并利用不同规模的CodeT5模型作为学生SLMs。他们手工创建了指导性示例，以生成每个数据集的4种推理路径，并使用这些数据集进行模型微调。

#### 实现与部署
论文中提出的EoTD方法通过在四个数学推理数据集上的实验表现出一定的有效性，让SLMs实现了显著的绝对提升，范围在25.51%到43.52%不等。而Mix Thoughts Distillation（MTD）框架，通过结合多样化的推理路径，使得SLMs达到了当前最先进的推理性能，提升了48.14%到57.58%。結果还显示SLMs模型的规模对于推理能力至关重要，更大的模型能够融合更多的推理知识，从而带来更优的推理性能。

#### 总结
这篇论文通过介绍EoTD和MTD，表明了可以将LLMs的数学推理能力转化给参数数量少于一十亿个的SLMs。通过实验验证了这些方法不仅保留了SLMs的推理能力，还在一定程度上提升了该能力，使SLMs在推理任务上达到了最好水平。这一进展对于在资源受限的环境中推广SLMs的应用打开了大门，并缩小了对强大推理模型需求与计算资源限制之间的差距。