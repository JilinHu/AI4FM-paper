#### 背景
- **背景**
    本论文介绍了Vlogger，一种能够根据用户描述生成分钟级视频博客（即vlog）的通用人工智能系统。与仅数秒短视频不同，vlog通常包含复杂的故事情节和多样化场景，这对大多数现有的视频生成方法来说是个挑战。
    
- **已有的工作**
    现有的视频扩散方法主要基于图像扩散模型生成几秒钟的短视频，而vlog通常为分钟级的长视频。已有的长视频生成尝试要么需要在大型、带有详细标注的视频数据集上进行大量训练，要么面临镜头变换不一致性的问题。

#### 核心贡献
- **提出了一个全新的系统 Vlogger**
    - **挑战1：生成长视频的脚本和镜头**
        Vlogger通过聘请大型语言模型（LLM）作为导演（例如GPT-4），该导演利用其丰富的语言知识理解，规划vlog生成的四个步骤，将用户故事转换为脚本，并为每个镜头设计演员图像。
        
    - **挑战2：视频片段的空间-时间连贯性**
        Vlogger引入了一个名为ShowMaker的新型视频扩散模型，作为摄影师，根据脚本文本和演员图片生成每个镜头的视频片段，并增强了片段的空间-时间连贯性。

#### 实现与部署
Vlogger通过顶层规划和自底向上的拍摄的合作，有效转换开放世界中的故事变为分钟级vlog。ShowMaker结合了生成和预测模式，在推理阶段连续组合，能够生产具有可控持续时间的视频片段。最终，实验结果表明Vlogger在零样本T2V生成和预测任务上实现了最先进的性能，且能生成超过5分钟的vlogs，没有显著的故事情节和演员连贯性丧失。

#### 总结
本论文通过介绍Vlogger系统，展示了一个创新的办法将LLMs应用于视频博客的生成过程中，从而克服了生成分钟级连贯视频内容的挑战，并取得了优异的实验结果。