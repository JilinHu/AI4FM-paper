#### 背景
- **背景**       
    文章介绍了Text-to-SQL模型可以生成候选的SQL查询列表，往往最佳查询在候选列表中但不在首位。有效的重新排序(re-rank)方法可以从候选列表中选择正确的SQL查询，从而提高模型性能。

- **已有的工作** 
    在代码生成研究中，常通过自动生成测试用例并使用它们来重新排序候选代码。然而，针对text-to-SQL的自动生成测试用例是一个不太被关注的领域。已有研究对生成测试用例的方法进行了探索，但要么需要人工标注预期执行结果，要么依赖于模型生成的测试用例，二者都限制了text-to-SQL的测试用例自动生成。

#### 核心贡献
- **提出了自动生成text-to-SQL测试用例的方法**
    - **挑战1：自动生成测试用例**
        目前缺乏一种在不知道正确SQL查询的情况下，自动获取预期执行结果的方法。本文提出使用大型语言模型(LLMs)预测预期执行结果，生成新数据库，并通过实验探索生成易于LLMs预测的数据库和设计易于理解的提示。

    - **挑战2：重新排序方法**
        在text-to-SQL中，最佳查询通常不在候选列表的顶部，需要一个有效的方法从候选列表中选择正确的查询。本文提出了一个三步重新排序方法，首先根据执行结果对候选列表进行分类，然后生成包含多个测试用例的测试套件，最后根据测试用例的通过数量和生成概率对候选列表重新排序，并选出最佳SQL查询。

#### 实现与部署
在Spider数据集的验证集上，实验结果表明，在应用重新排序方法后，部分最先进的模型性能提高了3.6%。文章使用GPT-4-turbo和GPT-4生成测试用例，并跟踪了两个最先进的模型DAIL-SQL和RESDSQL来生成候选列表。

#### 总结
本文提出了一种借助大型语言模型自动生成text-to-SQL测试用例的方法，并设计了三步重新排序过程，实验显示该方法能显著提高现有text-to-SQL模型的性能。