#### 背景
- **背景**       
    文章介绍了如何通过一个称为“Concise Chain-of-Thought (CCoT)”提示的方法来优化大型语言模型（如GPT-3.5和GPT-4）的问题解决效率。当前问题解决主要依赖于详细的推理过程引导（verbose Chain-of-Thought, CoT），但文章认为可以通过减少文字冗余来保持高效解答而不损失准确率。

- **已有的工作**
    已有研究很少直接探讨简洁提示（concise prompting），大多数是基于现实运用中的最佳实践。此外，也缺乏专门研究简洁CoT提示（CCoT）的文献。如此一来，未能充分了解简洁提示对大型语言模型问题解决性能的潜在影响。

#### 核心贡献
- **提出了一个新方法**
    - **挑战1：如何减少大型语言模型产出的冗余文字**
        CCoT提示方法通过添加指示模型“简洁地”解答的指示，帮助模型缩减输出长度，同时通过对比研究确保问题解决性能不受影响。

    - **挑战2：验证CCoT提示相对于标准CoT提示的有效性**
        通过在多个标准化问题和回答基准测试集上将CCoT与标准CoT进行对比验证，使用Mann-Whitney U测试验证了两者之间的显著性差异，并发现CCoT不仅减少了输出的长度，且几乎不影响正确答案的准确率。

#### 实现与部署
研究人员使用GPT-3.5和GPT-4来测试CCoT和标准CoT的效果，并涵盖了多个问题域和难度级别的基准测试。实验显示，CCoT提示相比于CoT，在平均响应长度上有显著减少（分别为47.62%和49.77%），且这种减少是统计学上显著的，具有实际意义。这些发现表明在不牺牲解答正确率的情况下，CCoT能有效地降低模型输出的长度。

#### 总结
此研究表明，通过使用简洁的思维链提示（CCoT），在大型语言模型中可以大幅减少文本输出的长度，而不会影响解决问题的性能。