#### 背景
- **背景**       
    论文指出当前大型语言模型（LLMs）在生成独立函数方面表现出色，但由于缺乏对仓库级依赖（例如用户定义的属性）的意识，在仓库级代码生成方面面临限制，导致了未定义变量和无成员错误等依赖性错误。

- **已有的工作**
    现有的工作没有成功解决代码LLMs在仓库级代码生成中因缺少依赖性意识而产生的问题。

#### 核心贡献
- **提出了一个名为TOOLGEN的新方法**
    - **挑战1：依赖性问题**
      TOOLGEN通过将自动完成工具集成到代码LLMs生成过程中以解决依赖性问题。通过数据增强和模型微调（离线阶段），结合使用特殊标记代表调用自动完成工具的位置，以及基于此增强函数对代码LLMs进行微调。在线阶段中，TOOLGEN迭代生成函数，并在遇到特殊标记时调用自动完成工具，从而解决了依赖性问题并有效提高代码生成质量。

#### 实现与部署
论文详细描述了TOOLGEN的实现包括数据增强、模型微调和工具集成代码生成。为评估TOOLGEN的效果，作者创建了一个基准，包括12744个Python函数和680个真实世界代码仓库，以及引入了两个新的仓库级指标：依赖性覆盖率和成功率。实验结果表明，TOOLGEN在三个不同的代码LLMs上显著提高了依赖性覆盖率（15.2%至45.8%）和成功率（10.9%至42.2%），同时在诸如BLEU-4、CodeBLEU和编辑相似性等广泛认可的相似性指标上保持了竞争性能。

#### 总结
该论文成功提出了一种新方法TOOLGEN，通过集成自动完成工具到仓库级代码生成中的LLMs，解决了依赖性问题，提高了代码生成的质量和成功率。