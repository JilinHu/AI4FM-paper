#### 背景
- **背景**       
    论文指出，临床医生在患者出院时必须编写一份长篇总结。由于入院时所涉及的临床概念众多，这项任务消耗时间且繁琐。正确识别和覆盖关键实体对于书写临床有用的总结至关重要。文章分析了医疗保健行业的现状，揭示了由电子健康记录(EHR)所带来的信息过载及文档负担问题，这是导致临床医生身心俱疲的重要因素。

- **已有的工作**
    大型语言模型(LLMs)在减轻文档负担方面具有潜力，可作为减轻临床医生工作量的辅助工具。然而，LLMs目前在医疗健康领域主要应用于定义明确的专项任务，如闭卷问答和单文档放射学报告总结。对于跨越整个住院过程的长期文档任务，现有的LLMs并没有得到充分的应用。

#### 核心贡献
- **提出了一个SPEER系统**
    - **挑战1：完成长篇临床总结中关键实体的覆盖**
        在现有的工作中，经过微调的开源大型语言模型（如Mistral和Zephyr）生成的总结通常不完整且缺乏可靠性。论文提出通过训练一个小型的仅编码器模型预测关键实体，并将这些实体视为内容计划，指导LLM更好地覆盖和提取关键信息。

    - **挑战2：将内容计划与源文档相结合**
        为了使内容计划更贴近原始笔记，提出了SPEER方法：通过嵌入式实体检索进行句子级规划。具体方法是在每个关键实体周围标记特殊的界限标签，并指导LLM在生成每个句子之前检索这些标记的跨度。这种句子级规划充当了一种状态跟踪的形式，使得模型能够清晰记录其使用的实体。

#### 实现与部署
SPEER通过在已有的LLM上进行微调，并使用大规模、多样化的约167,000条住院记录进行训练，并在不同电子健康记录(EHRs)的三个数据集上进行评估。结果显示SPEER在覆盖度和可信度方面均超越了无引导和有引导的基线模型。此外，论文还证明了即便是在存在大型语言模型的情况下，内容选择也应作为独立的分类任务进行，并证明了由小型编码器分类器执行的显式内容选择比LLMs的自回归解码执行的隐式内容选择表现更佳。SPEER的方法易于实施，且能明显提升覆盖范围和摘要质量。

#### 总结
本论文针对医院出院总结的长篇文档任务，提出了一个基于嵌入式实体检索的句子级规划方法SPEER，通过引导大型语言模型LLMs更好地覆盖关键实体，生成更完整和可信的临床总结。研究证明了SPEER方法在实际应用中可以提高文档的覆盖度和准确性，减轻临床医生的文档负担。