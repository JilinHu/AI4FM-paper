#### 背景
- **背景**       
    论文讨论了基于大型语言模型（LLMs）构建的AI助手在多任务执行中尽管具有丰富的世界知识却依然难以准确应对一些知识密集型任务，从而产生事实错误。

- **已有的工作**
    论文指出当前AI助手在生成回答时，存在“幻觉”问题，包括在回答中添加事实错误。这些会减少AI助手的可信度，并可能对社会造成伤害。现有的方法没有有效解决AI助手识别并承认其不知道的问题这一挑战。

#### 核心贡献
- **提出了一个模型特定的"I don't know" (Idk)数据集**
    - **挑战1：制作Idk数据集**
        通过现有的开放领域问答数据集来构建，标明助手所知及未知的问题。挑战在于如何让AI助手识别并承认它的知识范围，论文通过计算助手对某一问题多次回答的平均准确度来决定其是否知道该问题的答案。

    - **挑战2：联合Idk数据集**
        使AI助手对应Idk数据集进行调整，观察其是否能拒绝回答它不知道的问题。挑战在于确保AI助手的输出在未知问题上可以选择性地保持沉默，论文使用指导、监督精调和偏好感知优化等方法。

#### 实现与部署
实验结果显示，通过与Idk数据集的联合调整后，助手可以拒绝回答大多数它不知道的问题。而对于它尝试回答的问题，准确性显著提高。论文使用了prompting， 监督式微调（SFT），以及偏好感知优化等方法，以指导AI助手去识别和拒绝那些它不知道的问题。具体结果展示了AI助手在进行Idk数据集的调整前后在知识象限分类的变化，表明了该方法在提高回答知识性问题准确性上的有效性。

#### 总结
这篇论文重点探究了AI助手识别自己知识边界的能力，并通过构建Idk数据集并对助手调整，实现了让AI助手识别并承认不知道的问题，以减少回答中的事实错误。