#### 背景
- **背景**       
    论文研究了一个新的用户定位方式，非专业营销人员可以仅根据自然语言形式的需求选择目标用户。该问题的关键在于如何将自然语言转换成实用的结构化逻辑语言，即对营销人员需求的结构化理解。
    
- **已有的工作**    
    既有研究表明，通过链式推理（CoT）提示，可以有效地增强大型语言模型（LLMs）的推理能力。然而，现有方法存在局限性：一些方法使用简单的“Let's think step by step”方法，或是在示范中提供固定示例，而没有考虑提示与问题之间的兼容性，这使得 LLMs 在某些复杂的推理任务（如结构化语言转换）中表现不佳。此外，先前的方法通常在封闭源模型或过大的模型中实现，并不适合工业实践场景。

#### 核心贡献
- **提出了一个模型叫做ARALLM (Analogical Reasoning Augmented Large Language Models)**
    - **挑战1：自然语言转换成结构化逻辑语言**
        首先引入了一个适用于营销场景的结构化语言SELL，并构建了包含将自然语言转换为SELL（NL2SELL）的几个高质量推理示例的推理库。接着采用基于检索的方法进行类比推理以辅助这个推理库。实验结果表明，类比推理提示的方法比普通提示方法在NL2SELL任务中表现更好。

    - **挑战2：实现模型在工业实践场景中的部署**
        进一步通过类比推理，从超大型LLMs(如ChatGPT)中提炼知识，并构建一个用于微调较小学生LLMs的NL2SELL数据集，通过多任务训练范式进行微调，使模型能够轻松部署在实际用户定位环境中。

#### 实现与部署
在实验中，研究人员首先在ChatGPT上测试了基于类比推理的提示方法，并提出了四个不同的提示作为基准以进行比较。实验结果显示ARALLM的性能显著优于其他提示方法，特别是在结构准确性方面提高了超过7%。此外，即使是随机选择的例子，也比固定的例子更有效，这表明为所有输入提供固定推理例子往往是次优的，并证实了建立推理库以提供多样化推理样本的必要性。在知识提炼阶段，研究人员选择了ChatGLM2-6B-32K和Baichuan2-13B-Chat作为学生LLMs，对它们使用LoRA进行微调，并进行了多任务训练。研究人员还采用了其他三种训练策略作为基准，包括不使用多任务策略，不提供推理步骤，以及在模型输入中简单结合指令和需求的普通训练方式。

#### 总结
本文提出了一种名为ARALLM的新方法，该方法结合了类比推理和多任务模型提炼，有效促进了大型语言模型从自然语言中理解并转换为结构化的逻辑语言的能力。通过这种方法，非专业营销人员能够利用自然语言来选择目标用户，有望改变用户定位实践。这种能力的提升，不仅在营销场景中有实际的应用价值，同时也为大型语言模型的功能性和实用性做出了有益的探索。