#### 背景
- **背景**       
    文章介绍了分布式（联合）大型语言模型（LLM）在使用孤立数据共同训练特定领域 LLM 的重要方法。然而，恶意从服务端或客户端窃取模型参数和数据已成为急需解决的问题。

- **已有的工作**
    之前的工作主要关注了服务端的威胁，但并未同时考虑客户端的参数和数据泄露问题。虽然联合学习已经面对多种安全威胁，包括加法同态加密（AHE）以及差分隐私（DP），这些方法或只能保护数据而不能防止参数泄漏，或者会显著降低性能。

#### 核心贡献
- **提出了一个基于模型切片的安全分布式 LLM**
    - **挑战1：避免模型参数和数据的泄露**
        为解决这个问题，论文提出运用可信执行环境（TEE）和轻量级加密相结合来确保安全。特别是在分布式训练中，只对部分参数进行微调，提出了不同类型TEE（即有小内存但无GPU的SGX 和有大内存但无GPU的Intel TDX/SGX）的不同方案。

    - **挑战2：降低设备成本及提高模型性能和精度**
        论文提出了一种分裂微调方案，将LLM按层分裂并将后续层放在服务端TEE中（客户端不需要TEE）。同时将提出的稀疏化参数微调（SPF）与LoRA部分相结合，以提高下游任务的准确性。

#### 实现与部署
实验结果表明，该方法在保证安全性的同时，确保了高效率和准确性。通过在客户端和服务器端都部署TEE，并在其上进行LoRA和P-Tuning v2的微调结构，文中的框架使得在TEE和一般环境中进行的通信都经过轻量级加密，提高了安全性。在加密和解密特征时，使用了一次性密码（OTP）来保护在GPU和TEE之间传输的特征，从而保护用户信息。

#### 总结
本论文提出了一个基于模型切片的安全分布式训练框架，能在保证模型训练精度和高效率的同时，解决了服务端和客户端的模型参数及数据泄露问题。