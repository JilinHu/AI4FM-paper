#### 背景
- **背景**       
    论文指出，大型语言模型（LLMs）在多个领域取得了巨大突破，尤其在推理能力方面吸引了研究者的关注，这一能力被认为是人工普遍智能(AGI)的关键能力。

- **已有的工作**
    已有的工作通过各种评估基准（如算数、符号推理、常识等）表明LLMs在无需训练的情况下，可以利用in-context少次学习（zero-shot）提示技术达到先进水平。然而，有研究辩论称这些基准在任务解决逻辑上相对简单，仅需浅层推理即可完成，并不足以支撑LLMs推理能力的断言。

#### 核心贡献
- **提出了一种对LLMs进行关系推理能力综合评估的方法**
    - **挑战1：关系推理能力的缺陷和局限性**
        当前最先进的LLMs在关系推理能力方面远未达到完美，与采用了程序归纳的神经网络模型相比存在明显的劣势。论文通过建立一套评估模块对LLMs的关系推理能力进行全面的评估，揭示了这一点。

    - **挑战2：提出工具和评估模块**
        论文实现了一个样本生成器，它可以产生表示输入输出关系的真值矩阵；提出了一个(tv nl)-模态编译器，用以将从真值提示转换为自然语言提示的样本；并实现了一个评估模块，用来评估来自真值源和自然语言源的结果，验证模型在独立同分布(IID)情景和非同分布(OOD)情景中的表现。

#### 实现与部署
论文对LLMs使用标准自然语言提示的关系推理能力进行了评估，并与DLM模型使用了少次训练的结果进行了对比。尽管LLMs在一些较简单的任务上显示出优异的性能和普遍性，但在要求更为复杂的任务解决逻辑的任务上（例如，基准程序中包含较多谓词的任务）其表现明显下降。例如，尽管GPT-4模型在HasFather任务上取得了100%的F1分数，但在IsUncle等更为复杂的任务上，它的性能显著下降。所有评估中，GPT-4 Turbo和GPT-4在表现和OOD概括性方面表现最佳，这可以归因于这两种模型规模更大，训练数据比其他LLMs的基线更丰富。然而，与DLM相比，LLMs仍然显示出相对较差的性能。

#### 总结
本论文主要探讨了大型语言模型在关系推理方面的能力和局限性。通过全面的评估，包括新提出的测试方法和评估模块，发现LLMs虽然在某些关系推理任务上表现不错，但与专门为逻辑推理设计的模型相比，其性能相对较差。