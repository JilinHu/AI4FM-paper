#### 背景
- **背景**       
    论文指出中等规模（7B或13B参数）的大型语言模型（LLMs）在机器翻译（MT）任务中展现了令人瞩目的性能，如13B参数模型ALMA。然而，尽管它们表现出众，这些LLMs的表现仍然无法匹敌最先进的传统编解码器翻译模型或更大规模的LLMs，例如GPT-4。

- **已有的工作**
    论文提出，尽管现有的研究努力通过监督微调（Supervised Fine-tuning, SFT）提高这些LLMs的表现，但成果相对有限。原因之一是LLMs的预训练数据集以英语为中心，导致语言多样性受限。此外，ALMA模型通过在不同语言的单语数据上进行初步微调以增强多语言理解，并通过高质量的平行数据进行SFT来引导模型生成翻译，尽管这种方法使得ALMA模型超过了之前的中等规模LLMs，甚至超过了GPT-3.5，但性能仍然落后于GPT-4和WMT竞赛获胜者。

#### 核心贡献
- **提出了一个叫做Contrastive Preference Optimization (CPO)的新方法**
    - **挑战1：避免生成只是适当但非完美的翻译**
        CPO的目标是解决SFT固有的两个主要缺点：SFT将模型性能限制在训练数据的质量水平，这是一个显著的限制，因为即使是人工编写的高质量数据也存在质量问题。CPO通过避免生成只是充分但非最佳的翻译来解决这个问题。

    - **挑战2：推动SFT性能的瓶颈**
        CPO打破了SFT模仿参考翻译学习过程中固有的瓶颈，推动已经通过SFT训练达到饱和的模型的性能边界。

#### 实现与部署
研究者们将CPO方法应用于ALMA模型，并且仅使用22K平行句子和12M参数（等同于原始模型大小的0.1%）就取得了显著改善，使得调整后的模型（称为ALMA-R）能够匹敌甚至超过WMT'21、WMT'22和WMT'23测试数据集上WMT赛事获胜者和GPT-4的性能。特别地，ALMA-13B-R通过采用CPO方法进一步训练ALMA-13B-LoRA开发，不仅在性能上匹敌或超过最先进的翻译模型，还有效缩小了中等规模LLM翻译器与最先进翻译系统之间的性能差距。

#### 总结
本论文提出了CPO，一个新的LLM微调方法，有效解决了SFT在机器翻译任务中存在的瓶颈，实现了在资源消耗极少的情况下显著提升中等规模LLM翻译模型的性能，最终与最先进的状态艺术翻译系统齐头并进。