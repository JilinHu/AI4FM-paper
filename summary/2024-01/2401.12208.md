#### 背景
- **背景**       
    文章介绍了胸部X光片(CXR)是临床实践中最常进行的影像检查。近期在视觉-语言基础模型（FMs）的发展中，出现了可能通过自动化CXR解释帮助医生临床决策并改善患者结果的机会。然而，准确解释CXR的FMs的开发面临着挑战，包括大规模视觉-语言数据集在医学图像领域的缺乏，无法捕获医学数据复杂性的视觉和语言编码器，以及缺乏用于基准测试FMs在CXR解释上能力的评估框架。

- **已有的工作**
    现有的工作未能解决CXR解释的问题，因为缺乏专门的大规模医学影像数据集、现有的视觉和语言编码器无法理解医学数据的复杂性，以及评估模型在医学领域的性能的框架存在限制。

#### 核心贡献
- **提出了一个xxx**
    - **挑战1：缺乏针对医学成像的大规模指导式数据集**
        论文通过引入CheXinstruct，一个收集自34项任务和65个不同数据集的6百万指令-图像-答案三元组的大规模指令调整数据集来解决这个挑战，旨在提高FMs解释CXR的能力。

    - **挑战2：现有的多模态编码器无法理解医学数据**
        论文发展了基于8亿参数、经指令调整的CheXagent基础模型。该模型通过训练一个能够理解放射学报告的临床大型语言模型（LLM）、一个能够解读CXR图像的视觉编码器，以及一个桥接视觉和语言模态的网络来解决这一挑战。随后，使用CheXinstruct数据进行指令调整。

#### 实现与部署
通过CheXbench比较了CheXagent和其他六个通用领域及医疗领域的先前FMs，CheXagent在六项视觉任务上超过通用领域FMs的性能97.5%，超过医疗领域FMs的性能55.7%。另外，在两项文本生成任务中，CheXagent提供了通过自动量化度量和五位专家放射科医师的定性度量评估的医疗文本。此外，该研究还评估了潜在的模型偏差，并通过关注性别、种族和年龄的人口因素来突出性能差异，以提高模型的透明度。

#### 总结
本论文致力于解决在自动化胸部X光解释方面存在的挑战，通过引入专为CXR解释设计的大型数据集、开发了新的基础模型以及创建了一个全面的评估基准，实现了在医学成像领域的应用，并证明了在多项评估任务中CheXagent的性能优于其他模型。同时也对模型中可能存在的偏差进行了检查，为未来的研究和应用提供了重要参考。