#### 背景
- **背景**       
    论文介绍了大型语言模型（LLMs）在自然语言理解和生成任务中的杰出表现激发了人们使用它们作为构建代理系统的中心控制器的探索。已有的工作试图将LLMs与外部工具连接，以拓展应用场景。然而，目前LLMs感知工具使用的能力仅限于单个文本查询，这可能导致理解用户真实意图时的模糊性。LLMs需要通过感知视觉或听觉指令的信息来消除这种模糊性。

- **已有的工作**
    已有的工作将LLMs扩展应用到例如餐厅预定和在线购物这样的外部任务，或涉及检索和处理外部知识的内部操作。但是，这些工作仅限于使用文本输入，导致在文本指令不明确时可能发生混淆和误解。

#### 核心贡献
- **提出了一个名为Tool-LMM的系统**
    - **挑战1：如何处理多模态输入**
        论文提出的Tool-LMM系统整合了多模态编码器和开源的LLMs，使得所学习的LLMs能够意识到多模态输入指令，并正确选择与功能匹配的工具。这是首次尝试训练一个大型多模态模型进行工具代理学习。

    - **挑战2：如何评估模型的工具选择能力**
        为了评估模型的能力，研究者收集了一个名为ToolMMBench的数据集，它包含来自HuggingFace的多模态输入工具。此外，该数据集包含对相同指令的多种潜在选择，由于存在功能相同和同义功能的现象，为同一查询提供了更多的潜在解决方案。

#### 实现与部署
在24个流行的LLMs上的实验结果显示，通过在ToolMMBench上微调Tool-LMM，其工具选择的准确率达到令人印象深刻的88.19%，这证明了提出方法的有效性。此外，为了评估LLMs在处理文本含糊查询时的外部工具使用意识和选择能力，作者制定了一些评估指标，并对多种LLMs进行了广泛的子集消融实验。

#### 总结
Tool-LMM为首个致力于训练大型多模态模型以学习工具代理的系统，创新地整合了多模态输入与外部工具的正确选择，克服了文本模糊带来的问题，展现了在多模态指令下自动选择合适工具的能力。