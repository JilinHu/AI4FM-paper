#### 背景
- **背景**       
    本篇论文提出，尽管检索增强生成（Retrieval-augmented Generation, RAG）的系统已经在知识密集型任务中表现出强大的效果，但现有研究大多将检索器和大语言模型（LLMs）分别独立研究。这导致检索出的信息可能并不完全符合LLMs的"偏好"，从而存在着优化RAG系统的潜力。

- **已有的工作**
    已有的研究尝试通过微调LLMs或检索器以使二者的"偏好"更加一致，然而这些方法大多集中在排名（ranking）这一方面，没有解决整体的"偏好差"问题。微调检索器只能实现重新排名，而微调LLMs经常不现实，因为许多模型只能通过API访问。

#### 核心贡献
- **提出了一个框架 BGM (Bridging the Gap between retrievers and LLMs)**
    - **挑战1：偏好差**
        文章指出，检索器和LLMs之间存在"偏好差"，特别是在排名和选择上。这个框架旨在不改变现有检索器和LLMs的情况下，通过一个称为"桥模型"的方式，转换检索出的信息，使其更符合LLMs的处理方式。
    - **挑战2：缺乏有效的监督**
        由于在典型的RAG系统中不存在关于检索内容的"真实"相关性标签，只有下游任务的真实标签，现有的监督学习方法由于监督稀疏，效率不高。文章提出结合监督学习（SL）和强化学习（RL）的框架来提高模型在下游任务中的表现，并探索更高级的策略，如重复信息的关联性加权。

#### 实现与部署
BGM框架在多个下游任务上进行了实验评估，包括问答(QA)和个性化文本生成。实验结果表明，BGM改进了检索出的内容，在一系列公开的QA数据集、亚马逊评论和私人电子邮件对话中，性能超越了强大的检索器和重新排名的基准模型。这证明了"桥接方法"在RAG领域的重要性和前景。

#### 总结
本论文介绍了BGM框架以解决检索器和LLMs之间的"偏好差"问题，通过一个序列到序列（seq2seq）的桥模型结合SL和RL的训练方案，优化了检索信息以满足LLMs的偏好，改进了多个下游任务的表现。