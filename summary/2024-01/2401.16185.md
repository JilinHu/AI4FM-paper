#### 背景
- **背景**       
    论文探讨了大型语言模型（LLMs）在处理代码漏洞分析任务时可能遇到的挑战。目前存在的系统并不能有效地解决在代码漏洞检测中提供深度内容增强和推理能力的问题，这是因为它们没有充分利用知识检索、工具调用、提示方案和指令跟随方面的策略。

- **已有的工作**
    以往的研究虽然在大型语言模型（LLMs）的基础上尝试解决代码漏洞识别的问题，但这些尝试通常没有结合知识检索和外部工具调用等能力，限制了模型对复杂问题的理解和解决能力。

#### 核心贡献
- **提出了一个名为LLM4Vuln的框架**
    - **挑战1：如何增强模型的知识检索能力?**
        LLM4Vuln通过构建一个可搜索的漏洞知识向量数据库来解决这个挑战，其创新点在于不仅包含原始的漏洞报告，还包括每个漏洞的概述知识和功能描述。这使得基于功能相似性的相关知识能够被检索出来，从而提高了检索的有效性和准确性。

    - **挑战2：如何通过模型调用工具来增强模型的漏洞推理能力?**
        该框架首次引入了通过LLM调用外部工具来支持漏洞分析的能力，这种机制可以提供程序分析的上下文，并可以扩展以包括更复杂的信息，例如控制流和数据流。

    - **挑战3：应如何设计提示方案来提高模型的执行能力？**
        LLM4Vuln采用了如链式思考（CoT）这样的常见提示技术，并为漏洞分析场景定制了特定的CoT方案，从而使得LLM在漏洞识别中的表现更为精确且稳定。

    - **挑战4：如何提高指令跟随能力不足的模型的输出结构化能力？**
        作者们建议利用指令跟随能力较强的模型来对齐和结构化指令跟随能力较弱的模型的输出，以促进自动化的结果评估。

#### 实现与部署
论文实现了LLM4Vuln并用其对智能合约代码的1013份高质量漏洞数据进行知识“训练”，并使用75份有漏洞的代码片段进行基准测试。测试覆盖了4950个场景，包括三种类型的知识增强、两种上下文补充选项和三种提示方案，并使用GPT-4、Mixtral和Code Llama这三种代表性LLMs。研究人员通过分析LLMs注释的结果，识别出了十项关键发现，这些发现揭示了知识增强、上下文补充和提示方案对LLMs漏洞推理能力的影响。例如，增加漏洞知识有助于LLMs的漏洞推理能力，并且简短的概述知识比完整的漏洞报告在提高漏洞识别准确性方面更为有效。同时，所提出的框架在实际项目中成功提交了若干问题，并获得了确认和奖金。

#### 总结
LLM4Vuln是一个创新的框架，它通过提供漏洞知识的向量数据库、调用工具的功能、定制的CoT提示方案以及使用精通指令的模型来结构化输出，显著提高了LLMs在代码漏洞分析中的性能。