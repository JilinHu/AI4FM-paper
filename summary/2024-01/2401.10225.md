#### 背景
- **背景**       
    该文章探究了利用大型语言模型（LLM）进行对话式问答（Conversational QA）的能力。现有方法对于多轮对话和背景知识的处理还存在不足，如何改善LLM在对话中的问答能力已成为研究的关键点。

- **已有的工作**
    已有研究通过预训练模型和单次对话的问答来处理对话式问题，但当面对多轮对话和需要背景知识的复杂情况时，模型的性能仍有限。此外，大多数研究没有关注相比专业知识更多涉及的日常对话问答场景。

#### 核心贡献
- **提出了一个名为ChatQA的两阶段指令微调框架**
    - **挑战1：多轮对话式问答和深层次语义理解**
        该方法首先使用预训练的LLM基础模型，在第一阶段应用监督式微调（Supervised Fine-tuning, SFT），以便让模型能够理解和遵循日常对话指令。通过统一各个SFT数据到对话格式，并将其应用到LLM基础模型上的微调。

    - **挑战2：背景知识和信息获取能力**
        在第二阶段，引入了新的阶段称为上下文增强指令微调，这个阶段特别为增强模型对对话式问答中的上下文意识或检索增强生成的能力而设计。通过集成上下文QA数据集到指令微调数据集中，进一步增强模型的问答能力。
  
#### 实现与部署
本论文使用多数据集进行了实验验证，结果显示ChatQA模型在多轮对话式问答任务中表现出色。该模型不仅在标准问答基准上表现强劲，而且在对于无法解答的问题，模型能够明确指出无法找到答案，减少了幻觉式回答的情况。此外，通过与GPT-3.5-turbo等现有模型的比较，证实了ChatQA的有效性和优越性。

#### 总结
ChatQA模型通过两阶段的指令微调策略显著改进了多轮对话式问答的效果，尤其是在上下文理解和信息检索方面。