#### 背景
- **背景**       
    文章介绍了在与LLMs（Large Language Models）的交互中，如何通过使用人在环中（Human in the Loop）的方式将提示工程（Prompt Engineering）转化为提示科学（Prompt Science）。这是为了提高提示（用于引导模型提供期望的输出）生成过程的系统性、一致性和可解释性。

- **已有的工作**
    以往的工作通常缺少一种系统性和一致性的方法来创建和验证用于LLMs的提示。已有工作往往依赖于启发式方法和研究者的直觉，导致结果带有主管性和不透明性。

#### 核心贡献
- **提出了一个基于人在环中的质性编码过程的新方法**
    - **挑战1：如何系统地创建一个可靠且普遍适用的提示**
        文章提出的方法将提示的创建过程看作是质性研究中的编码手册构建。通过多阶段的方法，确保LLM生成的响应是可验证的、可解释的，并且符合预定的质量标准。

    - **挑战2：确保生成的提示能持续产生期望的响应**
        通过使用至少两位人类评估者对LLM的响应进行评估，并迭代地开发和调整提示，使其在不同的实验、LLMs和情境中保持一致性和普遍适用性。
    - ...
#### 实现与部署
该方法包括四个阶段：设置初始流程、确定评估LLM响应的标准、迭代开发提示和验证整个流程。通过测试和重构提示，确保能够系统地产生所需的响应。这个过程包括大量的人工审核和迭代调整，确保提示生成的过程不只是依赖于直觉或个人偏好，而是通过科学方法和清晰标准来指导。

#### 总结
文章展示了如何将LLMs的提示工程转化为更为科学和系统的提示科学。通过引入人在环中的质性编码方法，确保了LLM生成的响应的质量和一致性，同时消除了个体主观性和随意性。