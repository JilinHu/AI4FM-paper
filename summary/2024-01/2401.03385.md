#### 背景
- **背景**       
    文章讨论了大型语言模型（LLMs）中的上下文学习（In-context learning, ICL）能力和其变化情况，指出模型的类型、模型架构、学习数据的体量和参数大小等因素都会对ICL能力造成显著影响。一般来说，模型参数越大，学习数据越丰富，则ICL能力越强。

- **已有的工作**
    现有的工作指出ICL的能力是由数据自身的分布特征所驱动，强调数据结构的重要性。然而，这些工作对于如何将大型模型的能力移植到性能较弱的模型中以提高它们的ICL能力没有给出有效的方法。

#### 核心贡献
- **提出了一个名为SLEICL（Strong LLM Enhanced ICL）的方法**
    - **挑战1：如何提高弱语言模型的ICL能力**
        现有方法要求模型自身学习提示示例，并选择最合适的示例来优化性能。SLEICL方法从强大模型那里学习示例功能，并将这些技能转移给弱模型，从而简化了弱模型的学习流程，以此解决提升弱模型ICL能力的问题。

    - **挑战2：如何确保各个模型和任务选择最佳的grimoire**
        研究者们建立了grimoire排序方法，自动选择最适合不同模型和任务的grimoire，克服了在广泛的场景中自动化选择最佳学习示例的挑战。

#### 实现与部署
该研究的实验结果显示，利用SLEICL方法可以让各种参数规模的弱语言模型在多种任务上都取得显著的性能提升，尤其是较小模型的提升更为明显。在某些数据集上，弱语言模型借助SLEICL甚至超过了GPT4-1106-preview的zero-shot表现。提出了四种不同的代表性样本选择方法（KCS、HCS、HSS、RSS）和两种grimoire生成模板（PG和SG），生成了10种类型的单个grimoire。实验涉及5个模型和8个数据集，涵盖4种任务类型，证明了SLEICL在实际部署中的有效性。

#### 总结
该论文提出了一种名为SLEICL的方法，通过强语言模型学习示例技能并将其转移给弱语言模型，显著提高了弱模型的ICL能力。通过实验验证了该方法的有效性，展现了该技术在增强弱语言模型上下文学习能力方面的潜力。