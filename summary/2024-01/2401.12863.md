#### 背景
- **背景**       
    文章介绍了大型语言模型 (LLMs) 在自然语言处理任务中通过利用思维链 (chain of thought, CoT) 实现了卓越的性能，CoT让LLMs能够以一种逐步的方式进行思考和推理，模仿人类的认知过程。

- **已有的工作**
    系统存在计算成本高且需大量硬件资源的问题。传统的语言模型在复杂的推理场景中往往不能给出最优解答，因为它们没有明确的中间步骤。最近LLMs向多模态能力的延伸已成为研究热点，但这些模型的庞大规模对硬件基础设施的要求非常高。虽然也有提出通过微调较小模型来适应多模态并引出CoT能力的方法，但这种方法往往会导致幻觉，即模型产生的推理和答案听起来合理但实际上是错误的。

#### 核心贡献
- **提出了KAM-CoT框架**
    - **挑战1：整合多模态数据和知识图谱**
        论文提出了KAM-CoT框架，可以整合CoT推理、知识图谱（KGs）和多种模态，来全面理解多模态任务。论文提出了一个两阶段训练流程，利用知识图谱来生成有效的解释和答案，从而在推理过程中通过引入来自知识图谱的外部知识，可以获得更深的上下文理解，减少幻觉并提高答案质量。

    - **挑战2：提高效率与性能**
        KAM-CoT在只有280M可训练参数的情况下实现了新的行业领先水平。在ScienceQA数据集上，平均准确率达到了93.87%，超过了GPT-3.5的75.17%和GPT-4的83.99%，展示了其成本效率和有效性。

#### 实现与部署
KAM-CoT框架集成了语言模型以处理语言上下文、视觉编码器以编码视觉特征，以及图神经网络（GNN）来推理知识图谱。该框架将文本、视觉和图形特征无缝结合在一起，从而能够使机器以类似于人类认知的方式进行思考和推理。通过对ScienceQA数据集的广泛实验和评估，KAM-CoT达到了93.87%的平均准确率，超过了GPT-3.5的75.17%和GPT-4的83.99%，在展示其成本效率和有效性的同时，KAM-CoT也仅仅使用了280M的可训练参数。

#### 总结
KAM-CoT是一个多模态CoT推理框架，整合了CoT推理、知识图谱和多种模态。它在具有较少可训练参数的情况下优于现有的最先进方法，展现出卓越的性能和成本效率。