#### 背景
- **背景**       
    论文讨论了在大量多样化的指导数据集上训练大型语言模型（LLMs），以使模型理解和遵循人类指令的重要性。现有研究显示，使用一小部分高质量指令可以胜过使用大量但噪声更多的指令。然而，已有的活跃学习方案因为需要模型的信心标签，无法直接用于选择未标记的指令。

- **已有的工作**
    创建一个大规模且多样化的有注释的指导数据集需要大量的人工标注资源，并且成为了指导调整（instruction-tuning）的一个主要挑战。虽然高级大型语言模型（如GPT-4）生成的合成数据集部分解决了这个问题，但这些数据集经常包含低质量的数据，表明需要更专注于数据集的精炼。

#### 核心贡献
- **提出了一个名为SELECTLLM的方法**
    - **挑战1：选择高质量的指令**
        SELECTLLM使用聚类算法将未标记的指令分成多个簇，然后利用LLMs通过提示来选择每个簇内的高质量指令，而不需要对应的标签（即响应）。该方法比现有的先进选择方法在流行的指令基准上显示出相当或略好的性能。

    - **挑战2：保持数据集的全局结构**
        SELECTLLM首先将整个数据集划分为几个小的子集，通过使用相等大小的K-means聚类以在保留整个数据集的全局结构的同时构建具有多样化未标记指令的每个子集。然后，为每个子集构造使用精心设计的输入提示的输入查询，以用LLMs进行选择。之后就会生成查询并选择最有助于微调LLMs的一些指令。

#### 实现与部署
SELECTLLM的有效性在两个流行的指令调整基准测试Dolly和清洁的Alpaca上与各种最新的选择方法相比较。实验结果表明，无论选择的样本大小如何，该方法在各种样本大小上均一致地超越了基准线。例如，在从Dolly选择样本时，SELECTLLM在Rouge F1得分和余弦相似度指标上相对于最强基线分别显示出接近2.5%-3%的相对改进。此外，SELECTLLM在跨任务泛化方面表现更好，这是指导调整后LMs的一个重要特征。

#### 总结
这项工作提出了一个利用LLMs选择未标记的高质量指令的新方法SELECTLLM，通过挑战传统的选择算法并在保持数据集的全局结构的同时提升选择效果。实验结果显示了其在指令调整基准测试上的优越性能。