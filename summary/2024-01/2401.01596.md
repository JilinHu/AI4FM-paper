#### 背景
- **背景**       
    在医疗领域，总结患者提出的医疗问题对于改善医患互动和医疗决策至关重要。现有的研究主要集中在基于文本的方法，忽视了视觉线索的整合。此外，现有的医疗问题总结工作都局限于英语。这项工作引入了一个新的任务：在资源有限的环境下对混合语码输入的多模态医疗问题进行总结。

- **已有的工作**
    现有的研究没有利用整合文本信息和视觉数据（如图像）的机会，尽管视觉辅助在医疗问题总结（MQS）中扮演了一个关键角色。此外，医疗图像的复杂性和语境理解的潜在差距可能导致模型生成的总结具有误导性或不相关性。对于综合文本和图像的医疗问询总结，使用LLMs和VLMs的领域还相对未被探索。

#### 核心贡献
- **提出了一个名为MedSumm的框架**
    - **挑战1：集成视觉信息用于总结**
        提出的框架MedSumm利用LLMs和VLMs的能力来整合文本和图像，解决了现有工作忽视视觉线索整合的问题。通过MMCQS数据集的使用，该工作展示了整合图像中的视觉信息可以提高医疗详细总结的创造。

    - **挑战2：多模态和混合语码输入的处理**
        MedSumm框架之所以能解决这个挑战，是因为它使用了四个独特的组件：使用预训练大型语言模型来生成文本嵌入，利用视觉编码器如ViT对视觉信息编码，采用QLoRA低秩适配技术进行高效微调，以及使用精确的推理流程来生成对应的症状名称和概述。

#### 实现与部署
由于篇幅有限，论文的实验结果和相关工作的比较在此未展示。要获得关于MedSumm框架实际性能的具体信息，推荐查阅原文的实验部分，以了解其实验设置、评估指标（如MMFCM），以及与其他现有工作的对比情况。

#### 总结
MedSumm是一个新颖的多模态医疗问题总结框架，它能够通过整合文本和视觉信息生成医学细节丰富的总结，有潜力提高医疗决策的质量并加深对患者问题的理解。