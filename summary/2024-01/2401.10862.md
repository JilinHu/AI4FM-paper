#### 背景
- **背景**       
    论文讨论了为了在不进行微调的情况下，提升与LLMs对齐的模型对“越狱”攻击的抵抗力，研究员利用了称为 Wanda 的剪枝方法，这是一种计算效率高的技术，可以在保持良好性能的同时进行模型压缩。

- **已有的工作**
    现有的工作存在矛盾的实验结果，特定的压缩方法和实施细节能够提高鲁棒性或者导致性能折中。针对LLMs的安全过滤器规避方法存在所谓的“越狱”攻击，用户精心设计提示以忽略底层系统提示或无视其安全培训。

#### 核心贡献
- **提出了一个基于Wanda剪枝方法的模型压缩研究框架**
    - **挑战1：提高模型越狱攻击的抵抗性**
        本文研究了剪枝方法Wanda对模型安全性的影响，尤其是模型如何抵抗恶意用户的“越狱”攻击。通过定义权重的重要性分数，对模型进行压缩，剪除低重要性的连接，以期望在不牺牲性能的情况下提高模型的安全性。

    - **挑战2：数据集和评估方式的设计**
        研究人员构建了一个包含225个假设性恶意任务的数据集，这些任务代表着不同类型的恶意意图，并且分为五个类别。为了评估模型的鲁棒性，设计了“越狱”攻击的实验设置，使用fine-tuned的ChatGPT-3.5 Turbo模型对基模型和剪枝后的模型生成的响应进行分类和评估。

#### 实现与部署
实验中用到三个7亿参数的FP16模型，并以10%、20%、30%的稀疏率使用Wanda方法剪枝这些模型。剪枝后的模型未进行微调。评估过程中，收集了剪枝模型和基模型响应恶意任务的数据，并使用fine-tuned的ChatGPT-3.5 Turbo模型对这些响应进行了分类。分类结果提供了“越狱”成功率的全面衡量，并通过手动验证保证了分类的准确性。此外，为了确保剪枝模型仍然具备完成各种任务的能力，对剪枝模型在Huggingface的Open LLM Leadboard进行了基准测试。

#### 总结
论文展示了通过Wanda剪枝方法，无需微调而提升LLMs从对齐安全性方面抵御“越狱”攻击的能力，并通过构建特定的数据集和评估体系验证模型表现。