#### 背景
- **背景**       
    论文介绍了大型语言模型（LLMs）解决问题的能力受到预定义知识和领域特定工具的能力限制，这限制了模型泛化和推理能力的扩展。

- **已有的工作**
    现有方法通常无法抽象和分离LLMs的普遍推理和领域特定知识的获取，导致模型在推理过程中无法有效利用外部工具，也限制了推理过程的速度。

#### 核心贡献
  - **提出了一个链式抽象推理(Chain-of-Abstraction, CoA)方法**
    - **挑战1：如何提高LLMs利用领域特定工具的能力**
        LLMs通常困难在于如何结合和应用外部工具提供的特定领域信息进行推理。CoA通过将推理过程中具体值替换为抽象占位符，使模型专注于学习一般的推理策略而不需生成特定实例的知识，解决了这一问题。

    - **挑战2：如何加速LLMs的推理过程**
        由于使用抽象占位符，LLMs可以在API调用（通过管道）并行处理和切换样本，这允许模型开始生成下一个抽象链而工具填充当前链，从而加速了整体的推理过程。
    
#### 实现与部署
论文在数学推理和维基百科问答（Wiki QA）两个领域进行了实验，并与几个基线方法进行了比较，包括使用链式思考数据的少量示例提示、原始链式思考数据的微调以及Toolformer方法。结果表明，CoA方法在处理多步骤推理问题时，特别是在数学理解方面表现优异，总体准确率达到了78.89%，显著优于其他测试方法。

#### 总结
本文提出了一种新的链式抽象推理方法，有效地提升了LLMs使用外部工具的能力，并加速了推理过程。实验结果证明了其在多步骤推理任务上的有效性和高效性。