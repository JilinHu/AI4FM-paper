#### 背景
- **背景**       
    文章介绍了当前大型语言模型（LLMs）在推理能力方面的挑战。作者指出，尽管LLMs的模型参数规模增大可以提高其隐式知识，但推理能力与语言能力并不等同。归纳推理是LLMs的一个主要短板，如ChatGPT等LLMs表现除了在某些情况下表现出惊人的推理能力外，在一些非常简单的推理问题中却经常失败。

- **已有的工作**
    评估模型的推理能力通常意味着在需要这些技能的不同NLP任务中评估其算术、常识和符号推理的各种技能。然而，由于推理本身是一个更宽泛的概念，因此基于现有和当前关于推理的工作很难断言模型是否具备“推理”能力，现有的工作也是零散的。

#### 核心贡献
- **提出了一个更加细致的评估ChatGPT推理能力的方法**
    - **挑战1：推理令人困惑**
        现有的评估方法无法准确评价模型是否具备推理能力。文章通过更加细粒度的方式，包含演绎、归纳、溯因、类比、因果、多跳、数学、时间和空间推理来通过问答任务对ChatGPT的推理能力进行评估，并手动检查答案的准确性及由ChatGPT生成的理由和解释，通过避免测试集的重叠，选择主要需要特定类别推理的测试集。

    - **挑战2：非文本语义推理缺失**
        对ChatGPT进行推理能力的评估发现它在非文本语义理解方面，如数学、时间和空间推理能力存在不足。尤其是在测试数学推理的MATH数据集上表现不佳。这部分评估揭示了ChatGPT在空间推理任务上的短板，例如在理解时钟方向和对角线空间关系方面的错误。

#### 实现与部署
因篇幅所限，无法提供完整实现与部署信息。然而，论文中提到了使用了多种分类的问答任务来评估ChatGPT的不同类型推理能力。例如，在逻辑推理类别中，使用了bAbI任务和其他高级任务来测试演绎和归纳推理。在非文本语义推理中，使用了MATH、Timedial、SpartQA等数据集来测试数学、时间和空间推理。测试结果在论文中的表5中展示，ChatGPT在演绎、因果、多跳和类比推理任务中显著胜出，而在归纳、数学和空间推理任务中表现较差。

#### 总结
文章通过更细粒度的方式评估了ChatGPT的推理能力，并且找到了LLMs中的一个关键问题，即在非文本语义理解方面的不足。这一发现对于未来LLMs的改进和推理能力的研究提供了重要的方向。