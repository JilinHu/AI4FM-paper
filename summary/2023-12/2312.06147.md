#### 背景
- **背景**
    文章展开了关于大型语言模型（LLMs）处理和理解HTML代码的能力的研究，并考察了这些模型如何在web界面中检索和定位用户查询请求中的重要元素。与之前主要聚焦于自动化网络导航的工作不同，本文将问题进一步细化为更基础的操作—LLMs是否能够识别出web页面中用户查询请求的重要信息。这一分解使研究者能够审视LLMs目前的能力，并揭示它们所带来的机遇与挑战。

- **已有的工作**
    尽管早期的研究成果展示了LLMs在处理移动端用户界面（UI）任务中的潜力，但真实世界网站任务的完成率尚未超过15%，暗示这些自动化助手在日常使用中尚不够实际。此外,现有研究多集中于移动UI的处理,与web UI相比,移动UI的探索空间较小,web UI则更为复杂且元素更多，这使得LLMs在处理并结合Web UI时面临更大的挑战。

#### 核心贡献
- **提出了一个对LLMs在Web UI信息检索中潜力的实验研究**
    - **挑战1：选择何种例子对于In-context learning (ICL) 效果最佳？**
        研究发现，选择与任务语义相关的少部分例子可以提高LLMs在单次提示时的表现，但在两次提示时会降低性能。这表明选择适当的少量示例对于提升LLMs的性能至关重要，同时也要注意输入序列的长度。

    - **挑战2：用户查询的具体程度如何影响LLMs的性能？**
        研究表明，较详细的任务描述能够帮助LLMs更好地泛化处理不同准确性层面上的任务。提供更抽象的固定示例可能帮助模型更好地理解和执行用户指令。

#### 实现与部署
通过对Claude2模型的实验，研究人员探讨了对模型性能有影响的几个关键组件，包括少量样本示例的选择、用户指令中自然语言命令的详细程度、HTML编码的截断策略、以及LLMs扮演的特定角色（persona）。结果显示，LLMs的性能受到这些组件的明显影响。例如，选用语义相似的少量示例可以提高单次提示时的召回率，但在两次提示时则减少了性能。有效的HTML截断策略可以独立地带来性能提升。然而，LLMs的关键限制包括产生不存在的网页元素与无法遵循输入指令的问题。研究结束时给出了未来可能的研究方向和克服这些限制的解决方案【8】【10】【11】【12】【16】。

#### 总结
本文研究了LLMs在从Web界面检索信息中的应用潜力和面临的挑战。通过一系列实验，揭示了模型性能的关键因素及其限制，并为未来工作指明了方向。