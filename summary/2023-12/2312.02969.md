#### 背景
- **背景**       
    当前的大语言模型（LLMs）基于的列表重排序器在零样本情况下是最先进的，然而这些研究都依赖于GPT模型，使其在科学可重现性方面成为一个单点故障。此外，还有疑虑当前的研究结果是否仅适用于GPT模型，而不是通用的LLMs。

- **已有的工作**
    现有的工作在列表重排序上取得了成功，但他们的成功关键地依赖于GPT模型，这既是科学复现的失败点，也引发了研究成果是否只适用于GPT模型的疑虑。

#### 核心贡献
- **提出了一个无需依赖GPT就能构建有效列表重排序器的方法**
    - **挑战1：构建不依赖GPT的列表重排序器**
        目前用于训练LSMs的列表重排序器都依赖于GPT模型。作者提出一种方法，不依赖于GPT，能够超过基于GPT-3.5的重排序器13%，并实现与基于GPT-4的重排序器97%的效果。

    - **挑战2：构建高质量的列表排序数据**
        当前用来训练点式重排序器（pointwise rerankers）的训练数据并不充分，特别是在用于列表式（listwise）重排序器的训练时。作者提出需要更多高质量的列表排序数据，这对于改进模型至关重要，呼吁未来的工作在建设人类注释的列表数据资源方面进行更多努力。

#### 实现与部署
论文中使用了训练模型的数据来自于MS MARCO v1语料库，这包含了880万个段落。使用从RankVicuna训练数据中随机抽取的n个训练查询（n ∈ {2k, 5k, 10k, 20k}），并且依据先前提出的四种设置重新排序了每个查询的文档列表。使用Code-LLaMA-Instruct模型进行实验，该模型为开源LLM。对比了不同大小的模型（7B、13B 和 34B），并把实验结果与基于Llama 2但在ShareGPT指令数据上进行了微调的Vicuna-v1.5模型进行了对比。在TREC-DL-19 和 TREC-DL-20数据集上的评估显示，研究中最好的列表重排序器在nDCG@10指标上比基于GPT-3.5的重排序器高出13%，并达到了基于GPT-4重排序器效率的97%。

#### 总结
本文的核心成果是演示了如何构建一种不依赖GPT模型的有效列表重排序器，能显著超越现有基于GPT的重排序器，并呼吁研究社区开发更高质量的列表排序训练数据，以提升模型的表现。