#### 背景
- **背景**       
    文章介绍了大型语言模型（LLMs）在复杂推理任务中取得的显著进展，特别是链式思维（Chain-of-Thought，CoT）技术的发展。尽管取得了一定的进步，但这些模型的推理能力仍然受限于它们内在的理解，缺少外部的洞察力。

- **已有的工作**
    已有工作中提出的CoT和自我修正策略无法克服模型在推理任务中表现不佳的根本问题，因为它们仅依赖于模型自身对问题的理解和视角。此外，模型在没有外部反馈的情况下很难修正它们的响应，这主要是因为模型完全依赖于内部表示来生成响应，从而无法克服能力上的内在局限。

#### 核心贡献
- **提出了一个称为Exchange-of-Thought（EoT）的新框架**
    - **挑战1：如何增强模型的推理能力并克服内在理解上的限制**
        EoT框架通过建立模型间的交流，允许它们在解决问题时纳入其他模型的思考，从而提供外部洞察力。EoT的设计灵感源自网络拓扑结构和代理通信，提出了四种通信范例：Memory、Report、Relay和Debate，来丰富模型解决问题的思路和理解。

    - **挑战2：如何平衡正确与错误推理链传播的风险**
        为了平衡正确与错误理由链传播的风险，EoT实现了一种可靠的信心评估机制，在通信过程中评估模型的答案变化，以此评估模型的信心水平，并减轻错误推理的影响。
      
#### 实现与部署
在多个复杂的推理任务上的实验结果显示，EoT在增强LLM性能方面显著超越了现有的基准模型。EoT利用了四种通信范例，并结合信心评估机制进行实验验证，结果表明EoT显著提升了模型在复杂推理任务中的表现，同时也突出了外部洞察力在问题解决中的重要性和在成本效益上的优势。

#### 总结
本文提出的Exchange-of-Thought（EoT）框架通过模型间交流提升LLMs的推理能力，凭借四种通信范例和信心评估机制，在多个推理任务上取得了显著成效，并证明了外部思维在增强模型性能中的作用。