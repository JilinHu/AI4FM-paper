#### 背景
- **背景**       
    论文提出，在现有的方法中，使用大型语言模型（LLM）进行源代码摘要（Code Summarization）需要专业知识同时还需要对LLM有深入理解。现有的方法包括手工设计提示（prompt）和基于任务的微调（task-oriented fine-tuning），尽管可以提高性能，但成本高且需要大量训练资源。

- **已有的工作**
    现有的工作由于需要构建高成本的训练环境以及专业知识的需求，对于研究团体来说门槛较高，同时手动设计的提示效果不一定理想。

#### 核心贡献点
- **提出了一个名为PromptCS的提示学习框架**
    - **挑战1：需要专业知识与复杂手动设计提示**
        PromptCS简化了生成源代码摘要的过程，不需要手动设计复杂提示，通过非侵入式的方式降低对训练资源的要求，保持LLM参数在训练过程中不变，只需更新提示代理（prompt agent）的参数。

    - **挑战2：高昂的训练成本**
        PromptCS显著降低了与基于任务的微调相比的训练成本。例如，当使用StarCoderBase-7B模型作为基础LLM时，PromptCS仅需要大约67小时来训练提示代理，而基于任务的微调方案需要大约211小时来进行一个周期的训练。

#### 实现与部署
论文中对PromptCS进行了广泛的实验，并在广泛使用的基准数据集上评估了其性能。实验结果显示，在全部四项评价指标（即BLEU, METEOR, ROUGE-L和SentenceBERT）上，PromptCS显著优于以零样本和少样本学习的指令提示方案，并且与基于任务的微调方案相当。某些LLM上，例如StarCoderBase-1B和StarCoderBase-3B，PromptCS甚至超过了基于任务的微调方案。作者还开源了PromptCS的代码，以促进未来的研究和应用。

#### 总结
本论文提出了一个新颖的PromptCS框架，用于源代码摘要，能够生成高质量的摘要，减少了训练成本，并提供了代码以供他人研究。