#### 背景
- **背景**       
    现有的大型语言模型（LLMs）如ChatGPT在各种编码任务中展现出了极高的能力，尤其是在代码生成方面。但是，这些模型倾向于在通用领域内展现最佳性能，当它们被应用于特定领域时（如Web开发），其效果则需要进一步评估。

- **已有的工作**
    现有的LLMs依赖于大量训练数据来获取广泛的通用领域知识，并且现有LLMs的评估通常集中在通用领域基准测试（如HumanEval和MBPP），这些基准测试安排编程竞赛类问题（如排序、动态规划），在展示模型在某些方面的能力时忽略了与现实世界代码生成场景相关的复杂性和挑战。

#### 核心贡献
- **提出了一个名为DomCoder的新代码生成方法**
    - **挑战1：特定领域的代码生成**
        现有LLMs由于使用特定领域库的技能有限，在生成特定领域的代码时表现出不够理想的性能。为了应对这个挑战，研究者构建了一个特定领域代码数据集，并对多种LLMs进行了实验评估。

    - **挑战2：如何有效地利用领域知识来提示LLMs生成特定领域的代码**
        研究者探索了几种整合领域知识的策略，例如询问外部知识GPT（kg-GPT）、基于链式思考的提示（CoT-PT）和基于链式思考的微调（CoT-FT），最终证明这些策略可以在某些设置下提高特定领域代码生成的有效性。

#### 实现与部署
研究者首先调查了ChatGPT、CodeGen和PolyCoder等几种LLMs在特定领域的能力，并发现尽管这些模型在生成通用领域应用程序代码方面取得了显著进展，但应用于特定领域时其性能显著下降。以ChatGPT为例，平均CodeBLEU分数下降了51.48%。研究者发现问题通常是由于缺乏领域知识，特别是第三方库的使用错误造成的。接着，研究者设计了几种基于知识的提示，并使用它们来引导LLMs生成更专业的代码，实验表明在所有特定于库的数据集上使用知识增强型提示时均可持续改进结果。

#### 总结
这项研究表明，通过有效地整合领域知识到代码生成过程中，可以增强LLMs在特定领域内的代码生成能力。DomCoder作为一个新的代码生成方法，利用了不同策略以整合领域知识，并在特定设置下提升了代码生成的实际效果。