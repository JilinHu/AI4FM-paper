#### 背景
- **背景**       
    目前大型语言模型（LLMs）在各种任务中显示出了突出的能力，但面对复杂的多步数学推理问题时仍面临挑战。现有的研究采用了包括预训练、微调、提示策略及验证等不同方法。其中，验证被视为一种重要技术，通过重排候选答案来提高LLMs输出的准确性和一致性。已有的验证模型可以分为结果奖励模型（ORM）和过程奖励模型（PRM）。PRM通过逐步评估推理路径，在强化学习和自动纠正中提供精确的反馈。然而，获取用于训练PRM的数据通常需要大量的人力资源和成本，因为这类任务的复杂性要求高技能的标注人员。

- **已有的工作**
    尽管现有的验证模型在改进LLMs的表现方面取得了一些进展，但它们通常依赖于人工标注来提供过程监督注释，这在成本和标注技能方面构成了巨大的挑战，从而限制了PRM在更实际应用场景中的发展。

#### 核心贡献
- **提出了一个自动过程注释框架**
    - **挑战1：减少对人工标注的依赖**
        本文中的自动过程注释框架能够自动地收集分步的监督数据，通过比较推理步骤与正确答案之间的关联以自动化的方式为每个步骤打分。

    - **挑战2：提高数学推理任务的准确性**
        根据从以往步骤解码得出的多个后续推理路径的正确性，来为特定的解题步骤打分，从而保证只有能推导出更多正确答案的步骤会被赋予更高的正确性分数，有效提高了LLMs在数学推理任务上的准确率。
    
#### 实现与部署
自动过程注释框架（MATH-SHEPHERD）通过自动生成处理监督数据来训练，进而验证了作者的理念，并在GSM8K和MATH两个广泛使用的数学基准测试上进行了实验。MATH-SHEPHERD可与不同的LLMs兼容，特别是DeepSeek 67B在GSM8K数据集上取得了93.3％的准确率，在MATH数据集的代表性子集上取得了48.1％的准确率。这些结果超越了GPT-4早期版本以及其它现有的验证模型，成为开源模型中的佼佼者。

#### 总结
MATH-SHEPHERD通过自动生成监督数据训练LLMs，来解决高成本人力标注的问题，并提高了LLMs在复杂数学问题上的准确性。这一成果为LLMs的进步和实际应用开辟了新的可能性。