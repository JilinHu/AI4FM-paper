#### 背景
- **背景**       
    论文探讨了在自然语言处理领域中大型语言模型（LLMs）的兴起如何显著影响任务表现。文中重点讨论了增强检索生成（Retrieval-Augmented Generation，RAG）与微调（Fine-Tuning，FT）两种策略，并提出了假设知识图谱增强（HyKGE）框架，以此通过知识图谱增强医疗领域的LLMs。

- **已有的工作**
    现有论文虽然采用检索增强的方式，可以通过检索外部知识减少知识密集型任务中的事实错误，但依旧面临很多挑战。这些挑战包括避免事实不准确性（即幻觉现象），知识过时，以及在特定领域或高度专业化的查询中缺乏专业知识等问题。尤其是在需要高度可靠性和可信任度的领域（如法律、医疗和科学），这些问题削弱了大型语言模型的可靠性。如何将用户输入与高质量的结构化知识对齐的同时，也减少与LLMs的交互并过滤检索信息中的噪声，仍然是一个尚未解决的问题。

#### 核心贡献
- **提出了一个XXX**：HyKGE框架
    - **挑战1：用户查询表达不清与噪声过多**
        存在的问题是如何将用户输入与高质量的结构化知识有效对齐，并减少和LLMs交互过程中的信息冗余。HyKGE框架通过利用LLMs的零样本能力和丰富知识补偿用户查询的不完整性，并以假设性文档输出探索和定位准确、可信赖的LLM响应方向，在知识图谱上识别相应的锚点，提供探索方向并对图谱进行修剪，同时利用图谱知识对假设输出中不正确和不合理的响应进行纠正，避免产生幻觉。

    - **挑战2：交互的时间开销和累积错误**
        现有的方法可能因多次与LLMs的交互导致时间开销大，同时会在分布式推理过程中累积错误。HyKGE框架通过一个片段重排序模块利用从假设输出中的多个短片段来重新组织和合并检索到的知识，确保了精细的交互和过滤，同时解决了长文本（假设性文档）与短文本（知识推理路径）匹配不准确的问题。

#### 实现与部署
HyKGE框架通过实际数据集对其优势进行了评估，特别是在复杂和困难的情况下，该框架能够提供准确知识并具有明确的可信度。通过引入零样本能力的大型语言模型，HyKGE将不完整的用户查询转化为探索性假设输出，并将其与知识图谱的锚点对齐，减少了与LLMs的交互次数，提高了效率。此外，通过重排片段的方式，HyKGE还提高了用户查询与外部知识推理路径之间的对齐度，实现了精细的交互和过滤。

#### 总结
HyKGE框架有效解决了大型语言模型在面对医疗领域复杂问题时的准确性和解释性挑战，具有在医疗领域中的潜在应用并且在实际场景中展示出了很大的优越性。