#### 背景
- **背景**       
    论文探索了利用外部实体进行代码生成的新任务，这一任务要求模型在生成代码的过程中重用项目中定义的函数。研究者发现现有的检索增强型大型语言模型在为相似实体名分配相关性分数以及扩展实体名集方面存在困难。这是因为上下文的大小受到限制，无法容纳整个项目无限大的上下文。

- **已有的工作**
    文章提出，尽管现有的大型预训练语言模型如T5和GPT-3在自然语言任务和代码生成方面取得了显著进展，但在利用知识库中的外部实体进行生成过程中存在不足。例如，在传统的代码生成任务中，当需要生成使用项目内函数的代码时，模型往往无法有效地利用这些函数。

#### 核心贡献
- **提出了一个名为 entity-augmented decoding 的新型架构**
    - **挑战1：如何在生成代码时使用动态词汇表直接查找实体**
        为了解决该挑战，文章提出的模型将实体检索器直接集成到语言模型的解码器中，而不是编码器中。这种架构允许生成器一次性查看所有实体，从而消除了早期架构引入的对top-k近似的依赖。

    - **挑战2：如何处理特别多样化的样本，这些样本可能同时引用不同主题的文档**
        文章提出的模型允许解码器在生成输出的同时也考虑到已经生成的输出部分，这有助于处理多样化的样本，也使得模型能够在不同情境下比常见基线表现更好，包括项目级别的代码生成以及Bash和SQL脚本编写。

#### 实现与部署
文章提出的模型在多个场景下都显示出优于常见基线的表现，尤其是在项目级别的代码生成以及Bash和SQL脚本编写等方面。该模型由两部分组成：实体检索器和生成器（LLM）。实体检索器负责将实体描述转换为实体嵌入，并利用与生成器的最后一个输入令牌表示的交叉注意力。生成器则是一个通用的大型语言模型，用于自回归解码并增强了实体检索器，它接受输入字符串和实体嵌入，并输出代码字符串。生成的代码字符串包含常规令牌和词汇表以外的实体令牌。通过简单的后处理，这些实体令牌会被转换回常规令牌。此外，该模型还使用了T5架构，并与生成器一起通过交叉注意力机制改进了实体描述的总结，并使其依赖于输入。

#### 总结
论文为解决利用外部实体进行代码生成的任务提出了一个新颖的架构。该架构能在不牺牲性能的前提下扩展，通过将实体检索器注入到解码器而非编码器中，模型可以一次性查看所有实体并直接使用它们。新架构不仅解决了现有模型的限制，还在多个实验场景中展示了其优越性。