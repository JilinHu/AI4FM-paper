#### 背景
- **背景**       
    该论文研究了在执行复杂指令时，如何提高大型语言模型（LLMs）作为计划代理的效率和准确性。LLMs在从回答生成、逻辑推理到程序合成的多种任务中表现出色，但经常面临信息不足或过时，以及有时会产生幻觉性错误的问题。

- **已有的工作**
    文中指出，使用文本检索方法将工具纳入LLMs的计划生成中是一个新兴的研究方向。现有工作主要处理的是已明确定义或无歧义的查询，而对于需求不明确的查询则表现不佳。以往的研究通过CoT（Chain of Thought）生成机制的增强来提高查询的语义相似性，但这会增加LLMs的输入长度，造成新的问题。

#### 核心贡献
- **提出了一个新方法**

    - **挑战1：改善检索步骤**
        挑战是当查询不完整或缺乏上下文时，语义检索方法可能会失败。解决这个挑战的方法是引入了Context Tuning for RAG，一个智能上下文检索系统，可以提取出提高工具检索和计划生成效果的相关信息。其轻量级上下文检索模型使用数字类别和习惯性使用信号来检索和排名上下文项。

    - **挑战2：降低幻觉性错误**
        在正确检索到工具后，加入相关上下文到计划生成中，可以帮助降低幻觉性错误提升准确性。文中采用了一个轻量级的基于LambdaMART的RRF方法改善了这一问题，这一方法不仅优于GPT-4的检索方法，而且在提供性能改进方面也避免了增加查询增强的需要。

#### 实现与部署
使用OpenLLaMA-v2-7B对计划生成进行微调，并通过Abstract Syntax Tree (AST) 匹配策略来评估计划性能。实验结果表明，上下文调优显著提高了上下文检索的召回率（Recall@K）和工具检索的Recall@K，并且在计划生成精度上增加了11.6%，显著优于利用传统语义检索的基于RAG的计划生成器。

#### 总结
本论文通过引入上下文调优这一新颖组件，提高了基于检索的增强计划（RAG-based planning）的效果，使其能处理不完整或不明确的查询，同时还降低了幻觉性错误的产生。研究对比了不同的检索方法在轻量模型和LLMs中的应用，并展示了新方法在提高上下文理解上的有效性。