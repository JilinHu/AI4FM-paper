#### 背景
- **背景**       
    文章指出，大语言模型（LLMs）因其逐渐准确的反应和连贯的推理能力，已经在实际应用中获得了巨大的关注。然而，由于这些模型的黑箱本质和复杂的推理过程，对LLMs生成内容的可扩展和忠实的解释的需求不断增长。

- **已有的工作**
    已有的工作中，包括LIME、SHAP以及Integrated Gradients等后验解释性方法，特别是Shapley值，已经被证明对解释深度学习模型是有效的。但是，这些方法在为LLMs特别是处理含有数千token的长输入上下文和自回归生成的输出序列时扩展Shapley值时遇到了重大挑战。此外，目前不清楚如何有效地利用生成的解释来改进LLMs的性能。

#### 核心贡献
- **提出了一个有效的后验解释方法 TextGenSHAP**
    - **挑战1：扩展Shapley值至长输入上下文的效率问题**
        这是一个挑战，因为Shapley值的计算对于LLMs来说往往非常耗时，尤其是在处理长输入和大规模模型时。TextGenSHAP通过整合特定于LM的技术来解决这个问题，实现在计算上更快，将处理时间从小时级减少到分钟级，甚至只需几秒钟就可以完成文档级别的解释。

    - **挑战2：利用生成的解释来改进LLMs的性能**
        英文论文介绍了通过实时Shapley值在两个重要场景中的应用可以获得改进，第一，通过定位重要的词和句子来更好地理解长文档的问答；第二，通过提升选定段落的准确性来改进现有的文档检索系统，最终改善相应结果。

#### 实现与部署
论文实施了 TextGenSHAP 方法，并在长文档问答和文档检索系统两个不同场景中测试。结果显示，与传统Shapley值计算方法相比，TextGenSHAP显著提高了计算速度，并在文档级别解释上加速到只需几秒。尽管论文并未详细报道与其他具体工作的对比结果，但其速度上的增加以及在提高长文档问答理解和文档检索系统准确性方面的潜在应用表明，TextGenSHAP是一种有前景的后验解释性方法。

#### 总结
TextGenSHAP是一个为大型语言模型设计的高效后验解释性方法，通过改进解释生成的速度，并展示了如何利用这些解释改进长文档问答和文档检索系统。