#### 背景
- **背景**       
    论文介绍了大型生成AI模型的发展已经超越了文本（1D）生成，开始囊括了图像（2D）和视频（3D）生成。这些生成处理的空间和时间信息提出了对性能和效率的新挑战，当前文献中还缺乏针对多模态文本到图像（TTI）和文本到视频（TTV）生成模型的系统设计领域的研究。

- **已有的工作**
    现有的系统主要针对LLMs进行了优化，例如使用Flash Attention技术。然而，TTI和TTV模型的独特属性意味着这些新兴工作负载可能无法获得相同的优化效果，需要进行深入分析，以识别TTI/TTV优化的机会。

#### 核心贡献
- **提出了一个综合研究**
    - **挑战1：系统性能瓶颈**
        论文通过在一套代表性的TTI/TTV模型上进行系统性能特征化表明，应用了如Flash Attention的最先进优化技术后，对于基于扩散的TTI模型，卷积计算占据了多达44%的执行时间，而对于基于Transformer的模型，线性层消耗了多达49%的执行时间。这一发现提示我们，为LLMs设计的优化技术并不直接适用于TTI/TTV模型，需要对这些工作负载进行彻底的特征化分析，以获取新的优化机会。

    - **挑战2：序列长度的可变性**
        与LLMs不同，TTI/TTV工作负载在推断过程中序列长度会有高达4倍的变化，特别是在扩散模型推断过程中。这种可变的序列长度影响了整个推断过程的计算密集度，并为系统设计提供了定制的机会。

#### 实现与部署
论文通过定量分析最前沿的TTI/TTV模型，并与广泛使用的语言模型，例如LLaMA进行比较，发现了新的系统性能瓶颈。研究还包括对时间注意力（Temporal Attention）的系统性能瓶颈的调查，该注意力允许在TTV模型中生成时间上连贯的帧，与之相对的是空间注意力（Spatial Attention）。结果显示，时间注意力的执行时间是空间注意力的两倍，但却消耗了9倍的FLOP计数。此外，实验分析发现时间注意力随帧数的增加呈指数级增长，表明未来系统优化的需求。

#### 总结
该论文是针对跨文本、图像和视频生成模型的系统性能特征化的首次工作，它揭示了不同于传统LLMs的独特系统属性，并提出了对于TTI/TTV模型而言，传统的优化技术需要重新考虑的挑战和机会。