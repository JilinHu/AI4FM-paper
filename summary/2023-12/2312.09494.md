#### 背景
- **背景**       
    论文分析了大型语言模型(LLM)在计算成本和能源消耗方面的问题，并旨在通过"错过加速"策略逐层动态丢弃输入序列中不重要的令牌，同时保留具有语义重要性的令牌，来减少这些开销。然而，作者们首次揭示了这种加速策略可能容易受到服务拒绝(DoS)攻击的威胁。

- **已有的工作**
    现有的工作虽提出了各种基于"错过"的语言模型，以实现在计算预算内减少不重要令牌数量的目的，但它们的这种丢弃令牌的决策可能会被不引人注意的、具有对抗性的文本输入改变所操纵，进而可能增加计算复杂度。这对于实时服务平台和资源有限的边缘设备部署来说是一个严重的挑战。

#### 核心贡献
- **提出了一个名为No-Skim的框架**
    - **挑战1：测量加速方案的鲁棒性**
        No-Skim框架旨在帮助基于"错过"加速的LLM所有者理解和衡量他们加速方案的鲁棒性。具体来说，该框架通过在字符级和令牌级搜索最小且不易察觉的干扰来生成增加剩余令牌比例的对抗性输入，进而增加计算成本和能源消耗。

    - **挑战2：广泛评估基于'错过'的加速的脆弱性**
        框架在不同的LLM架构上，包括BERT和RoBERTa，并基于GLUE基准对基于"错过"的加速的脆弱性进行了系统化评估。最坏情况下，通过No-Skim找到的干预举措可将LLM的运行成本平均增加超过145%。此外，No-Skim还扩展了评估框架到各种场景，以便能在不同知识水平下进行评估。

#### 实现与部署
No-Skim框架设计了一个通用的对抗输入生成流水线，并将其划分为三个步骤：（1）单词重要性排名，（2）候选集生成，表示原始文本上的扰动可能的搜索空间，以及（3）最好候选搜索，选择对原始文本进行最有效扰动以增加计算复杂度的方法。该评估框架使用不同和可扩展的插件组件处理文本，确保了框架的通用性，并使评估在不同知识水平和对目标基于"错过"语言模型的访问级别下更加实用。

#### 总结
本论文首次系统地研究了从效率角度出发，基于"错过"的语言模型的脆弱性，并提出了一个有效和通用的效率鲁棒性评估框架No-Skim，以生成增加计算复杂度的对抗性输入。同时，该框架还通过不同的插件模块进行了模块化设计，这些模块在不同的实际情景下工作，评估可以在三种不同的知识水平下进行。