#### 背景
- **背景**       
    该论文探讨小型语言模型（SLM）在数学推理方面的能力。目前已知的最小的在GSM8K基准测试上达到超过80%准确率所需的模型大小是34B。但是对于小型模型是否能达到类似的数学推理能力仍是一个开放性问题。

- **已有的工作**
    GSM8K训练集虽然高质量，但只有大约7473个问题，对于训练一个合理大小的语言模型来说太小了。此外，现有的方法未能有效利用小模型的潜力，因此有必要探索新的数据集和优化方法来改善小型模型在数学推理任务上的性能。

#### 核心贡献
- **提出了一个名为TinyGSM的合成数据集**
    - **挑战1：被动学习的限制**
        由于小型语言模型面临着被动学习的限制，特别是在数值计算和代码执行方面，TinyGSM通过使用GPT-3.5生成的数学问题及其Python解决方案来克服这个问题。数据集中的问题具有合适的随机性和多样性，这有助于提升小型模型的数学推理能力。

    - **挑战2：准确性验证问题**
        TinyGSM使用了单独的验证器来预测生成的答案是否正确，并从多个临时抽样生成的候选答案中选择得分最高的一个。这种方法可以在不清楚标签的情况下判断生成答案的优劣。
        
#### 实现与部署
根据该论文，研究团队在TinyGSM数据集上微调了Phi-1.5 125M、350M和1.3B的模型，并取得显著成功。特别是1.3B版本的Phi-GSM模型在GSM8K数据集上达到了81.5%的准确率，超过了GPT-3.5-turbo的77.4%测试准确率。使用Adam优化器、FP16精度进行训练，并且通过温度抽样产生多个候选解，再使用验证器对这些解进行评分和选择。实验结果表明，使用TinyGSM和验证器进行训练和选择，即使是小型语言模型也可以在数学推理任务上表现优异。

#### 总结
这篇论文通过创建一个合成的数学问题数据集TinyGSM及其对应的Python解决方案，成功使小型语言模型在GSM8K数学问题推理基准测试上的准确率超过了80%，展示了通过高质量数据集和验证器策略显著提高了小型模型性能的可行性。