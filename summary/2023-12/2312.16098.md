#### 背景
- **背景**       
    本文研究采用大型语言模型（LLM）进行零样本（zero-shot）列表级重新排序（listwise reranking）的工作。尽管这样的方法取得了一些成功和领先成果，但它们依赖于具有数十亿参数和有限上下文大小的大型模型，这引入了在计算需求方面的挑战。

- **已有的工作**
    现有的LLM训练方法依赖于使用外部通道相关性标签进行培训，这些标签可能来自人类裁判的判断或者由教师模型生成的排名。这一策略和仅利用LLM内在的信息理解和处理能力进行排名的方法形成对比。

#### 核心贡献
- **提出了一个xxx**
    - **挑战1：如何在不影响效果的前提下减小模型大小**
        本研究提出了两种方法LiT5-Distill和LiT5-Score，这两种方法使得即便是远小于现有最先进模型的模型，也能展示出与之媲美的重新排序效果。这挑战了大型模型对于有效零样本重新排序的必要性，并为更高效的列表级重新排序解决方案提供了可能性。

    - **挑战2：如何消除在重新排序训练中依赖外部通道相关性标签的必要性**
        LiT5-Score方法探索了通过交叉关注点来计算相关性得分以进行重新排序的方法，这消除了在训练中依赖外部通道相关性标签的必要性。同时展示了使用交叉关注分数的FiD模型可以基于上下文通道对查询作出反应，从而有效地进行再排序。

#### 实现与部署
在MS MARCO和BEIR数据集上得到的结果表明，即便是参数规模小得多的模型，也能达到与大型模型媲美的重新排序效果。研究还通过在原有的序列到序列编码器-解码器重新排序模型的基础上增加新功能来提高其效率和准确性。

#### 总结
这篇论文提出了LiT5-Distill和LiT5-Score两种序列到序列的编码器-解码器模型，用于有效的零样本列表级重新排序。这些方法不仅在模型效果上竞争力强，并且解决了传统依赖于大型LLM和外部相关性标签的问题，展示了在这一领域的优化和进步。