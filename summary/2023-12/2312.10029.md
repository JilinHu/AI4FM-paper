#### 背景
- **背景**       
    文章介绍了现代大型语言模型（Large Language Models, LLMs）在各种任务中的良好表现，这表明它们系统地融入了关于世界的信息，也就是“知识”。然而，访问LLMs中的知识是一个挑战，因为LLMs输出的事实性陈述并不总是描述其内部编码的知识。

- **已有的工作**
    现有的工作介绍了一种学习算法——无监督的对比一致性搜索（contrast-consistent search, CCS），用以发掘LLMs中的隐性知识。其核心假设是知识满足一种一致性结构，可以通过CCS损失函数来发现。然而，作者指出CCS一致性结构对于识别知识不仅仅是略有不准确，它与任意模式都兼容，这意味着现有的方法不足以探索LLMs中的隐性知识。

#### 核心贡献
- **理论证明**
    - **挑战1：CCS一致性结构的有效性**
        文中首先理论证明任意的二值分类器在CCS损失下都是最优的，然后证明存在一个保持CCS损失的变换到任意分类器。这表明CCS一致性结构并不是特有于知识，而是与任意模式都兼容，进而对发掘知识的准确性造成挑战。

    - **挑战2：无监督方法检测的特征**
        通过一系列实验，文章展示了在实践中无监督方法（如CCS）并未能发现知识，而是学习了其他更突出的特征。这说明现有的无监督方法在实际发现LLMs中的潜在知识时是不足够的。

#### 实现与部署
在一系列实验中，作者证明了无监督方法（如CCS和PCA）在实际应用中存在明显的问题。例如，它们倾向于学习噪声数据（如额外添加的意见）而非知识，对提示的细微变化很敏感，并且没有原则上的理由选择特定的提示。实验证明了，尽管CCS和PCA的原理不同，它们生成的预测非常类似，这表明CCS并不是利用知识的一致性结构，而这一点可能会被未来的方法继续存在。

#### 总结
本文通过理论证明和实验验证，挑战了现有无监督方法在探索LLMs中隐性知识的能力，并提出了未来评估知识启发方法时应考虑的理智检查。总体上，作者认为未来的无监督方法很可能会遇到类似的问题，即难以准确区分模型知识和其他特征。