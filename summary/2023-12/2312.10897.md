#### 背景
- **背景**       
    文章介绍了泛化类别发现（Generalized Category Discovery, GCD）的重要性，即在使用少量只包含已知类别的标注数据时，从无标签数据集中识别已知和新的类别。现有方法通常在新类别上表现不佳，且由于缺乏监督和类别信息，无法揭示发现集群的语义含义，这限制了它们在现实世界中的应用。

- **已有的工作**
    已有工作通常先对标注数据进行监督预训练和自监督学习，然后使用如KMeans等聚类方法来发现已知和新类别。然而，这些方法往往只能提升对已知类别的表现，对新类别由于缺少监督而表现不佳。此外，它们还难以揭示分类群集的语义含义（例如类别名称或描述），因为新类别缺乏先验知识。尽管大型语言模型（LLMs）如ChatGPT在没有任何标注样本的情况下也显示出了卓越的应用能力，但LLMs不能直接应用于需要聚类成千上万个样本的GCD问题。

#### 核心贡献
- **提出了一个名为Loop的端到端主动学习框架**
    - **挑战1：错误集群划分的可能性高的样本识别**
        挑战在于如何有效地选择那些可能被错误分类的样本。论文通过局部不一致采样选择这些样本，基于邻域预测一致性和簇分配概率的熵进行选择，从而克服这一挑战。

    - **挑战2：真实邻居选择与语义解释的生成**
        挑战在于如何准确选择样本的真实邻居，并为发现的新类别生成语义解释（如类别名称）。论文提出了一个可扩展的查询策略，让LLMs从多個候选样本中选择真实邻居，并利用精炼邻域对比学习（Refined Neighborhood Contrastive Learning, RNCL）来拉近样本与它们的邻居，以学习有利于聚类的表示。最后，从对应于新类别的簇中选择代表性样本，让LLMs为其生成类别名称，从而解决了这一挑战。

#### 实现与部署
根据与LLMs的反馈，研究人员进行了精炼的邻域对比学习，选择针对新类别的代表样本，并让LLMs生成这些新类别的名称。在三个基准数据集上进行的广泛实验表明，Loop框架在性能上大幅超越了当前最先进的模型，并且能为发现的簇生成准确的类别名称。研究结果表明，Loop的H-score在不同的数据集上分别达到了74.60%，91.57%，和90.74%，相较于前一最佳方法分别提高了13.01%，8.44%，和6.18%。

#### 总结
本论文提出了一个端到端的主动学习框架，该框架通过引入大型语言模型进入训练循环，有效地提升了模型在泛化类别发现任务上的性能，并能自动生成类别名称。