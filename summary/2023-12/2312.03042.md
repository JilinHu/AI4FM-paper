#### 背景
- **背景**       
    论文讨论了大型语言模型（如ChatGPT）在空间信息处理方面的困难，尤其是在二维和三维路径规划领域。尽管LLM在遵循指令等方面展现出了显著能力，当前的评估标准已经过时，缺乏针对LLM空间理解和推理能力的专门评估。

- **已有的工作**
    已有工作主要集中在综合评估LLMs的处理广泛世界知识和复杂任务的推理能力，但目前没有专门针对LLMs空间理解和推理能力的基准评估。

#### 核心贡献
- **提出了一个创新的评估框架和数据集**
    - **挑战1：空间理解能力评估缺乏**
        实验针对LLM在处理空间信息能力，特别是3D空间信息的局限性，提出了新的评估框架，入手于评估和量化GPT-4这样的模型如何处理空间信息。

    - **挑战2：专门数据集的缺失**
        作者专门设计了一个数据集，结合了三个关键任务：标记空间点、在二维空间规划路线和在三维环境设计路径，以便更具体地评估LLMs在空间推理方面的能力。

#### 实现与部署
实验通过与现有工作比较，显示本工作在更高的难度级别上评估语言模型在空间推理方面的性能。作者设计了可调节难度级别的任务，通过特定规则生成的一组独特的可解决问题，使用传统方法生成标准答案，然后评估GPT-4的表现，并自动验证LLMs产生的答案的有效性和正确性。

#### 总结
论文为GPT-4等大型语言模型在处理空间信息方面的能力提供了新的评估框架和专门设计的数据集，并分析了GPT-4在处理空间信息方面的能力和局限性。