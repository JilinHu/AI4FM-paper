#### 背景
- **背景**       
    文章介绍了当前自然语言处理中大型语言模型（LLMs）在真实世界任务中展现出与人类相媲美的语言理解与生成能力，并被认为是实现人工通用智能（AGI）的潜在途径。然而，现有的开源LLMs多数针对英语场景设计，中文场景表现不佳。针对这个问题，该论文提出了YAYI 2模型，它针对多语言场景进行了训练。

- **已有的工作**
    其他的开源LLMs，例如Llama和Falcon，尽管在性能上可以与专有模型相媲美，但它们主要设计用于英语环境，缺乏针对中文上下文的优化，导致它们在中文任务上表现不佳。为了弥补这一缺陷，已经有一些以中文为基础的LLMs被提出，但仍需进一步拓展和优化以覆盖更广泛的多语言使用场景。

#### 核心贡献
- **提出了一个名为YAYI 2的多语言大型语言模型**
    - **挑战1：多语言识别与理解**
        YAYI 2模型具有30亿参数，并且从零开始在包含2.65万亿个符号的多语言语料库上进行预训练。模型通过监督式微调和人类反馈的增强学习与人类价值观进行对齐。

    - **挑战2：数据处理及模型训练**
        为了提高数据质量，开发了自建数据处理流程。通过训练，模型累积各种知识并习得数学、编码和逻辑推理等专业能力，以提升模型对多语种场景和多样化数据格式的响应能力。

#### 实现与部署
论文描述了YAYI 2模型的训练过程，包括预训练数据的获取、多语言分词器的构建、模型架构的详细信息以及计算集群配置和训练策略。此外，论文还展示了如何通过多个基准测试来验证提出的基础模型的有效性。基于这些测试，YAYI 2表现出优于其他同等规模开源LLMs的性能，并在某些基准测试中甚至超过了参数更大的LLMs。

#### 总结
该论文提出了YAYI 2，一个针对多语言场景优化的大型语言模型，通过在大规模语料库上进行预训练，并通过多种方法与人类价值观对齐，显著提升了模型在多种任务中的表现，特别是在中文相关任务上。