#### 背景
- **背景**       
    文章介绍了条件生成图像研究领域的迅速发展，尤其是在如何有效评估各种模型的性能和能力方面存在的挑战，其中包括有限的可解释性问题。

- **已有的工作**
    论文指出，现有的评估技术（比如LPIPS、CLIP-Score和DreamSim）存在限制：它们通常是对结束任务不敏感，可能无法衡量生成图像想要展现的特定方面；评分结果不透明，可解释性有限。此外，一些研究工作依赖于人工评估方法，但这些方法在规模可扩展性和偏好主观性上存在挑战，这突显了在该领域内需更加统一的评估方法。

#### 核心贡献
- **提出了一个VIEScore (Visual Instruction-guided Explainable Score)**
    - **挑战1：任务意识**
        VIEScore可以承接所有条件图像生成的评估过程，因为它具有指导性的属性。它可以根据不同的指令需求进行精确调整，为解决传统度量标准设计不当的问题而设计。

    - **挑战2：可解释性**
        与生成单一浮点数评分的现有度量标准不同，VIEScore能够提供自然语言形式的评价理由，帮助人类理解评估过程。这大大提高了VIEScore的信任度，并解决了现有度量标准不足以提供详尽解释的问题。

#### 实现与部署
VIEScore通过多模态大型语言模型（MLLMs），如GPT-4和LLaVA实现，可以接收图像输入并生成类似人类的文本回应。它不需要训练或微调即可使用，并且在对七个重要的条件图像任务进行评估时，VIEScore（使用GPT-4-v）与人类评估的斯皮尔曼相关性高达0.3，而人与人之间的评估相关性为0.45。VIEScore在生成任务中与人类评分相当，但在编辑任务中表现不佳。

#### 总结
该论文提出了一个名为VIEScore的评估框架，旨在提供对条件图像生成任务的可解释性评价。VIEScore克服了现有自动化度量无法解释评分理由的挑战，并能够适应各种任务需求。