#### 背景
- **背景**       
    文章介绍了当前大型语言模型（LLMs）在数学问题解决中的应用。针对几何问题，当前的多模态大型语言模型（MLLMs）常常无法正确理解几何图形和其内在的关系。这样的情况限制了模型解决涉及几何信息的问题的能力。比如，现有的MLLMs在面对几何图形时，经常产生不准确的描述，说明这些模型在理解基础几何元素及其相互关系上存在明显不足。

- **已有的工作**
    现有的MLLMs 通常使用通用领域的图片和描述进行训练，这导致模型难以准确理解几何认知所需的语义。尽管可以通过增加与几何信息相关的描述来增强这些模型的能力，但是，最大的公共可用几何问题数据集大小有限，且缺乏几何图像的描述，这限制了模型对基本几何元素的理解以及解题能力。

#### 核心贡献
- **提出了一个新的多模态几何数据集 Geo170K**
    - **挑战1：几何图形理解**
        现有MLLMs在处理标注有几何信息的图像时表现不佳。为了应对这一挑战，论文基于现有数据集并利用纯文本语言模型（如 ChatGPT），通过融入几何逻辑形态的独特性、几何表示的唯一性以及几何的可扩展性等特点，构建了一个新的多模态几何数据集 Geo170K，其中包含约 6 万个几何图像-标题对和逾 11 万个问题-答案对，是GeoQA+ 数据集的 28 倍，大幅扩展了几何问题的覆盖范围。
    - **挑战2：MLLMs的理解能力与几何问题解决**
        针对现有模型在理解几何图形和问题解决能力方面存在的限制，论文开发了以 Geo170K 为基础的 G-LLaVA，一个强大的MLLM，能够解决几何问题，且性能大幅超过现有的最先进模型。特别是在 MathVista 的 GPS 小测试集上，G-LLaVA-13B 的性能比 LLaVA-13B 提高了 27.4，7B 参数的G-LLaVA 甚至超过了 GPT4-V。

#### 实现与部署
G-LLaVA 在 Geo170K 数据集的基础上，展现出卓越的几何问题解决能力。特别是它的一个分支 G-LLaVA-13B，在 MathVista 的 GPS 小测试集上比 LLaVA-13B 的性能提高了 27.4。即使只使用 7B 参数的 G-LLaVA，它也能在几何问题解决测试中超过性能强大的 GPT-4-V。此外，论文承诺在未来提供代码和数据资源，以供更广泛的研究和开发使用。

#### 总结
这篇论文通过构建 Geo170K 数据集和开发基于它的 G-LLaVA 模型，克服了多模态大型语言模型在解决几何问题上的限制，并实现了比现有最先端模型更好的性能。