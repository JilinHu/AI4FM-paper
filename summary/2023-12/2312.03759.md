#### 背景
- **背景**       
    随着大型语言模型(LLMs)的出现，科学界开始探讨这些模型在提高科研质量方面的潜力以及应当如何使用这些模型来加速科学实践。LLMs的发展引发了一系列重要且非平凡的问题：它们实际上是改善了我们的科学产出，抑或是阻碍了良好的科学实践？结合伴随而来的伦理和法律问题，我们应该在多大程度上使用这些模型？

- **已有的工作**
    已有的观点主要集中在LLMs作为提供知识或技术支持的研究助手，但同时也强调LLMs固有的局限性和可能引起的偏见。这些观点建议我们对LLMs持审慎态度，并强调尽管LLMs在编程、写作支持、知识提取等方面的应用有助于科学实践的质量提升，我们仍然需要认识到它们可能带来的误差和错误。

#### 核心贡献
- **提出了社会科学中LLMs应用的长期影响的讨论**
    - **挑战1：保护现状与面向未来**
        论文提出，我们有责任确保工作的质量和完整性，并坚持现行的科学实践规则。同时指出，LLMs虽然能提供即时、准确的反馈，有利于改进科学流程，如文献审核，但对其使用也应有所限制，尤其是考虑到模型可能带来的隐私和可复制性问题。

    - **挑战2：机器写作与科学认证**
        科学是一个社会过程，不能自动完成。LLMs在审稿和甚至在某些科学活动中发挥作用的设想过于乐观。论文强调不应该高估LLMs输出审核所需的时间，并质疑它们在科学活动中的适用性。认为LLMs在科学中通常被错误地使用及过度炒作。

#### 实现与部署
论文最终倾向于认为LLMs是辅助工具而非直接的科研参与者。作者认为避免对LLMs人格化非常关键，它们不是研究助理；它们只能产生错误，使用这些工具的人需要理解它们的功能并小心使用。论文也谈到了专门为特定任务设计的模型相对于LLMs在效率、性能、可解释性和易于修复方面的优势。总之，科学是由科学家间的对话构成的，那些仅设计用于生成表面合理的文字的模型不能取代科学探讨中的人类互动。

#### 总结
本文讨论了LLMs对科学实践的影响，并建议对其使用持审慎态度，同时强调了保护科学的规范和认识论方面的重要性。虽然LLMs可能提升某些科研任务的效率，但作为工具，其使用应该谨慎并确保符合科学规范。