#### 背景
- **背景**       
    本文讨论了使用大型语言模型（LLMs）自动化测试网络协议实现的方法。现有的方法需要员工对特定(网络)协议进行大量人工建模，对执行过程进行精确控制，以确保测试用例的覆盖面和细致程度。这可能导致耗时数月才能建立有效的协议模型。而且生成的测试用例也未必能覆盖所有可能的执行路径。

- **已有的工作**
    传统的模型基础测试方法（MBT）虽然能够发现很多新的缺陷，但需要大量的手动工作来精确表述协议规范。此外，直接从LLMs中生成测试用例也不能保证测试用例的覆盖性或完整性。

#### 核心贡献
- **提出了一个基于神谕的测试方法**
    - **挑战1：全面性测试**
        现有的LLM生成测试用例方法无法保证测试用例的覆盖性和全面性。作者提出的基于神谕的测试结合了LLM和传统的符号执行测试生成，通过利用LLM建立丰富的协议行为模型，并使用符号程序执行系统地衍生出详尽的测试用例。

    - **挑战2：有效输入**
        协议通常具有高度结构化的输入，而生成无效输入会使测试变得无意义。利用LLM生成正确格式和正确类型的示例并不总是直接的。因此，作者提出的方法能够保证LLM生成的示例满足可能的复杂输入约束。

    - **挑战3：模块测试**
        许多协议高度复杂并包含多个组件。作者的工作提供了一种方法，可以将这些复杂的协议分解成更容易由LLM测试的更小的模块组件。
        
    - **挑战4：带符号输入的测试生成**
        与挑战二相关，一些提出的方法需要额外的抽象层来帮助LLM与传统的符号执行工具集成。这意味着，即使是LLM生成的代码，也能保证输入测试的正确性。实现这一点需要工具提供的特殊抽象来补充LLM，并且能够由符号执行引擎强制执行所有LLM模型测试的额外有效性约束。

#### 实现与部署
Eywa是实现基于神谕测试的Python库，它为描述协议组件及其约束条件提供了新的抽象描述。Eywa不仅可以利用LLM自动生成C语言代码实现协议模型，同时还会生成一个符号测试工具，以将此模型与Klee符号执行引擎相集成。通过Klee执行，Eywa可以获得能够引发代码中不同执行路径的所有符号输入值。效果评估显示，通过Eywa对DNS协议的案例研究，发现了包括11个以前未发现的新缺陷在内的26个独特缺陷，对十个广泛使用的DNS实现进行了测试。

#### 总结
本文介绍了基于神谕的测试方法，充分利用LLMs建立了丰富的协议行为模型，并通过符号执行和传统测试生成方法相结合，提升了网络协议测试用例的自动生成和覆盖面。