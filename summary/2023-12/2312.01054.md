#### 背景
- **背景**       
    该论文探讨了大型语言模型（LLMs）在空间推理能力方面的表现，特别是在处理数值轨迹数据时的性能。尽管LLMs在序列建模和一般模式识别方面显示出强大的能力，但其在空间推理——特别是针对数值轨迹数据的——能力仍未充分探讨。

- **已有的工作**
    先前的研究表明，LLMs能够改进和完成低水平的机器人动作序列或者重复的进程，如正弦波。然而，对于完整序列的标注——这需要长期上下文保持、语义理解以将序列与其文本注释联系起来、以及对非重复复杂模式的泛化——尚未解决。已有的工作或者是评估较短的序列、排除了更高维度的分析，或是使用了附加的令牌嵌入模型。总体上，LLMs在空间推理能力上表现很差。该论文通过解决LLMs在未充分探索的高维轨迹识别子问题上的固有性能来扩展这些工作。

#### 核心贡献
- **提出了一个xxx**
    - **挑战1：空间推理能力**
        在没有接受过特定空间信息训练的情况下，研究了它们识别简单空间模式（如圆形或直接方向）的能力，并探讨了LLMs在辨识更复杂的空间模式（如不规则的3D轨迹）时是否面临困难。此外，研究了在简单空间任务到更复杂任务间是否存在知识迁移，以及如何影响整体性能。

    - **挑战2：数据类型的理解**
        该研究集中于直接理解连续的3D点序列，这在以零样本（zero-shot）的方式理解控制级别（例如轨迹）上仍是一个开放性问题。先前的工作要么使用视觉模型或联合视觉-语言模型来整合视觉嵌入，要么在提示中添加有限数量的由检测模型获取的3D物体位置，但这篇论文通过关注提示侧对连续3D点序列的理解来区分自身。
    - ...

#### 实现与部署
论文中介绍了一种新颖的以前缀为基础的提示机制，这在3D轨迹数据上带来了33%的性能提升，在SpartQA任务上相对于零样本提示（zero-shot prompting）也有多达10%的提升。实验结果表明，该方法不仅在研究LLMs处理数值和空间信息的方式方面提供了有趣的洞见，而且为未来增强目标领域的识别奠定了坚实的基础。论文指出其他提示类型（例如In-context Learning和Chain-of-Thought）也可从这种新前缀提示机制中受益。

#### 总结
论文提高了对LLMs在空间推理和序列标注方面能力的理解，提出了一种改进LLMs处理3D轨迹识别任务的方法，具有显著的性能提升。