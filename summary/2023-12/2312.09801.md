#### 背景
- **背景**       
    文章介绍了通过与大型语言模型（LLM）的互动，可以刺激学生的创造性/批判性思维和写作能力。由于担心学生在写作中作弊，许多教育工作者选择禁止使用LLM，因为这些模型的输出很难区分，且某些情况下几乎与人类无异。这些模型也因为产生假“事实”即幻觉而声名狼藉。

- **已有的工作**
    现有的工作没有明确提出一个能够在防止学生作弊的同时，利用这些AI工具来提高学生批判性思维和写作能力的方法。同样，LLMs目前的输出有时过于冗长，并且不太适合用于教育评价中对批判性思维和独立写作能力的培养。

#### 核心贡献
- **提出了一个名为Probing Chain-of-Thought (ProCoT)的方法**
    - **挑战1：防止学生通过使用LLM作弊**
        LLM的当前局限性意味着其生成的输出可以通过比较容易地与人类写作相区分来防止作弊。通过要求学生挑选他们自己的作品中可以用同行评审引用证实或反驳的陈述，并将这些输出与LLM生成的ProCoT输出进行比较，可以防止学生作弊。

    - **挑战2：通过与LLM互动刺激学生的批判性思维与写作**
        实证研究表明，与LLM的互动实际上可以促进学生的批判性思维和写作能力。与仅仅使用LLM生成的输出相比，学生的ProCoT输出展示了良好的创造性和批判性思维。

#### 实现与部署
研究是在两个不同的课程中进行的，涉及约66名学生。研究示范了ProCoT方法如何有助于阻止学生作弊，并鼓励他们进行深入思考和辩论。学生被要求选择一个问题，并使用LLM（大多数使用ChatGPT）产生一个输出，然后需要使用同行评审的引用来证实或反驳LLM输出中的陈述。结果显示学生倾向于使用比LLM少的词语量进行回答，表明了他们更倾向于简洁的回答方式。此外，与学生自己的ProCoT输出相比，LLM的ProCoT输出也显示出LLM的局限。

#### 总结
本文通过引入ProCoT方法，展示了如何利用LLM促进学生批判性思维与写作，同时防止作弊。这种方法有助于教育者更好地利用这些技术工具，并培养学生成为更好的批判性思维者。