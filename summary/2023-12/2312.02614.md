#### 背景
- **背景**       
    文章介绍了对于大规模语言模型（LLMs）的推理和利用，突出了现有模型在进行in-context learning（ICL）时的一些局限性和优化需求。

- **已有的工作**
    传统的对抗学习（如GANs）导致了在多个领域的重大进展，但这种方法在预训练大型语言模型时由于数据和计算资源限制变得不切实际，特别是在数据稀缺的新领域中，这就需要通过使用有限的数据来提高模型性能的方法。

#### 核心贡献
- **提出了一个Adversarial In-Context Learning (adv-ICL) 方法**
    - **挑战1：优化ICL中的prompt选择问题**
        传统GAN需要通过后向传播更新模型参数，对于大型预训练模型来说不可行。论文提出了adv-ICL方法，通过对抗学习的方式在不更新模型参数的前提下优化prompt，使用三个LLM模块：生成器、鉴别器和prompt修改器来实现prompt优化，从而有效提高LLM在多个任务上的性能。

    - **挑战2：在资源受限的背景下提高LLM性能**
        由于adv-ICL依赖预先训练好的模型并且只更新prompt而非模型参数，因此在数据和计算资源有限的设置下依然有效。通过prompt的编辑来提升逆向损失，方法实现计算上高效，容易扩展到任何LLM和任务上。

#### 实现与部署
adv-ICL被用于对比聊天机器人的优化技巧，结果显示该方法在各个配置和任务上比其他最先进的prompt优化技术表现更好。例如，它将ChatGPT在MMLU、GSM8K以及BBH任务上的准确率分别提升了3.0%、2.4%、1.9%。而且计算效率高，需要的迭代次数和训练样本少，在仅进行五轮训练后就显著提升了性能。同时，由于该方法易于实现，也鼓励其在实际应用中的使用。

#### 总结
论文介绍了一个新颖的Adversarial In-Context Learning（adv-ICL）方法，用于优化大型模型中prompt的选择，以此提高模型性能。它可以实现对抗训练目标，克服数据和计算资源限制，通过优化prompt而不是模型参数来提升性能，且实验结果在多个任务上显著优于现有技术。