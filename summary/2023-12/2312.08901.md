#### 背景
- **背景**       
    论文讨论了大型语言模型(LLMs)在各种任务中表现出色，但在数学推理方面却遇到了困难。尽管已有研究尝试优化思维链路（Chain-of-Thought，CoT）提示和微调LLMs，但仍没有充分探索少样本学习在提高数学推理能力方面的潜力。

- **已有的工作**
    现有的研究集中在优化CoT提示和在零样本（zero-shot）设置下微调LLMs，未能探索少样本学习（few-shot learning）在提升数学推理方面的潜力。此外，现有方法在压缩提示或选择有用示例方面性能有限，特别是在数学推理任务中不尽理想。

#### 核心贡献
- **提出了一个名为CoT-Max的新方法**
    - **挑战1：选择有用的示例和由于受限的上下文窗口长度导致的示例数量有限**
        CoT-Max引入了一个粗到细的剪枝器作为LLMs的即插即用模块，首先从大批量CoT示例中识别关键示例，然后进一步剪除不重要的标记。通过搜集具有多样难度和步骤的数学推理数据集，引入奖励来衡量输入对数学推理的有效性及标记长度限制，并提出了一种结合强化学习的新训练方法。

    - **挑战2：扩展上下文窗口长度需要昂贵的LLM微调和增加推理开销，现有压缩提示方法在数学推理任务中表现不佳**
        CoT-Max通过剪枝方法优化输入上下文，不需要额外的微调或增加推理成本即可显著提升数学推理能力，并不会增加推理开销。

#### 实现与部署
CoT-Max在各种LLMs和五个数学数据集上的广泛实验证明了其有效性。CoT-Max显著增强了LLM的推理能力，在数学推理准确性上建立了新的基于提示的基准，无需任何微调或额外推理成本，就取得了2.13%-4.55%的绝对改进。尤为值得注意的是，LLaMA2-70B配合CoT-Max在GSM8K数据集上超过了GPT-3.5和一系列更大型的LLMs，并在示例选择和标识关键标记方面显著优于检索和提示压缩基准。

#### 总结
这篇论文提出了CoT-Max，一个通过粗到细的剪枝技术来增强LLMs数学推理能力的方法，有效地提高了少样本学习在数学推理任务中的效果。