#### 背景
- **背景**       
    论文讨论了大型语言模型（LLMs）在复杂的语言建模任务中的显著表现。然而，LLMs在计算和存储需求上的高要求为它们在边缘设备上的广泛使用带来了障碍。为了提高设备效率，提出了量化策略。目前研究表明，用8位或以下进行权重量化对端到端任务性能的影响很小，但激活值的量化仍未实现。另外，主流的边缘设备往往难以有效执行这些低于8位的量化网络。

- **已有的工作**
    目前的工作主要集中在采用4位进行权重量化，但保留激活值的浮点表示（FP16）。这种做法使模型在常见边缘设备上的快速推理受到限制，因为这些设备通常只支持16x16和8x8整数乘法器。特别是在模型规模增大时，激活值中出现显著的异常值，量化激活值往往对任务性能造成负面影响。而且，大型模型对计算能力的要求使得许多学术研究机构难以承担相关的训练成本。因此，虽然后训练量化（PTQ）成为了一种流行的方法，但它并没有最小化由于激活值中的异常值所造成的量化误差。

#### 核心贡献
- **提出了一个名为Agile-Quant的框架**
    - **挑战1：激活量化和异常值处理**
        论文提出的Agile-Quant框架，考虑到硬件延迟剖析和LLMs的激活分析，首先引入了一个基本的激活量化策略，以平衡任务性能和真实推理速度的权衡。然后，论文利用激活感知的token修剪技术来减少异常值和对注意力的负面影响，在数量上通常围绕相同或相邻通道的不同Token分布，通过修剪Token可以有效地消除一些异常值。

    - **挑战2：边缘设备上的硬件实现优化**
        论文为LLMs设计了针对边缘设备的优化实施方案，以充分利用SIMD指令，包括基于SIMD的4位乘法器，以及有效的TRIP二维改进修剪矩阵乘法，减轻异常值的负面影响。

#### 实现与部署
在不同规模的LLMs，包括LLaMA、OPT和BLOOM上应用Agile-Quant框架，进行了4位或8位的激活量化以及4位的权重量化。实验表明，Agile-Quant实现了模型权重和激活的同时量化，同时保持了与现有仅权重量化方法相当的任务性能。在4位和8位场景中，Agile-Quant在多个边缘设备上实现了最高2.55倍的设备加速，与FP16版本相比，在这个领域标志着开创性的进步。

#### 总结
本文提出了一个名为Agile-Quant的激活引导量化框架，以加速大型语言模型的边缘设备推理。Agile-Quant克服了激活值异常的挑战和边缘设备上的硬件实施问题，并实现了与仅权重量化方法相当的任务性能，同时在实际设备上获得了显著的推理速度提升。