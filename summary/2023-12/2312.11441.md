#### 背景
- **背景**       
    论文介绍了大型语言模型(Large Language Models, LLMs)在个人助理和企业代理中的应用，并强调了信息传递和协作的重要性。然而私密信息的安全传输和隐私保护是现有研究尚未解决的挑战。

- **已有的工作**
    由于隐私泄露的担忧，当前的作品无法在保护用户隐私的同时，实现LLMs之间的知识传递。

#### 核心贡献
- **提出了社交学习（social learning）框架**
    - **挑战1：如何在不泄露私密信息的情况下传递知识**
        社交学习框架允许代理生成例子和指令，以针对特定任务传递信息，同时强调保护共享的例子和知识的隐私。这提供了一种在不共享私人数据的情况下，以人类可解释的方式传递知识的方法。

    - **挑战2：如何评估社交学习方法**
        本论文通过多个任务的基准实现并评估社交学习，同时建立度量私有数据泄露的指标，证明了社交学习在保护隐私的同时具有积极效益。

#### 实现与部署
对于学习协议的实现，本文设计了一个用例，即短信服务(SMS)中的垃圾信息探测。在这个设置中，多个“老师”代理通过文本交互将任务传达给一个“学生”代理，但不共享原始例子以保护隐私。学生在训练时作为聚合器，从老师那里选取一部分例子，而在推理时根据这些传输的知识来回答任务实例。论文中通过不同的数据集和隐私量化方法来评估这些方法，并显示出与使用原始标签和提示相比，结果具有可比性，且对原始数据的记忆化程度低。

#### 总结
本文提出了在LLMs中实现知识传递的新框架—社交学习，并提供了保护隐私的解决方案。该框架通过自然语言在模型间交换知识，同时避免敏感信息泄露，并通过实验验证了其有效性和隐私保护能力。