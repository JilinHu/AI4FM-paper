#### 背景
- **背景**       
    该论文探讨了在数据匮乏的情况下进行机器学习的重要挑战，尤其是在低收入和中等收入国家。在这些地区，由于受限的数字基础设施，获取大型数据集的能力很有限或者根本不存在。这导致这些地区在机器学习的进展方面处于边缘地带，无法发展准确的模型。

- **已有的工作**
    已有的工作多集中于通过生成模型或传统方法进行数据增强来解决数据匮乏问题。但这些方法在极低数据设定（n < 100）下未能很好地描述完整的数据分布，这会导致生成的数据不够多样化和准确，限制了基于这些数据训练的预测模型的泛化能力。还有研究通过迁移学习框架来解决表格数据的数据匮乏问题，但这通常前提是存在先验知识源，比如预训练模型或知识图谱，而这些在所有设置中都不一定可用。

#### 核心贡献
- **提出了一个名为 CLLM (Curated LLM) 的方法**
    - **挑战1：在极低数据设定下的数据增强和泛化能力**
        CLLM 使用 LLM（大型语言模型）的先验知识来降低计算负担，并假设用于预训练的多样化语料库对于增强生成的多样性十分有价值。然而，并非所有LLM生成的数据对下游任务都是有用的，因此需要系统地评估生成的数据。

    - **挑战2：保证生成的数据对下游模型的有用性**
      CLLM 引入了一个原理化的数据策展过程，该过程利用学习动态以及置信度和不确定性度量来获取高质量数据集。这种方法专注于学习一个小型真实数据集上训练的模型的学习动态，并通过计算两个关键度量：置信度和内在（数据）不确定性，这些度量作为策展合成样本的基础。

#### 实现与部署
CLLM的实证研究展示了在多个真实世界数据集上，与传统的生成器相比，LLMs在数据匮乏的设定下的优越性能。该方法还展示了其策展机制能够提高包括LLM在内的所有生成器的下游性能。此外，研究还提供了对LLM生成和策展机制的洞察，并解释了它们生成高质量增强数据集的特征。

#### 总结
本文介绍了CLLM，这是一种结合了大型语言模型的先验知识和强大的数据中心方法来进行数据增强的新方法，旨在为资料匮乏的领域和地区的机器学习提供了新的途径。