#### 背景
- **背景**       
    随着大型语言模型（LLMs）的快速发展，越来越需要能够利用LLMs做出决策以实现人工智能的目标。目前多数方法使用手工制作的示例来提示LLMs模仿人类的决策过程，但是优化提示的设计是困难的，而且这些固定模式的提示很难泛化到更复杂的环境中。

- **已有的工作**
    以往的研究使用手工制作的示例来引导LLMs，这导致在固定方向上做出决策。而且，一些方法无法在复杂的环境中生成可接受的决策，且一旦例子固定，模型无法从环境反馈中进一步学习和提高性能。

#### 核心贡献
- **提出了一个名为大规模决策模型与内存（LDM2）的新模型**
    - **挑战1：模仿人类的决策并适用于复杂环境**
        LDM2结合了动态内存机制来构建动态提示，以指导LLMs根据当前状态制定合适的决策。它分为内存形成和内存细化两个阶段：在内存形成阶段，利用LLMs的强大总结能力将人类行为分解为状态-动作对，并存储于内存中，该内存的索引是通过LLMs生成的，便于根据当前状态检索最相关的记忆子集。在细化阶段，LDM2进行树探索来发掘更合适的决策过程，并通过添加有价值的状态-动作对来丰富内存。

    - **挑战2：实现动态学习和适应新情境的能力**
        与传统的模仿学习不同，LDM2装备了动态内存细化阶段，通过探索与环境的反馈来增强内存，并将高奖励的状态-动作对添加到内存中，从而实现动态学习。这使得LDM2不仅扩展了LLMs的行动空间，而且能够处理初始内存未覆盖的新情况。

#### 实现与部署
在两个互动环境（WebShop和ALFworld）中评估了所提出的LDM2。结果显示，LDM2在得分和成功率方面优于标准的少量提示方法以及其他用口头推理提示的方法。还分析了两项任务中的成功案例，并发现LDM2比使用固定示例提示的方法有更多样化的行动空间优势，这使得LLMs能够处理未见过或复杂的情境。此外，通过消融实验评估了内存细化机制，结果证明了将高奖励的状态-动作对添加到内存中的有效性。

#### 总结
该论文提出了LDM2模型，它使用动态内存机制和树探索策略来增强LLMs的决策能力，使其能够适应更复杂和未知的环境，并实现动态学习能力。