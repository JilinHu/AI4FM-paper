#### 背景
- **背景**       
    论文提出，在自然语言处理中，语义文本相似性（Semantic Textual Similarity, STS）是一个重要任务，而现有的STS方法大多依赖于非监督技术或者仅部分与文本相似度相关的训练信号，比如基于NLI数据集的方法。

- **已有的工作**
    已有的STS方法无法有效解决训练数据匮乏的问题。尽管大型语言模型（LLMs）如GPT能根据句对生成准确的语义相似度分数，但每遇到新的句对都用GPT或其他LLMs生成STS分数成本太高且处理速度慢。

#### 核心贡献
- **提出了一个名为Sim-GPT的框架**
    - **挑战1：如何使用LLMs生成可靠的STS训练数据的同时解决成本问题**
        Sim-GPT使用GPT-4来一次性生成大量STS标注数据，以BERT或RoBERTa为基本骨架来训练STS模型，比起为每对句子反复调用LLM，这种方式能够长期节约成本和提高速度。

    - **挑战2：如何提高STS任务的模型表现**
        在GPT-4生成的646K（其中371K）及NLI数据集275K的数据上训练的Sim-GPT在七个广泛使用的STS基准测试上取得了最佳性能，与现有的有监督的SimCSE和最新的SOTA级的PromCSE模型相比，在性能上有显著提高。Sim-GPT框架不仅在提供训练信号和成本效益方面取得了突破，同时实际效果上也显现出优势。

#### 实现与部署
Sim-GPT在实现上使用LLMs生成高质量的标注数据，解决了STS模型训练过程中缺乏直接监督信号的问题。作者收集了来自GPT-4的371K STS标注示例，这些数据将会开放给社区以促进领域的进一步发展。在测试阶段，用这些数据训练的模型显著提高了STS基准测试的性能，例如在与Supervised-SimCSE（Gao et al. 2021）相比提高了0.99，在与当前的SOTA PromCSE（Jiang et al. 2022）模型相比提高了0.42。Sim-GPT展示了利用LLMs为STS任务提供强大训练信号的潜力，同时在成本和速度上优于反复调用LLMs的方法。

#### 总结
Sim-GPT是一个利用GPT-4生成数据标签来训练STS模型的框架。它在生成数据时仅产生一次性成本，速度较快，模型在多个STS基准上性能优越。