#### 背景
- **背景**       
   论文探讨了知识图谱上的会话式问题回答（ConvQA），这涉及到回答多轮自然语言问题以获取知识图谱中包含的信息。当前最先进的ConvQA方法经常难以处理隐晦的问题-回答对，这对于人类来说在考虑到对话历史后容易理解，但对于机器来说却难以解读，从而降低了ConvQA的性能。

- **已有的工作**
    由于ConvQA性能受到隐含问题-回答对的限制，以及存在的方法在处理含糊不清的输入时难以发挥作用，现有方法未能充分解决这一问题。

#### 核心贡献
- **提出了一个基于强化学习的模型CoRnNet**
    - **挑战1：提高ConvQA性能**
        CoRnNet 使用通过大型语言模型生成的问题改写来改进ConvQA性能。这个模型采用了教师-学生架构，教师模型通过人类编写的改写来学习问题表示，学生模型通过模仿教师模型的输出来间接学习，从而通过LLMs生成的改写达到接近人类水平的性能。

    - **挑战2：定位正确答案**
        CoRnNet 教授了一个强化学习模型，该模型使用学习到的问题表示在知识图谱里定位正确答案。这种方法在实验上证明比现有的state-of-the-art ConvQA模型有更好的性能。

#### 实现与部署
CoRnNet模型经实际数据集测试显示，在多轮对话问题回答任务中表现优越。在测试集中，不提供问题改写时，使用已训练的模型输出每个对话中每个问题的答案。通过与其他最先进的ConvQA模型对比，CoRnNet展示了较优的效果，这表明CoRnNet在改进ConvQA性能方面是有效的。

#### 总结
CoRnNet 是一种新型RL模型，用于在知识图谱上进行会话式问题回答并结合LLM生成的改写，展现了比其他先进模型更出色的性能。