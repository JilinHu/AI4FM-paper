#### 背景
- **背景**     
    论文提出了链式思考(Chain-of-Thought, CoT)引导大型语言模型(LLMs)进行逐步推理，并可以激励其逻辑推理能力。虽然CoT在逻辑任务中十分有效，但并不利于需要“跳出思维框架”（out-of-box）的创造性问题解决。对创新进展至关重要的创造性问题解决通常需要非顺序的、强关联的思考和知识跳跃。

- **已有的工作**
    现有工作没有充分展示LLMs在需要非顺序创造性思维和强远程联想的场景下的能力。CoT框架尽管提升了LLMs的精确性和逻辑处理能力，但对于需要强远程联想和创造性洞察力的任务则效果有限。

#### 核心贡献
- **提出了一个基于创建性思维的Creative Leap-of-Thought (CLoT)范式**
    - **挑战1：如何提升LLMs的Leap-of-Thought (LoT)能力进行创造性生成**
        构建了一种新的创造性LoT框架（CLoT），它通过两个阶段来增强LLMs的LoT能力。第一个阶段是关联性指导调优，将Oogiri-GO数据集转化为指导调优数据以训练LLM，提高其LoT能力。第二阶段是探索性自我完善，鼓励LLM生成更多创造性LoT数据并自我完善。
    - **挑战2：如何确保生成的LoT数据既高质量又具有多样性**
        通过探寻弱关联条件下概念之间的远程联想，LLM能够在给定的用户输入下生成创意回复的候选，并对这些多样化的回复进行排名，筛选出高质量的数据用于自我完善。这一方法利用了弱关联条件鼓励LLM进行创意探索，打破了传统认知限制。
    
#### 实现与部署
CLoT通过对Oogiri-GO数据集进行关联性指导调优和探索性自我完善的过程，显著提升了LLMs在多种创造性任务上的表现。实验结果展示，CLoT不仅在Oogiri游戏上的幽默生成中表现出色，还在诸如“猜云朵”和“发散性联想任务”等多种任务上提升了创造性能力，验证了其良好的概括和迁移能力。用户研究也表明，用户对CLoT生成的创意内容有强烈偏好。CLoT的提出不仅加深了我们对LLMs创造性能力的理解，还提供了一条改善该能力的路径。

#### 总结
本论文提出了一种旨在提升大型语言模型创造性思维能力的Creative Leap-of-Thought (CLoT)范式，并验证了其在多种任务中的有效性和概括能力。