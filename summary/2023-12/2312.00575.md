#### 背景
- **背景**       
    文章探究了指令调整（instruction-tuning）是否提升了大型语言模型（LLMs）与人类语言系统的对齐程度。研究评估了从7700万到330亿参数范围内的25个LLMs在人类阅读自然故事和句子的三个神经数据集上的表现。研究发现，指令调整普遍改善了LLMs表示与大脑活动的对齐。进一步研究揭示，世界知识和模型大小是大脑对齐的关键决定因素，这表明世界知识有助于塑造人类语言系统中的表示，并突显了将世界知识整合到未来LLMs发展中的重要性。

- **已有的工作**
    目前的研究主要聚焦于提升LLMs的性能和输出质量，并使其能够以最小的任务特定训练适应新任务。然而，这些研究往往忽视了指令调整如何改变LLMs内部表示以实现这些改进。使用大脑活动数据从神经科学的角度来解释这一点仍然是一个未解之谜。而先前的工作已经使用大脑活动的结果来解释神经网络，构建更高性能的模型，但尚未深入探究指令调整如何影响LLM的内部表示与大脑活动的对齐。

#### 核心贡献
- **提出了一个评估方法**
    - **挑战1：提高LLMs与大脑活动的对齐度**
        研究采用了先前的大脑评分包（Brain-Score）来训练线性函数，使用LLMs的表示作为输入特征来预测与人类语言系统相关的fMRI体素，并通过计算LLMs的表示与实际大脑活动数据之间的皮尔逊相关性来评估LLMs的大脑对齐度。这一方法揭示了指令调整与人类大脑记录的内部表示更加一致。
    - **挑战2：探索影响LLMs与人脑表示相似度的因素**
        通过计算LLMs大脑对齐度与模型的不同属性（如各种推理能力的基准测试表现、领域特定世界知识、语言建模能力和模型大小）之间的皮尔逊相关性，研究者识别了影响LLMs与人类大脑表示相似性的因素。结果显示，世界知识的表现力和模型大小是LLMs与人类大脑对齐的关键决定性因素。

#### 实现与部署
本研究发现，指令调整通常提高了大型语言模型与大脑活动之间的对齐。研究涉及的LLMs不仅包括由各种不同机构精调的模型版本，还有在不同类型的指令数据集上调整的模型。此外，研究还评估了模型在多领域知识基准测试（MMLU）和处理不同推理能力的基准测试（BBH）中的表现，以及这些表现与LLMs大脑对齐度之间的关系。研究表明，大脑对齐度与世界知识跨所有主题领域以及BBH中的世界知识类别呈现强相关，而与BBH中的其他问题解决能力（如算法或多语言推理）不显著相关。

#### 总结
本研究表明，通过指令调整训练的大型语言模型在世界知识表示方面以及与人脑活动的对齐程度上表现更佳。这为未来LLMs的发展提供了将世界知识集成到模型中的重要视角。