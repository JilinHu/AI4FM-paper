#### 背景
- **背景**       
    论文提出，尽管大型语言模型（LLM）在理解自然语言和Zero-Shot任务中表现突出，但其在知识限制方面仍存在问题。特别是在需要长逻辑链或复杂推理的场景中，LLM的知识限制和幻觉现象会限制其在问答（QA）中的表现。

- **已有的工作**
    针对LLM的知识限制和推理能力不足的问题，传统方法通过人工设计语法和规则进行推理，但这些方法缺乏普适性和可扩展性。随着表示学习的发展，嵌入式模型和神经网络用于提高KGQA（基于知识图谱的问答）任务的自动化和准确性。然而，这些方法依赖于嵌入式模型表征的准确性，仍然缺乏可解释性。

#### 核心贡献
- **提出了一个称为KnowledgeNavigator的新框架**
    - **挑战1：如何高效准确地从知识图谱中检索外部知识并用其加强LLM推理**
        KnowledgeNavigator首先挖掘和增强给定问题的潜在约束，以指导推理。然后，它通过迭代推理从知识图谱中检索和过滤支持回答的外部知识，最后将构建的结构化知识转换为LLM友好的提示，以辅助其推理。

    - **挑战2：如何克服知识图谱中的噪声和多跳搜索带来的挑战**
        KnowledgeNavigator预测给定问题所需的检索范围，并为其生成若干相似问题。借助问题的指导，它在知识图谱中迭代检索和过滤潜在的候选关系和实体，从而回忆起回答问题所需的知识。然后，该知识被聚合并转换为自然语言，以减少知识冗余并避免LLM对三元组的处理能力有限。

#### 实现与部署
KnowledgeNavigator在MetaQA和WebQSP等多个公开的KGQA基准数据集上进行评估，显示出该框架具有很高的有效性和泛化能力，超越了先前增强型知识图谱LLM方法，并与全监督模型相媲美。具体来说，KnowledgeNavigator在三个数据集上的表现分别超过了KV-Mem模型16.8%，46.1%，和36.8%，展现了其有效性和鲁棒性。此外，通过消融实验评估了KnowledgeNavigator内部不同组件对其性能的影响，结果显示每个部分都是有效且必不可少的。

#### 总结
这篇论文介绍了一个新型框架KnowledgeNavigator，它通过改善知识图谱上的推理过程，解决了LLM在复杂推理任务上的性能局限问题。实验结果证实了其有效性，并有望在高风险和高敏感领域推广LLM的应用。