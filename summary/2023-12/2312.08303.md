#### 背景
- **背景**       
    文章用于解决网络服务中有害内容的自动探测问题，现有的机器学习方法在准确性和跨数据集转移方面存在局限性。尽管最近的大型语言模型（LLMs）在零样本和少样本学习能力以及跨任务转移性方面显示出潜力，但设计高效的提示（prompting）方式仍然具有挑战性，并且高运行成本可能阻碍其在生产中的部署。

- **已有的工作**
    现有的工作通过监督学习的方式来自动探测网络有害内容。但因缺乏标准定义，尤其是隐性有害内容的数据标签获取困难；并且，这些方法可能会导致模型过拟合，限制了它们在其他数据集上的应用。另外，它们通常只能预测二分类标签，而没有详细的推理过程。

#### 核心贡献
- **提出了一种称为 "DToT" 的新型提示方法**
    - **挑战1：提高精度并缩小模型大小**
        面对LLMs在有害内容探测中高成本和低可转移性的问题，通过DToT方法赋予LLMs在零样本和少样本环境中更好的表现，并在不损害准确性的前提下细化并压缩模型，以便可以更有效地部署在生产环境中。

    - **挑战2：提升跨数据集转移能力**
        通过DToT提纯出的推理基础上，对较小的学生模型（student LMs）进行微调，使其可以在检测有害内容时预测标签和提出推理，从而提升其跨数据集的转移能力。

#### 实现与部署
实验结果表明，DToT方法在各种不同的数据集上都一致地提高了零样本和少样本学习的表现，准确率提高了高达4.6%。此外，使用DToT提取的推理进行微调的学生模型在所有数据集上的表现均超过了基准，准确率提高了高达16.9%，模型大小也比传统的LLMs小了60倍以上。此外，这些学生模型在跨数据集转移方面的表现也有显著提升。

#### 总结
文章针对现有的网络有害内容自动探测面临的问题，提出了一个称为BD-LLM的新方法，它通过一个新的方法DToT来提升LLMs在有害内容检测任务中的效能和转移性，并将优化模型压缩以便更有效地部署。