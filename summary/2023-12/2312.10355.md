#### 背景
- **背景**       
    近期自然语言生成（NLG）评估已从单一方面评估向多方面评估转变，以实现更精确的评估。大型语言模型（LLMs）在各种NLG评估任务上均展现出了卓越的性能。然而，当前的研究工作通常独立评估不同方面，这大大忽视了各种方面之间的丰富联系。

- **已有的工作**
    现有的工作由于缺少对不同NLG评估方面之间联系的考量，无法提供一个全面精准的评估结果。

#### 核心贡献
- **提出了一个叫作 CoAScore 的评估指标**
    - **挑战1：如何利用多方面知识在评估某一特定方面时提升评估精度？**
        提出 CoAScore 架构，使用LLMs 通过一系列相关方面的提示来评估目标方面的质量。首先提示 LLM 生成与目标方面相关的一系列方面，这些方面对于评估是有用的。然后为每个生成的方面收集评分，并最终利用这些方面的知识来提升目标方面的评估。

    - **挑战2：如何验证 CoAScore 的有效性并展示LLM在不同阶段的表现？**
        在五个NLG评估任务（例如，摘要生成、对话响应生成等）和九个评估方面（例如，整体质量、相关性、连贯性等）上评估 CoAScore，结果显示比起单独的方面评估，CoAScore 与人类判断的相关性更强。此外，还进行了广泛的消融研究来验证 CoAScore 框架内各个阶段的有效性，并进行案例研究以展示 LLM 在这些阶段的表现。

#### 实现与部署
CoAScore 通过三个阶段对NLG生成的文本进行评估：（1）生成与目标评估方面相关的方面链；（2）为假设中的每个生成方面评分；（3）利用有关相关方面链的知识来增强目标方面的评估能力。实验结果表明，在评估整体质量和其他方面时，CoAScore 显示出与人类判断的更高相关性，超过了现有的无监督基准。此外，随着相关方面数量的增加，CoAScore 与人类判断的相关性通常会变得更强。不同阶段的效果也分别通过比对实验得到了验证。

#### 总结
CoAScore 是一个新颖的评估指标，它通过“方面链”的方法提升了对于 NLG 任务的评估精度，并且该效果获得了实验的证实。