#### 背景
- **背景**       
    文章介绍了游戏理论作为一种分析工具，常用于社会科学研究中分析人类行为。由于大型语言模型 (LLMs) 的行为与人类行为高度一致，LLMs 被视为社会科学研究中替代人类参与游戏实验的有前途的研究方向。然而，目前关于将LLMs与游戏理论结合的研究很多，但LLMs在游戏理论中的能力界限仍然不清晰。

- **已有的工作**
    现有工作没有系统地分析大型语言模型在游戏理论背景下的运作情况。虽然经验研究表明LLMs能够在某些社会科学研究中替代人类，但关于LLMs的能力边界缺乏系统的分析。

#### 核心贡献
- **系统分析LLMs在游戏理论中的应用**
    - **挑战1：建立明确的欲望**
        LLMs在基于非常见偏好构建欲望方面存在困难，数学能力下降，无法理解偏好。

    - **挑战2：提炼游戏中的不确定性信念**
        LLMs不能从许多简单的模式中提炼信念，这使我们对LLMs参与需要提炼复杂信念的游戏感到悲观。
    - **挑战3：基于欲望和信念采取最优行动**
        当LLMs采取行动时，可能会忽视或修改已提炼的信念，这个现象在LLMs中是不可避免的。

#### 实现与部署
研究结果表明，即使是目前最先进的LLM（GPT-4），在游戏理论方面与人类仍然存在显著差异。例如，在处理Rock-Paper-Scissors（石头、剪刀、布）游戏时，虽然GPT-4在某些模式下的表现与人类惊人地相似，能够随着游戏信息的增加对提炼出的信念越来越有信心，但在其他情况下LLMs无法从多种简单模式中提炼信念。在指挥官游戏中，尽管LLMs具有建立清晰欲望的基本能力，但当赋予不寻常的偏好时，LLMs常常表现出数学能力下降和无法理解偏好的问题。另外，在环形网络游戏中，LLMs不能自主遵循玩家行为，明确分解游戏过程中的行为可以提高LLMs采取最优行动的能力，但忽视或修改提炼信念的现象仍然无法避免。

#### 总结
本研究系统地探索了LLMs在游戏理论背景下的能力边界，并从三个角度出发，提供了将LLMs在社会科学研究中使用的进一步指导。