#### 背景
- **背景**      
    论文介绍了大型语言模型（LLMs）对人工智能和自然语言处理领域的重大影响，特别是长上下文大型语言模型（LCLMs）因具备解锁新能力的潜力而变得越来越受欢迎。然而，最近的研究揭示了它们在利用上下文方面存在的诸多问题，如技术能力尚且有限，导致即使在合成检索任务中也表现不佳，以及经常分心于从多个文档中检索相关信息，尤其是难以利用输入中部的信息。

- **已有的工作**
    之前的研究没有在训练数据中包含足够的长距离语义依赖关系，对此，该论文通过在训练输入中频繁整合相关文档来寻找解决方案，提出通过自然的代码数据目录结构来改进LCLMs的上下文利用性。

#### 核心贡献
- **提出了一个结构性打包（SPLICE）方法**
    - **挑战1：长上下文利用不足**
        为了克服无法直接利用元信息对文档进行额外结构打包的挑战，SPLICE通过检索方法识别相关文档来构建训练示例。这种做法提供了一种在数据包含元信息的情况下构造训练示例的方法，旨在通过提供更多相关文档来增加依赖关系密度，从而帮助模型更好地学习并利用长距离依赖。

    - **挑战2：训练数据缺乏结构性**
        使用SPLICE，研究者通过构建文档树并用基于检索的方法（例如BM25或Contriever）逐级发掘最相关的文档，以便将其集成到单一的训练环境中。SPLICE的总体架构具有灵活性，可以通过调整参数来在不同检索模式之间进行插值。它最终产生了一个合并了相关文档的训练示例，提高了模型运用长上下文进行预测的能力。

#### 实现与部署
SPLICE方法在一个大规模的代码生成数据集上得到了实证验证，展示了在更大上下文情境下的困惑度改进以及在TREC、Qasper和合成任务上的更高执行表现。SPLICE通过训练一个大规模的OpenLLaMA 3B LLM以改进长上下文评估上的困惑度，提高了在上下文学习能力和更好的检索性能。此外，还分析了SPLICE设计选择的影响，包括检索到的文档数量以及将文档合并到训练示例中的顺序。

#### 总结
这篇论文通过提出SPLICE方法来改进长距离上下文的利用，验证了其在提高大规模语言模型上下文利用率和改进长上下文任务性能方面的有效性。SPLICE特别适用于在缺乏额外结构化信息的训练数据上构造训练示例。