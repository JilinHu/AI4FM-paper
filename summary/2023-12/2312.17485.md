#### 背景
- **背景**       
    论文探讨了大型语言模型（LLMs）在修复代码审查（CR）过程中审查员和自动检查器识别的缺陷方面的应用。研究表明，在大多数CR缺陷的修复过程中，相关的审查意见起着关键作用。这些评论不仅解释缺陷，而且通常会提供修复缺陷的建议。与开发人员一样，预训练的LLMs具有理解自然语言和编程语言的能力。因此，它们可以有效地分析审查评论和有缺陷的代码，并生成适当和纠正的版本。

- **已有的工作**
    当前的研究尚未充分探索LLMs在理解代码审查中给出的反馈及修改代码的能力，这是为软件开发过程中识别和修复代码缺陷的一个潜在强大工具。

#### 核心贡献
- **提出了一个半自动的APR（自动程序修复）范例**
    - **挑战1：如何有效利用LLMs理解代码审查意见并生成修复补丁**
        该研究实施了一个半自动的APR范例，利用LLMs的能力理解代码审查意见并生成修复补丁，从而解决了通过自然语言意见指导代码缺陷修复的挑战。

    - **挑战2：如何设计有效的提示来引导LLMs修复代码**
        该研究设计了7种基于CR过程中信息的提示，并发现审查意见和修复范围是两种最有效的提示。通过验证两个不同的数据集，证明了数据多样性的重要性。

#### 实现与部署
研究团队研究了包括ChatGPT-3.5、ChatGPT-4、LLaMA、CodeLLaMA在内的9种不同LLMs。他们为此设计了七种不同的提示，并对比了这些LLMs在不同提示下修复代码的成功率。CodeLLaMA在所有LLMs中表现最佳，其修复成功率高达72.97%。该研究通过对比两个不同的数据集（约16K条审查意见和约15K条自动生成的评论），强调了数据多样性的重要性。此外，研究还提供了一个具体代码缺陷修复的示例，展示了CodeLLaMA如何成功修复涉及多个代码修改的复杂缺陷。

#### 总结
研究探讨了LLMs在代码审查缺陷修复中的应用，提出了一个有效的半自动APR范例，分析了9种流行模型的性能，并设计了有效的提示以指导代码修复过程。