#### 背景
- **背景**       
    论文指出，使用带标签数据对视觉嵌入进行训练是计算机视觉中表示学习的标准设定。受到在自监督表示学习中采用掩蔽图像建模（MIM）成功案例的启发，作者提出了一种简单且有效的设置，可以将MIM轻松整合到现有的监督训练范式中。在他们的设计中，除了对视觉变换器图像编码器应用原始分类任务外，他们还在编码器之上增加了一个基于变换器的浅层解码器，并引入了一个MIM任务，该任务尝试根据掩蔽图像输入来重建图像标记。

- **已有的工作**
     目前的工作主要集中在使用分类损失作为监督的表示学习，并没有考虑结合MIM的方法。现有的监督训练方法使用单个语义标签为每个图像提供监督，而MIM尝试预测大量的低级别标记层面的细节。所以既有方法可能没有提供在监督学习范式中融合MIM来进一步改善学习到的图像表示的方法。

#### 核心贡献
- **提出了一个将监督表示学习与MIM结合的训练设置**
    - **挑战1：如何整合MIM到现有的监督训练范式**
        论文提出一种在训练时结合监督学习与MIM的新设置。提出的设置包括图像编码器和一个浅层解码器，每个图像通过两项任务进行处理：一个标准的带有分类损失的监督学习任务和一个对掩蔽图像进行编码和解码图像标记的MIM任务。这两任务所产生的损失聚合，用于指导训练。

    - **挑战2：确保这种设置不会引入显著的训练或推理开销**
        由于在监督学习任务和MIM任务之间共享原始图像编码器，且解码器层浅、没有引入额外训练数据，因此这种设置对现有架构造成的变更最小。在测试时，由于仅需要训练过的编码器来计算表示，所以与未集成MIM的标准监督模型相比，这种设置具有相同的推理成本。

#### 实现与部署
在ImageNet-1k数据集上，使用该方法训练的ViT-B/14模型验证准确性达到了81.72%，比基线模型高出2.01%。在ImageNet-1k的K-Nearest-Neighbor图像检索评估中，同一模型的性能比基线模型高出1.32%。在ADE20k数据集上进行的语义分割任务中，该模型比基线模型高出1.21%。这些结果表明，与未使用MIM任务的基线模型相比，所学习的图像表示显著改善。此外，作者还对训练参数的选择进行了全面的消融研究，并展示了该方法可以轻松地扩展到更大型的模型和数据集。

#### 总结
这篇论文提出了一种融合监督表示学习和MIM的新训练设置，该设置在不增加显著的训练或推理开销的前提下，显著提高了下游任务如分类、图像检索和语义分割的表示学习质量。