#### 背景
- **背景**       
    针对评估大型语言模型（LLM）的现有方法在使用已有的知识图谱（KG）进行评估时往往忽视了KG的结构并且随意选择了哪部分图谱进行评估的问题。

- **已有的工作**
    现有的评估方法面临的挑战 include information that's been trained or evolved over time leading to data leakage, as well as the challenge of dynamic knowledge where information constantly updates while old datasets remain fixed.

#### 核心贡献
- **提出了一个KGLens方法**
    - **挑战1：生成自然问题**
        现有的方法在将KG边缘转换为自然问题和评估LLM回应时存在挑战，因为缺乏上下文，实体的含糊不清以及谓词的多样性。KGLens通过设计图指导的问题生成（QG）策略来增强问题的自然度并减少生成的问题的歧义性，通过包括实体别名提供额外的上下文并减少实体的含糊。

    - **挑战2：利用参数化的KG**
        参数化的知识图谱（PKG）使我们能够有效地评估LLM的知识可靠性，并且由于KG在架构上的便利性，可以让信息更新过程中更高效地处理可靠性评估。
    - ...

#### 实现与部署
KGLens不仅能够评估LLM的整体表现，还能提供有关主题、时间和关系的分析。实验证明KGLens可以对LLM的整体性能进行评估，而且还能提供主题、时态和关系分析。这展示了KGLens的适应性和可定制性，强调了其能够根据具体标准聚焦评估的能力。

#### 总结
本文提出了一种新的名为KGLens的框架，用于评估LLM中的事实知识。KGLens利用KG结构生成自然语言问题并进行评估，OD辅以参数化的KG和图指导的QG策略以提高自然问题的生成质量和评估过程的效率。