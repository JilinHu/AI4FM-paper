#### 背景
- **背景**       
    当前，文档理解任务中所使用的多模态大型语言模型（MLLM）通常依赖于全局文档结构的理解。然而，这些模型在零样本（zero-shot）文档理解方面面临挑战，因为它们需要使用标注数据进行微调才能在下游任务上取得好的表现。

- **已有的工作**
    尽管已有研究设计了许多预训练任务以增强模型对文档布局的理解，但这些研究有一个局限性：它们仅侧重于全局的文档理解，而没有充分利用文档的局部特征，例如，文档中的表格、标题、图片等区域。此外，现有方法在进行有监督的微调时缺乏对布局信息的明确学习，这是文档理解至关重要的部分。

#### 核心贡献
- **提出了一个LayoutLLM及其布局指导调整策略**
    - **挑战1：增强对文档布局的理解**
        研究人员提出了从全局到局部的不同层次来增强模型对文档布局的理解。这包括了三组不同层次的预训练任务，均通过指令调整方式实现。这使得LayoutLLM能够更全面地理解和利用文档结构。

    - **挑战2：在微调环节引入布局信息**
        研究人员提出了一种新的LayoutCoT（布局链式思维）策略，该策略显式引入布局信息到有监督的微调（SFT）中。通过这种方式，LayoutLLM能够专注于文档中相关的区域，并利用该区域的特征以生成准确的答案，从而使得模型在答案生成过程中具有一定程度的可解释性。

#### 实现与部署
论文提出了一个新的大型语言模型LayoutLLM及其布局指导调整策略，专门为了增强文档布局的理解和利用而设计。在实践中，作者们使用了三组不同层次的预训练任务实现从全局到局部对文档布局的学习，并提出了LayoutCoT策略来实现有监督的微调。在零样本文档理解任务中的实验结果表明，LayoutLLM在文档视觉问答和视觉信息提取等基准测试中取得了优于其他开源大型语言模型和多模态语言模型的表现。

#### 总结
该论文成功提出了LayoutLLM模型及其布局指导的调整策略，显著提高了模型对文档布局信息的理解和利用，尤其在零样本文档理解任务上表现出了卓越的效果。