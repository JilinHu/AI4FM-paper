#### 机构&分类
Stanford University, UC Santa Barbara
Knowledge and Retrieval
  
---

#### 背景
- **背景**       
    文章讨论了科学论文发表中LLMs使用情况的增加，并指出人们普遍对ChatGPT等大型语言模型（LLMs）在学术写作中的用途以及可能带来的影响作出了猜测。尽管如此，我们却缺少确切的数据来衡量学术写作中被LLMs大幅度修改或产生的内容比例。

- **已有的工作**
    已有工作提出了多种检测LLM修改文本的方法，包括零样本检测和基于训练的分类方法。但是，这些方法面临着对LLM内部的访问需求、过度拟合训练数据、对非主流语言变体的偏差等挑战。公开可用的LLM修改文本探测器的有效性和可靠性也受到质疑。

#### 核心贡献
- **提出了一个统计框架**
    - **挑战1：如何在更宏观的层面检测科学论文中LLM修改的内容**
        探索如何量化AI修改学术写作的使用情况，使用的统计框架将人写和LLM修改文档的概率分布组合为混合分布，估计混合文档中有多少是由LLM修改。该框