#### 机构&分类
East China Jiaotong University, Guangdong University of Technology, University of Toronto
Agent

---

#### 背景
- **背景**       
    文章介绍了大型语言模型（LLM）在自然语言处理（NLP）领域取得显著进展，能够在多种任务中展现出色的性能。但是LLMs的有效操作仍然严重依赖于人类输入，以准确引导对话流程。因此，作者提出了TinyAgent模型和协同多代理调节（CMAT）框架来解决这种依赖性，增强语言代理能力，通过基于环境反馈的自适应权重更新，促进多智能体之间的协作学习和实时适应性。

- **已有的工作**
    传统的LLMs需要人类参与调节以提高对话质量。用户必须基于他们的意图和聊天代理程序的反馈提供相关和精确的提示。这引出了一个问题：我们是否能用自主通信代理替代人类干预，最小化人类监督，并引导对话实现任务完成？此外，LLMs还面临现实部署中的显著挑战，尤其是高计算资源需求，数据偏差和缺乏鲁棒性限制了它们在资源有限的环境中的应用性，突显了增强模型效率和适应性的紧迫性。

#### 核心贡献
- **提出了一个CMAT框架**
    - **挑战1：高效性能与实时适应能力**
        CMAT框架是一个创新的系统设计，通过基于环境反馈的适应性权重更新来增强语言代理能力。该框架促进了多智能体间的协作学习和实时适应，增强了他们的情境感知能力和长期记忆。

   