#### 背景
- **背景**       
    论文分析了大型语言模型（LLMs）生成内容的真实性问题，指出这些模型偶尔会生成非真实的知识，这限制了它们在实际应用中的使用。已有的基于人工注释的真实性探测方法（factuality probes）存在传递性限制，因此难以适应分布以外的内容。最新的研究通过在线自我一致性检查来检测非真实内容，但这增加了计算负担，因为需要生成多个输出，并且由于缺乏训练过程，这些方法的稳定性不如之前的探测方法。

- **已有的工作**
    由于现有方法需要大量的人力进行数据注释，并且不够适应新的数据分布，同时在线自我一致性检查计算成本高且稳健性差，因此需要一种更有效的方法来检测LLMs生成内容的真实性。

#### 核心贡献
- **提出了一个PINOS系统**
    - **挑战1：非真实内容的传递性和有效检测问题**
        论文通过PINOS解决了现有方法需要人工注释数据和计算成本高的问题。PINOS通过离线自我一致性检查训练探测模型，不需要依赖人工注释数据，因此能够适应不同的数据分布，并减少计算负担。

    - **挑战2：数据分布的适应性和效果提升**
        与现有的在线自我一致性检查相比，PINOS提高了计算效率，还通过分析LLMs内部状态而不是响应中的离散标记，访问了更广泛的信息范围，从而增强了其预测的有效性。

#### 实现与部署
PINOS通过对大型语言模型内部状态的不同方面进行分析，文中提出了一种名为PINOS的新方法，此方法能够检测这些模型生成的非真实内容。在一系列实验中，PINOS在各种事实检测基准测试和问答数据集上的表现超过了现有的事实检测方法。该方法通过在线自我一致性检查避免了在推理过程中生成多个输出的计算负担，提高了时间效率。进一步的实验结果显示，PINOS在QA数据集上的表现比有监督探测基准高出7.7-14.6 AUC，并且在与无监督一致性检查基准相比时取得了更显著的性能改进（3-7 AUC），同时还展示出优越的时间效率。

#### 总结
本论文提出了一种通过离线自我一致性检查训练探测模型的新方法PINOS，有效地解决了现有真实性检测方法的限制。PINOS提高了过程的转移能力和效率，并且在真实性检测和问答基准测试上取得了超越现有方法的结果。