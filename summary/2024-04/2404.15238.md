#### 背景
- **背景**       
    文章介绍了大型语言模型（LLMs）在各种应用中变得越来越重要，例如用于推荐系统和客户服务。这些模型往往反映出西方中心的观点，因为它们主要训练在反映这些价值观和行为的数据上。这种文化偏见会导致不希望的后果，例如强化刻板印象、疏远非西方用户、阻碍全球部署等。因此，研发能够意识到多元文化的语言技术变得越来越重要。

- **已有的工作**
    现有的研究已经开发了文化知识数据库来表示与文化相关的知识和规范，但存在几个局限性：它们通常依赖于像维基百科和在线文章这样的正式知识来源，而这些来源错过了当地社区所体验的丰富、不断演化和长尾的文化细微差别；这些方法倾向于以一种断言的方式呈现文化知识，未能捕捉到文化习俗和价值观在同一文化群体内部个人之间的差异；此外，它们的评估方法通常依赖于分类任务和问答任务，这与LLMs在现实世界中的部署方式非常不同，因此无法反映它们在实践中的文化意识。

#### 核心贡献
- **提出了一个可扩展的流水线，用于从不同的在线社区大规模构建文化知识库**
    - **挑战1：处理大规模噪声数据**
       为了应对现有文化知识资源的断言性问题和文化描述的多样性问题，研究创建了一个通用框架，该框架从在线社区（如TikTok和Reddit）收集文化知识，并在大规模的自我叙述中建构了包含1.2万条来自TikTok和1.1万条来自Reddit的文化描述符的文化知识库——CultureBank。这样生成的知识库收录了针对相似文化习俗的多元视角，并计算了一致性级别，以支持包容性的文化理解。

    - **挑战2：评估语言模型的文化意识**
        为了更有效地评估LLMs的文化意识，研究提供了一个基于真实世界场景的文化情境，每个文化描述符都与一个相关的情境相结合（例如旅行咨询）。然后，研究评估了先进的LLMs在CultureBank上的文化意识，并发现了提升的空间。此外，研究证明，在CultureBank上训练LLMs可以提高其在下游文化相关任务上的表现。

#### 实现与部署
CultureBank 是一个开源的知识库，通过Framework收集了大量的在线文化自述，并用于训练和微调LLMs。评估结果显示，通过在CultureBank上进行微调的LLMs在两项文化任务上的零样本设置中展现了更好的性能。其中，CultureBank包含了丰富的文化描述符和场景，这些资源可以用于评估语言模型在文化意识方面的表现，并且能够指出改进的方向。

#### 总结
该论文提出了一个用于构建文化知识库的通用流水线，并使用该流水线创建了CultureBank，这是一个包含TikTok和Reddit上文化描述符的知识库。论文还通过这个知识库评估了LLMs在文化意识方面的表现，并用于训练更具文化意识的语言模型，以此促进未来语言技术的文化意识发展。