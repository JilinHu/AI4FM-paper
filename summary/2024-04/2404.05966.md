#### 背景
- **背景**       
    这篇论文介绍了大型语言模型（LLMs）如GPT、LLaMA和Claude在解决各种推理任务时，如何通过使用不同的提示策略和指导性教学来提升其表现。

- **已有的工作**
    以前的方法，例如Chain-of-Thought（CoT）和它的延申，像Tree-of-Thoughts和Graph-of-Thoughts，只允许LLMs在固定的候选集内探索，而不能在后续步骤中对其原始答案进行持续的修正和编辑。这限制了LLMs处理需要频繁修正和修改的问题的能力。

#### 核心贡献
- **提出了一个xxx**
    - **挑战1：构建一个允许持续自我修正的推理网络**
        当前的LLM推理策略不支持在推理过程中对先前输出的连续修正。本文通过提出THOUGHTSCULPT，一个新型的基于图的框架，使用自我修正机制允许LLMs对以前的输出进行迭代式的精炼和改进。

    - **挑战2：处理文本生成中巨大的搜索空间**
        对于无法通过常规的图搜索算法（如DFS、BFS和A*搜索）穷举所有可能的路径的情况，研究者使用蒙特卡洛树搜索（MCTS），一个强大的启发式技术，有效导航搜索空间并提供高质量的解决方案。

#### 实现与部署
THOUGHTSCULPT包括三个核心模块：思维评估器、思维生成器和决策模拟器。它在三个具有挑战性的任务上进行实验，分别是Story Outline Improvement、Mini-Crosswords Solving和Constrained Generation。与现有的先进推理策略相比，THOUGHTSCULPT在Story Outline Improvement任务中展现了高达30%的趣味性提升，在Mini-Crossword Solving任务中有高达16%的成功率提高，在Constrained Generation任务中有10%的概念覆盖率提高。

#### 总结
THOUGHTSCULPT作为一个基于图的框架，通过内嵌的自我修正机制，能够让LLMs在生成新的思维节点的同时迭代地改进之前的输出，特别在需要持续修正和修改的任务中表现出卓越的能力。