#### 背景
- **背景**       
    论文介绍了大型语言模型（LLMs）可以通过想象、搜索和批评自身的输出，从而进行自我提高，无需额外的注解数据。

- **已有的工作**
    现有研究在AlphaGo自学习算法在LLMs中的应用存在挑战：数据稀缺、搜索空间的复杂度以及反馈的微妙性质。现有工作没有解决如何在没有额外注解数据的情况下，让LLMs进行有效的自我提高。

#### 核心贡献
- **提出了一个名为ALPHALLM的框架**
    - **挑战1：如何在没有额外注解的情况下提升LLMs？**
        论文提出的ALPHALLM框架融合了蒙特卡洛树搜索（MCTS）与LLMs，使模型能够在没有额外注解的情况下，通过想象、搜索和批评自身的输出来进行自我提高。

    - **挑战2：有效搜索与自我改进**
        针对应用在LLMs上的MCTS搜索策略，论文设计出可以有效指导搜索流程的多重批评信号，并通过反馈从MCTS的输出中进行学习来继续训练LLM，实现了模型的有效自我提高。

#### 实现与部署
实验结果显示，使用ALPHALLM框架，提高了LLaMA-2 70B在数学推理任务上的性能，使其达到了与GPT-4相当的水平。论文中提到，ALPHALLM整合了搜索策略和LLMs的自我改进能力，创新地使用MCTS作为训练数据的引导，其输出的质量高于标准核采样，确保了LLM可以自我提高。

#### 总结
该论文介绍了一种名为ALPHALLM的新型框架，通过蒙特卡洛树搜索（MCTS）和大型语言模型（LLMs）的结合，实现了LLMs的自我提高，无需额外的注解数据。