#### 背景
- **背景**       
    文章介绍了当前大型语言模型（LLMs）在处理涉及上下文理解的复杂推理任务时存在的困难。尽管最近的研究提出了多种方法来增强LLMs的推理能力，如链式推理（Chain-of-Thought, CoT）和树状推理（Tree of Thoughts, ToT），但这些方法通常忽视了识别上下文中逻辑关系的重要性。这导致了模型对上下文的理解和交互仅停留在表面层面。

- **已有的工作**
    现有的工作在提升LLMs的推理能力方面侧重于改进推理过程以得出精确答案，但是在处理涉及上下文理解的任务时，它们往往忽略了首先识别上下文逻辑关系的必要性，这可能导致推理结果的不可靠和质量下降。

#### 核心贡献
- **提出了一个信息重组（InfoRE）方法**
    - **挑战1：识别上下文中的逻辑关系**
        现有方法通常忽略这一关键步骤，我们通过信息重组过程，将上下文内容重新组织成MindMap结构，明确显示隐含在文本中的逻辑关系。通过这种结构的重组信息，LLMs能够更深层次地理解上下文内容，从而提高推理质量和可靠性。

    - **挑战2：改进LLMs在处理需上下文理解的多跳推理任务的能力**
        我们的方法可与现有提示方法（如CoT）集成，进一步提升LLMs的推理能力。在不同的上下文理解的多跳推理任务中验证了我们的方法，结果显示在零次射击（zero-shot）设置下，我们的方法在所有任务中平均改进了3%，从而证明了该方法的有效性。
 
#### 实现与部署
我们在用于上下文理解的多跳推理任务上测试了InfoRE方法，包括索赔验证、问题回答和阅读理解任务。采用零次射击的设置，我们的方法在Llama2-70B、GPT-3.5和GPT-4这些模型上取得了平均3%的改进。这一结果高于现有的工作，突出了我们方法在提高LLMs推理性能方面的潜力。

#### 总结
本论文提出了一个新颖的信息重组方法（InfoRE），通过重组上下文内容来揭示逻辑关系，从而增强LLMs的推理能力。方法在零次射击设置下对LLMs进行上下文理解的多跳推理任务测试，取得了显著效果。