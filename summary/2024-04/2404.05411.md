#### 背景
- **背景**       
    论文着眼于当下语言模型在生成文本时的“语义漂移”问题，即模型在生成文本的开始阶段能产生正确的事实信息，但随着文本长度增加，模型会逐步“漂移”，开始产生不正确的事实信息。这种现象之前已有观察，但未曾有过精确的衡量。

- **已有的工作**
    现存的工作主要集中在自回归语言模型上，这种模型在生成文本时没有预先设定的文本结构，导致它们难以维持高水平的结构一致性，而且过分强调局部连贯性。尽管现有研究指出，长文本生成的质量可能会降低，暗示着文本质量的特定排序（质量高的内容先生成，后生成的质量低），但这种有序行为从未被正式定义或深入研究和衡量过。

#### 核心贡献
- **提出了一个语义漂移评分**
    - **挑战1：量化语义漂移**
        为了解决语言模型在长文本生成过程中出现语义漂移的问题，研究者们开发了一种语义漂移评分方法，用以测量生成文本中正确与不正确事实的分离程度。该方法是通过观察模型在生成文本时，先产生正确事实然后系统地转向产生不正确事实的模式来衡量的。他们使用了 FActScore 任务来为单独的事实标记正确或不正确的标签，从而量化语义漂移的严重性。

    - **挑战2：改善事实准确性的方法**
        分析表明，通过在合适的时机中止生成，可以提高事实的准确性。研究者提出了多个早停方法以及重采样然后重新排序的策略，通过选择基于句子相似度测量最好的版本，进一步提高了事实准确性。他们还尝试通过外部 API 调用来让模型回到正确的生成路径上，但没有得到显著的提升。

#### 实现与部署
他们通过实验发现，简单的早停方法可以显著提高事实性，而基于句子相似度重新排序的复杂方法能够在不缩短文本的情况下将事实准确性提高近10%。然而，尽管将这些方法与早停方法结合使用可以在信息量和准确性之间取得不同的折中，调用外部 API 的方法并没有带来显著的性能改进。

#### 总结
本文为理解和测量语言模型在长文本生成中的语义漂移现象提供了工具。通过早停和重采样-重新排序等方法，显著提高了事实准确性，并为如何平衡信息量与事实准确性提供了可能的解决策略。