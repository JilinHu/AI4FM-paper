#### 背景
- **背景**       
    文章探讨了语言模型（LLMs）和压缩之间的关联性，以及压缩能力是否可以作为智能的指标。传统上，一直有观点认为良好的压缩能力与智能息息相关，最近的研究将语言建模等同于压缩，从而对LLMs的成功提供了合理化的解释。本文的目标是实证考察这一联系，并探索更好的压缩能力是否意味着更高的智能。

- **已有的工作**
    目前，关于压缩与智能之间的关系缺乏足够的实证研究。尽管理论上已经存在这样的讨论，但仍缺乏对LLMs的实证支持，即一个语言模型如果能够更少的比特以无损的方式编码文本语料库，这是否表明它具有更高的智能。

#### 核心贡献
- **提出了一个考察LLMs智能与压缩能力关系的方法**
    - **挑战1：如何量化“智能”**
        智能的概念较为抽象，难以直接量化。论文采用平均下游基准分数作为智能的替代指标，专注于与知识和常识、编码和数学推理相关的智能，并通过12个基准测试对来自不同组织的30个公共LLMs进行评估。发现LLMs的智能（通过平均基准分数反映）几乎线性相关于它们压缩外部文本语料库的能力，为上述信念提供了具体证据。

    - **挑战2：确保研究的普适性和实用性**
        以往的研究可能只在相同模型系列（共享大部分配置如模型设计、分词器等）内探讨基准分数与类似压缩的指标（如验证损失）之间的关系。而这项研究第一次记录了不同模型大小、分词器、上下文窗口长度和预训练数据分布的LLMs之间压缩和智能的线性关联，建立了作为通用原则的压缩与智能之间的线性关联，并且提出压缩效率作为一个无监督指标，与模型的能力具有线性关系。
#### 实现与部署
在30个不同的语言模型和12个不同的基准测试中的实验表明，LLMs的下游能力与它们的压缩效率几乎呈线性相关，皮尔逊相关系数约为-0.95。这表明更好的压缩效率确实表明了更高的智能。LLMs的压缩效率作为一个无监督指标，可以作为一个稳定、灵活和可靠的评估标准，与模型能力线性相关。作者还开源了他们的压缩数据集以及数据收集管道，便于未来的研究人员能够适当地评估压缩。

#### 总结
这篇论文通过实证研究，证明了LLMs在下游任务性能与它们的压缩效率之间存在着几乎线性的相关性，为“更好的压缩能力表明了更高的智能”这一长期信念提供了支持。同时，提出了使用压缩效率作为评估LLMs性能的无监督度量标准的建议。