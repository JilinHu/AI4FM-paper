#### 机构&分类
None
Reasoning
  
---

#### 背景
- **背景**       
    论文指出现有的大型语言模型（LLMs）存在在长上下文理解（long-context understanding）方面的挑战，尤其是在执行需要扫描和理解整个输入以识别标签空间的极端类别分类（extreme-label classification）任务时。这类任务要求LLMs全面理解输入内容以进行预测，但是大量的类别空间会使得任务演示（demonstration）变成很长的序列，从而超出了模型训练时遇到的最大序列长度限制。

- **已有的工作**
    之前的工作没有专注于在极端标签空间下对LLMs长上下文学习的能力进行评估。现存的评估方法不能充分衡量LLMs理解和推理整个输入序列的能力。此外，现有的长上下文技术和基准测试主要集中在如长文档摘要、问答或信息检索等任务，未涵盖长上下文学习。

#### 核心贡献
- **提出了一个LongICLBench基准测试**
    - **挑战1：长上下文学习的分析**
        在这项工作中，作者们提出了LongICLBench，这是一个专门为评估