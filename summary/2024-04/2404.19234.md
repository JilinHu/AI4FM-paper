#### 背景
- **背景**       
    论文研究如何利用大型语言模型（LLMs）进行基于知识图谱（Knowledge Graphs, KGs）的多跳问答。现有的研究多数采取统一方法去处理不同的KG数据集，但这篇文章提出针对不同的KG数据集应采用不同的策略。
    
- **已有的工作**
    文章指出，使用统一方法处理所有KG数据集存在局限性，因为不同数据集有各自的特点和挑战，使用同样的处理方式难以取得最佳效果。

#### 核心贡献
- **提出了一个根据数据集特点选择策略的方法**
    - **挑战1：如何应对没有可用子图的KG数据集**
        文章提出了 SP-LLM 策略来解决没有可用子图的数据集问题，利用三项技能（节点识别、边缘/谓词识别和SPARQL查询生成）来处理问答任务。
        
    - **挑战2：如何处理有可用子图的KG数据集**
        文章使用 IR-LLM 策略来处理具有子图信息的KG数据集。这个方法有多个步骤，包括识别相关的1跳关系、过滤并返回排名靠前的关系，以及确定节点是否可以作为答案。

#### 实现与部署
论文中比较了提出的方法与现有方法的效果，如WebQSP、MetaQA、ComplexWebQuestions、LC-QuAD V1 和 V2 等不同的KG数据集上的问答性能。实验结果显示在WebQSP和MetaQA数据集上，论文提出的方法相比其他基线方法有显著的提升，其中，在WebQSP上使用GPT-4模型（少数样本）达到了85.32%的准确率，而在MetaQA数据集上，使用ChatGPT（5个少数样本）准确率高达98.68%。与现有方法相比，这说明论文的方法在多跳问答任务中更为有效。

#### 总结
论文在多跳问答任务中提出针对不同的知识图谱数据集采用不同策略，展示了利用大型预训练语言模型在这些复杂问答任务中的强大能力。通过实验，验证了所提方法相比现有技术的优势。