#### 机构&分类
Microsoft Research Asia
Reasoning

---

#### 背景
- **背景**       
    文章提到进行放射学报告的生成评价对于放射学人工智能的发展至关重要，但现有的评估指标无法反映任务的临床要求。本研究提出了一种使用大型语言模型（LLMs）比较放射学报告进行评估的新评价框架。

- **已有的工作**
    现有的评价放射学报告的指标主要分为两类：语言指标和临床指标。语言指标，如BLEU、ROUGUE和METOER得分，主要关注语法和词汇的相似性，而不够关注临床事件的描述，从而丧失了临床意义。临床指标，如CheXpert F1，强调临床描述的准确性，但由于受限于预定义的疾病实体集或匹配规则，它们无法充分处理报告中广泛存在的模糊情况和准确评估临床描述。此外，目前的研究主要集中在一般性文本生成任务的评价上，没有针对于临床意义放射学报告评价。

#### 核心贡献
- **提出了一个名为LLM-RadJudge的评估方法**
    - **挑战1：在放射学报告生成的自动评估方法中达到接近放射科医生级别的评估一致性。**
        本文通过比较各种大型语言模型的性能，并展示了使用GPT-4时提出的评估指标能够达到接近放射科医生的评估一致性。