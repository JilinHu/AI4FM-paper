#### 背景
- **背景**       
    文章介绍了大型语言模型（LLMs）在多个领域和智能代理应用中取得了突破性进展，但现有的LLMs在学习复杂度和多样性增加的任务时可能会遇到性能瓶颈。为了解决这个问题，自我进化方法正在迅速发展，使LLM能够自主地获得、提炼经验，并从模型自身生成的经验中学习，从而推动LLMs朝向超级智能的方向发展。

- **已有的工作**
    现有的LLMs在复杂任务中遇到挑战，例如科学发现和未来事件预测，主要是由于现有训练范式（例如注释、模型构建和评估）的固有困难。此外，目前LLMs面临的一个限制是，通过添加更多真实世界的数据来显著扩展模型性能可能是有限的。

#### 核心贡献
- **提出了一个自我进化的概念框架**
    - **挑战1：如何构建能够自主获得和提炼经验的系统**
        论文通过将自我进化过程细化为四个阶段：经验获取、经验提炼、更新和评估，提出一个概念框架，使LLM能通过迭代循环不断进化。

    - **挑战2：如何系统化地组织和分析自我进化方法之间的关系**
        文章收集和总结了大量关于不同自我进化方法的文献，为研究人员提供分类和见解，同时指出现有挑战并提出未来方向，以促进自我进化框架的发展和下一代模型的产生。
    
#### 实现与部署
本文以全面的方式调研了自我进化的方法，并提出了自我进化的概念框架。通过分析如静态数据模型等现有挑战，文章概述了开放性问题，并提出了未来研究的方向。虽然具体的实施和部署细节未在这部分内容中给出，评价结果显示，如DeepMind的AMIE系统和Microsoft的WizardLM-2这样的使用自我进化框架的模型超越了初版GPT-4的性能。

#### 总结
这篇综述文章提出并总结了LLMs的自我进化方法，为推动自我进化的研究提供了概念框架和未来方向的见解，旨在推动下一代自我进化LLMs的发展。