#### 背景
- **背景**       
    论文指出，在软件工程任务，尤其是自动程序修复（Automated Program Repair, APR）中，大型语言模型（LLMs）展现出了显著的有效性。现有的深度学习（DL）基于的APR方法多数基于已知错误位置或使用行级的本地化工具，或者一次性解决错误预测和修复。本研究独特地利用LLMs预测错误位置到token级别，并使用它们进行错误修复。

- **已有的工作**
    尽管最近基于LLMs的APR技术相比基于DL的技术已经取得了重大进展，但它们仍然依赖于行粒度的信息，并且缺乏对LLMs多样化应用于错误修复的全面探索。现有方法并未有效地解决LLMs在无需外部假设或工具的情况下进行错误定位的潜力，token级别错误定位与行粒化定位的效果对比，以及不同类型的提示对错误修复效果的影响。

#### 核心贡献
- **提出了一个名为Toggle的新方法**
    - **挑战1：错误定位的效果提升**
        提出的Toggle方法不同于现存基于行粒度的方法，能够确保不会重新生成错误和修复函数之间共享的前缀或后缀代码，而是通过token粒化的方式定位错误，避免了在LLMs生成修正代码时产生过剩的非错误代码，减少了输入冗余，并通过设计不同的提示来比较和理解各提示在不同情景下的效果。通过防止LLMs生成共享的前缀和后缀，深入注入了强烈的归纳偏置，显著提高了错误修复的准确性。

    - **挑战2：错误修复模型的集成与优化**
        通过集成错误定位模型、调整单元和错误修复模型，构建了一个全面的程序修复框架。Toggle使用多种不同的基于生成的LLMs进行错误修复任务的微调，显著提升了修复准确率，并在CodeXGLUE代码优化基准测试中达到了新的最高水平，同时在包括Defects4J在内的几个广泛使用的APR数据集上也展示了更好或相当的性能。

#### 实现与部署
论文中的Toggle取得了CodeXGLUE代码优化基准上的最优性能，并且在包括Defects4J在内的其它几个广泛使用的APR数据集上表现出了更好或相当的表现。这项研究通过在Defects4J基准上的排名持续领先，显示出在Top-10, Top-30, Top-50, 和 Top-100这几个指标上的卓越性能。研究还检查了Toggle对未见数据的泛化能力，评估了各种提示的有效性，调查了诸如错误行和代码注释这样的上下文信息对错误定位的影响，以及探索了调整单元的重要性。

#### 总结
这篇论文提出了一种名为Toggle的新方法，该方法使用token粒度的bug定位并修复，克服了现有行粒度方法的局限，通过输入设计和LLMs的微调，大幅提升了错误修复的准确性，并在多个数据集上取得优异的表现，为APR领域带来新的进展。