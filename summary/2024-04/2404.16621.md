#### 机构&分类
Koç University, KUIS AI Center, Hacettepe University
Application

---

#### 背景
- **背景**       
    这篇论文提出了大型语言模型在医疗领域的集成可望改革医疗诊断、研究和患者护理。但是，医疗大型语言模型（LLMs）的发展面临诸多障碍，比如复杂的训练需求、严格的评估要求，以及限制学术探索的专有模型的主导地位。透明的、全面的访问LLMs资源对推进领域发展、增进可再现性和鼓励医疗AI创新至关重要。

- **已有的工作**
    现有的尝试通过进一步训练LLMs、监督式微调或二者结合以开发先进的医学LLMs取得了一些有希望的结果。然而，数据收集、预训练和微调阶段可能包含相当的复杂性，这使得在该领域内复制、分析和比较最近LLMs变得具有挑战性。此外，闭环模型（例如GPT4、Gemini等）使用封闭领域数据集进行训练，使得其结果不具有可复制性，更不用说它们的昂贵计算成本和使理解这些先进医学框架成功的关键组件变得更复杂。

#### 核心贡献
- **提出了一个开源LLM框架Hippocrates**
    - **挑战1：缺乏域特定知识和医学术语的细微差别**
        该框架采用透明开放的方法，为整个社区提供了从数据源到训练配置、再到可复制的评估协议的完全访问权限。通过进一步的实证分析，识别出对LLMs性能产生影响的各种设计要素，进而开发了一套优化的、适应医学领域的框架，在多个医学测试基准上展示出卓越的性能。

    - **挑战2：高性能模型的开发和验证的复杂性**
        该框架开发了两种高级的7B参数模型Hippo-Phoenix和Hippo-Griffin，并通过详细的实证分析和分步指导来高效训练医学LLMs。这两个模型在性能上不仅超过了现有的7B和13B模型，甚至在某些情况下超过了70B模型。

#### 实现与部署
论文中介绍了Hippocrates框