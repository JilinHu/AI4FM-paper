#### 背景
- **背景**       
    论文介绍了在文本到图像扩散模型中，尽管已经取得了一定进展，但现有方法仍然面临着显著挑战，尤其是在生成与图像条件控制一致的图像方面。为此，研究者们提出了ControlNet++，这是一种新方法，通过显式优化生成图像与条件控制之间的像素级循环一致性来改善可控生成。
- **已有的工作**
    现有的方法通常涉及对扩散模型进行重训练，但这需要巨大的计算需求和大型公众数据集，后者比较稀缺。为改善可控性，有研究采用微调预训练的文本到图像模型或引入可训练的模块，如ControlNet。然而，即便如此，现有的方法仍然未能精确和细致地控制生成的图像，生成的图像显著偏离输入条件且缺乏明确的改进策略。

#### 核心贡献
- **提出了一个ControlNet++**
    - **挑战1：精确可控性的缺失**
        控制生成图像以使其与输入条件一致是一个显著的挑战。ControlNet++通过使用预训练的判别模型来提取生成图像的对应条件，然后优化输入条件控制和提取条件之间的一致性损失来解决这一挑战。该方法采用循环一致性的概念，通过在像素层面直接优化控制性来改进性能。

    - **挑战2：计算效率与资源限制**
        直接实现像素级损失可能导致效率问题，需要在多个采样时间步存储梯度，导致显著的时间和GPU内存消耗。为了避免这些代价，ControlNet++引入了一种有效的奖励策略，通过向输入图像添加噪声来故意扰乱一致性，然后使用单步去噪图像进行奖励微调来重建一致性，避免了由图像采样引起的时间和内存开销。

#### 实现与部署
ControlNet++通过多项实验评估，展示了在多种条件控制下显著提高了可控性。例如，与ControlNet相比，对于分割遮罩、线条艺术边缘和深度条件，ControlNet++分别在mIoU、SSIM和RMSE上取得了7.9%、13.4%和7.6%的改善。这表明ControlNet++在各种条件控制下都能产生更准确的可控生成图像，并为其他研究提供了一个统一和公开的可控性评估。

#### 总结
ControlNet++通过优化生成图像与条件控制之间的像素级一致性，并通过高效的奖励微调策略减少了与图像采样相关的时间和内存成本，显著改善了在多种条件控制下的可控性。