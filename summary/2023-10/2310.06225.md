#### 背景
- **背景**       
    文章介绍了利用大型语言模型（LLMs）回答与农业相关的考试问题。尤其关注的是如何提高模型在农业领域问题上的表现。研究者发现，尽管LLMs在多个领域表现出了强大的回答能力，但在某些专业领域，特别是农业，仍面临着理解和准确回应问题的挑战。这源于模型缺乏足够的针对性领域知识，以及难以将其预训练的知识应用于特定问题上。这就需要一种方法来增强LLMs在特定领域的表现。

- **已有的工作**
    尽管已有研究提出了诸如chain-of-thought和self-consistency之类的方法，试图通过增强理解和推理来提高LLMs的性能，这些方法往往不足以处理特定于农业的复杂问题，因为它们忽视了将领域知识有效整合进LLMs的重要性。此外，这些方法没有考虑如何在没有给定明确文本材料作为背景的情况下优化模型的性能。

#### 核心贡献
- **提出了一个被称为 Ensemble Refinement（ER）的新策略**
    - **挑战1：提高模型在回答农业领域问题上的表现**
        ER通过在多个阶段中结合chain-of-thought和self-consistency技术，克服了之前方法的不足。在第一阶段，模型生成多个可能的解释和答案。第二阶段，模型会综合这些生成的解释并产生更精细的答案。该方法通过整合不同解释项的优缺点，使LLMs能够生成更准确的回答。

    - **挑战2：降低重复采样带来的资源成本**
        ER方法仅在多项选择评估中实施，减少了因重复采样模型而产生的高资源成本。通过这种策略，能够有效地使用LLMs的生成提炼出最准确的答案，最后通过多数票选出最终答案。

#### 实现与部署
研究通过使用Azure Open AI部署对GPT-3.5和GPT-4模型进行了评估，并使用了Llama2模型（13亿参数和70亿参数）。评估包括无视频背景信息的问题（依赖LLMs的预训练知识）和使用RAG、ER以及前置文段（preamble）的文本基础问题。GPT-4在多个情境下表现一致超过了其他模型，特别是当采用前置文段后，其表现由无ER的79%提升至有ER的83%。在使用给定情境信息的文本基础问题上，采用ER的GPT-4的表现提升至84%，而使用RAG技术时表现进一步提升至93%。

#### 总结
本研究展示了在农业领域使用LLMs进行问题回答的新方法，特别是通过Ensemble Refinement策略，大幅提升了LLMs在多选题目上的表现，并显示出在处理专业领域问题时的广泛潜力。