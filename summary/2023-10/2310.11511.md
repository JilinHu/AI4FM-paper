#### 背景
- **背景**       
    文章介绍了大型语言模型（LLMs）通常仅依赖它们封装的参数性知识，因此可能在响应中包含事实不准确的内容。为了减少这些问题，有种称为检索增强生成（RAG）的方法，即通过检索相关知识来增强语言模型，从而减少在知识密集型任务中的事实错误。然而，这种方法可能会妨碍LLMs的多样性，或引入不必要的或离题的段落，导致生成质量低下，因为它们不加选择地检索文段，不管检索是否有助于增强事实依据。

- **已有的工作**
    传统的RAG方法可能会损害LLMs的多样性或导致生成质量低下。现有的RAG方法中，模型并没有被明确培训来更好地利用和跟随提供的段落中的事实，其输出也不能保证与检索到的相关段落保持一致。

#### 核心贡献
- **提出了一个自我反思型检索增强生成（SELF-RAG）框架**
    - **挑战1：改进事实准确性而不损害多样性**
        SELF-RAG通过按需检索和自我反思来改进LLMs的生成质量，包括其事实准确性。该框架培训任意LM以学习在给定任务输入时通过生成任务输出和间歇性特殊标记（即反思标记）来对自己的生成过程进行反思。这种方法与传统的RAG方法不同，后者始终检索固定数量的文档以进行生成，无论检索是否必要，也从不第二次审视生成质量。

    - **挑战2：定制解码算法**
        SELF-RAG进一步使能了定制的解码算法来满足硬性或软性约束，这些约束由反思标记预测定义。特别地，其推理时算法使我们能够灵活调整不同下游应用程序的检索频率，并通过利用反思标记通过段级beam搜索定制模型的行为，使用反思标记概率的加权线性总和作为段落得分。

#### 实现与部署
实验结果表明，SELF-RAG在包括推理和长篇生成在内的六个任务上显著优于具有更多参数的预训练和指令调整LLMs以及广泛采用的RAG方法，并且提供更高的引用准确性。具体来说，SELF-RAG在四个任务中胜过了增强型检索的ChatGPT，在所有任务中优于Llama2-chat和Alpaca。分析展示了使用反思标记进行训练和推理对于整体性能改进以及测试时模型定制（例如，在引用预测和完整性之间平衡权衡）的有效性。

#### 总结
论文推出了SELF-RAG，这是一种新的框架，通过按需检索和自我反思来增加LLMs的质量和事实性。它通过生成反思标记让LM在推理阶段变得可控，可以满足多样化的任务要求。SELF-RAG在多个任务上显著超越了现有LLMs和RAG模型，并通过定制的解码算法和反思标记，为模型自我评估和定制提供了新的方案。