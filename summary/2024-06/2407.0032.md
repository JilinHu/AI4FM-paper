#### 背景
- **背景**       
    文章介绍了在解决复杂数学推理任务时，大型语言模型（LLMs）面临的挑战，尤其是当问题的推理步骤增加时。当前LLMs在处理这些任务的能力类似于心理学中的“系统1”模式思维，即快速直觉型，但易犯错误。

- **已有的工作**
    尽管通过各种方法（如层次提示、自动提示细化等）努力增强了LLMs的“系统1”能力，但这些方法在处理需要刻意思考和不断细化的复杂数学推理任务时，仍然存在限制。研究人员也尝试使用树搜索算法（如深度优先搜索、广度优隔搜索和蒙特卡洛树搜索(MCTS)）来模拟“系统2”模式思维。然而，由于这些方法通常需要设计专家级效用函数，并且计算资源消耗巨大，这限制了它们在实际应用中的部署。

#### 核心贡献
- **提出了一个动态节点选择和节点级探索预算计算的新颖的树搜索算法**
    - **挑战1：资源消耗**
        研究人员介绍了一个新的树搜索算法，该算法考虑到向最终答案的搜索进程（历史）和从未经任何逐步注释训练的值网络获得的指导（未来），在分配的计算预算范围内，迭代选择最有潜力的树节点进行扩展。

    - **挑战2：性能**
        该算法不仅在GSM8K和TabMWP数据集上展示了具有竞争力的性能，但相较于基线方法，其所需计算成本大幅降低。

#### 实现与部署
本研穯通过在GSM8K和TabMWP数据集上的实验验证了新算法的有效性。结果表明，该方法不仅展现了与其他方法相当的性能，而且在计算成本上远低于传统搜索算法，如蒙特卡洛树搜索(MCTS)和其他使用自定义效用函数的方法。

#### 总结
该论文通过提出一种效率更高的树搜索算法来降低在辅助大型语言模型解决复杂数学推理任务时的资源消耗，同时确保保持高性能水平。