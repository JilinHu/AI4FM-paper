#### 背景
- **背景**       
    论文介绍了大型语言模型（LLMs）在执行如摘要、问答和翻译等任务上表现出色，但在处理开放式问题中的理论心智（ToM）推理方面仍面临挑战。ToM 推理包含识别他人拥有自己的意图、情绪和思想等心理状态的能力。尽管 LLM 在很多方面取得了进步，但其真正理解 ToM 推理的程度，以及其与人类 ToM 推理的一致性在开放性场景中还没有充分探讨。

- **已有的工作**
    已有研究表明 LLM 在需要细腻理解和整合人类心理状态的零样本ToM推理任务上表现出限制。这些研究通常使用多项选择和短答案问题来展示 LLM 的局限性，而不是开放式问题。

#### 核心贡献
- **研究开放式问题中的 ToM 推理**
    - **挑战1：开放式问题中的 ToM 推理能力不足**
        论文通过比较人类和 LLM 生成的回应之间的语义相似性和词汇重叠度量，揭示了开放式问题中 LLM 在 ToM 推理能力上存在显著差异。即便是最先进的模型也显示出了显著的局限性。

    - **挑战2：有效整合人类的意图和情绪**
        为了提升 LLM 的功能，论文实施了一种提示调整方法，包括人的意图和情绪，导致在 ToM 推理性能上有所改进。尽管如此，这种增强仍未完全实现类似人类的推理。

#### 实现与部署
论文使用来自 Reddit 的 ChangeMyView 论坛的帖子作为数据，该平台以其对有说服力的回应需求严格的社交推理而著称。通过对比人类和各种 LLM（如 Zephyr-7B、Llama2-Chat-13B、GPT-4）回应的语义相似性和词汇重叠分数，发现两者之间存在显著差异。研究还运用了一种提示调整方法来改善 LLM 的 ToM 推理性能，并取得了一定的进步，但即便如此，LLM 在社交推理上仍有限制，这表明尽管有所改进，但距离真正实现人类般的推理效果还有很长的路要走。

#### 总结
本研究强调了 LLM 在社交推理方面的不足，并展示了如何通过整合人类的意图和情绪来增强其有效性。研究结果凸显了 LLM 理解人类心理状态并在开放式问题中进行社交推理的需求，标明了未来发展的关键领域。