#### 背景
- **背景**       
    论文指出，大型语言模型（LLMs）在提供最新信息方面经常面临挑战，原因在于LLMs的一次性培讓和世界不断进化的特性。为了保持LLM的时效性，现有方法通常涉及在新文档上继续预训练。然而，经常难以提取存储的知识。论文以费曼技术在促进人类学习和知识理解方面的显著成功为启发，提出了一种新的学习框架SELF-TUNING。

- **已有的工作**
    现有研究主要通过对LLMs进行持续的预训练来注入新知识。这种方法涉及在包含新知识的原始语料库上持续地对LLMs进行预训练。尽管直接，但通常在有效使LLMs在推理阶段提取获得的知识方面面临障碍。在预训练后使用QA数据进行指令微调可以增强知识提取，但这种方法的效果仍然有限。

#### 核心贡献
- **提出了一个SELF-TUNING**
    - **挑战1：知识迅速陈旧**
        为了解决LLM存储的知识迅速过时的问题，SELF-TUNING作为一个学习框架，目标是通过自我教育提高LLM从原始文档中有效获得新知识的能力。具体来说，通过开发了一种自我教学策略来强化文档，创建了一系列以自我监督的方式从文档中得出的知识密集型任务。

    - **挑战2：有限的知识提取与应用**
        面对从LLMs检索到的知识显著受限的问题，SELF-TUNING借鉴了费曼技术，设计了包括记忆、理解和自我反思三个关键方面的策略。此外，论文还引入了三个Wiki-Newpages-2023-QA数据集，用于深入分析LLM的知识获取能力，包括记忆、提取和推理。

#### 实现与部署
在LLAMA2家族模型上的大量实验结果表明，SELF-TUNING在所有知识获取任务中始终表现出色，并且在保持以前知识方面表现优异。此外，SELF-TUNING在知识记忆和提取任务上明显优于所有其他比较方法，并在推理任务上始终保持高精度，而比较方法在不同场景下的表现则大幅波动。

#### 总结
论文通过引入SELF-TUNING，提出了一种改进LLM通过自我教学获取知识能力的框架，并通过Wiki-Newpages-QA数据集在多个关键知识获取任务上验证了其有效性。