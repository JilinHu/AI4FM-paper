#### 背景
- **背景**       
    论文介绍了大型语言模型（LLMs）如GPT-4、PaLM和LLaMA在各种推理任务上的表现，而为了进一步提升其功能和性能，人们提出了更有效的提示方法。当前的提示方法可以分为单查询推理和多查询推理，但它们都面临着限制，比如缺乏通用性和泛化性，以及计算强度高等问题。

- **已有的工作**
    已有工作依赖于为特定任务设计的示例和推理结构，忽略了从已完成任务中提取通用和高层次的指导思想或思维模板，这些模板可以在解决类似问题时提高效率和精度。

#### 核心贡献
- **提出了一个名为Buffer of Thoughts (BoT)的新型思维增强推理框架**
    - **挑战1：如何增强LLMs的推理准确性、效率和鲁棒性**
        BoT框架通过设计一种轻量级的库（meta-buffer），存储从多个问题解决过程中提取的通用高层次思维模板（thought-template），可以跨任务共享。然后针对每一个问题，检索相关的思维模板，并将其用特定的推理结构实例化，从而进行有效的思维增强推理，解决了推理结构手动构建的问题。

    - **挑战2：如何确保框架的可扩展性和稳定性**
        BoT还引入了buffer-manager，用于动态更新meta-buffer，有效地随着解决的任务增多而增强meta-buffer的容量，以保证框架的扩展性和稳定性。

#### 实现与部署
BoT通过在10个具有挑战性的推理密集型任务上进行广泛实验，取得了显著的性能提升，相比以前的最高水平方法平均性能提升了：24游戏11%、几何形状20%以及国际象棋中的制胜一步51%。此外，BoT在维持推理效率的同时只需要平均12%的多查询提示方法的成本。值得注意的是，结合BoT的Llama3-8B模型有望超越Llama3-70B模型。

#### 总结
BoT通过为LLMs提供一个存储高层次思维模板的meta-buffer，增强了推理的准确性、效率和鲁棒性，克服了现有方法的限制，并实现了显著的性能提升。