#### 背景
- **背景**       
    文章介绍了当前人工智能领域对长上下文语言模型（LCLMs）的需求和研究。传统上，由于上下文长度限制，许多任务需要依赖于工具、数据库或复杂的流水线。长上下文语言模型具有潜力整合这些复杂流水线到单一的模型中，解决级联错误和优化困难等问题，并能在整个系统中应用高级提示技术来优化任务处理。

- **已有的工作**
    已有的研究和基准测试在评价长上下文任务时面临挑战，大多依赖于合成任务或固定长度的数据集，未能与“长上下文”的不断演变的定义保持同步。现有评估也没有足够压力测试LCLMs在颠覆性任务上的表现。

#### 核心贡献
- **提出了一个长上下文前沿（LOFT）基准**
    - **挑战1：真实应用中的长上下文任务**
        该论文提出LOFT基准，一组六个任务构成的35个数据集，旨在评估LCLMs在上下文检索和推理方面的表现。这一基凹测试覆盖文本、视觉和音频模态，并鼓励自动创建不断增长的上下文长度。挑战在于评价LCLMs在真实世界长上下文任务中的性能，这些任务在现实应用中是有用的。

    - **挑战2：多样化模态和任务**
        LOFT基准测试涵盖了需要LCLMs颠覆现有范式的几个领域，例如检索系统、RAG（检索增强生成）、SQL任务处理以及多示例ICL（上下文学习）。难点在于LCLMs如何在这些不同的领域中直接消化和检索语料库的信息，而不需要复杂的任务特定优化或流水线，并处理像组合推理这样的任务。
  
#### 实现与部署
我们使用如Gemini 1.5 Pro、GPT-4o和Claude 3 Opus这样的LCLMs，并采用《语料库中的上下文》（CiC）提示方法对LOFT进行评估。评估结果显示，LCLMs能够在没有专门流水线的情况下处理LOFT任务，并且在某些任务上与精心优化的专门模型在性能上不分伯仲。这些结果强调了LCLMs可以简化各种任务的潜力。同时，提示策略对性能的显著影响强调了随着上下文长度的增长，进行持续研究的需求。

#### 总结
本论文通过引入LOFT基准，探索了长上下文语言模型在替代现有范式和处理新颖任务方面的潜力。发现LCLMs在未经明确训练的情况下，能够在特定任务上与现有的检索和RAG系统相媲美，并指出了未来在提高问题表现上需要继续研究的领域。