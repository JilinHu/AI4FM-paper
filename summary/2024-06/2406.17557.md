#### 背景
- **背景**       
    论文介绍了大型语言模型（LLMs）的性能在很大程度上依赖于它们预训练数据集的质量和规模。然而，像Llama 3和Mixtral这样的最先进的开放LLMs的预训练数据集并未公开，关于它们如何创建的信息也鲜为人知。论文的目的是通过开发和发布FineWeb数据集来缩小专有数据集与公共知识之间的差距，该数据集是可用于训练性能优良的LLMs的大规模预训练数据集。

- **已有的工作**
    论文指出，尽管Common Crawl提供了足够的数据用于最近的LLMs训练，但LLMs的性能在很大程度上依赖于web文本如何被过滤和预处理之后再用于训练。例如， web文本可能含有大量的“非自然语言”（如模板文本、乱码等）。在此类数据上进行训练可能会损害LLMs的性能，因为LLMs的大多数下游使用并不涉及此类数据。另一方面，过度过滤内容可能会产生一个过小的数据集，不足以完成常规模型所需的充足预训练。

#### 核心贡献
- **提出了FineWeb和FineWeb-Edu数据集**
    - **挑战1：如何筛选和预处理web文本**
        本研究通过引入一个大规模的预训练数据集FineWeb，它含有15万亿token的文本，源自96个Common Crawl快照。通过选择和调整过滤启发式策略，FineWeb制定了一套过滤原则策略，并对去重策略和粒度如何影响性能进行了深入探究。实验证明，FineWeb训练出的模型比其他公开的基于web的预训练数据集表现更好。

    - **挑战2：如何获得针对知识和推理密集型基准表现更好的模型**
        研究者通过创建FineWeb-Edu数据集，一个从FineWeb中筛选出的被自定义分类器评定为高度教育性的1.3万亿token的集合，来应对这个挑战。在知识和推理密集型基准测试，如MMLU和ARC上，预训练于FineWeb-Edu上的模型展现出显著更好的性能。

#### 实现与部署
论文对FineWeb数据集的制作进行了详尽的文档记录和设计选择的逐项剖析。除了数据集本身，还公开发布了数据策划代码库以及在剖析实验中用到的所有训练模型。研究者通过公开这些资料，希望促进公共知识和资源，在策划LLMs预训练数据集方面有所进步。为了验证设计选择的有效性，研究者论证了FineWeb训练出的模型比其他公开的基于web预训练的数据集表现得更好，这证明了数据策划的成功性能提升。

#### 总结
本论文通过介绍FineWeb数据集，突出了如何策划出一个有效的基于Common Crawl的预训练数据集的重要性，并通过实验证明了其对于提升大型语言模型的性能的贡献。