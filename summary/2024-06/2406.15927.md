#### 背景
- **背景**       
    论文介绍了大型语言模型(LLMs)在各种自然语言处理任务中展现出惊人的能力，然而它们也倾向于产生“幻觉”——即生成虽听起来合理却事实上错误和随意的内容。这在需要事实性的高风险领域可能导致严重后果，因此可靠地检测或减轻幻觉非常关键。

- **已有的工作**
    现有工作采用多样本策略来检测幻觉，核心思路是如果模型“知道答案”，那么在给定提示的情况下，将会一致地提供相同答案。如果模型正在产生幻觉，其响应可能在不同生成中有所不同。然而，基于现有方法的计算成本增加了5到10倍，这对于实际应用构成了障碍。

#### 核心贡献
- **提出了一个Semantic Entropy Probes (SEPs)**
    - **挑战1：高昂的计算成本**
        由于在实际应用中不能承担高昂的计算成本，SEPs通过直接从单个生成的隐藏状态近似计算语义熵(SE)来解决这个问题。SEPs易于训练，在测试时无需生成多个样本，显著降低了语义不确定性量化的开销。

    - **挑战2：关于幻觉的预测和泛化能力**
        SEPs通过预测语义熵而非直接预测模型准确性来训练，这比前人工作设置了一个新的成本效率幻觉检测标准。SEPs不仅能够预测幻觉，还在泛化到新任务上胜过直接训练为预测准确性的探测器。

#### 实现与部署
SEPs能够成功地从LLMs的单个模型生成的隐藏状态中提取语义不确定性信息，表明这些隐藏状态确实编码了该信息。通过在不同的模型、任务、层和令牌位置上进行消融研究，SEPs展现出了良好的性能并提供了对LLMs内部工作机制的深入洞察。另外，SEPs证明比直接预测模型准确性的探针有更好的泛化能力，并能够在测试时无需生成多个样本，这些结果建立了一个新的成本效率幻觉检测的状态。

#### 总结
论文提出SEPs为成本高效和可靠的幻觉检测方法，能够在无需生成多样本的条件下，直接从LLMs单次生成的隐藏状态中捕捉到语义不确定性。