#### 背景
- **背景**       
    论文介绍了大型语言模型（LLMs）在没有足够外部知识的情况下生成的内容容易出现幻觉的问题，幻觉指的是LLMs生成的错误信息却看似正确的回答。这通常是因为查询超出了LLMs有限的参数知识边界。

- **已有的工作**
    现有的检索增强生成（RAG）方法默认对每个输入查询进行知识检索。然而，由于数据存储的嘈杂性，检索出的知识可能会误导，甚至在LLMs能够从它们自己的参数知识中提取正确答案的情况下产生冲突。对每一次生成都进行检索既低效又不必要。因此，提出了一种自适应检索策略来动态决定是否需要外部知识，然后相应地调用检索步骤。

#### 核心贡献
- **提出了一个SEAKR模型**
    - **挑战1：何时检索**
        现有的自适应RAG方法仅基于LLMs的输出来判断知识的充足性，这容易受到LLMs的自我偏见的影响。SEAKR利用LLMs内部状态的自我意识来动态决定何时进行检索，并有效整合检索出的知识。

    - **挑战2：如何整合**
        SEAKR会根据LLMs的自我意识不确定性对检索到的知识片断进行重排，以保留最大程度降低不确定性的片断。SEAKR使用自我意识不确定性以选择不同的推理策略，帮助解决需要多次检索的复杂任务。
  
#### 实现与部署
SEAKR在复杂和简单的问答数据集上的实验表明，它在自适应RAG方法中的表现优于现有方法。作者在Github发布了代码。尽管没有提供详细的评估过程和与相关工作的对比数据，但文中提到了SEAKR模型与现有自适应RAG方法相比的性能提升，这表明SEAKR在实际应用中的潜力。

#### 总结
本论文提出了一个名为SEAKR的新型自适应检索增强生成模型，通过利用LLMs的内部状态自我意识来动态决定何时进行检索，并有效整合检索到的知识，从而提高了在问答任务中的性能。