#### 背景
- **背景**       
    文章介绍了大型语言模型（LLMs）在自然语言处理任务中展现出的显著性能，特别是在机器翻译（MT）下游任务中。不过，现有方法无法产生与监督神经机器翻译（NMT）系统相匹配的翻译质量。推测原因是，当前方法中使用的简单提示无法充分发挥LLMs的指令跟随能力。

- **已有的工作**
    已有研究通过提示工程和指令调优来增强LLMs的翻译性能，但常常未能充分考虑机器翻译所必需的多语种知识的特性。而这些尝试中，LLMs的推理过程往往过于简单，不能充分利用其语言建模的复杂性和内在的语言知识。

#### 核心贡献
- **提出了一个名为TASTE的框架**
    - **挑战1：提升LLMs在翻译任务中的性能**
        TASTE通过二阶段推理过程促进LLMs提高翻译质量。首先指导LLMs生成初步翻译，并同时对这些翻译进行自我评估。然后在第二阶段，指导LLMs依据评估结果对初步翻译进行细化。

    - **挑战2：赋予LLMs执行整个自反思翻译过程的多任务能力**
        通过在多任务训练数据集上进行监督式微调（SFT），确保LLMs能够执行整个反思性翻译过程。这种方法促进了LLMs潜力的发挥，提升了模型的翻译性能。

#### 实现与部署
在WMT22基准测试的四种语言方向上的评估结果表明，与现有方法相比，TASTE框架的有效性更高。TASTE方法能够指导LLMs根据自我评估的结果改进初步的翻译结果，提升了最终输出的质量，从而增强了LLMs的翻译能力。

#### 总结
本文提出的TASTE框架通过自我反思过程提升了LLMs的机器翻译能力，它代表了利用LLMs翻译潜力的一种新方法，为理解和利用LLMs的复杂推理和语言建模能力树立了新的典范。