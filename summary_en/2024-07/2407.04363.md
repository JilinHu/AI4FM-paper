#### Background
- **Background**
The article introduces the expanded potential of Large Language Models (LLMs) in the development of autonomous agents. True autonomy requires accumulating and updating knowledge gained from interactions with the environment and effectively utilizing it. LLMs traditionally leverage past experiences through a full history of observations, summarization, or retrieval augmentation. However, these unstructured memory representations do not facilitate reasoning and planning needed for complex decision-making.

- **Existing Work**
Existing work relies on Retrieval-Augmented Generation (RAG) vector retrieval method, which by augmenting the model's prompt with an external database provides relevant information. However, these methods are challenged due to their unstructured nature, making it hard to retrieve information scattered across an agent's memory.

#### Core Contributions
  - **Introduced AriGraph, a memory architecture**
    - **Challenge 1: How to construct autonomous agents that can accumulate and use knowledge?**
        AriGraph addresses this challenge by constructing an episodic and semantic memory graph while exploring the environment. This graph structure enables efficient associative retrieval of interconnected concepts relevant to the agent's current state and goals, serving as an effective environmental model that enhances the agent's exploratory and planning capabilities.
        
    - **Challenge 2: How to improve the relevance of memory retrieval and enable effective exploration?**
        AriGraph overcomes this challenge by integrating semantic and episodic memories, effectively linking complex relationships within a knowledge graph, and learning a joint semantic and episodic world model during interactions, thereby improving spatial orientation and exploration capabilities.

#### Implementation and Deployment
In the TextWorld environment, AriGraph markedly outperforms traditional methods such as full history, summarization, and RAG based on recency, importance, and relevance scores. By learning through interactions with the environment, AriGraph models the agent on zero-shot tasks, assessing the agent's path planning and reasoning abilities in a simulated text world environment. Results show that the agent can effectively learn through interactions and significantly outperforms other memory approaches such as the complete history, summarization, and RAG. It also demonstrates that the method surpasses existing reinforcement learning (RL) baselines.

#### Summary
AriGraph is an innovative memory architecture that constructs a knowledge graph world model integrating semantic and episodic memories, enhancing the exploratory and planning capabilities of LLM agents. Experiments in the TextWorld environment have proven it to be more effective in handling complex tasks compared to other existing methods.