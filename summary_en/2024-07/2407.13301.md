#### Background
- **Background**
The paper introduces the significant change in the medical diagnosis field with the application of large language models (LLMs) but highlights the largely unaddressed issue of interpretability in these models. To enhance the interpretability of LLM-based medical diagnostics, the study presents the Chain-of-Diagnosis (CoD), which turns the diagnostic process into a chain of diagnostic steps that mirrors a physician's thought process, providing a transparent reasoning path and outputs the disease confidence distribution to ensure transparency in decision-making.

- **Existing Work**
Existing LLMs encounter significant interpretability challenges in medical diagnosis. Considering the hallucination issues, LLMs could arbitrarily make a diagnosis. Without interpretability, it's unclear if decisions are based on proper analysis and ethical standards. While LLMs can give rudimentary explanations for their decisions, they lack a comprehensive process to explain why potential diseases were excluded and how confident the model was in its decision.

#### Core Contributions
- **Introduced Chain-of-Diagnosis (CoD)**
    - **Challenge 1: Enhancing interpretability in medical diagnosis**
        CoD provides transparency in reasoning and decision-making by transforming the black-box decision process into a five-step mental model of a physician's process, revealing the thought process behind decisions. For decision transparency, CoD outputs a confidence distribution where higher confidence indicates a stronger belief in a particular diagnosis. This feature allows controlling the LLM's decisions using a confidence threshold.

    - **Challenge 2: Synthetic case data generation**
        Due to limitations in real-world cases, the paper proposes a method for generating synthetic cases from disease encyclopedias. This enables the scalable creation of CoD training data for various diseases without concerns about patient privacy. Using synthetic cases, the researchers constructed a training dataset with 48,020 CoD instances, leading to the development of DiagnosisGPT, which can diagnose 9,604 diseases.

#### Implementation and Deployment
DiagnosisGPT outperformed other LLMs on public diagnostic datasets and a newly-created benchmark DxBench. It has also achieved an accuracy exceeding 90% across all datasets with a diagnostic threshold of 0.55, emphasizing DiagnosisGPT's reliability in its confidence levels. DxBench is a diagnostic benchmark with 1,148 real cases covering 461 diseases, manually verified and derived from public doctor-patient dialogues.

#### Summary
This work introduces the Chain-of-Diagnosis (CoD), a diagnostic method meant to improve the interpretability of LLMs in disease diagnosis. It effectively generates training data through synthetic cases combined with disease encyclopedia data, resulting in the development of the DiagnosisGPT model. Experiments demonstrate that DiagnosisGPT performs better than other LLMs across numerous diagnostic datasets.