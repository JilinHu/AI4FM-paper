#### Background
- **Background**
The paper discusses the challenges faced by existing large language models (LLMs) in open-domain question answering (QA) tasks, particularly in accurately assessing the relevance of retrieved documents, which may lead to misleading or even incorrect utilization of external knowledge.

- **Existing Work**
Current LLMs struggle with effectively managing retrieval-augmented generation (RAG) tasks as they cannot precisely assess the relevance of retrieved documents, which could lead to the potential misapplication of external knowledge or incorrect outcomes. Moreover, the assessment of document relevance in existing methods is typically based on binary labels, which are too coarse and fail to capture fine-grained relevance. Consequently, existing methods have not been effective in improving the LLMs' ability to utilize external knowledge in QA tasks.

#### Core Contributions
- **Introducing the REAR Framework**
  - **Challenge 1: Enhancing Source Relevance Self-awareness**
      To better enable LLMs to judge the relevance of retrieved documents, the REAR framework incorporates a specially designed rank head to precisely assess the relevance of documents, employing it to capture relevance signals and avoid distractions from irrelevant external knowledge.
  
  - **Challenge 2: Overcoming Limitations of Binary Discriminative Methods**
      Previous binary discriminative methods only provided coarse supervision signals and were insufficient for fine-grained relevance judgment. The REAR framework addresses this by designing bi-granularity relevance fusion to leverage fine-grained supervision and enhances the discrimination ability of RAG systems with noise-resistant training.

#### Implementation and Deployment
Combining improvements in both architecture and training, the REAR framework enhances source relevance self-awareness when using reference documents in RAG systems. Extensive experiments on four different open-domain QA tasks show that REAR significantly outperforms a number of competitive RAG approaches.

#### Summary
The paper presented the REAR framework, which focuses on enhancing the ability of LLMs to utilize external knowledge in QA tasks by adding self-awareness of document relevance and has proven its effectiveness over previous methodologies.