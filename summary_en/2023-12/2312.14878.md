#### Background
- **Background**
The paper reveals the significance of Reinforcement Learning (RL) in developing decision-making skills through environmental interaction of Artificial Intelligence (AI) agents. However, the current standalone RL policies that directly map perception to action are facing major challenges, particularly in their lack of generality across multiple tasks and the need for extensive training data.

- **Existing Work**
Existing RL methods using a single mapping function to define a policy often fall short in complex environments. Additionally, RL-introduced priors are usually task-specific, necessitating extensive engineering and domain expertise. Even though recent studies have begun integrating Large Language Models (LLMs) into agent frameworks, existing frameworks often presume fixed reasoning structures and lack the ability to fine-tune new behaviors and skills, which limits agents to the capabilities of the pre-trained LLMs and could be risky in out-of-distribution tasks.

#### Core Contributions
- **Presenting the Pangu-Agent framework**
    - **Challenge 1: Lack of Structured Reasoning**
        The paper identifies that the standard RL process of learning policies that produce actions from perceptions might become a significant bottleneck when attempting to scale agents across tasks through foundational model policies. To overcome this issue, the authors introduce intrinsic functions to formalize agents' internal thinking processes as structured reasoning. These functions enable reformulation of the standard RL objective to accommodate multiple 'thinking' steps.
    - **Challenge 2: Lack of Fine-tuning Capability**
        Existing models are at risk in tasks that go beyond the capabilities of pre-trained LLMs. To address this, Pangu-Agent aims to allow agents to be fine-tuned through supervised learning and RL. The paper demonstrates how intrinsic functions can be used for fine-tuning, enabling agents to learn and adapt to new environments.

#### Implementation and Deployment
With the introduction of intrinsic and extrinsic functions, Pangu-Agent adds previous understandings of reasoning structures and provides adaptive capabilities to learn models within each module or function consistent with the modular structure of cognitive processes. By conducting a series of experiments, the paper explores practical applications of the Pangu-Agent framework demonstrating the efficacy of its approach. The findings suggest that the agents' performance and adaptability are significantly enhanced when organized reasoning and prior knowledge are embedded, paving the way for more resilient and general AI agent systems. An in-depth comparison with other AI pipelines and existing frameworks is also provided.

#### Summary
The paper introduces the Pangu-Agent framework, which addresses the challenges faced by standard RL methods in multi-task environments. By integrating structured reasoning through intrinsic functions and enabling fine-tuning through supervised learning and RL, Pangu-Agent enhances the ability of agents to adapt across various environmental interactions.