#### Background
- **Background**
Large Language Models (LLMs) have shown good performance on many downstream tasks but are known to produce erroneous information known as hallucination, impacting their reliability. Improving the reliability of LLMs and addressing hallucination issues involves guiding them to provide citations that can verify the accuracy of their generated content.

- **Existing Work**
Existing technologies for verifiable text generation in LLMs face significant challenges, such as attention shift during long text generation, the dilemma between precision and range in document retrieval, and reasoning for complex relationships between sentences and potential evidence. Current mechanisms struggle to effectively handle these challenges, especially when the focus of generated content gradually shifts and relevant citations need to be updated accordingly to remain consistent.

#### Core Contributions
- **Introduced a new framework called VTG (Verifiable Text Generation)**
    - **Challenge 1: Attention Shift**
        To address the challenge of focus-shifting in verifiable text generation, VTG employs an evolving long short-term memory system. This system stores the most valuable documents in long-term memory and the most recent documents in short-term memory to support the latest sentence. Additionally, VTG uses active retrieval only when necessary to enhance the precision of retrieved documents. Diverse query generation is also utilized to improve the breadth and diversity of retrieved documents.

    - **Challenge 2: Evidence Retrieval and Verification**
        VTG features a two-tier verifier and an evidence finder. When a sentence does not pass the verifier, the evidence finder is activated to retrieve additional supporting evidence. This allows the model to rethink and reflect on the relationship between a sentence and its potential evidence to ensure a thorough and accurate verification process.
  
#### Implementation and Deployment
VTG has been extensively tested on five QA datasets, demonstrating significant improvements over existing baselines in terms of citation quality and answer correctness. The method's effectiveness has been confirmed through comprehensive testing, showcasing its ability to enhance the accuracy of references and the verifiability of generated texts. The key contributions of VTG lie in its memory system and verification mechanism, which increase the credibility of the text generated by LLMs.

#### Summary
VTG improves the reliability and verifiability of text generated by LLMs through an evolving memory and self-reflection approach, effectively addressing challenges of complex attention shifting and document retrieval. It has been validated through experiments.