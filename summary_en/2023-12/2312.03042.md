#### Background
- **Background**
This paper discusses the difficulties of large language models (LLMs) like ChatGPT in processing spatial information, especially in the realms of 2D and 3D route planning. Although LLMs have shown significant abilities in following instructions, current evaluation standards have become obsolete, and there is a lack of specialized benchmarks to assess LLMs’ spatial understanding and reasoning capabilities.

- **Existing Work**
Existing work mainly focuses on comprehensive evaluation of LLMs’ capabilities in processing extensive world knowledge and reasoning through complex tasks. However, there currently are no benchmarks specifically designed to evaluate LLMs’ spatial understanding and reasoning abilities.

#### Core Contributions
  - **Introduced an innovative evaluation framework and dataset**
    - **Challenge 1: Lack of spatial understanding capability assessment**
      The study introduces a new evaluation framework aimed at the limitations of LLMs in handling spatial information, especially 3D spatial information, to evaluate and quantify how models like GPT-4 deal with spatial information.

    - **Challenge 2: Absence of a specialized dataset**
      The authors crafted a dataset that includes three key tasks: plotting spatial points, planning routes in 2D spaces, and devising pathways in 3D environments in order to concretely assess the spatial reasoning capabilities of LLMs.

#### Implementation and Deployment
The experiments show the work at evaluating the performance of language models in spatial reasoning at increased levels of difficulty compared to existing work. The authors have designed tasks with adjustable difficulty levels, with a set of unique solvable problems generated based on specific rules for each task. Standard answers were generated using traditional methods, and then GPT-4's performance was evaluated along with the automatic verification of the answers produced by LLMs for validity and correctness.

#### Summary
The paper provides a new evaluation framework and specially designed dataset for the capabilities of large language models like GPT-4 in handling spatial information, and analyzes the abilities and limitations of GPT-4 in dealing with spatial information.