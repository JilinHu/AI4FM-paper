#### Background
- **Background**
The paper introduces the significant impact of Large Language Models (LLMs) on AI and natural language processing, emphasizing the growing popularity and potential of Long-context Large Language Models (LCLMs) to unlock new abilities. However, recent studies revealed several issues with context utilization, such as limited technical capabilities resulting in poor performance on synthetic retrieval tasks and recurrent distractions from retrieving relevant information, particularly struggling to utilize information from the middle of their input.

- **Existing Work**
Previous research did not include sufficient long-range semantic dependencies in training data. In response, the paper seeks to address this by frequently incorporating related documents into training inputs, improving the utilization of context in LCLMs through the natural directory structure of code data.

#### Core Contributions
- **Introduced Structured Packing for Long Context (SPLICE)**
  - **Challenge 1: Inadequate Long-Context Utilization**
      SPLICE was developed to overcome the challenge of creating additional structure in training examples when meta-information is not directly available. It uses a retrieval method to identify relevant documents, intending to increase dependency density by providing more related documents, aiding better learning and utilization of long-range dependencies by the model.

  - **Challenge 2: Lack of Structured Training Data**
      Using SPLICE, researchers build a tree of documents and iteratively expand it to incorporate the most relevant documents identified through retrieval methods like BM25 or Contriever. SPLICE's overall architecture is flexible, allowing for interpolation between different retrieval modes by adjusting parameters. It results in a training example that encapsulates related documents, enhancing the model's capability to make predictions using a long context.

#### Implementation and Deployment
The SPLICE method was empirically validated on a large-scale code generation dataset, showing improvements in perplexity at larger contexts and higher performance on TREC, Qasper, and synthetic tasks. SPLICE improved perplexity on long-context evaluations, in-context learning ability, and better retrieval performance by training a large-scale OpenLLaMA 3B LLM. Furthermore, the paper analyzes the impact of SPLICE design choices, including the number of retrieved documents and the sequence in which documents are integrated into a training example.

#### Summary
This paper introduces the SPLICE method to enhance utilization of long-range contexts and validates its effectiveness in improving context utilization and performance on long-context tasks for large-scale language models. SPLICE is especially applicable for constructing training examples in training datasets that lack additional structured information.