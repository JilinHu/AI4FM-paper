#### Background
- **Background**       
The current state-of-the-art listwise rerankers based on large language models (LLMs) are heavily dependent on GPT models, creating a potential point of failure for scientific reproducibility. There is also concern over whether the current research findings are applicable only to GPT models rather than to LLMs in general.

- **Existing Work**      
Existing research demonstrates the success of listwise reranking; however, it heavily depends on the GPT models, leading to potential issues in scientific reproducibility and raising concerns about the applicability of the findings beyond GPT models.

#### Core Contributions
  - **Challenge 1: Constructing effective listwise rerankers without GPT dependency**
      The paper presents an approach that allows the construction of effective listwise rerankers without any dependency on GPT, surpassing rerankers based on GPT-3.5 by 13% and achieving 97% of the effectiveness of those based on GPT-4.

  - **Challenge 2: Constructing high-quality listwise ranking data**
      The existing training datasets for pointwise rerankers are insufficient for training listwise rerankers. The authors argue that high-quality listwise training data is critical and call for more efforts in building human-annotated listwise datasets to improve models.

#### Implementation and Deployment
The used training data is sourced from the MS MARCO v1 corpus, containing 8.8 million passages. Training queries are randomly sampled from RankVicuna's training data (n âˆˆ {2k, 5k, 10k, 20k}), and documents lists per query are reordered based on the previously mentioned setups. Experiments are conducted on the open-source LLM Code-LLaMA-Instruct with varying sizes of 7B, 13B, and 34B. Results are compared with the Vicuna-v1.5 model fine-tuned on ShareGPT instructional data. Evaluation on TREC-DL-19 and TREC-DL-20 datasets shows that the best listwise reranker in the study outperforms rerankers based on GPT-3.5 by 13% and achieves 97% effectiveness of those based on GPT-4 in terms of nDCG@10.

#### Summary
The paper's key achievement is demonstrating how to construct an effective listwise reranker without dependence on GPT models, significantly surpassing existing GPT-based rerankers, and calling for the development of higher-quality listwise training datasets to enhance model performance.