#### Background
- **Background**
The paper mentions that Retrieval-Augmented Generation (RAG) is a promising way to enhance large language model (LLM) outputs by leveraging external knowledge sources to reduce factual hallucinations. However, prior studies lack a comprehensive evaluation across different language families, which makes it challenging to assess LLM robustness against errors in external retrieved knowledge.

- **Existing Work**
Existing research has not thoroughly evaluated LLM's reasoning abilities in multiple languages, thus, it remains unclear whether the LLM and its utilization of external information are robust against first-stage retrieval errors across both high- or low-resource languages.

#### Core Contributions
- **Introduced NoMIRACL dataset**
  - **Challenge 1: Assessing LLM Retrieval Robustness Across Languages**
    NoMIRACL is a human-annotated dataset created to evaluate LLM robustness in RAG for 18 typologically diverse languages. NoMIRACL includes both a non-relevant and a relevant subset, providing metrics that can assess the model's propensity for hallucination in non-relevant subsets and inaccuracy in identifying relevant passages in the relevant subset.

  - **Challenge 2: Building a GPT-4 Baseline Model**
    Using the NoMIRACL dataset, researchers have built a GPT-4 baseline model for preliminary evaluation, showing that the model has a high average hallucination rate of 33.2% in non-relevant subsets and an error rate of 14.9% in relevant subsets, indicating the importance of research to improve the LLM's ability to reject non-relevant information in RAG.

#### Implementation and Deployment
The NoMIRACL dataset and GPT-4 baseline model are open-source and available for access. Experimental results show GPT-4 tends to misjudge non-relevant passages as relevant, with an average hallucination rate of 33.2% across all tested languages. In recognizing relevant passages with known answers, GPT-4 demonstrates a strong ability with an average error rate of 14.2%. The study also found a positive correlation (Spearman œÅ = 0.39) between GPT-4's hallucination rate and the size of language resources, i.e., Wikipedia corpus size.

#### Summary
This work introduces the NoMIRACL dataset, providing a multilingual tool for assessing robustness in LLMs during retrieval-augmented generation, and showcases challenges that LLMs face in differentiating between relevant and non-relevant retrieval results, highlighting the need for future research to improve LLM robustness.