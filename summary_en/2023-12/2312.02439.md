#### Background
- **Background**
The paper highlights that while Chain-of-Thought (CoT) is effective for logical tasks, it is not conducive to creative problem-solving, which often requires non-sequential, associative thinking, and leaps in knowledgeâ€”essential for innovation.
- **Existing Work**
Existing work has not adequately demonstrated LLMs' ability for non-sequential creative thinking and strong associative leaps. CoT, despite enhancing precision and rigor in logical tasks, is limited for tasks demanding strong associative reasoning and creative insights.

#### Core Contributions
- **Introduced a Creative Leap-of-Thought (CLoT) paradigm**
  - **Challenge 1: How to enhance LLMs' Leap-of-Thought (LoT) ability for creative generation**
      The paper proposes a novel Creative LoT framework (CLoT), which uses two stages to boost LLMs' LoT ability: associable instruction tuning to transform Oogiri-GO dataset into instruction data for training and explorative self-refinement to encourage creative LoT data generation and self-improvement.
  - **Challenge 2: Ensuring high quality and diversity of generated LoT data**
     Through explorative remote association under weakly-associated conditions, LLMs can generate a variety of creative response candidates and discriminate to select high-quality data for self-improvement, breaking away from traditional cognitive limitations.

#### Implementation and Deployment
The CLoT paradigm significantly improved LLMs' performance across various creative tasks. The experiments showed that CLoT not only excels at humor generation in Oogiri games but also enhances creativity in tasks like the "cloud guessing game" and the "divergent association task," demonstrating its excellent generalization and transferability. User studies also indicated a strong preference for the creatively generated content by CLoT. The introduction of CLoT advances our understanding and offers a pathway to improve the creative capacities of LLMs.

#### Summary
The paper introduced a Creative Leap-of-Thought (CLoT) paradigm for enhancing the creative thinking abilities of large language models, demonstrating its effectiveness and generalizability across various tasks.