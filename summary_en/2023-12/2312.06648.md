#### Background
- **Background**
Existing dense retrieval methods often utilize larger text units like sentences or paragraphs for information retrieval from source documents. This may lead to retrieved texts containing much irrelevant information, making the subsequent processing of retrieval results complex, especially when the results are used for Question Answering (QA) tasks.

- **Existing Work**
Most existing work focuses on optimizing retrieval models and algorithms but overlooks the potential impact of retrieval granularity on retrieval quality and the performance of downstream tasks. Therefore, existing methods may introduce unnecessary information when dealing with QA and other retrieval-based tasks, increasing the burden on the models.

#### Core Contributions
- **Introduced a Novel Retrieval Unit: Proposition**
    - **Challenge 1: How to effectively improve the precision of retrieval and provide more useful information for downstream tasks?**
        Traditional sentence or paragraph-level retrieval units often contain superfluous information. The paper proposes "propositions" as a new, more precise retrieval unit. Propositions are defined as atomic expressions within texts that encapsulate distinct factoids, presented in a concise, self-contained natural language format. By using propositions, dense retrieval performance is significantly improved, as is the efficacy of downstream QA tasks because the retrieved texts are more condensed with question-relevant information, thus reducing the length of input tokens and minimizing the inclusion of extraneous information.

    - **Challenge 2: How to optimize retrieval models' performance in cross-task generalization?**
        Cross-task generalization refers to the ability to transfer model performance among different tasks (e.g., datasets from different sources or styles). The paper's results demonstrate that retrieval by propositions presents a clear advantage in cross-task generalization settings, especially on datasets the downstream model has not seen during training.

#### Implementation and Deployment
Evaluation on five different open-domain QA datasets shows that both unsupervised and supervised dense retrievers perform better on most tasks when using propositions for retrieval compared to sentence or passage-level retrieval. The study found that proposition retrieval consistently outperforms traditional paragraph and sentence-level retrieval across all tested dense retrievers. For instance, with unsupervised retrievers SimCSE and Contriever, there was an average improvement in Recall@5 of +12.0 and +9.3 (35.0% and 22.5% relative improvement, respectively) across five datasets. Particularly on datasets not seen by the model during training, such as SQuAD or EntityQuestions, proposition retrieval significantly outperforms the other two granularity levels of retrieval, with 17-25% relative improvement in Recall@5 observed.

#### Summary
This paper introduces propositions as a new retrieval unit for dense retrieval, which improves the performance of downstream QA tasks and cross-task generalization capabilities while reducing irrelevant information in the retrieved texts.