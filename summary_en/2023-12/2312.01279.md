#### Background
- **Background**
Large language models (LLMs) have become widely adopted in practical applications due to their accurate responses and coherent reasoning abilities. Given their nature as black boxes that process complex reasoning on inputs, there is increasing demand for scalable and faithful explanations for the content generated by LLMs.
- **Existing Work**
Existing post-hoc explainability approaches, especially Shapley values, have proven effective for interpreting deep learning models. However, existing methods face challenges in scaling to LLMs when dealing with long input contexts containing thousands of tokens and output sequences generated autoregressively, and it is often unclear how to effectively apply generated explanations to improve LLM performance.

#### Core Contributions
- **Introduced an efficient post-hoc explanation method named TextGenSHAP**
  - **Challenge 1: Efficiency in extending Shapley values to contexts with long inputs**
      The challenge is significant as the computation of Shapley values for LLMs, especially with long inputs and large models, is generally time-consuming. TextGenSHAP integrates LM-specific techniques that vastly speed up computation, reducing processing times from hours to minutes for token-level explanations, and to seconds for document-level explanations.

  - **Challenge 2: Utilizing generated explanations to enhance the performance of LLMs**
      TextGenSHAP demonstrates how real-time Shapley values can be utilized in two important scenariosâ€”understanding long-document question answering by localizing important words and sentences and improving existing document retrieval systems by enhancing the accuracy of selected passages, thus improving the final responses.

#### Implementation and Deployment
The paper implemented TextGenSHAP and tested it in two different scenarios: long-document question answering and document retrieval systems. Results showed that there is a significant increase in computational speed compared to traditional Shapley value calculations, making document-level explanations possible in just seconds. Although the paper does not report detailed comparative results against other specific works, the highlighted speed improvements and its potential applications in enhancing understanding for long-document question answering and document retrieval accuracy indicate that TextGenSHAP is a promising post-hoc explainability method.

#### Summary
The paper introduces TextGenSHAP, an efficient post-hoc explanation method designed for large language models. The method improves the speed of explanation generation and demonstrates how to leverage these explanations to enhance long-document question answering and document retrieval systems.