#### Background
- **Background**       
The article pointed out that large language models (LLMs) using in-context learning (ICL) have exhibited impressive few-shot generalization abilities. However, the scale and computational requirements of larger models also increase significantly, leading to unprecedented computational demands and deployment challenges.

- **Existing Work**
Researchers attempt to transfer the capabilities of larger models to smaller, more efficient, and compact models by typically aligning the smaller models' outputs with those of larger models. Current methods involve training the smaller models either on outputs generated by larger models or by imitating their token-level probability distributions, with little to no consideration given to the input partâ€”crucial for ICL.

#### Core Contributions
  - **Introduced Bidirectional Alignment (BiAlign)**
      - **Challenge 1: Impact of input selection on ICL performance**
      Considering that the performance of ICL is highly sensitive to the choice of demonstration examples, the article proposes Bidirectional Alignment (BiAlign). BiAlign not only aligns the output distribution but also introduces a novel ranking loss for aligning input preferences.

#### Implementation and Deployment
The research demonstrates through extensive experimentation and analysis that BiAlign consistently outperforms existing baselines across a variety of tasks, including language understanding, reasoning, and coding.

#### Summary
The paper introduced Bidirectional Alignment (BiAlign), which effectively improves the ICL abilities of smaller models by integrating a new ranking loss along with aligning the output distribution.