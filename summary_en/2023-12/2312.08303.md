#### Background
- **Background**       
The paper addresses the issue of automatically detecting toxic content in online services, where existing machine learning methods have limited accuracy and transferability across datasets. Although Large Language Models (LLMs) have shown promise in zero-shot and few-shot learning abilities and broad task transferability, efficient prompting design remains challenging, and high operational costs may hinder production deployment.

- **Existing Work**
Existing work automates toxic content detection using supervised learning. However, obtaining training data labels, particularly for implicit toxic content, is challenging due to the lack of standard definitions. Moreover, these methods may cause model overfitting, limiting their application to other datasets, and they usually predict binary labels without detailed reasoning.

#### Core Contributions
- **Introduced a novel prompting method called DToT**
    - **Challenge 1: Enhancing precision while reducing model size**
        To address the issues of high costs and low transferability of LLMs in toxic content detection, the DToT method improves the performance of LLMs in zero-shot and few-shot scenarios. It refines and compresses the models without sacrificing accuracy, thus enabling more efficient production deployment.

    - **Challenge 2: Improving cross-dataset transferability**
        By fine-tuning smaller student LMs with rationales extracted via DToT, the approach enhances their ability to predict labels and rationalize when detecting toxic content, thereby improving transferability across datasets.

#### Implementation and Deployment
Experimental results demonstrate that the DToT method consistently improved the zero-shot and few-shot learning performance on all datasets, with up to a 4.6% increase in accuracy. Additionally, student LMs fine-tuned with rationales extracted from DToT outperformed baselines on all datasets, showing up to a 16.9% improvement in accuracy and a model size reduction of more than 60 times compared to conventional LLMs. The transferability of the student LMs across datasets also significantly improved.

#### Summary
The paper presents BD-LLM, a new method to enhance the efficiency and transferability of LLMs in toxic content detection tasks, proposing the DToT method and optimizing model compression for more effective production deployment.