#### Background
- **Background**
  The paper conducts an in-depth examination of the LLaMA large language model (LLM), probing its capabilities to handle high-order tasks, including calculation, math problem solving (MPS), logical reasoning, truthfulness, and factual knowledge detection. The research notably focuses on how the size of the model and its network layers affect these advanced capabilities. Such analysis is crucial for understanding and advancing the development of high-quality, powerful language models.

- **Existing Work**
  Although models like BERT have been analyzed through probing tasks to understand their internal representations, there is currently a lack of comprehensive research that deeply analyzes the relationship between the advanced capabilities of contemporary LLMs and factors such as model size and network layers.

#### Core Contributions
  - **Introduced a set of probing tasks targeting LLaMA**
    - **Challenge 1: Assessing LLM's capabilities in high-order tasks**
      To assess LLM's abilities in high-order tasks and understand how these abilities vary with model scale and layering, researchers developed a series of high-order tasks, such as arithmetic computations, logic reasoning, and truthfulness detection. These tasks enable researchers to compare the model's performance on different types of computations, from simple operations like addition and subtraction to more complex calculations.

    - **Challenge 2: Exploring model efficiency in multilingual mathematical reasoning**
      The researchers also explored the efficiency of LLaMA in multilingual mathematical reasoning tasks, which involved an extra layer of diversity and complexity, as the model needed to process mathematical problems in different linguistic contexts and generate accurate outcomes.

#### Implementation and Deployment
A series of probing tests - including basic arithmetic, math problem solving, logical reasoning, and others - demonstrated the LLaMA model's performance against these challenges. The test tasks examined the model's computational ability in various contexts, including multiple-choice question answering to check the model's sensitivity to minor computational discrepancies. Furthermore, misleading options constructed using GSM8K data assessed the model's mathematical reasoning ability. In logical reasoning, the Reclor dataset, derived from graduate admission standardized tests, was utilized. Through these tests, the paper showcased the model's reasoning capabilities and how its performance varied across different task types, data scales, and layers.

#### Summary
The core contribution of the study lies in proposing a series of probing tasks to evaluate the higher-order capabilities of large language models, focusing on computation, mathematical reasoning, logical reasoning, and truthfulness detection. It reveals how the performance of LLMs varies with changes in model scale and structural layers.