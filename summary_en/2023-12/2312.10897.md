#### Background
- **Background**
Generalized Category Discovery (GCD) is crucial for recognizing both known and novel categories from unlabeled data using a small amount of labeled data with known categories. Current methods perform poorly on novel categories and struggle to reveal the semantic meaning of discovered clusters, limiting real-world applications.
- **Existing Work**
Existing GCD methods start with supervised pre-training on labeled data and then move to self-supervised learning on unlabeled data, followed by clustering methods to identify known and novel categories. However, they suffer from a lack of supervision and prior knowledge for novel categories. Large Language Models (LLMs) like ChatGPT have shown promise without labeled samples but cannot directly address the clustering of thousands of samples required in GCD.

#### Core Contributions
  - **The Loop Framework**
    - **Challenge 1: Identifying Samples Likely to Be Misclustered**
        The challenge is effectively selecting samples that have a higher likelihood of wrong clustering. The paper tackles this challenge by proposing Local Inconsistent Sampling (LIS), relying on the consistency of neighborhood predictions and the entropy of cluster assignment probabilities.
    - **Challenge 2: True Neighbor Selection and Semantic Explanation Generation**
        The challenge is accurately selecting true neighbors for samples and generating semantic explanations (like category names) for new categories. The paper introduces a Scalable Query strategy, allowing LLMs to pick true neighbors from multiple candidates and perform Refined Neighborhood Contrastive Learning (RNCL) to pull samples and their neighbors closer together, all while leveraging LLMs to generate category names for novel clusters.

#### Implementation and Deployment
Based on feedback from LLMs, the researchers refined neighbor relationships through RNCL, selected representative samples for new categories, and had LLMs generate names for these new categories. Extensive experiments across three benchmark datasets show that the Loop framework significantly outperformed state-of-the-art models, increasing H-scores to 74.60%, 91.57%, and 90.74% respectively, over the best previous method by 13.01%, 8.44%, and 6.18%.

#### Summary
This paper presents an end-to-end active learning framework that incorporates Large Language Models into the training loop, significantly enhancing model performance on the task of generalized category discovery and autonomously generating category names.