#### Background
- **Background**
The paper investigates the capabilities of small language models (SLMs) in mathematical reasoning. The smallest known model size so far required to exceed the 80% threshold on the GSM8K benchmark is 34B, leaving the potential for smaller models to achieve similar reasoning abilities an open question.

- **Existing Work**
The GSM8K training set, despite its high quality, only contains about 7473 problems, too few for training a language model of reasonable size. Additionally, current methods have not capitalized effectively on the potential of small models, necessitating the exploration of new datasets and optimization techniques to improve the performance of SLMs in mathematical reasoning tasks.

#### Core Contributions
- **Introduced a new synthetic dataset called TinyGSM**
    - **Challenge 1: Passive learning limitations**
        Addressing the limitations of passive learning, especially in numerical calculation and code execution faced by small language models, TinyGSM overcomes this via math problems and their Python solutions generated by GPT-3.5. The problems in the dataset feature appropriate randomness and diversity, aiding in enhancing the mathematical reasoning capability of small models. 

    - **Challenge 2: Accuracy verification issue**
        TinyGSM uses a separate verifier to predict whether a generated answer is correct and selects the highest-scoring one among multiple temperature-sampled candidate answers. This strategy enables the determination of the best generation when labels are unclear.
        
#### Implementation and Deployment
According to the study, the research team fine-tuned models Phi-1.5 125M, 350M, and 1.3B on the TinyGSM dataset and achieved significant success. Notably, the 1.3B variant of Phi-GSM model reached an 81.5% accuracy rate on the GSM8K dataset, surpassing the 77.4% test accuracy of GPT-3.5-turbo. Using an Adam optimizer with FP16 precision for training and generating multiple candidate solutions via temperature sampling, the solutions were then scored and selected by a verifier. The results show that training and selection using TinyGSM and a verifier can allow even small language models to perform strongly in mathematical reasoning tasks.

#### Summary
This paper has successfully demonstrated that small language models can exceed an 80% accuracy rate on the GSM8K math problem reasoning benchmark by creating a synthetic dataset of math problems with corresponding Python solutions (TinyGSM), showing the feasibility of significant performance improvement of small models through high-quality datasets and verifier strategies.