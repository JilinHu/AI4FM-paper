#### Background
- **Background**
The paper discusses the capacity of Large Language Models (LLMs) to reason with knowledge graphs using the internal knowledge graph they learned during pre-training. The study formulates two research questions to probe the precision of LLMs in recalling information from pre-training knowledge graphs and their ability to infer knowledge graph relations from context.

- **Existing Work**
Previous research has not examined the capability of LLMs to deduce knowledge using their internal knowledge graphs. Since the training process and training data are undisclosed for mainstream LLMs such as text-davinci-003 and ChatGPT, it is unclear whether LLMs are pre-trained on knowledge graph data. The study thus investigates the capacity of LLMs in recalling information from their internal KGs, in particular deducing direct relations (one-hop connections in the KG), and explores LLMs' ability to extract contextual information from a given text. The paper addresses two primary queries: the accuracy of LLMs in recalling KG information (RQ1), and the ability of LLMs to infer KG relations from context (RQ2).

#### Core Contributions
  - **Introduced a method to explore the reasoning capability of LLMs using their internal knowledge graphs**
    - **Challenge 1: How to accurately recall information from knowledge graphs**
        This was assessed by performing two non-contextual relation generation tasks: tail entity prediction and relation prediction, requiring LLMs to remember and utilize the KG structure learned during pre-training. In addition, the study defined two types of hallucinations that may occur during knowledge reasoning with LLMs: content and ontology hallucination.

    - **Challenge 2: How to infer knowledge graph relations from context**
        This was done by undertaking two tasks: Relation Extraction (RE) and Contextual Path Generation (CPG) to generate contextual relations using LLMs. This is a more challenging task that requires not only relation inference but also the formation of paths within the KG.

#### Implementation and Deployment
The study employed three text-based large language models—text-davinci-003, ChatGPT, and GPT-4—for testing the LLMs. These experiments were conducted in a zero-shot setting, meaning the models were not specifically trained for the task at hand prior to the experiments. Using two evaluation metrics, Hard Accuracy (H-ACC) and Soft Accuracy (S-ACC), the study conducted tests on a random sample of 100 entity-relation pairs from DBpedia. The results indicated that LLMs can handle both simple and complex knowledge graph reasoning tasks from memory and infer knowledge graph relations from given context.

#### Summary
The study demonstrates the capability of LLMs to successfully work through knowledge graph reasoning tasks using their internal knowledge graph and to infer knowledge graph relations from context, showcasing the potential and applicative value of LLMs in knowledge graph reasoning.