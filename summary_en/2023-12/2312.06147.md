#### Background
- **Background**
This paper examines LLMs' ability to process and understand HTML code and investigates how LLMs can be used to retrieve and locate important elements from web interfaces in response to a user's query. The article dissects the issue into a more fundamental operation, distinctly different from previous works which focused on autonomous web navigation—asking if LLMs can identify the important information in the web page for a given query. Decomposing the problem allows for a thorough assessment of LLMs' current capabilities, revealing both opportunities and challenges.

- **Existing Work**
Earlier research demonstrated LLMs' potential in handling tasks related to the mobile user interface (UI), but these autonomous assistants have not yet surpassed a 15% task completion rate for real-world websites—demonstrating that they are not practically applicable for everyday use yet. Additionally, contemporary studies have concentrated more on mobile UI which has a smaller search space compared to the more complex Web UI with more elements per page, posing greater challenges in processing and integrating with LLMs.

#### Core Contributions
  - **An in-depth experimental study on the potential of LLMs in Web UI information retrieval**
      - **Challenge 1: What example selection is best for In-context learning (ICL) effectiveness?**
          It was found that selecting examples semantically related to the task improves LLM performance with single-shot prompts but decreases it with two-shot prompts, suggesting that careful example selection is crucial to enhancing LLM performance while also being mindful of the sequence length.

      - **Challenge 2: How does the specificity of user queries affect the performance of LLMs?**
          The research indicates that more detailed task descriptions help LLMs generalize better across tasks with varying levels of specificity. Providing more abstract fixed examples may have helped the model better understand and execute user commands.

#### Implementation and Deployment
The researchers conducted experiments on the Claude2 model to investigate several key components impacting model performance. These include the selection of a few-shot examples, the level of detail in natural language commands within the user query, strategies for HTML truncation, and the particular role played by the LLM (persona). Results show that performance depends on these components, with carefully prompted few-shot examples aiding success. However, critical limitations of LLMs, such as fabricating non-existing web elements and failing to follow input instructions, were identified. The study concludes by suggesting future research directions and potential solutions to these observed limitations【8】【10】【11】【12】【16】.

#### Summary
The paper explores the capabilities and challenges of LLMs in retrieving information from web interfaces, unveiling key factors affecting model performance and their limitations, setting a direction for future work.