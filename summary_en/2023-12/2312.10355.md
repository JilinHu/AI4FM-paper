#### Background
- **Background**
Natural language generation (NLG) evaluation has recently moved from a single-aspect to a multi-aspect paradigm, allowing for more accurate assessments. Large language models (LLMs) perform exceptionally well in various NLG evaluation tasks. However, the current research often evaluates different aspects independently, largely ignoring the rich correlations between multiple aspects.

- **Existing Work**
The existing work fails to provide a comprehensive and precise evaluation due to the lack of consideration of the interrelations between different aspects of NLG evaluation.

#### Core Contributions
- **Introduced an evaluation metric called CoAScore**
  - **Challenge 1: How to improve evaluation accuracy by using multi-aspect knowledge in assessing a specific aspect?**
      The CoAScore framework uses LLMs to assess the quality of a target aspect through a series of related aspect prompts. It begins by prompting the LLM to generate a chain of aspects relevant to the target aspect and useful for evaluation. Evaluation scores for each generated aspect are then collected, and finally, the knowledge of these aspects is used to enhance the evaluation of the target aspect.

  - **Challenge 2: How to validate the effectiveness of CoAScore and demonstrate LLMâ€™s performance in different stages?**
      CoAScore was evaluated across five NLG evaluation tasks (e.g., summarization and dialogue response generation) and nine aspects (e.g., overall quality, relevance, coherence). The results indicate that CoAScore has a stronger correlation with human judgments compared to individual aspect evaluations and it significantly outperforms unsupervised evaluation metrics in assessing both overall quality and other aspects. Extensive ablation studies were also conducted to confirm the effectiveness of the three stages within the CoAScore framework, and case studies were presented to illustrate LLM performance at these stages.

#### Implementation and Deployment
The CoAScore evaluation process consists of three stages to assess the quality of NLG hypothesis text: (1) generating a chain of aspects related to the target evaluation aspect; (2) scoring each generated aspect within the hypothesis; (3) enhancing the evaluation capability for the specific target aspect using the relevant aspect chain knowledge. The experimental findings show that CoAScore correlates more closely with human judgments in terms of overall quality and other aspects than existing unsupervised baselines. The correlation tends to strengthen as the number of related aspects grows. The effectiveness of each stage was also independently confirmed through comparative experiments.

#### Summary
CoAScore is an innovative evaluation metric that improves the accuracy of NLG task assessments through a "chain of aspects" method, an approach that has been experimentally validated.