#### Background
- **Background**
The paper introduces in-context learning (ICL) as a promising capability of large language models (LLMs), enabling them to perform a variety of tasks by learning from provided examples. Despite its potential, the underlying mechanism of how LLMs learn from context remains underexplored.

- **Existing Work**
Existing work has not delved into the working mechanism of LLMs in terms of in-context learning, which results in a lack of understanding of the specific processes through which LLMs learn.

#### Core Contributions
  - **Introduced a new perspective based on an information flow perspective to investigate the ICL working mechanism**
    - **Challenge 1: Understanding the Mechanism of In-Context Learning**
      The analysis from an information flow perspective found that label words in examples serve as anchors: semantic information aggregates into label word representations during the processing of shallow computation layers; and in deep layers, this aggregated information serves as a reference for LLMsâ€™ final predictions. They proposed a hypothesis based on label words functioning as anchors in the ICL information flow, which was then validated and supported by the results.

    - **Challenge 2: Improving ICL Performance and Error Analysis**
      Using the findings on label words acting as anchors in the information flow, they introduced an anchor re-weighting method to improve ICL performance, a demonstration compression technique to speed up inference, and an analysis framework for diagnosing ICL errors in GPT2-XL. These applications confirm the uncovered working mechanism and lay the groundwork for future research.

#### Implementation and Deployment
The GPT2-XL model was chosen as the main subject for exploration, and various datasets were used to evaluate the proposed hypothesis. They manipulated the attention mechanism to block information flow, studied whether label words aggregate information in shallow layers, and extract information in deep layers to form the final prediction. They assessed model prediction consistency using metrics like Label Loyalty and Word Loyalty. Experimental results demonstrated a significant impact on model behavior when label words were isolated in shallow layers, confirming the importance of information aggregation through label words. The research ultimately showed that label words indeed act as anchors in ICL, a finding that can enhance model performance.

#### Summary
The paper explores the internal mechanism of in-context learning (ICL) by large language models from an information flow perspective, identifying the anchoring phenomenon of label words, proposing a new hypothesis, and experimentally validating its effectiveness. Moreover, the insights were used to propose methods for improving ICL performance, providing a theoretical foundation and practical guidance for future related researches.