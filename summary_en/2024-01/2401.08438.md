#### Background
- **Background**
The paper discusses the limitations of large language models (LLMs) in simulating cognitive dynamics.
- **Existing Work**
Existing efforts have failed to fully replicate the dynamism and the continuous information processing of human cognition, leading to deficiencies in decision-making rationality and authenticity in complex environments.

#### Core Contributions
  - **Introduced a LLM-driven agent with an iterative cognitive mechanism named CogGPT**
    - **Challenge 1: Continuous perception and storage of information**
      CogGPT utilizes a memory retention system to mimic brain functions, with its short-term memory acquiring textual information and its long-term memory filtering information. The model is designed following the forgetting curve principle to simulate the forgetting and retention of information, enhancing adaptability to dynamic information flows.
    - **Challenge 2: Life-long cognitive dynamics**
      CogGPT incorporates a collaborative refinement framework enabling the model to imitate the continuous updating and evolution of human cognitive dynamics. This framework is activated when short-term memory is full, selecting preferred textual information to update the current profile, ensuring adaptability to continuous information flows.

#### Implementation and Deployment
Evaluation results show that CogGPT outperforms baseline agents CoT, ReAct, and Reflection on two specially created CogBench tests in terms of Authenticity and Rationality metrics. CogGPT effectively imitates cognitive dynamics, demonstrating more human-like scoring and reasoning abilities.

#### Summary
CogGPT addresses challenges faced by large language models in emulating human cognitive dynamics by introducing an iterative cognitive mechanism and a memory retention system, showcasing impressive performance in continuous information processing.