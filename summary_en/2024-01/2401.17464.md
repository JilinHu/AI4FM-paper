#### Background
- **Background**
The paper discusses the limitations of Large Language Models' (LLMs) abilities to solve problems due to their reliance on predefined knowledge and domain-specific tools, constraining their potential for generalization and expanded reasoning.

- **Existing Work**
Existing approaches typically fail to abstract and decouple LLMs' generic reasoning from the acquisition of domain-specific knowledge, hence restricting the efficient use of external tools during reasoning and limiting the speed of the reasoning process.

#### Core Contributions
- **Introduced a method named Chain-of-Abstraction (CoA) Reasoning**
  - **Challenge 1: How to improve LLMs' ability to utilize domain-specific tools**
    LLMs usually struggle to integrate and apply information from external tools for reasoning. CoA overcomes this issue by replacing concrete values in reasoning processes with abstract placeholders, allowing the model to focus on learning general reasoning strategies without generating instance-specific knowledge.
  
  - **Challenge 2: How to speed up the reasoning process of LLMs**
    With the use of abstract placeholders, LLMs can process and switch between samples in parallel with API calls (through a pipeline), enabling the model to generate the next abstract chain while the tool fills in the current one, which speeds up the overall reasoning process.

#### Implementation and Deployment
The paper conducted experiments in two domains: mathematical reasoning and Wikipedia Question Answering (Wiki QA), comparing their CoA reasoning method with several baselines including few-shot prompting with original chain-of-thought data, fine-tuning with original chain-of-thought data, and the Toolformer method. The results show that the CoA method performed exceptionally well, especially in understanding multi-step reasoning problems, with an overall accuracy of 78.89%, significantly better than other methods tested.

#### Summary
The paper proposes a novel Chain-of-Abstraction reasoning approach that effectively enhances LLMs' capability to use external tools and expedites the reasoning process. Experimental results demonstrate its effectiveness and efficiency in multi-step reasoning tasks.