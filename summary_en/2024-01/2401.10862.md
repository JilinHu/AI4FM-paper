#### Background
- **Background**
The paper discusses increasing resistance to "jailbreak" attacks on aligned LLMs without fine-tuning by employing a pruning method called Wanda, which is computationally efficient and able to maintain good performance while compressing the models.

- **Existing Work**
There are conflicting experimental results with existing work, where specific compression methods and implementation details can lead to improvements in robustness or a trade-off. The "jailbreak" attempts involve users ingeniously crafting prompts to ignore underlying system prompts or disregard its safety training.
  
#### Core Contributions
  - **Introduced a model compression framework based on the Wanda pruning method**
    - **Challenge 1: Enhancing model resistance against jailbreak attacks**
      This work explores the impact of the Wanda pruning method on model safety, specifically on how the model resists adversarial "jailbreak" attacks. The method compresses models by assigning importance scores to weights, pruning less important connections, and aims to improve the model's safety without compromising performance.
      
    - **Challenge 2: Dataset curation and evaluation methodology**
      The researchers curated a dataset of 225 hypothetical malicious tasks representing various types of malintent, divided into five categories. They designed an experimental setup of "jailbreak" attacks and assessed the model's robustness using a fine-tuned ChatGPT-3.5 Turbo model to classify and evaluate the responses from the base models and pruned models.

#### Implementation and Deployment
In experiments, three 7-billion parameter FP16 models were used and pruned at 10%, 20%, and 30% sparsity using the Wanda method. The pruned models were not fine-tuned. During evaluation, responses from both pruned and base models to malicious tasks were collected, and a fine-tuned ChatGPT-3.5 Turbo model classified these responses. The classification results provided a comprehensive measure of jailbreak success, with manual verification ensuring the accuracy of the categories. Additionally, pruned models were benchmarked on Huggingface's Open LLM Leaderboard to ensure that they still have the capacity to perform various tasks.

#### Summary
The paper presents how LLMs can be made more resistant to "jailbreak" attacks from a safety alignment perspective through Wanda pruning without the need for fine-tuning and validates model performance through a constructed dataset and evaluation system.