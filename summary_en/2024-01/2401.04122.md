#### Background
- **Background**
The paper addresses the transformation from prompt engineering to prompt science in interactions with LLMs, employing a human-in-the-loop approach to refine the systematicity, consistency, and explainability of the process of generating prompts that guide models towards desired outputs.

- **Existing Work**
Existing practices often lack a systematic and consistent approach to the creation and validation of prompts for LLMs, relying instead on heuristic methods and researcher intuition, which results in outcomes that are subjective and opaque.

#### Core Contributions
- **Introduces a new method based on a qualitative coding process with human in the loop**
  - **Challenge 1: How to systematically create prompts that are robust and generally applicable**
    The proposed method treats the creation of prompts as the construction of a codebook in qualitative research. Through a multi-phase approach, it ensures that the responses generated by the LLM are verifiable, explainable, and conform to predetermined quality standards.
  
  - **Challenge 2: Ensuring that generated prompts consistently produce the desired responses**
    By employing at least two human evaluators to assess the responses from the LLM and iteratively developing and refining the prompts, the method maintains consistency and general applicability across different experiments, LLMs, and contexts.
  - ...

#### Implementation and Deployment
The methodology consists of four stages: setting up the initial pipeline, identifying criteria for evaluating LLM responses, iteratively developing the prompt, and validating the entire pipeline. Throughout this process, testing and restructuring of the prompt ensures systematically produced desired responses. This process involves significant human review and iterative refinement to guide the prompt generation process not by intuition or personal preference but by scientific methods and clear criteria.

#### Summary
The paper demonstrates how to transition prompt engineering for LLMs into a more scientific and systematic prompt science. By incorporating a qualitative coding method analogous to the human-in-the-loop approach, it ensures the quality and consistency of the responses generated by the LLM while eliminating individual subjectivity and randomness.