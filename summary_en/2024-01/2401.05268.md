#### Background
- **Background**
This paper presents a framework named AUTOACT, which aims to automatically learn agents from scratch through self-instructing and self-planning methods. The process only requires the target task information and a language agent (META-AGENT). It starts by augmenting task data from the ground up and then uses a tool library to further automate the learning process.

- **Existing Work**
Existing methods may not provide a systematic framework for learning new tasks from scratch, without any prior knowledge, through self-instruction and planning. AUTOACT is designed to fill this gap by offering a flexible and efficient method for automatic agent learning.

#### Core Contributions
  - **Introduced a framework named AUTOACT for automated agent learning**
      - **Challenge 1: How to enhance and learn agents from limited task information?**
        AUTOACT utilizes the META-AGENT as the backbone model to perform autonomous learning from limited task information through self-instruction and self-planning. It generates new question-answer pairs to expand its database, achieving self-enhancement and learning for the agent.

      - **Challenge 2: How to ensure efficiency and effectiveness in the automated agent learning process?**
        Through self-differentiation and a lightweight LoRA fine-tuning process, AUTOACT ensures the generation and utilization of high-quality planning trajectories, thereby increasing the efficiency and effectiveness of automated learning.

#### Implementation and Deployment
The core components of the AUTOACT framework include the META-AGENT, target task information, a tool library, and the creation of self-differentiated sub-agents. In implementation, META-AGENT uses the prepared tool library to select appropriate tools based on task information and expands the database through self-instruction. Through self-planning, the META-AGENT generates planning trajectories and self-differentiates based on these trajectories into three sub-agents with distinct functions: a planning agent, a tool agent, and a reflection agent. Experimental results demonstrate that AUTOACT's trajectory quality significantly outperforms that of other methods, showcasing its effectiveness in multiple aspects.

#### Summary
This research introduces AUTOACT, a framework for autonomous learning of language agents through self-instruction and self-planning to tackle the challenge of learning new tasks from scratch. The key contributions lie in its effective data augmentation method and the highly efficient automatic agent learning process.