#### Background
- **Background**
    The paper introduces Vlogger, a generic AI system capable of generating minute-long video blogs (vlogs) based on user descriptions. Unlike short videos spanning just a few seconds, vlogs often contain complex storylines and diversified scenes, presenting challenges for most prevailing video generation methodologies.
    
- **Existing Work**
    Current video diffusion approaches primarily function on adapting image diffusion models to produce short videos of a few seconds. In contrast, vlogs typically entail minute-scale length, and previous efforts have faced challenges requiring extensive training on large, well-captioned datasets or falter with inconsistent scene transitions.

#### Core Contributions
    - **A novel system Vlogger**
        - **Challenge 1: Creating scripts and designing shots for long videos**
            Vlogger employs a Large Language Model (LLM) as a Director, such as GPT-4, leveraging its extensive understanding of linguistic knowledge to schedule a four-step plan for vlog generation, converting a user story into a script and designing actor images for each shot.
        
        - **Challenge 2: Spatial-temporal coherence in video snippets**
            Vlogger introduces a novel video diffusion model, ShowMaker, serving as a cinematographer, generating video snippets of each shooting scene from script texts and actors' images while enhancing the snippets' spatial-temporal cohesion.

#### Implementation and Deployment
Vlogger, through the collaborative efforts of top-down planning and bottom-up shooting, effectively turns an open-world story into a minute-long vlog. ShowMaker implements a sequential combination of generation and prediction modes in the inference phase, producing video snippets with controllable durations. The experimental findings indicate Vlogger's state-of-the-art performance in zero-shot T2V generation and prediction, as well as its capability to create over 5-minute vlogs without compromising video coherence on script and actors.

#### Summary
This paper presents the innovative use of LLMs in the production of video blogs, addressing the challenges of creating minute-scale coherent video content and delivering exceptional experimental results.