#### Background
- **Background**
The article highlights that Large Language Models (LLMs) have demonstrated exceptional aptitude in understanding intent, following instructions, and tackling tasks across various applications. However, as general-purpose task assistants, LLMs typically lack human-like attributes, such as experiential events and emotions, limiting their ability to facilitate engaging and extensive conversations with users. Role-play LLMs seek to infuse emotional value into user interactions by allowing users to define and create profiles for their desired characters. Existing efforts have aimed to replicate the role-play capabilities demonstrated by proprietary models like GPT-4 by using weaker open-source models.

- **Existing Work**
Existing studies generally presume the presence of more capable role-play models and depend on manually annotating large datasets to build such models. Imitation models are effective at emulating GPT-4’s style but struggle to replicate its factual accuracy, leading to increased hallucination and are also bound by OpenAI’s terms of use.

#### Core Contributions
- **Introduced a self-alignment method named DITTO**
    - **Challenge 1: Enhancing LLMs' Role-play Abilities**
        DITTO leverages character knowledge embedded in massive training corpora to encourage instruction-following LLMs to simulate role-play dialogues as a variant of reading comprehension. This approach creates a role-play training set with 4000 characters—ten times the number of roles in currently available datasets.

    - **Challenge 2: Designing an Effective and Reproducible Role-play Assessment Method**
        An objective role-play evaluation method was designed focusing on consistent role identity, accurate role-specific knowledge, and the cognitive boundary. This assessment is more reproducible, explainable, and efficient compared to manual annotations.

#### Implementation and Deployment
The LLM was fine-tuned using this self-generated dataset to enhance its role-play capabilities. DITTO was rigorously evaluated on a reproducible role-play benchmark and the role-play subset of MT-Bench, maintaining consistent role identity and providing precise role-specific knowledge in multi-turn role-play conversations. Remarkably, it surpassed all open-source role-play baselines, displaying performance levels on par with advanced proprietary chatbots. Moreover, through comprehensive cross-supervision alignment experiments, it was revealed that role-play knowledge is limited by the intrinsic abilities of LLMs in strong-to-weak settings, while weak-to-strong generalizations remained stable for knowledge-related metrics. These insights provide a deep and sound understanding of LLM role-play and alignment, indicating that the knowledge of seed LLMs and proper demonstrations, such as simulation data from DITTO, are crucial for achieving impressive role-play capabilities.

#### Summary
The paper proposes DITTO, a self-alignment method that enhances LLMs' role-play capabilities through knowledge augmentation and dialogue simulation. It also provides a reproducible, explainable, and efficient role-play evaluation method and explores the dissection of role-play through cross-supervision experiments, offering an in-depth understanding and insights into building role-play functions for LLMs.