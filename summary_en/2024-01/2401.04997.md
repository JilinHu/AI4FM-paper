#### Background
- **Background**
The paper explores how large language models such as ChatGPT have demonstrated their ability to solve general tasks, showing potential for applications in recommender systems.

- **Existing Work**
Existing research typically classifies work based on specific criteria and introduces them separately, focusing more on showcasing and summarizing the related work's strengths and limitations instead of validating existing results and exploring for new findings. Due to these limitations, this paper focuses on the capabilities of LLMs as direct recommenders, aiming to establish a general framework to efficiently employ LLMs as recommendation systems.

#### Core Contributions
  - **A general framework named ProLLM4Rec**
      - **Challenge 1: How to use LLMs as recommender systems**
        The framework formalizes the input to LLMs as natural language prompts and explains how to generalize the framework to various recommendation scenarios and tasks. It assesses the application of LLMs as recommenders by analyzing the impact of public availability, tuning strategies, model architecture, parameter scale, and context length on recommendation outcomes.

      - **Challenge 2: Constructing and applying effective prompt engineering**
        It analyzes the impact of four crucial components: task description, user interest modeling, candidate item construction, and prompting strategies. These involve personalized prompts that include task description and user interest, wherein the LLM selects, generates, or explains candidate items based on general world knowledge and personalized user profiles.

#### Implementation and Deployment
Extensive experiments were conducted on two public datasets, leading to key findings for recommendations using LLMs. Findings include experimental settings for each aspect of the proposed framework and provide empirical insights for evaluating the performance of LLMs on recommendation tasks for future research.

#### Summary
This work introduced a framework named ProLLM4Rec, offering a systematic analysis of utilizing Large Language Models (LLMs) as foundation models for recommendation systems and tested the impact of different conditions on LLMs through experiments. Empirical findings were summarized, providing insights for future research.