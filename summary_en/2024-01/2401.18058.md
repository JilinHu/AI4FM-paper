#### Background
- **Background**
Large Language Models (LLMs) are advantageous in handling tasks like summarization, question-answering on long texts, and coding. They could be foundational for persistent conversations and complex agent scenarios. Existing long-context LLMs focus mainly on extending the context, particularly through position encoding extension and continuous training on long texts. This paper, however, focuses on long context alignment, i.e., fine-tuning LLMs to handle longer user prompts.

- **Existing Work**
Although methods that don't require fine-tuning, such as sliding window attention or neighboring token compression, can extend LLMs context length in a plug-and-play manner, they cannot match the performance of fine-tuned methods. The main fine-tuned methods for long context scaling typically involve position encoding extension and continuous pretraining on longer sequences. Besides, to ensure that the model can interact with various user requests in a chat interface, it is necessary to align the model with instruction-following data. The introduction of long sequences poses unique challenges in terms of data training methods and alignment evaluation.

#### Core Contributions
  - **Introduced LongAlign**
    - **Challenge 1: Lack of long instruction-following datasets**
      To address the absence of long instruction-following datasets, the paper presents the use of Self-Instruct to construct a diverse long instruction-following dataset. The dataset covers a wide range of tasks from various long context sources.

    - **Challenge 2: Inefficient training due to uneven length distribution of long-context data**
      The paper tackles this issue by adopting packing and sorted batching strategies to speed up supervised fine-tuning on data with varied length distributions. They also develop a loss weighting method to balance the contributions to the loss across different sequences during packing training.
  - ...

#### Implementation and Deployment
In experiments, LongAlign significantly outperforms existing recipes for LLMs in long context tasks by up to 30%, while maintaining proficiency in handling short generic tasks. The packing and sorted batching strategies implemented in the paper can increase training speed by over 100% without sacrificing performance. Additionally, the proposed loss weighting technique improves long context performance by 10%.

#### Summary
The paper proposes a novel recipe, LongAlign, for the long context alignment of LLMs, by constructing a long instruction dataset, adopting new training strategies, and introducing evaluation benchmarks, enhancing the LLMs' ability to handle lengthy contexts. The code, data, and long-aligned models are open-sourced.