#### Background
- **Background**
This paper begins with an introduction to the LLM-based intelligent agent system, followed by a synopsis of the framework for LLM-based agent systems, prevalent datasets, and evaluation methodologies for agents. It examines the uses of LLM-based agents across a wide range of domains including natural sciences, social sciences, engineering systems, and general domains. Finally, it explores the developmental trajectory of agents involving the enhancement of LLM-based agents' adaptive capacity by incorporating multimodal models or LMMs and addressing encountered challenges.

- **Existing Work**
Existing research classifies LLM-based intelligent agents into two main categories: Single-Agent and Multi-Agent systems. However, current evaluation methods and tools are not standardized, and considerable differences exist between different types of LLM agents. For instance, an agent in a single-agent system consists of an individual LLM performing tasks based on its language comprehension and generation capabilities. In contrast, multi-agent systems require complex coordination among multiple agents, especially regarding interaction and information sharing. Hence, existing work has not completely resolved the issue of unified evaluation and functional standardization of LLM agents across diverse tasks and environments.

#### Core Contributions
- **Proposed a framework for LLM-based intelligent agent systems**
    - **Challenge 1: Unified intelligent agent evaluation**
The lack of standardized evaluation methods and tools for agent systems leads to non-unified assessments and difficulties in comparison. The paper presents a framework for LLM-based intelligent agent systems that clearly outlines key components like planning, memory, rethinking, environment, and action, thus aiding future researchers and enthusiasts in the development of more relevant and functional agents, and ensuring the unified evaluation and comparison of agent performance.
    - **Challenge 2: Adaptation and planning capabilities of LLMs**
LLMs primarily communicate via natural language or specific texts, their internal structures and training methods grant them a degree of planning capability. The paper stresses that guiding LLMs to think and plan is an important direction for development and proposes concepts such as Chain of Thought, Self-consistency, Tree of Thought, and various in-context learning methods to enhance the adaptive and planning capabilities of LLMs.

#### Implementation and Deployment
The paper lists various existing projects of LLM-based single-agent and multi-agent systems with differences in functionalities, feedback mechanisms, planning, and reflection, and proposes multiple templates and projects such as ToolLLM, AutoGPT, XLang, which support different functionalities, approaches to thinking, planning, and reviewing, and permit the integration of different models as the core component. The paper also showcases how various LLM agents are deployed in different application fields and provides detailed examples and comparative tables.

#### Summary
The paper presents a framework for guiding future research and development of LLM-based intelligent agent systems, explores different methods of improving their planning capabilities, multimodal information processing, and how to address the challenges faced by LLM agents, offering a clear guide for future research directions.