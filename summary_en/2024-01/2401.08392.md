#### Background
- **Background**
The field of AI agents has been focusing primarily on static image tasks, which limits their capability to understand the dynamic nature of the real world. Existing research rarely explores video modalities, which can better reflect the continuously changing and perceptually intensive nature of real-life scenarios.

- **Existing Work**
Existing efforts have been directed at creating task-specific multimodal systems that show impressive performance within their domains but have limited applicability to broader real-world scenarios due to a lack of generalizability. Although there has been some progress with LLMs, the majority of work still concentrates on strategies for solving composite tasks of static modalities while overlooking the essential differences between static and dynamic modalities crucial for achieving General Artificial Intelligence (AGI).

#### Core Contributions
  - **DoraemonGPT**
    - **Challenge 1: Understanding dynamic video tasks**
        DoraemonGPT was introduced, which transforms input video content into a symbolic memory that stores task-related attributes. This structured representation facilitates spatial-temporal querying and reasoning through sub-task tools, resulting in concise and relevant intermediate results. It also incorporates plug-and-play tools to evaluate external knowledge and address tasks across different domains.

    - **Challenge 2: Effective Planning and Execution**
        A novel planner based on Monte Carlo Tree Search (MCTS) was developed to explore the vast planning space efficiently. The planner iteratively finds possible solutions and consolidates multiple solutions into an enhanced final answer, allowing for handling more complex questions.

#### Implementation and Deployment
DoraemonGPT includes a Task-related Symbolic Memory (TSM) for converting massive video content into symbolic memory that stores attributes related to tasks. It supports two types of memories based on instances and time frames and uses sub-task tools for querying this information. DoraemonGPT also automates the scheduling of toolsets for querying symbolic memory, accessing external knowledge, and using other utility tools. The MCTS planner explores the planning space, generates multiple possible answers, and summarizes the best answer. Extensive evaluations of DoraemonGPT in dynamic scenes have demonstrated its ability to tackle more complex issues than previous studies.

#### Summary
DoraemonGPT is an LLM-driven agent that employs symbolic memory and a set of tools to understand and answer complex questions involving dynamic videos. It leverages an MCTS planner to optimize the process of generating answers, enabling it to handle more complex tasks in real-world scenarios.