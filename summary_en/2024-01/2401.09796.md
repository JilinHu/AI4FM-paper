#### Background
- **Background**
The paper discusses the significance of distributed (federated) LLM as a method for co-training domain-specific LLMs using isolated data. The issue of maliciously stealing model parameters and data from both the server and client side has been identified as a pressing concern that needs to be addressed.

- **Existing Work**
Past work has primarily focused on threats from the server side without considering the simultaneous leakage of parameters and data on the client side. Although federated learning has various security threats, including Additively Homomorphic Encryption (AHE) and Differential Privacy (DP), these methods can either only protect the data, not prevent parameter leakage, or significantly reduce performance.

#### Core Contributions
  - **A secure distributed LLM framework based on model slicing**
    - **Challenge 1: Avoiding parameter and data leakage**
      To tackle this problem, the paper proposes a combination of Trusted Execution Environment (TEE) and lightweight encryption to ensure security. In distributed training, only part of the parameters are fine-tuned, and the paper presents different schemes for different types of TEEs, i.e., SGX (small memory without GPU) and Intel TDX/SGX (large memory without GPU).
 
    - **Challenge 2: Reducing equipment cost and enhancing model performance and accuracy**
      The paper introduces a split fine-tuning scheme, where the LLM is split by layers, and the latter layers are placed in a server-side TEE (not required by the client). It also combines the proposed Sparsification Parameter Fine-tuning (SPF) with the LoRA part to improve the accuracy of downstream tasks.

#### Implementation and Deployment
The experimental results have demonstrated that the proposed method ensures high efficiency and accuracy while maintaining security. Deploying TEE on both client and server sides and fine-tuning structures such as LoRA and P-Tuning v2 within the TEE, the framework ensures secure communication executed in the TEE and general environments via lightweight encryption. For feature encryption and decryption, One Time Pad (OTP) is employed to protect features transmitted between the GPU and TEE, hence safeguarding user information.

#### Summary
This paper presents a secure distributed training framework based on model slicing, which solves the problem of model parameter and data leakage on both server and client sides while ensuring the precision of the model training and high efficiency.