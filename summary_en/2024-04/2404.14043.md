#### Background
- **Background**
The paper discusses the challenges faced by Large Language Models (LLMs) in dealing with Retrieval-Augmented Generation (RAG) issues. RAG has demonstrated substantial value in mitigating outdated knowledge or hallucinations by supplying LLMs with updated and relevant knowledge. However, there are still some difficulties in understanding complex multi-hop queries and retrieving relevant documents.

- **Existing Work**
Existing research has utilized LLMs for summarizing documents and extracting information. For complex multi-hop queries, breaking the query down into sub-questions has been effective. However, traditional CoT-based methods are susceptible to hallucination during query decomposition and often require the integration of task-specific demonstrations to improve reasoning quality.

#### Core Contributions
- **Introduced the Missing Information Guided Retrieve-Extraction-Solving paradigm (MIGRES).**
    - **Challenge 1: Sparse or opaque information resulting from complex multi-hop queries.**
        To overcome the challenges of complex and multi-hop user input queries, researchers proposed the MIGRES method, leveraging the identification of missing information to create targeted queries that guide subsequent knowledge retrieval. Additionally, they designed a sentence-level re-ranking filtering method to filter out irrelevant content from documents, and using the information extraction capability of LLMs to extract useful information from cleaned-up documents, thus improving the overall efficiency of RAG.

    - **Challenge 2: The difficulty of retrieving relevant documents and filtering out irrelevant content.**
        MIGRES also made efforts on the document side, enhancing model's capabilities by removing irrelevant content through a re-ranking filtering strategy, and providing LLMs with cleaned-up documents to further boost their ability to extract valuable information from retrieved documents.

#### Implementation and Deployment
The paper set up preliminary experiments to verify LLMs' capabilities in information extraction and identifying what is missing, utilizing datasets like 2WikiMultiHop and Musique and operating under a zero-shot setting. They also used the gpt-3.5-turbo model as the backend LLM, with outstanding precision in information extraction and missing information generation, achieving an average accuracy of 95.6% when knowledge is incomplete.

#### Summary
The MIGRES framework proposed in this study enhances RAG by exploiting LLMs' ability to identify missing information. Research results prove the superiority of MIGRES across multiple public datasets, addressing challenges in RAG's understanding of complex queries and retrieval of relevant documents.