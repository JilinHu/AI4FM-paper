#### Background
- **Background**
This paper explores whether LLMs can truly perform analogical reasoning, which is a human ability to tackle unfamiliar challenges by recalling relevant experiences from the past. In psychology, it's regarded that recalling relevant experiences rather than irrelevant ones can better help humans to handle new tasks. The AI community has also recently found that self-generating relevant examples in context can help LLMs better solve a given problem than hand-crafted prompts. However, it's still unclear if relevance is the key factor that triggers such capability in LLMs.

- **Existing Work**
Prior studies have indicated that LLMs are capable of generating examples relevant to the query as context to improve problem-solving. This suggests that LLMs might exhibit analogical reasoning capabilities. However, current studies haven't systematically assessed the ability of LLMs to conduct analogical reasoning, nor have they engaged in extensive experiments and analysis.
#### Core Contributions
  - **Challenge 1: Effectiveness of self-generated relevant examples**
      In this study, through extensive experiments and analysis, it was demonstrated that prompting LLMs to self-generate random examples can surprisingly achieve comparable or even better performance than relevant examples, for instance, achieving a 4% performance boost on the GSM8K dataset with random biological examples. This finding challenges the assumed importance of relevant examples in analogical reasoning, suggesting that LLMs may not always perform analogical reasoning.
      
  - **Challenge 2: Accuracy of self-generated examples**
      To address the above challenge, the paper points out through controlled experiments that the accuracy of self-generated examples is a key factor. Two improved methods that significantly reduce inference costs while improving performance were designed. Specifically, LLMs are tasked to randomly generate several problems and manually verify their correctness, then use this verified set of problems as in-context learning demonstrations for all test samples.

#### Implementation and Deployment
The paper primarily used the GPT-3.5 model as the LLM and tested performance on various reasoning-intensive tasks, including mathematical reasoning and other forms of reasoning such as logical and temporal reasoning. Experiments were conducted three times with different random seeds to produce consistent results that were then compared with relevant work, showing that self-generated irrelevant examples consistently excelled over relevant examples in performance. Furthermore, the research was expanded to the open-source Llama-2-Chat model to verify the consistency of the observations and conclusions across different models.

#### Summary
The paper thoroughly assessed LLMs' capability for analogical reasoning and introduced two methods that significantly reduce inference costs while enhancing performance. Findings revealed that, contrary to the previously held belief of the critical importance of relevance, self-generated irrelevant examples could perform equally or even better in some tasks. The study hopes to encourage further research on the design of self-generated contexts.