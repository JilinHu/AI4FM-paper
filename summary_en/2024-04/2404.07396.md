#### Background
- **Background**
This study explores the accuracy of OpenAI's ChatGPT-3.5 and ChatGPT-4 at forecasting future events, leveraging the fact that the model's training data stopped in September 2021, to inquire about events occurring in 2022. It employed two prompting strategies: direct prediction and what the study refers to as future narratives, where ChatGPT was prompted to tell fictional stories set after its own training data timestamp.

- **Existing Work**
Although Large Language Models (LLMs) like OpenAI's GPT-4 are capable of emulating intelligent human speech and performing complex cognitive tasks, the accuracy of these models as forecasting tools remains unknown due to the inherent limitations in their training data. Moreover, the creativity and hallucinatory tendencies in LLMs could impede their predictive capabilities.

#### Core Contributions
  - **New method for predicting future events**
    - **Challenge 1: Enhancing the accuracy of predictions**
      Narrative prompts were found to significantly improve the forecasting accuracy of ChatGPT-4, especially when predicting major Academy Award winners and economic trends. This approach leverages the model's capacity for creative construction of narratives to synthesize data and make extrapolations more effectively than straightforward prediction tactics.

    - **Challenge 2: Adhering to OpenAI's terms of service**
      Direct prediction could contravene OpenAI's terms of service as it could imply high-risk automated decisions with significant impacts on individual's safety, rights, or well-being. This was addressed by directing ChatGPT to tell stories about the future rather than predicting future events directly.

#### Implementation and Deployment
The study revealed that when ChatGPT-4 was prompted with narrative cues to tell stories set in the future, the prediction machine exhibited unusually high accuracy. Researchers conducted 100 total trials per prompt by using two research assistants and two separate ChatGPT accounts with 50 inquiries per prompt. The findings were presented in box plots showing the entire distribution of answers for each prompt, indicating narrative prompts led to higher accuracy, especially in predicting awards and economic trends as inferred from scenarios where models impersonated public figures.

#### Summary
The research by probing the predictive abilities of ChatGPT-3.5 and ChatGPT-4 unveils new potential in reasoning capabilities of LLMs. The study confirms that future narrative prompts significantly enhance accuracy, offering valuable insights for potential applications of LLMs in analytical settings.