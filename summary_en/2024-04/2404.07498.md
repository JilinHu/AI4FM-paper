#### Background
- **Background**
The paper discusses Sequence Salience, a visual tool for interactive prompt debugging using input salience methods, tailored for complex LLM prompts. It is especially well-suited for long texts by providing controllable aggregation from token-level salience to higher levels including word, sentence, or paragraph, facilitating tractability over long inputs.

- **Existing Work**
Existing work mainly involves black-box interaction, and although there are sophisticated prompt engineering tools to guide developers, they often rely on external heuristics and design patterns, lacking real-time feedback and iterative improvement on complex prompts.

#### Core Contributions
  - **System: Sequence Salience**
    - **Challenge 1: Interactive debugging and rapid iteration**
      Existing input salience methods generally do not offer causal predictions of model behavior, but they provide useful heuristic information. Sequence Salience allows practitioners to interact in real-time, making changes to the input and immediately seeing the model's response, thus enabling error detection and prompt refinement.

    - **Challenge 2: Lowering cognitive load and aligning with the developer's mental model**
      Sequence Salience provides dynamic aggregation extending granularity from individual tokens to coarser levels such as words, sentences, and paragraphs, greatly reducing the cognitive load of practitioners and improving the alignment of salience prompts with the developer's mental model.

#### Implementation and Deployment
Sequence Salience is implemented as a browser-based user interface. Users can input or edit prompts through the Datapoint Editor, or select pre-loaded examples from a Data Table. They then choose a sequence to explain, either the model's response or a predefined target. Salience is computed and displayed over the text as a heatmap, with darker highlights indicating more importance to the chosen prediction target. Prompt Editing allows users to edit prompts based on their observations, run the model, and re-compute salience, using this iterative workflow to quickly improve prompts to achieve the desired behavior.

#### Summary
The paper presents a system called Sequence Salience, which extends existing input salience (IS) methods to support complex LLM prompt debugging. This tool offers real-time interactive debugging, lowers practitioner cognitive load, supports prompt iteration based on salience results, and aligns more closely with the developer's mental model.