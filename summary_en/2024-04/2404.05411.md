#### Background
- **Background**
This paper focuses on the issue of "semantic drift" in text generation by modern language models, where models tend to generate correct facts at the beginning of text generation but start to produce incorrect information as the text gets longer. Such observations have been made previously but have never been accurately measured.

- **Existing Work**
Current works primarily focus on autoregressive language models, which lack a predefined text structure during generation, making them unable to maintain high-level structural consistency and overly emphasizing local coherence. While the decrease in text quality with increasing generation length hints at a specific order in generation quality (high-quality first, low-quality later), this ordered behavior has not been formally defined or thoroughly investigated and measured before.

#### Core Contributions
  - **Introduced a semantic drift score**
    - **Challenge 1: Quantifying Semantic Drift**
      To address the issue of semantic drift in language model generations over long texts, the researchers developed a semantic drift scoring method to measure the separation degree of correct and incorrect facts in the generated texts. This score is measured by observing the pattern where the model starts by generating correct facts and then systematically transitions to producing incorrect ones. They used the FActScore task to provide correct/incorrect labels for individual facts, thus quantifying the severity of semantic drift.

    - **Challenge 2: Methods to Improve Factual Accuracy**
      Analysis indicates that stopping generation at the right time can improve factual accuracy. The researchers proposed several early stopping methods and resample-then-rerank strategies, which further improved factual accuracy by choosing the best version based on sentence similarity measures. They also attempted to bring the model back onto the correct generation path by calling an external API, but this did not significantly enhance performance.

#### Implementation and Deployment
Through experimentation, they found that simple early stopping methods can significantly improve factuality, while complex methods like reranking based on sentence similarity can increase factual accuracy by almost 10% without shortening texts. However, although combining these methods with early stopping allows for different trade-offs between informativeness and factuality, the method of calling an external API did not result in significant performance improvements.

#### Summary
The paper provides tools for understanding and measuring the phenomenon of semantic drift in long-form text generation by language models. Significant improvements in factual accuracy were achieved through early stopping and resampling-then-reranking methods, offering potential solutions to balance informational quantity with factual accuracy.