#### Background
- **Background**      
The paper addresses the factual correctness in content generated by large language models (LLMs), highlighting issues with non-factual knowledge occasionally produced by such models which limits their practical application. Current factuality probes relying on human-annotated labels have limited transferability to out-of-distribution contents. Recent research focuses on online self-consistency checking for detecting non-factual content, but this incurs high computational costs due to the need to generate multiple outputs and lacks robustness because of the absence of a training process.

- **Existing Work**
Existing methods face challenges with manual data annotation and adapting to new data distributions, along with high computational costs and a lack of robustness in the online self-consistency checking processes, indicating a need for a more effective means of detecting the factualness of LLM-generated content.

#### Core Contributions
- **Presented a system called PINOS**
  - **Challenge 1: Transferability and effective detection of non-factual content**
    The paper addresses the challenges posed by existing methods requiring human annotations and high computational costs. PINOS solves these by training a probing model through offline self-consistency checks, thus avoiding reliance on human-annotated data and adapting to different data distributions, reducing computational burdens.

  - **Challenge 2: Adaptation to data distributions and improvement of results**
    Compared to existing online self-consistency checks, PINOS improves computational efficiency and, by analyzing the broader spectrum of information within the LLMsâ€™ internal states rather than discrete tokens in the response, enhances its effective prediction.

#### Implementation and Deployment
PINOS, which analyzes different aspects of internal states in large language models to detect non-factual content, outperformed existing factuality detection methods in a series of experiments across various factuality detection benchmarks and question-answering datasets. By avoiding the computational burden of generating multiple outputs during inference through online consistency verification, PINOS enhanced time efficiency. Further results showed that PINOS surpassed supervised probing-base baselines by 7.7-14.6 AUC across QA datasets and demonstrated significant performance improvements (3-7 AUC) over unsupervised consistency checking baselines, displaying superior time efficiency.

#### Summary
This paper introduces PINOS, a novel approach for training a probing model via offline self-consistency checking, effectively addressing the limitations of existing factual detection methods. PINOS exhibits enhanced transferability and efficiency, and achieves superior results on factuality detection and question-answering benchmarks compared to existing methods.