#### Background
- **Background**
The paper discusses the challenges large language models (LLMs) face in information extraction (IE) tasks, particularly highlighting the difficulty LLMs have in following complex IE task instructions due to a lack of alignment with human expectations, as current alignment datasets usually do not include IE data.

- **Existing Work**
Current research mainly explores three areas: prompt engineering, coding LLMs, and multitask fine-tuning. However, these efforts do not sufficiently align LLMs for IE tasks. The prompt engineering approach does not inherently align LLMs without tuning model parameters, and works using code LLMs and multitask fine-tuning usually fine-tune models on homogeneous data, lacking diverse alignment data, limiting the generalized capabilities of fine-tuned models on IE tasks.

#### Core Contributions
  - **Introduced an aligned large language model named ADELIE**
    - **Challenge 1: Diversity and quality of data**
      Existing alignment datasets lack complex IE data. The ADELIE project addresses this challenge by constructing a high-quality instruction-tuning dataset, IEInstruct, which contains 83,585 instances across various IE tasks. This dataset includes a diverse set of instructions and input-output formats, enhancing the diversity and quality of the data.
  
    - **Challenge 2: Model generalization and maintaining capabilities**
      Traditional fine-tuning methods may improve performance on specific tasks but at the cost of general capabilities. ADELIE addresses this by training on the LLAMA 2 base using supervised fine-tuning (SFT) combined with broad alignment data and further training using the direct preference optimization (DPO) objective, thus maintaining task-specific performance while preserving the model's general capabilities.

#### Implementation and Deployment
Through comprehensive experiments across various held-out IE datasets, ADELIE models (ADELIESFT and ADELIEDPO) demonstrated top-tier performance surpassing other open-source models including GPT-3.5. Evaluations on closed, open, and on-demand IE tasks showcased their superiority, proving the effectiveness of their model alignment and instruction tuning while retaining good general performance on broader tasks, such as natural language understanding.

#### Summary
The ADELIE models proposed in this paper effectively address the alignment issues of LLMs in information extraction tasks, improving performance via novel datasets and training methods while maintaining robust general capabilities. This provides valuable insights and a foundation for future research in this area.