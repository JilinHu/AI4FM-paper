#### Background
- **Background**
The article addresses the issue of knowledge editing in Large Language Models (LLMs), with a particular focus on the challenges of lifelong knowledge editing, which requires ongoing updates to the model to correct outdated or erroneous knowledge. Current editing methods mainly concentrate on single or batch editing but fall short in lifelong editing scenarios due to knowledge forgetting and the degradation of model performance.
- **Existing Work**
Existing editing methods suffer from performance degradation or failure due to cumulative parameter biases in lifelong editing scenarios, as well as difficulty in maintaining efficiency of editing and inference speed. For example, methods of modifying parameters (altering model's parameters) and adding extra parameters (adding new neurons) may lead to a decrease in model performance throughout continuous editing. Although retrieval-based methods mitigate these issues, they still face speed challenges and practical complexities in editing and applying knowledge after retrieval.

#### Core Contributions
  - **Introduced the RECIPE framework**
    - **Challenge 1: How to enhance editing efficacy and inference efficiency in lifelong learning scenarios**
RECIPE refines responses based on knowledge by converting knowledge statements into short and informative continuous prompts that are prefixed to the embedding of the LLM's input query. This method is built upon previous studies demonstrating that continuous prompts make LLMs perform downstream tasks more effectively.

  - **Challenge 2: How to dynamically determine whether retrieval has relevant knowledge for an input query**
RECIPE incorporates the Knowledge Sentinel (KS), which acts as an intermediary to dynamically calculate thresholds, determining whether the repository contains relevant knowledge. It uses a specially designed contrastive learning mechanism, jointly trained with the prompt encoder, to align retrieval with model editing.

#### Implementation and Deployment
RECIPE was extensively evaluated across multiple LLMs and editing datasets, including LLaMA-2 (7B), GPT-J (6B), and GPT2-XL (1.5B). It demonstrates optimal editing performance and robustness against the degradation of LLM general results, as well as a significant advantage in both editing and inference speed. The method doesn't require substantial modifications to current LLMs and alleviates the need for accumulating parameter offsets or adding extra parameters.

#### Summary
The RECIPE method efficiently improves editing efficiency and inference speed in LLMs within lifelong learning scenarios by transforming knowledge statements into continuous prompts and utilizing Knowledge Sentinel for dynamic retrieval management. This approach overcomes the limitations of previous methods and performs excellently across multiple evaluation metrics while maintaining overall model performance.