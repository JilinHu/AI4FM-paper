#### Background
- **Background**
    The paper addresses the challenges in grounding the reasoning ability of large language models (LLMs) for embodied tasks, particularly in multi-agent collaboration settings where effective coordination is difficult due to the complexity of the physical world.
   
- **Existing Work**
    Existing methods primarily hinge on physical verification or self-reflection to enhance the planning capabilities of LLMs. Self-reflection involves LLMs performing self-evaluation to improve plan generation, and physical verification employs feedback from the external environment to dynamically replan. However, this feedback is often sporadic or heuristically designed, lacking an efficient feedback mechanism for LLMs in embodied task planning.

#### Core Contributions
  - **Reinforced Advantage (ReAd) as a closed-loop feedback framework**
  - **Challenge 1: Effective Feedback in Multi-agent Settings**
      The existing methods have difficulty evaluating the impact of individual actions within a multi-agent team outcome, leading to either frequent LLM queries or extensive interactions with the physical environment. The proposed ReAd framework addresses these issues by capturing and utilizing multi-agent advantage functions, allowing for efficient plan refinement by LLMs.

  - **Challenge 2: Excessive Interactions and Queries**
      Current LLMs need many interactions and queries to produce feasible joint-action plans for embodied tasks. ReAd minimizes these interactions by estimating the advantages of each agent's action, prompting LLMs to generate actions that maximize the advantage value.

#### Implementation and Deployment
ReAd estimates the advantage function through a critic network that regresses LLM-planned data. An LLM planner, acting as an optimizer, is prompted to generate actions that maximize the advantage value. The paper demonstrates that ReAd significantly reduces interaction and query rounds on both DV-RoCoBench and Overcooked-AI datasets while surpassing baseline models in terms of success rate. This showcases ReAd's ability to train LLMs effectively for multi-agent collaboration tasks.

#### Summary
This paper proposes the ReAd framework to address the effective planning for LLMs in multi-agent collaborative tasks, proving its capability to reduce interaction rounds and enhance success rates, thus laying the groundwork for the application of LLMs in multi-agent systems.