#### Background
- **Background**
This paper discusses the notable results achieved when using Large Language Models (LLMs) as agent models for interactive planning tasks. Despite their achievements, these models struggle with aimless trial-and-error in global planning and producing hallucinatory actions in local planning due to a poor understanding of the "real" physical world.

- **Existing Work**
Existing work fails to efficiently support the planning needs of agent models due to a lack of understanding of the real world, resulting in the generation of hallucinatory actions and blind trials and errors in planning tasks.

#### Core Contributions
- **Introduced a parametric World Knowledge Model (WKM) that self-synthesizes knowledge from expert and sampled trajectories, imitating the human mental world knowledge model**
  - **Challenge 1: Blind trial-and-error and hallucinatory actions**
Traditional LLMs often exhibit aimless trial-and-error and hallucinatory actions in planning tasks. The paper's WKM provides global prior task knowledge and local dynamic state knowledge for the agent model, effectively reducing these issues and guiding global planning as well as assisting local planning, thus enhancing the performance of the agent model.

  - **Challenge 2: Adapting to a variety of real-world simulated planning tasks**
The introduced WKM combined with three advanced open-source LLMs (Mistral-7B, Gemma-7B, Llama-3-8B) demonstrate excellent performance over a range of strong baselines on three complex real-world simulated datasets (ALFWorld, WebShop, and ScienceWorld). This proves the powerful generalization ability of WKM across different planning tasks.

#### Implementation and Deployment
The experimental results show that the introduced WKM, in conjunction with agent models based on three state-of-the-art open-source LLMs (Mistral-7B, Gemma-7B, Llama-3-8B), achieves superior performance on three real-world simulated planning tasks over various strong baselines, including both seen and unseen tasks. Additional analysis indicates that the WKM effectively reduces both blind trial-and-error and hallucinatory actions, the task-level knowledge generated by the model generalizes better to unseen tasks, and strong agent planning guided by weak WKM is viable. The study also explores the potential of unified WKM training and the impact of explicit state knowledge on the performance of agent planning.

#### Summary
This paper introduces a parametric World Knowledge Model (WKM) to enhance the performance of Large Language Models (LLMs) executing interactive planning tasks. The model utilizes knowledge from expert and exploratory trajectories and has been validated through comparisons with various strong baselines in simulated environments, addressing the issues of hallucinatory action generation and aimless trial-and-error.