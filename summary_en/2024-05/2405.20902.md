#### Background
- **Background**
This paper discusses the state-of-the-art performance of Large Language Models (LLMs) in a variety of NLP tasks using Chain-of-Thought (CoT) prompting. However, the robustness of this method needs more scrutiny, especially in cases where an LLM is exposed to scenarios where it gets answers prematurely, either deliberately through malicious prompt injection or inadvertently.

- **Existing Work**
Previous research has explored scenarios of attacks on CoT reasoning, but this paper presents the scenario of preemptive answers as a significant real-world threat, primarily based on the vast amount of problem-solving data from the Web that is structured with the answer provided first, then the solution.

#### Core Contributions
  - **Introduced a "preemptive answer" scenario**
    - **Challenge 1: Investigate the impact of preemptive answers on CoT reasoning abilities**
The study finds that preemptive answers significantly impair the model's reasoning capabilities across different CoT methods and a wide range of datasets, highlighting the need for further investigations into enhancing the robustness of CoT.

    - **Challenge 2: Develop strategies to mitigate the effects of preemptive answers**
The paper proposes problem restatement and self-reflection to mitigate the influence of preemptive answers. Problem restatement recalibrates the model's focus on the original question, and self-reflection involves prompting the model to self-assess its outputs to integrate the rationales more effectively.

#### Implementation and Deployment
Comprehensive experiments on ChatGPT and GPT-4 across various datasets showed that common CoT methods can suffer up to a 62% performance decrease when faced with preemptive answers. The paper reports greater robustness in GPT-4 during two preemptive answer setups. Furthermore, no significant differences were found in resilience between Few-Shot and Zero-Shot CoT variants, suggesting that in-context learning does not effectively resist preemptive answer attacks. CoTs with SC showed improved resistance, but still some performance degradation may persist due to preemptive answer attacks.

#### Summary
The paper investigates the negative impact of preemptive answers on the reasoning capabilities of LLMs and proposes strategies for mitigation. The experimental results indicate that these strategies cannot completely neutralize the impact, pointing to a need for further enhancement of CoT robustness.