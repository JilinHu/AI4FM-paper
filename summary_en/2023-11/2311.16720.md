#### Background
- **Background**
The paper discusses the enhancement of text ranking tasks through unsupervised LLMs in the realm of information retrieval. Text ranking, a pivotal issue in this field, involves ordering a set of candidate documents by relevance. Prior research has begun to use the generative capacity of LLMs to gauge the probability of a query given a document as a relevance indicator. However, this approach is not perfect, as it has failed to explicitly handle the correlation between queries and documents.

- **Existing Work**
Current attempts to utilize LLMs for unsupervised text ranking have not explicitly included signals of query-document correlation, limiting the models' ability to comprehend subtle text relationships. Consequently, the benefits garnered in the pre-training phase may be lost during the transition to fine-tuning.

#### Core Contributions
- **Introduced a comprehensive two-stage training model**
  - **Challenge 1: How to maintain continuous pre-training advantages**
The conventional pre-training of LLMs typically doesn't involve explicit signals about query and document correlation. The continuous pre-training stage proposed combines weakly supervised data sources to refine the model's understanding of the relationship between queries and documents. The generative pre-training tasks are specifically aimed at improving the model's proficiency in capturing relevance signals within the query-document space.

  - **Challenge 2: How to prevent losing pre-training benefits during fine-tuning**
The manuscript introduces Supervised Fine-tuning (SFT) to improve performance by enhancing the model's ability to differentiate between positive and negative text pairs. However, there is an inconsistency between the objective of continuous pre-training and the discrete nature of SFT, which could erode the benefits of pre-training. To address this, strategies such as the Difference Penalty (DP) were designed to regularize the fine-tuning process, ensuring the model remains faithful to the pre-training distribution while adapting to the new task-specific objectives.
  - ...

#### Implementation and Deployment
In the experimental section, the proposed method is validated on performance using recognized benchmarks in the information retrieval domain, like MS MARCO, TREC 2019, and TREC 2020 datasets. BEIR benchmark was also used for out-of-domain evaluation, covering various domains like finance and medicine, and tasks like question answering and fact-checking. The models proposed in the paper demonstrated enhanced efficacy over the state of the art. Notably, in models with â‰¤3B parameters, BLOOM-560M surpassed comparable models such as MonoBERT-340M, MonoT5-220M, and MonoT5-770M by margins of +2.0, +3.7, and +2.1 in terms of average score, respectively. For models with 7B parameters, proposed models maintained superior performance across all datasets except for one outlier, DL20. The paper conducted consistent optimization and testing for LLMs of different types and sizes to demonstrate the method's generality.

#### Summary
This study presents a two-stage training model for text ranking that combines weakly supervised pre-training and supervised fine-tuning. It smoothly transitions from pre-training to fine-tuning without sacrificing pre-training benefits, enhancing fine-tuning performance. The experiments have shown significant superiority over existing techniques.