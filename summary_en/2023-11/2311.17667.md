#### Background
- **Background**
The paper discusses the importance of temporal reasoning in NLP and AI, highlighting that current state-of-the-art Large Language Models (LLMs) have yet to fully tackle the problem. Despite advancements, a considerable gap remains between LLMs and human performance, particularly in temporal reasoning abilities.

- **Existing Work**
Existing research has not adequately addressed the issue of temporal reasoning, primarily due to the lack of a comprehensive and hierarchical temporal reasoning benchmark, as well as robust challenges and complex scenarios. Additionally, language models face numerous difficulties and challenges in temporal reasoning tasks, such as understanding basic time expressions, comprehension of the temporal aspects of world knowledge, and the ability to model time relationships between events.

#### Core Contributions
- **Introduced TIMEBENCH benchmark**
  - **Challenge 1: Rich and Hierarchical Evaluation of Temporal Reasoning**
      The benchmark covers 10 datasets and a total of 16 subtasks, thoroughly evaluating the temporal reasoning capabilities of language models in challenging and complex scenarios, indicative of the approach to address this challenge.

  - **Challenge 2: Established Three Hierarchical Categories: Symbolic, Commonsense, and Event Temporal Reasoning**
      Symbolic Temporal Reasoning focuses on the understanding of basic abstract temporal expressions; Commonsense Temporal Reasoning emphasizes mastery of temporal principles, concepts, and world knowledge; Event Temporal Reasoning concentrates on modeling the temporal relationships between events in real scenarios. This classification facilitates a comprehensive evaluation of language models.

#### Implementation and Deployment
The evaluation employed various task forms, including multiple-choice and multiple-answer questions (MCQ and MCMAQ), to cover a broad spectrum of temporal reasoning phenomena. The assessments revealed a significant gap between even the most advanced language models and humans, suggesting substantial research opportunities in this field. The study conducted in-depth analyses to expose the dilemmas faced by models in temporal reasoning and sought to identify potential solutions.

#### Summary
The introduction of the TIMEBENCH benchmark marks an important step in the comprehensive assessment of temporal reasoning abilities in Large Language Models, showcasing the current gap between models and humans in this area and providing guidance for future research.