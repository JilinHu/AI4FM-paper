#### Background
- **Background**
Large language models (LLMs) possess many traits desirable for intelligent robot assistants. However, they are prone to "hallucinations," where they predict actions or events not based on reality. This problem is significant in consumer robotics, as hallucinations may lead to robots executing plans opposite to the user's goals, increasing the reliance on human assistance or hindering the robot from asking for help.
- **Existing Work**
Existing approaches often do not seek user clarification in uncertain or ambiguous situations, or if they do, it is through manual programming, which tends to over-rely on human help. While solutions like KnowNo have been proposed, they are more focused on establishing evaluative baselines for when robots should ask for help rather than improving confidence measures, success rates, and reducing human intervention.
#### Core Contributions
  - **Introduced the LAP methodology**
    - **Challenge 1: Reducing LLM hallucinations in planning tasks and knowing when to seek help**
        Using and leveraging a scene affordance score can mitigate hallucinations in LLM predictions and better align the LLM’s confidence measure with the probability of success.
    - **Challenge 2: Increasing success rates and reducing the frequency of human intervention without extensive training**
        LAP employs different affordance scores, which can be used singly or in combination, to improve performance across various scenarios. The most successful method employs prompting an LLM to assess if an action is possible and safe, using its response to calculate the affordance score. Experiments demonstrate LAP’s significant increase in success rate and reduction in required human intervention.
#### Implementation and Deployment
The LAP methodology was evaluated in simulations and real-world robot hardware settings, using language-instructed manipulation tasks from the KnowNo Simulation and Mobile Manipulator Datasets. These datasets involve various potential ambiguities that LAP must address. Results showed that LAP substantially improved the success rate and lessened the need for human assistance compared to baselines. In real-world tests, LAP lowered the human assistance rate by over 33% at a 70% success rate and displayed similar improvements at various success rates. The paper also compared different methods for deriving an affordance value for use in LAP, including a novel prompt-based method, and exhibited the outperformance of LAP using the latest and most powerful LLMs straight out-of-the-box over fine-tuned LAP and previous approaches optimized for this task.
#### Summary
The paper introduces the LAP method that combines LLMs with scene affordances to reduce hallucinations and achieve uncertainty alignment in planning tasks. Demonstrating significant improvements in successful outcomes and decreased reliance on human assistance through experiments in both simulated and real-world robot manipulations, the LAP method advances the domain of intelligent robotics.