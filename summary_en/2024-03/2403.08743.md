#### Background
- **Background**
  The paper recognizes that Large Language Models (LLMs) trained on massive text corpora exhibit alarming levels of social biases. These unchecked biases can perpetuate and amplify societal inequities, leading to unfair or even unethical outcomes. As LLMs become more robust and start to function as core components in decision-making systems across various sectors such as healthcare and education, mitigating these biases becomes increasingly imperative.

- **Existing Work**
    There are various debiasing approaches that have been proposed, including direct fine-tuning of model parameters, modifying the decoding steps, and prompting-based techniques. However, many powerful LLMs, such as GPT-4, Gemini, and Claude 2, are closed-source due to reasons like security and business interests, which makes accessing the models' internal structures or parameters impossible for the general public. Hence, prompting-based techniques are the only feasible option to counteract biases for closed-source LLMs.

#### Core Contributions
  - **A Causality-Guided Debiasing Framework**
    - **Challenge 1: How to debias LLMs without access to internal structures and parameters**
      The causality-guided debiasing framework works by using causal insights from the training corpus data generation process and LLMs' internal reasoning process. It guides the design of prompts to debias LLM outputs, uniting existing debiasing prompting approaches and proposing new ways to encourage unbiased reasoning, demonstrating effectiveness even with black-box access only.

    - **Challenge 2: Enhancing the Design of Debiasing Prompts**
      By constructing detailed causal models to understand the data-generating process of the training corpus and the reasoning process of LLMs, they identify selection mechanisms as key to determining how LLMs' outputs could be modulated by different prompts. Prompt design strategies introduced by the framework show superior empirical results in debiasing various social biases across different LLMs, showing the clear advantage of the framework.

#### Implementation and Deployment
Through empirical studies, the paper found that prompts employing both intuitions—that is, discouraging biased reasoning and encouraging bias-free reasoning—perform significantly better than existing prompting-based debiasing methods. The strong empirical results clearly demonstrate the effectiveness of the causality-guided debiasing framework even in situations where only black-box access is provided.

#### Summary
This paper successfully introduces a new causality-guided debiasing framework, which has been empirically validated for effectiveness. It not only integrates existing prompting-based debiasing methods but also proposes new avenues for eliciting unbiased reasoning.