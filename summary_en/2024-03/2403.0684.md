#### Background
- **Background**
LLMs excel in many tasks but are overly dependent on stored knowledge, updating which is cost-intensive. Retrieval-augmented generation (RAG) overcomes this by integrating external knowledge, yet irrelevant text can impair performance.

- **Existing Work**
Existing RAG frameworks face issues: retrieving irrelevant knowledge texts hinders task solving, and integrating stored knowledge with retrieved knowledge poses challenges. Current methods lack effective strategies for answering knowledge-intensive questions and various sub-questions.

#### Core Contributions
  - **Introduced an innovative framework, RA-ISF**
    - **Challenge 1: Performance drop due to irrelevant text integration**
      RA-ISF employs an iterative question decomposition approach, a first in retrieval-augmented frameworks, to mitigate the impact of irrelevant text interference.
    - **Challenge 2: Lack of effective task decomposition strategy**
      It uses task decomposition to reduce the impact of irrelevant prompt texts, iteratively answering sub-questions and integrating text relevance with self-knowledge answer capabilities, enhancing performance on solving the entire problem.

#### Implementation and Deployment
RA-ISF starts with a self-knowledge module to check if a question can be answered from existing knowledge. For retrieval, the passage relevance module assesses retrieved paragraphs' relevance. Irrelevant paragraphs lead to question decomposition, iterating the steps for sub-questions before synthesizing answers. RA-ISF outperforms existing methods, demonstrating the framework's potential and robustness.

#### Summary
RA-ISF is an innovative retrieval-augmented framework that enhances LLMs' problem-solving by iterative task decomposition and mitigates irrelevant text interference, significantly improving knowledge retrieval performance.