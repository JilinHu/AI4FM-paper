#### Background
- **Background**
LLMs often lack domain-specific knowledge essential for tasks in vertical domains such as legal and medical. Current methods like continuous pre-training and retrieval augmentation to support LLMs are either cost-intensive or unreliable in practical applications.
- **Existing Work**
Existing work to improve LLMs' performance in a specific domain often involves cost-intensive methods or methods not reliable in practical settings.

#### Core Contributions
- **Introduced a novel framework named BLADE**
  - **Challenge 1: Insufficient domain-specific knowledge**
    BLADE integrates a black-box LLM with a small domain-specific LM to enhance the application of domain-specific knowledge. A small LM preserves domain-specific insights, while the general LLM contributes robust language comprehension and reasoning capabilities. The method is executed in three steps: pre-training the small LM with domain-specific data, fine-tuning using knowledge instruction data, and joint Bayesian optimization.
  
  - **Challenge 2: Inefficient domain adaptation methods**
    The BLADE framework uses Knowledge Instruction Tuning (KIT) and Bayesian Prompted Optimization (BPO) to significantly improve the smaller LMs' interaction and collaboration with the general LLMs. These methods notably enhance the smaller LMs' abilities for interaction and help ensure the privacy of data. Through domain-specific pre-training and Bayesian prompted optimization, BLADE provides an intricate token-level cross-attention that generates deeper question-specific knowledge, which goes beyond the simple interactions between questions and documents seen in dense retrieval models.

#### Implementation and Deployment
Extensive experiments on public legal and medical benchmarks show that BLADE consistently improves performance across various models when compared with the baselines LLMs. BLADE achieved a 28.4% improvement with Baichuan-7B and a 31.3% improvement with ChatGPT, indicating that it's applicable to diverse language models of different sizes and has reached state-of-the-art results on the Chinese legal question-answering tasks.

#### Summary
This research presented a novel architecture, BLADE, capable of enhancing black-box LLMs through smaller domain-specific models, addressing the lack of domain-specific knowledge in LLMs for specialized applications. BLADE demonstrated to be an effective and cost-efficient solution both in performance and cost.