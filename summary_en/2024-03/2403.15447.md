#### Background
- **Background**       
LLMs have shown exceptional abilities in language understanding, generation, and reasoning, but their deployment is limited by their massive size and resource requirements.

- **Existing Work**
While training smaller LLM models alongside larger ones responds partially to the issue of limited resources, it is a huge undertaking. In contrast, model compression is a more efficient alternative that significantly speeds up inference while preserving performance even at high compression rates.

#### Core Contributions
  - **Comprehensive Evaluation Introduced**
      - **Challenge 1: Variability in Trust Dimensions**
      The challenge is the inconsistent performance of compressed or smaller models across trust dimensions. The paper evaluates three advanced LLMs using five compression techniques across eight trust dimensions, revealing the complex interplay between compression techniques and trust dimensions.

  - **Challenge 2: Lack of Holistic Evaluation**
      Most current evaluations focus on limited aspects, missing a broader spectrum of trust dimensions in compressed models. The paper addresses this gap, providing a more comprehensive understanding.

#### Implementation and Deployment
The paper performs a comprehensive evaluation of LLMs' trustworthiness across eight critical dimensions, including stereotypes, toxicity, privacy, fairness, ethics, and robustness. It finds that quantization is more effective than pruning and that moderate quantization can unexpectedly improve certain trust dimensions. Extreme quantization, however, significantly reduces trustworthiness.

#### Summary
This paper presents the first extensive evaluation of the trustworthiness of compressed LLMs across multiple dimensions and offers practical guidelines for considering efficiency and trustworthiness during compression.