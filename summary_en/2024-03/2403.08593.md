#### Background
- **Background**
The paper introduces the potential of Large Language Models (LLMs) in reasoning over structured environments such as knowledge graphs and tables, where tasks commonly require multi-hop reasoning, which is matching natural language utterances with instances in the environment.

- **Existing Work**
Existing approaches rely on LLMs to incrementally build a reasoning path, selecting items through step-by-step interaction with the environment. However, this method sacrifices reasoning efficiency, hindering its practical feasibility. Each step of the LLM makes one choice based on history, which is susceptible to error propagation. Moreover, fine-tuned methods implant environmental data into model parameters and recall schema patterns during inference, which is efficient but does not ensure that the model's output is grounded in SEs. Current methods, therefore, cannot efficiently and truthfully reason over large-scale SEs.

#### Core Contributions
- **Introduced the Reasoning-Path-Editing (Readi) Framework**
    - **Challenge 1: Efficient and Truthful Reasoning**
        The Readi framework allows the model to initially generate a reasoning path and only edits the path when necessary, thus alleviating the burden of step-by-step interaction and improving overall efficiency. By collecting a reasoning log as immediate feedback, which includes details such as the location of stuck points, associated relations, halfway done instances, etc., the reasoning path can be refined more specifically, further enhancing truthfulness.

    - **Challenge 2: Utilizing the Intrinsic Planning Capability of LLMs**
        Readi is the first framework to fully leverage the LLMs' intrinsic planning capabilities for reasoning. Instead of injecting the entire static SEs into the model, it uses dynamic reasoning logs for guidance.

#### Implementation and Deployment
Experiments on Knowledge Graph Question Answering (KGQA) and Table Question Answering (TableQA) demonstrate that Readi surpasses existing solutions in terms of both efficiency and accuracy. Specifically, Readi achieves 67.0% Hit@1 on CWQ, 78.7% on WebQSP, and state-of-the-art results on MQA-1H. The analysis shows that the performance of Readi's reasoning path generation and editing modules is exceptional. With an average of only 1.55 calls for editing, Readi significantly reduces the number of LLM calls compared to the step-by-step interaction paradigm (which costs 4 to 8 calls). Furthermore, the reasoning log reveals that Readi exhibits characteristics akin to the human thought process.

#### Summary
The Readi framework presents an efficient and truth-based method for reasoning over large-scale structured environments, fully capitalizing on the planning capabilities of LLMs, and enhancing reasoning paths through dynamic feedback, resulting in significant improvements in multi-hop reasoning tasks.