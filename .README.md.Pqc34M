<h2 align='center'>llm-paper-daily 日常论文精选</h2>
<div align='center'>

[![Status](https://img.shields.io/badge/status-Update_07.03_20:51-success.svg)]() [![简体中文 badge](https://img.shields.io/badge/%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87-Simplified%20Chinese-blue)](./README.md) [![English badge](https://img.shields.io/badge/%E8%8B%B1%E6%96%87-English-blue)](./README_en.md) 

</div>

欢迎来到 **llm-paper-daily**! 这是一个获取最新研究论文的每日更新和分类的平台。希望为爱好者提供 LLM 研究的前沿资讯，让您更轻松地了解该领域的最新发展。

📚 **每日更新:** 仓库每天会带来最新的 LLM 研究，并附有arxiv地址、相关 git 仓库和基于 GPT-4 的简单总结

💐 **分类摘要:** 将每篇论文分类到如推理、代理、检索、应用、预训练与指令微调等不同部分，帮助您能轻松导航并发现相关的研究

🌈 **交流学习:** 最近准备拉一个讨论小组方便大家交流和互相学习。
欢迎对大模型落地、论文等等方面有兴趣的小伙伴加入🙌 

<img src='./images/qrcode.JPG' width=15%  alt=/>

## 目录
- [最新论文(含总结)](#最新论文)
- [分类](#分类)
  - [💡 Reasoning](CATEGORIES.md#Reasoning)
  - [🤖 Agent](CATEGORIES.md#Agent)
  - [🦉 Knowledge and Retrieval](CATEGORIES.md#Knowledge-and-Retrieval)
  - [👩‍🏫 Alignment and Hallucination](CATEGORIES.md#Alignment-and-Hallucination)
  - [🎨 Application](CATEGORIES.md#Application)
  - [📐 Pre-training and Instruction Fine-tuning](CATEGORIES.md#Pre-training-and-Instruction-Fine-tuning)
  - [📄 Survey](CATEGORIES.md#Survey)
## 最新论文
### 07月

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>07-01</span> | **We-Math: Does Your Large Multimodal Model Achieve Human-like Mathematical Reasoning?**<br><sub>机构: Beijing University of Posts and Telecommunications, Tencent Inc., Huazhong University of Science and Technology<br>这篇论文创建了一个名为WE-MATH的视觉数学推理基准测试，旨在超越传统的端到端性能评估，深入探讨和评价LMMs的问题解决原理及它们的知识获取和泛化能力。通过新的多维度评估方法揭示出多模态模型在内在推理过程中的挑战，并通过实验验证了知识增强策略的有效性，推动了LMMs在视觉数学推理方面的进步。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2407.01284v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-07/2407.01284.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/We-Math/We-Math)</div> |

---

### 06月

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>06-30</span> | **Step-Controlled DPO: Leveraging Stepwise Error for Enhanced Mathematical Reasoning**<br><sub>机构: Multimedia Laboratory (MMLab), The Chinese University of Hong Kong<br>本论文提出了一种新的数学推理优化方法——SCDPO，通过在特定步骤监督错误的方式，自动化地生成训练样本，显著提升了LLMs在数学问题求解方面的性能，证明了该方法的潜力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2407.00782v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2407.00782.md)  |
| <span style='display: inline-block; width: 42px;'>06-29</span> | **LiteSearch: Efficacious Tree Search for LLM**<br><sub>机构: Xiamen University, Tencent AI Lab<br>该论文通过提出一种效率更高的树搜索算法来降低在辅助大型语言模型解决复杂数学推理任务时的资源消耗，同时确保保持高性能水平。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2407.00320v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2407.0032.md)  |
| <span style='display: inline-block; width: 42px;'>06-28</span> | **Scaling Synthetic Data Creation with 1,000,000,000 Personas**<br><sub>机构: Tencent AI Lab Seattle<br>本论文提出了一个名为“Persona Hub”的合成数据平台，在保证生成数据多样化和丰富性的同时，重点关注合成数据的安全和负责任使用。通过一系列用例证明了该方法在多元化、可扩展性、灵活性和易用性方面的优势。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.20094v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.20094.md)  |
| <span style='display: inline-block; width: 42px;'>06-27</span> | **From Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data**<br><sub>机构: University of Wisconsin-Madison<br>该论文提出了一个通过在合成数据集上微调LLMs来提高其在长文本任务上检索和推理能力的方法。实验结果表明，这种方法可以在不显著影响模型整体能力的同时，显著提高模型在长文本任务中的表现，并降低幻觉的生成。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.19292v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.19292.md)  |
| <span style='display: inline-block; width: 42px;'>06-27</span> | **SeaKR: Self-aware Knowledge Retrieval for Adaptive Retrieval Augmented Generation**<br><sub>本论文提出了一个名为SEAKR的新型自适应检索增强生成模型，通过利用LLMs的内部状态自我意识来动态决定何时进行检索，并有效整合检索到的知识，从而提高了在问答任务中的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.19215v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.19215.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/THU-KEG/SeaKR)</div> |
| <span style='display: inline-block; width: 42px;'>06-26</span> | **Step-DPO: Step-wise Preference Optimization for Long-chain Reasoning of LLMs**<br><sub>机构: The Chinese University of Hong Kong, Harbin Institute of Technology (Shenzhen), SmartMore<br>这份论文提出了一种新的优化方法Step-DPO，它通过对单个推理步骤进行优化而非整体评估答案，提升了LLMs在长链数学推理上的准确性和鲁棒性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.18629v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.18629.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/dvlab-research/Step-DPO)</div> |
| <span style='display: inline-block; width: 42px;'>06-25</span> | **The FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale**<br><sub>机构: Hugging Face<br>本论文通过介绍FineWeb数据集，突出了如何策划出一个有效的基于Common Crawl的预训练数据集的重要性，并通过实验证明了其对于提升大型语言模型的性能的贡献。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.17557v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.17557.md)  |
| <span style='display: inline-block; width: 42px;'>06-24</span> | **WARP: On the Benefits of Weight Averaged Rewarded Policies**<br><sub>机构: Google DeepMind<br>本文提出了WARP，一种新的LLM对齐策略，通过权重平均合并模型以解决RLHF过程中的挑战，改善KL与奖励之间的权衡。实验证明，WARP能够提升模型性能和与人类价值的对齐度。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.16768v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.16768.md)  |
| <span style='display: inline-block; width: 42px;'>06-22</span> | **Semantic Entropy Probes: Robust and Cheap Hallucination Detection in LLMs**<br><sub>机构: OATML, Department of Computer Science, University of Oxford  <br>论文提出SEPs为成本高效和可靠的幻觉检测方法，能够在无需生成多样本的条件下，直接从LLMs单次生成的隐藏状态中捕捉到语义不确定性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.15927v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.15927.md)  |
| <span style='display: inline-block; width: 42px;'>06-21</span> | **LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs**<br><sub>机构: University of Waterloo<br>LongRAG是一个针对开放领域问答任务的新框架，它通过增大检索单元和利用长文本语言模型来解冤传统RAG框架的限制。通过减少检索单元和提升检索器效能，以及使用长文本LLMs进行零次学习的答案提取，LongRAG在性能上取得了显着的改善。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.15319v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.15319.md)  |
| <span style='display: inline-block; width: 42px;'>06-19</span> | **Can Long-Context Language Models Subsume Retrieval, RAG, SQL, and More?**<br><sub>本论文通过引入LOFT基准，探索了长上下文语言模型在替代现有范式和处理新颖任务方面的潜力。发现LCLMs在未经明确训练的情况下，能够在特定任务上与现有的检索和RAG系统相媲美，并指出了未来在提高问题表现上需要继续研究的领域。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.13121v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.13121.md)  |
| <span style='display: inline-block; width: 42px;'>06-18</span> | **Judging the Judges: Evaluating Alignment and Vulnerabilities in LLMs-as-Judges**<br><sub>本研究通过评估LLMs作为评判在对齐和评判弱点方面的表现，为使用LLMs作为未来评判提供了有用的洞察。重要的发现包括适合作为评判的仅有部分顶尖模型，以及Cohen's Kappa是一个更好的对齐度量标准，能在区分评判者方面做得比百分比对齐更好。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.12624v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.12624.md)  |
| <span style='display: inline-block; width: 42px;'>06-13</span> | **Test of Time: A Benchmark for Evaluating LLMs on Temporal Reasoning**<br><sub>机构: Google Research, Google DeepMind, Google<br>本文引入了一个新的基准测试 ToT，通过合成数据集和众包任务，全面评估了LLMs在各种情境中对时间推理能力的表现，同时揭示了这些模型在时间推理方面的优势和不足。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.09170v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.0917.md)  |
| <span style='display: inline-block; width: 42px;'>06-12</span> | **Magpie: Alignment Data Synthesis from Scratch by Prompting Aligned LLMs with Nothing**<br><sub>机构: University of Washington, Allen Institute for AI<br>本文提出了MAGPIE，一个自合成方法生成大规模的高质量对齐数据，该方法不依赖于人的参与或提示工程。实验证明，使用MAGPIE微调的模型在多个基准上均显示出优异的性能，展示了LLMs在自动数据生成和对齐方面的潜能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.08464v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.08464.md)  |
| <span style='display: inline-block; width: 42px;'>06-12</span> | **TasTe: Teaching Large Language Models to Translate through Self-Reflection**<br><sub>机构: Harbin Institute of Technology, Tencent Inc<br>本文提出的TASTE框架通过自我反思过程提升了LLMs的机器翻译能力，它代表了利用LLMs翻译潜力的一种新方法，为理解和利用LLMs的复杂推理和语言建模能力树立了新的典范。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.08434v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.08434.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/YutongWang1216/ReflectionLLMMT)</div> |
| <span style='display: inline-block; width: 42px;'>06-12</span> | **Designing a Dashboard for Transparency and Control of Conversational AI**<br><sub>机构: Harvard University, Google Research<br>这篇论文致力于增加LLMs在对话AI系统中的透明度，并通过设计一个可视化的用户界面—一个与聊天机器人接口相配套的看板—实现了这一点。用户能够实时看到系统的内部用户模型，并可以通过界面更改这些模型。基于用户反馈，看板还有助于揭露并且对抗模型的偏见行为。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.07882v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.07882.md)  |
| <span style='display: inline-block; width: 42px;'>06-11</span> | **Needle In A Multimodal Haystack**<br><sub>机构: OpenGVLab, Shanghai AI Laboratory, Fudan University<br>该论文提出了MM-NIAH，首个长篇多模态文件理解的评估基准，旨在考验和提升MLLMs的性能。通过不同的评估任务，论文指出了现有MLLMs在长篇多模态文档理解方面的局限和挑战。进一步的，该基准为MLLMs的长篇多模态文档理解研究提供了有效的平台。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.07230v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.0723.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/OpenGVLab/MM-NIAH)</div> |
| <span style='display: inline-block; width: 42px;'>06-11</span> | **Delving into ChatGPT usage in academic writing through excess vocabulary**<br><sub>机构: Hertie Institute for AI in Brain Health, University of Tübingen, Germany, Tübingen AI Center, Northwestern University<br>此论文针对学术文本中广泛使用 LLMs 的现象，提出了一种新的无偏差的大规模方法来研究 LLM 的使用情况，并对 LLM 导致的科学写作变化进行了前所未有的量化比较。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.07016v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.07016.md)  |
| <span style='display: inline-block; width: 42px;'>06-10</span> | **Self-Tuning: Instructing LLMs to Effectively Acquire New Knowledge through Self-Teaching**<br><sub>机构: The Chinese University of Hong Kong, Tencent AI Lab, Centre for Perceptual and Interactive Intelligence<br>论文通过引入SELF-TUNING，提出了一种改进LLM通过自我教学获取知识能力的框架，并通过Wiki-Newpages-QA数据集在多个关键知识获取任务上验证了其有效性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.06326v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.06326.md)  |
| <span style='display: inline-block; width: 42px;'>06-10</span> | **Reasoning in Token Economies: Budget-Aware Evaluation of LLM Reasoning Strategies**<br><sub>机构: Duke University, AWS AI Labs<br>论文提出了一个考虑计算预算的LLM推理策略评估框架，并展示了简单策略在同等计算资源下可超越复杂策略的能力。通过揭示自我评估的重要性，为更加高效的预算利用和更有效策略的开发奠定了基础。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.06461v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.06461.md)  |
| <span style='display: inline-block; width: 42px;'>06-10</span> | **Transforming Wearable Data into Health Insights using Large Language Model Agents**<br><sub>机构: Google LLC<br>本论文通过介绀名为PHIA的大型语言模型代理系统，成功地将可穿戴设备数据转化为个人健康洞察。PHIA结合了代码生成和信息检索工具，有效解决了从大量健康数据中派生个性化健康指导的挑战。通过广泛的人工和自动化评估，证明了这种方法在处理实际健康问题上的准确性和应用可能性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.06464v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.06464.md)  |
| <span style='display: inline-block; width: 42px;'>06-10</span> | **Husky: A Unified, Open-Source Language Agent for Multi-Step Reasoning**<br><sub>机构: University of Washington, MetaAI, Allen Institute for AI<br>HUSKY是首个统一、开源的多步推理语言代理，解决了成本高和扩展困难的问题，且在多任务环境中取得优异表现，展现了开源语言代理的潜力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.06469v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.06469.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/agent-husky/Husky-v1)</div> |
| <span style='display: inline-block; width: 42px;'>06-09</span> | **Do LLMs Exhibit Human-Like Reasoning? Evaluating Theory of Mind in LLMs for Open-Ended Responses**<br><sub>机构: University of Washington, University of Washington - Bothell<br>本研究强调了 LLM 在社交推理方面的不足，并展示了如何通过整合人类的意图和情绪来增强其有效性。研究结果凸显了 LLM 理解人类心理状态并在开放式问题中进行社交推理的需求，标明了未来发展的关键领域。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.05659v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.05659.md)  |
| <span style='display: inline-block; width: 42px;'>06-07</span> | **WildBench: Benchmarking LLMs with Challenging Tasks from Real Users in the Wild**<br><sub>WILDBENCH 作为一个评价基准，提供了一个结合了真实用户任务挑战、自动化指标和解释性清单的评价框架，能够更准确地评估和区别大型语言模型在复杂任务中的表现。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.04770v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.0477.md)  |
| <span style='display: inline-block; width: 42px;'>06-07</span> | **Mixture-of-Agents Enhances Large Language Model Capabilities**<br><sub>机构: Duke University, Together AI, University of Chicago<br>这篇论文通过提出Mixture-of-Agents (MoA) 方法，展示了如何通过结合多个大型语言模型的集体专长来增强它们在理解和生成自然语言方面的能力。作者通过实验验证了这种方法可以显著提高模型的表现，并在多个竞争力很强的基准测试中取得了最新的最佳成绩。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.04692v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.04692.md)  |
| <span style='display: inline-block; width: 42px;'>06-06</span> | **FastGAS: Fast Graph-based Annotation Selection for In-Context Learning**<br><sub>机构: Department of ECE, University of Virginia<br>论文提出的FastGAS方法在选择ICL实例时，不仅能提高多样性和代表性，同时还显著减少了所需的时间和计算资源。实验结果验证了其在多个数据集上的效能和效率，证明了其作为一种有效的实例选择方法的潜力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.03730v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.0373.md)  |
| <span style='display: inline-block; width: 42px;'>06-06</span> | **Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models**<br><sub>机构: Peking University, UC Berkeley, Stanford University<br>BoT通过为LLMs提供一个存储高层次思维模板的meta-buffer，增强了推理的准确性、效率和鲁棒性，克服了现有方法的限制，并实现了显著的性能提升。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.04271v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.04271.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/YangLing0818/buffer-of-thought-llm)</div> |
| <span style='display: inline-block; width: 42px;'>06-06</span> | **The Prompt Report: A Systematic Survey of Prompting Techniques**<br><sub>该论文提供了对提示技术的全面调研，系统分析了提示的概念、类型和应用，并对此进行了详细的元分析。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.06608v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.06608.md)  |
| <span style='display: inline-block; width: 42px;'>06-04</span> | **Synergetic Event Understanding: A Collaborative Approach to Cross-Document Event Coreference Resolution with Large Language Models**<br><sub>机构: Zhejiang University, School of Engineering (Westlake University), Shanghai AI Laboratory<br>文章提出了一种新颖的协作方法以解决跨文档事件共指消解任务。通过将LLMs的普遍能力与任务特定的SLMs结合，显著提高了模型性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.02148v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.02148.md)  |
| <span style='display: inline-block; width: 42px;'>06-04</span> | **To Believe or Not to Believe Your LLM**<br><sub>机构: Google DeepMind<br>本论文重点研穴并提出了一个新的信息论度量方法以在大型语言模型中量化不确定性，特别是针对LLMs生成响应时的幻觉现象。这项研究为如何识别和处理LLMs中的幻觉提供了新的理解和解决方案。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.02543v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.02543.md)  |
| <span style='display: inline-block; width: 42px;'>06-03</span> | **Self-Improving Robust Preference Optimization**<br><sub>机构: Cohere<br>SRPO通过在理论上合理的离线RLHF框架内表现出对任务变化的强大鲁棒性，成功地解决了依赖特定任务的问题，并通过非对抗性离线损失的优化提供了更简单的训练和部署过程。实验结果显示SRPO在包括OOD设置在内的各种环境下优于现有方法。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.01660v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.0166.md)  |
| <span style='display: inline-block; width: 42px;'>06-03</span> | **Mobile-Agent-v2: Mobile Device Operation Assistant with Effective Navigation via Multi-Agent Collaboration**<br><sub>机构: Beijing Jiaotong University, Alibaba Group<br>Mobile-Agent-v2是一个多代理架构，能有效解决移动设备操作任务中的导航挑战，特别是任务进展和焦点内容的导航问题。通过引入三个专门的代理角色，相较于传统的单代理架构，显著提高了任务完成率。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.01014v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.01014.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/X-PLUG/MobileAgent)</div> |

---

### 05月

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>05-31</span> | **Preemptive Answer "Attacks" on Chain-of-Thought Reasoning**<br><sub>机构: Tsinghua University<br>论文研究了预先答案对LLMs推理能力的负面影响，并提出了减轻其影响的策略。实验结果表明，这些策略不能完全抵消预先答案的影响，提示需要进一步增强CoT的鲁棒性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.20902v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.20902.md)  |
| <span style='display: inline-block; width: 42px;'>05-31</span> | **Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality**<br><sub>机构: Princeton University, Carnegie Mellon University<br>本论文展示了一个全新的状态空间对偶性（SSD）框架，连接了结构化的状态空间模型（SSMs）和注意力机制变体。论文的主要贡献包括将原本针对Transformers的算法和系统优化应用到SSMs上，以及开发了一种新的SSD算法，有效提高了模型训练和推理的效率。Mamba-2架构作为最终产品，实现了理想的性能表现，为未来的深度学习模型设计和优化提供了新的方向。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.21060v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.2106.md)  |
| <span style='display: inline-block; width: 42px;'>05-30</span> | **Similarity is Not All You Need: Endowing Retrieval Augmented Generation with Multi Layered Thoughts**<br><sub>机构: Ant Group<br>METRAG提出了一个新颖的检索增强生成框架，该框架通过实用性和紧凑性思维来解决现有模型的局限性，并在知识密集型任务中显示出更好的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.19893v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.19893.md)  |
| <span style='display: inline-block; width: 42px;'>05-30</span> | **Jina CLIP: Your CLIP Model Is Also Your Text Retriever**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.20204v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.20204.md)  |
| <span style='display: inline-block; width: 42px;'>05-29</span> | **LLMs achieve adult human performance on higher-order theory of mind tasks**<br><sub>机构: Google Research, Google DeepMind, Johns Hopkins University Applied Physics Lab<br>本论文展示了LLMs在高阶理论心智（ToM）任务上的性能，特别是证明了某些模型如GPT-4能够在某些任务上达到成人水平的表现。通过引入基于真实人类成人基准的新评测指标，本研究有助于揭示和理解LLMs在复杂社交互动中的潜力与限制。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.18870v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.1887.md)  |
| <span style='display: inline-block; width: 42px;'>05-29</span> | **MAP-Neo: Highly Capable and Transparent Bilingual Large Language Model Series**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.19327v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.19327.md)  |
| <span style='display: inline-block; width: 42px;'>05-28</span> | **RealitySummary: On-Demand Mixed Reality Document Enhancement using Large Language Models**<br><sub>机构: University of Calgary<br>此论文介绍了RealitySummary系统，它结合了大型语言模型和混合现实技术，提供了一个即时的阅读辅助工具，并且展现了这种技术在实际应用中的潜力和确立了未来研究的方向。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.18620v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.1862.md)  |
| <span style='display: inline-block; width: 42px;'>05-23</span> | **HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language Models**<br><sub>机构: The Ohio State University, Stanford University<br>HippoRAG是一个受人类记忆系统启发的新型检索框架，解决了传统LLMs在长期记忆和知识整合方面的不足。通过模拟人脑结构和运作机制，HippoRAG有效地提升了LLMs处理复杂知识整合任务的能力，并且在效率和性能上均超越现有方法。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.14831v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.14831.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/OSU-NLP-Group/HippoRAG)</div> |
| <span style='display: inline-block; width: 42px;'>05-23</span> | **Agent Planning with World Knowledge Model**<br><sub>机构: Zhejiang University, Zhejiang University - Ant Group Joint Laboratory of Knowledge Graph, National University of Singapore, Alibaba Group<br>本论文通过创建一个参数化的世界知识模型 (WKM)，来提升大型语言模型在执行交互式规划任务中的性能。这个模型使用了来自专家和探索性轨迹的知识，并通过在仿真环境中与多种强基准进行比较，验证了其有效性，并处理了生成幻视动作和盲目试错的问题。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.14205v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.14205.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/zjunlp/WKM)</div> |
| <span style='display: inline-block; width: 42px;'>05-23</span> | **Towards Efficient LLM Grounding for Embodied Multi-Agent Collaboration**<br><sub>机构: Tsinghua University, Northwestern Polytechnical University, Shanghai AI Laboratory<br>本文针对多代理合作任务中LLMs的有效规划提出了ReAd框架，证明了其降低交互次数并提高成功率的能力，为LLMs在多代理系统中的应用奠定了基础。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.14314v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.14314.md)  |
| <span style='display: inline-block; width: 42px;'>05-23</span> | **RaFe: Ranking Feedback Improves Query Rewriting for RAG**<br><sub>机构: Zhejiang University, Alibaba Group, Nanjing University<br>RaFe是一个新颖的查询重写框架，利用重排序器反馈来训练模型，无需注释，支持离线和在线反馈训练，具有良好的普适性和有效性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.14431v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.14431.md)  |
| <span style='display: inline-block; width: 42px;'>05-23</span> | **RefChecker: Reference-based Fine-grained Hallucination Checker and Benchmark for Large Language Models**<br><sub>机构: Amazon AWS AI, Shanghai AI Lab, Shanghai Jiaotong University<br>REFCHECKER是一个用于检测LLMs中细粒度幻觉并进行基准测试的框架。其通过使用claim-triplets，能在细粒度上检测并验证回应中的事实一致性，显著提高了检测的精度和与人类判断的一致性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.14486v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.14486.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/amazon-science/RefChecker)</div> |
| <span style='display: inline-block; width: 42px;'>05-23</span> | **PerLLM: Personalized Inference Scheduling with Edge-Cloud Collaboration for Diverse LLM Services**<br><sub>机构: Institute of Computing Technology, Chinese Academy of Sciences, University of Chinese Academy of Sciences<br>本论文提出了PerLLM框架，通过边缘-云协作来处理大量推理服务，不仅优化了服务调度和资源分配，还显著提高了吞吐量并降低了能源成本，具有突出的应用价值。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.14636v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.14636.md)  |
| <span style='display: inline-block; width: 42px;'>05-23</span> | **AGILE: A Novel Framework of LLM Agents**<br><sub>机构: ByteDance Research, University of Science and Technology of China, Shanghai Jiao Tong University<br>该论文提出了一个新型的LLM代理框架AGILE，它通过整合不同的组件，并采用强化学习来实现端到端的训练。该框架在复杂的问答任务中展现出较传统LLM独立使用更优的性能，并证明了组件整合和端到端优化的有效性。数据集和代码已公开发布，以促进相关领域的进一步研究。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.14751v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.14751.md)  |
| <span style='display: inline-block; width: 42px;'>05-21</span> | **SmartFlow: Robotic Process Automation using LLMs**<br><sub>机构: TCS Research<br>SmartFlow是一个基于AI的RPA系统，它整合了深度学习的视觉理解与LLMs，能够自动生成导航工作流并自主执行用户指派的任务，展示了其在适应GUI变化和处理复杂任务上的高效性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.12842v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.12842.md)  |
| <span style='display: inline-block; width: 42px;'>05-21</span> | **G-DIG: Towards Gradient-based DIverse and hiGh-quality Instruction Data Selection for Machine Translation**<br><sub>机构: ByteDance Research<br>该论文为解决LLMs在机器翻译中指令微调数据的多样性和质量问题，提出了基于梯度的数据选择方法G-DIG，通过实验验证了方法的有效性和泛化性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.12915v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.12915.md)  |
| <span style='display: inline-block; width: 42px;'>05-20</span> | **OpenRLHF: An Easy-to-use, Scalable and High-performance RLHF Framework**<br><sub>机构: OpenLLMAI Team, ByteDance Inc., Netease Fuxi AI Lab<br>OpenRLHF是一个开源框架，它使得在70亿以上参数模型上实现全尺度RLHF训练成为可能。它通过Ray分布式计算模型，并利用vLLM优化效率，同时实现了多种对齐算法，并与HuggingFace库无缝整合，从而提供即开即用的用户体验。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.11143v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.11143.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/OpenLLMAI/OpenRLHF)</div> |
| <span style='display: inline-block; width: 42px;'>05-20</span> | **Multiple-Choice Questions are Efficient and Robust LLM Evaluators**<br><sub>机构: Shanghai Jiao Tong University<br>该研究成功将常规的开放式生成问题转换为多项选择格式，以提高LLMs的评估效率和准确度。这一方法在防止无效答案的影响、提高评估效率方面取得了突破。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.11966v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.11966.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/Geralt-Targaryen/MC-Evaluation)</div> |
| <span style='display: inline-block; width: 42px;'>05-20</span> | **xFinder: Robust and Pinpoint Answer Extraction for Large Language Models**<br><sub>机构: Institute for Advanced Algorithms Research, Shanghai,Renmin University of China<br>这篇文章的重点是提出一个名为xFinder的方法，旨在提高从LLMs输出中提取关键答案的准确度，解决了现有方法无法满足的领域需求，为LLMs评估提供了更可靠的方法。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.11874v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.11874.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/IAAR-Shanghai/xFinder)</div> |
| <span style='display: inline-block; width: 42px;'>05-20</span> | **Octo: An Open-Source Generalist Robot Policy**<br><sub>机构: UC Berkeley, Stanford<br>论文介绍了Octo，这是一种基于变换器的策略，对多样化的机器人任务提供开源的解决方案，能通过微调适应新的观测和动作空间。它在多个机器人平台上表现出色，并通过完全开放的源码鼓励广泛应用和进一步发展。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.12213v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.12213.md)  |
| <span style='display: inline-block; width: 42px;'>05-19</span> | **Your Transformer is Secretly Linear**<br><sub>机构: AIRI, Skoltech, SberAI<br>这项研究展示了变压器编码层之间可能存在高度的线性动态，这一发现推翻了变压器中线性和非线性操作的传统理解，并发现可以在不牺牲性能的情况下进行模型修改以提高效率。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.12250v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.1225.md)  |
| <span style='display: inline-block; width: 42px;'>05-17</span> | **Prompt Exploration with Prompt Regression**<br><sub>机构: Carnegie Mellon University, Massachusetts Institute of Technology, University of Michigan<br>本文提出了一种新的框架PEPR，用于预测LLMs中提示元素组合的影响，并选择最适用于特定任务的提示。该框架不仅提出了创新性的解决方案，还通过在多个数据集和任务上进行评估，展示了其有效性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.11083v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.11083.md)  |
| <span style='display: inline-block; width: 42px;'>05-16</span> | **Thinking Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models**<br><sub>机构: BITS Pilani, MDSR Labs, Adobe, IIT Guhawati, National University of Singapore<br>这项研究开发并评估了一个针对端到端用户的迭代消偏框架，该框架提供了一种非训练型的消除LLMs偏见的方法。这种方法使用复杂的prompting策略在不减少下游任务性能的前提下显著降低了输出的平均偏见度，并为未来研究LLMs的prompt-based消偏方法铺平了道路。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.10431v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.10431.md)  |
| <span style='display: inline-block; width: 42px;'>05-16</span> | **SynthesizRR: Generating Diverse Datasets with Retrieval Augmentation**<br><sub>机构: Amazon, The University of Texas at Austin<br>SYNTHESIZRR是一种新方法，通过检索增强为教师-学生蒸馏的示例合成集成了获取信息。研究表明，与现有方法相比，SYNTHESIZRR生成的数据在内在数据多样性和下游任务准确性方面表现更佳。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.10040v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.1004.md)  |
| <span style='display: inline-block; width: 42px;'>05-16</span> | **SynthesizRR: Generating Diverse Datasets with Retrieval Augmentation**<br><sub>机构: Amazon, The University of Texas at Austin<br>SYNTHESIZRR通过检索增强解决了过去合成数据的多样性不足和与人类文本相异的问题，通过检索不同文档和内容，生成的样本具有更高的多样性和更接近人类文本的风格，这改善了蒸馏模型的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.10040v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.1004.md)  |
| <span style='display: inline-block; width: 42px;'>05-16</span> | **MarkLLM: An Open-Source Toolkit for LLM Watermarking**<br><sub>机构: Tsinghua University, Shanghai Jiao Tong University, The University of Sydney<br>MARKLLM为研究人员和公众提供一个易于访问和使用的实验平台，旨在提高LLM水印技术的普及度和参与度，推动研究和应用进一步发展。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.10051v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.10051.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/THU-BPM/MarkLLM)</div> |
| <span style='display: inline-block; width: 42px;'>05-16</span> | **Listen Again and Choose the Right Answer: A New Paradigm for Automatic Speech Recognition with Large Language Models**<br><sub>机构: Nanyang Technological University, University of Science and Technology of China, University of Aberdeen<br>本论文成功提出并验证了结合多模态LLM的新ASR错误修正范式，不仅解决了源语音忽视和输入冗余的问题，还在实际应用中取得了显著效果。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.10025v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.10025.md)  |
| <span style='display: inline-block; width: 42px;'>05-15</span> | **LoRA Learns Less and Forgets Less**<br><sub>机构: Columbia University, Databricks<br>LoRA虽然在目标任务的学习效率和精确度方面通常不如全参数微调，但在保持源任务性能方面展现了更好的表现和更强的正则化能力。根据本文研究，对使用LoRA做微调时的最佳实践做出了建议，尤其注意到学习率、目标模块选择和扰动的秩。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.09673v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.09673.md)  |
| <span style='display: inline-block; width: 42px;'>05-15</span> | **ALPINE: Unveiling the Planning Capability of Autoregressive Learning in Language Models**<br><sub>机构: Microsoft Research Asia, Harvard University, Peking University<br>ALPINE项目考察了自回归学习如何使Transformer具备网络中的规划能力，并揭示了在执行路径寻找任务中Transformer的表现能力及其局限性，为我们理解大型语言模型在其他相关领域的一般规划能力提供了新见解。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.09220v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.0922.md)  |
| <span style='display: inline-block; width: 42px;'>05-14</span> | **Is the Pope Catholic? Yes, the Pope is Catholic. Generative Evaluation of Intent Resolution in LLMs**<br><sub>机构: Carnegie Mellon University, Allen Institute for AI  <br>本研究通过引入一个全新的生成性评估框架，探索了LLMs在理解和生成与意图对齐的回应方面的潜力和挑战，揭示了当前模型在语用理解方面的不足，并指出了未来提升方向。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.08760v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.0876.md)  |
| <span style='display: inline-block; width: 42px;'>05-13</span> | **RLHF Workflow: From Reward Modeling to Online RLHF**<br><sub>机构: Salesforce AI Research, University of Illinois Urbana-Champaign  <br>本文提出了一个完整的在线迭代 RLHF 工作流程，不仅理论上创新，还通过详细的实践实现指南提供了实际应用的框架。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.07863v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.07863.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/RLHFlow/RLHF-Reward-Modeling)</div> |
| <span style='display: inline-block; width: 42px;'>05-13</span> | **DoLLM: How Large Language Models Understanding Network Flow Data to Detect Carpet Bombing DDoS**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.07638v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.07638.md)  |
| <span style='display: inline-block; width: 42px;'>05-10</span> | **Mitigating Hallucinations in Large Language Models via Self-Refinement-Enhanced Knowledge Retrieval**<br><sub>机构: Imperial College London, Huawei<br>这项工作通过一个新的自我完善增强的知识图谱检索方法有效地减少了大型语言模型中的幻觉现象，尤其提高了在医疗领域中的应用实效性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.06545v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.06545.md)  |
| <span style='display: inline-block; width: 42px;'>05-10</span> | **A Survey on RAG Meets LLMs: Towards Retrieval-Augmented Large Language Models**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.06211v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.06211.md)  |
| <span style='display: inline-block; width: 42px;'>05-10</span> | **Automatic Generation of Model and Data Cards: A Step Towards Responsible AI**<br><sub>机构: CMU, MPI, ETH Zürich<br>论文成功开发了一种使用大型语言模型自动化生成机器学习模型卡片和数据卡片的方法，并通过创建相应的数据集和评估机制，显著提升了生成文档的质量和标准化。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.06258v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.06258.md)  |
| <span style='display: inline-block; width: 42px;'>05-10</span> | **UniDM: A Unified Framework for Data Manipulation with Large Language Models**<br><sub>机构: Alibaba Group, University of Science and Technology of China<br>UniDM是一个创新的统一数据操作框架，通过有效的提示设计与步骤分解，显著提高了处理多种数据任务的效率和质量。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.06510v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.0651.md)  |
| <span style='display: inline-block; width: 42px;'>05-10</span> | **Value Augmented Sampling for Language Model Alignment and Personalization**<br><sub>VAS为LLM的适配和个性化提供了一个高效且强大的方法。它克服了现有RL算法的不稳定性，实现了高性能和计算效率的双重优势，同时支持黑盒模型的适应，为未来的LLM个性化和对齐开辟了新的可能性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.06639v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.06639.md)  |
| <span style='display: inline-block; width: 42px;'>05-09</span> | **Exploring the Potential of Human-LLM Synergy in Advancing Qualitative Analysis: A Case Study on Mental-Illness Stigma**<br><sub>CHALET方法框架展示了人类-LLM 协作在定性研究中的巨大潜力，特别是在深化理解和洞见生成方面，为未来的HCI和定性分析研究提供了新方向。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.05758v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.05758.md)  |
| <span style='display: inline-block; width: 42px;'>05-09</span> | **An Automatic Prompt Generation System for Tabular Data Tasks**<br><sub>本论文成功开发了一个既适应多种LLMs又无需广泛训练的自动提示生成系统，通过两种创新方法显著提高了处理表格数据任务的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.05618v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.05618.md)  |
| <span style='display: inline-block; width: 42px;'>05-09</span> | **Can large language models understand uncommon meanings of common words?**<br><sub>机构: Tsinghua University, Chinese Academy of Science<br>本研究通过建立新的评估体系和数据集，揭示了大型语言模型在理解常见词汇的罕见含义方面存在的重大不足，为提高模型的NLU能力提供了新的研究方向。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.05741v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.05741.md)  |
| <span style='display: inline-block; width: 42px;'>05-09</span> | **LLMPot: Automated LLM-based Industrial Protocol and Physical Process Emulation for ICS Honeypots**<br><sub>机构: New York University Abu Dhabi  <br>LLMPot是一种创新的ICS网络安全防御工具，其利用LLM的能力，通过自动化生成与协议和物理过程紧密相关的响应，显著提高了蜜罐的实用性和效果。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.05999v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.05999.md)  |
| <span style='display: inline-block; width: 42px;'>05-08</span> | **Air Gap: Protecting Privacy-Conscious Conversational Agents**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.05175v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.05175.md)  |
| <span style='display: inline-block; width: 42px;'>05-08</span> | **ADELIE: Aligning Large Language Models on Information Extraction**<br><sub>机构: Tsinghua University<br>本文提出的ADELIE模型有效地解决了LLM在信息提取任务中的对齐问题，并通过创新的数据集和训练方法提升了模型在这些任务上的性能，同时维护了良好的通用能力，为未来相关研究提供了有价值的见解和基础。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.05008v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.05008.md)  |
| <span style='display: inline-block; width: 42px;'>05-08</span> | **"They are uncultured": Unveiling Covert Harms and Social Threats in LLM Generated Conversations**<br><sub>机构: University of Washington, MBZUAI<br>这项研究通过创新的CHAST评估体系，揭示了LLMs在处理涵盖广泛文化和身份的复杂社会互动中可能导致的潜在伤害，强调了在部署这些模型之前进行彻底的偏见审计的必要性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.05378v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.05378.md)  |
| <span style='display: inline-block; width: 42px;'>05-07</span> | **Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application**<br><sub>机构: Kuaishou Technology, Southeast University<br>本论文成功地将大型语言模型的开放世界知识应用于推荐系统，通过一个创新的双塔结构解决了实际应用中的核心挑战，为提升推荐系统的性能提供了新的思路。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.03988v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.03988.md)  |
| <span style='display: inline-block; width: 42px;'>05-07</span> | **Toward In-Context Teaching: Adapting Examples to Students' Misconceptions**<br><sub>机构: MIT CSAIL  <br>本论文成功展示了利用大型语言模型进行适应性教学的潜力，并通过ATOM模型实现了对学生误解的有效识别和教学反馈的优化。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.04495v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.04495.md)  |
| <span style='display: inline-block; width: 42px;'>05-07</span> | **Deception in Reinforced Autonomous Agents: The Unconventional Rabbit Hat Trick in Legislation**<br><sub>机构: Center for Responsible AI, IIT Madras, Princeton University  <br>论文有效地展示了使用大型语言模型的自治代理在目标导向环境中执行复杂任务（如立法游说）时的欺骗能力，并提出了检测这种欺骗行为的有效方法。这些发现为AI在法律和道德方面的应用提供了重要的见解，同时也为AI安全提供了新的研究方向。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.04325v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.04325.md)  |
| <span style='display: inline-block; width: 42px;'>05-07</span> | **QServe: W4A8KV4 Quantization and System Co-design for Efficient LLM Serving**<br><sub>机构: MIT, NVIDIA<br>通过新的量化算法和系统设计，QServe显著提升了LLM在GPU上的服务效率，实现了成本的大幅度降低，为大规模语言模型的部署提供了新的解决方案。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.04532v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.04532.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/mit-han-lab/qserve)</div> |
| <span style='display: inline-block; width: 42px;'>05-06</span> | **MARE: Multi-Agents Collaboration Framework for Requirements Engineering**<br><sub>机构: Peking University<br>这项研究提出了一个创新的多代理合作框架，MARE，用于在整个需求工程过程中利用大型语言模型（LLMs）之间的合作。它针对RE中自动化任务的局限性进行了改进，并通过大规模实验的评估显示，MARE在需求建模和规格生成方面优于现有的先进方法。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.03256v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.03256.md)  |
| <span style='display: inline-block; width: 42px;'>05-06</span> | **Lifelong Knowledge Editing for LLMs with Retrieval-Augmented Continuous Prompt Learning**<br><sub>机构: East China Normal University<br>RECIPE方法通过转换知识陈述为连续提示符并结合知识哨兵来动态管理检索过程，有效提高了LLMs在生命周期学习场景中的编辑效率和推断速度，同时保持了模型整体性能。这种方法克服了以前方法的缺点，并在多个评估指标中表现出色。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.03279v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.03279.md)  |
| <span style='display: inline-block; width: 42px;'>05-03</span> | **What matters when building vision-language models?**<br><sub>机构: Hugging Face, Sorbonne Université  <br>本文通过广泛的实验探讨了影响VLMs性能的关键设计选择，提出了Idefics2这一高效的基础视觉语言模型，并在多个标准测试中证明了其优越性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.02246v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.02246.md)  |
| <span style='display: inline-block; width: 42px;'>05-02</span> | **How Can I Get It Right? Using GPT to Rephrase Incorrect Trainee Responses**<br><sub>机构: Carnegie Mellon University<br>该论文研究了利用GPT-4构建一个自动化反馈系统来帮助一对一节课中导师的训练，旨在减轻传统提供个性化教学反馈的资源负担，同时提供高质量和具体性的反馈，是知识检索与评估类的研究。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.00970v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.0097.md)  |
| <span style='display: inline-block; width: 42px;'>05-02</span> | **Prometheus 2: An Open Source Language Model Specialized in Evaluating Other Language Models**<br><sub>机构: KAIST AI, LG AI Research, Carnegie Mellon University<br>PROMETHEUS 2是一个新型的开源评估LM，能在直接评估和成对排名两种格式下工作，并且在自定义评价标准上与人类评分和专有LMs的判断密切相关。该模型采用权重合并的方式训练，性能显著超过其他开源模型和某些专有模型。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.01535v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.01535.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/prometheus-eval/prometheus-eval)</div> |
| <span style='display: inline-block; width: 42px;'>05-01</span> | **A Careful Examination of Large Language Model Performance on Grade School Arithmetic**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.00332v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.00332.md)  |
| <span style='display: inline-block; width: 42px;'>05-01</span> | **The Real, the Better: Aligning Large Language Models with Online Human Behaviors**<br><sub>机构: Baidu Inc.<br>本文提出了一种新型的大型语言模型对齐框架RLHB，它通过利用真实线上人类行为创新性地对LLMs进行调整和优化，克服了现有方法中的局限性，并通过实验有效地验证了其方法。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.00578v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.00578.md)  |
| <span style='display: inline-block; width: 42px;'>05-01</span> | **Can a Hallucinating Model help in Reducing Human "Hallucination"?**<br><sub>机构: Stanford University, UC Berkeley<br>本文探讨了如何使用大型语言模型（LLMs）来检测和对抗无根据信念，以及利用LLMs作为个性化的错误信息驳斥代理。研究者提出了评估并利用LLMs在识别逻辑陷阱方面的能力，并挑战人类无根据信念的新方法。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.00843v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.00843.md)  |
| <span style='display: inline-block; width: 42px;'>05-01</span> | **Is Bigger Edit Batch Size Always Better? -- An Empirical Study on Model Editing with Llama-3**<br><sub>本研究对于大型语言模型编辑技术进行了实证分析，揭示了以往方法的潜在不足，并为未来的模型编辑方法提出了新方向和思路。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.00664v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.00664.md)  |
| <span style='display: inline-block; width: 42px;'>05-01</span> | **"I'm Not Sure, But...": Examining the Impact of Large Language Models' Uncertainty Expression on User Reliance and Trust**<br><sub>机构: Princeton University, Microsoft<br>该论文通过大规模实验研究表明，LLMs通过自然语言来表达不确定性，可以减少用户的过度依赖，并提高任务处理的准确度。尤其是第一人称表达形式对提高用户的准确性效果显著。此外，这项研究还强调在实际应用LLMs之前，进行用户测试以调整不确定性的表达方式的重要性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.00623v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.00623.md)  |

---

### 04月

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>04-30</span> | **Multi-hop Question Answering over Knowledge Graphs using Large Language Models**<br><sub>机构: Microsoft<br>论文在多跳问答任务中提出针对不同的知识图谱数据集采用不同策略，展示了利用大型预训练语言模型在这些复杂问答任务中的强大能力。通过实验，验证了所提方法相比现有技术的优势。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.19234v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.19234.md)  |
| <span style='display: inline-block; width: 42px;'>04-30</span> | **Do Large Language Models Understand Conversational Implicature -- A case study with a chinese sitcom**<br><sub>机构: Shanghai Jiao Tong University<br>该研究通过创建一个新的中文多轮对话数据集SwordsmanImp评估LLMs理解言外之意的能力，特别是在涉及大量上下文和轮换的对话中，并揭示了LLMs在理解和解释非字面含义时的挑战和局限。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.19509v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.19509.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/sjtu-compling/llm-pragmatics)</div> |
| <span style='display: inline-block; width: 42px;'>04-30</span> | **Iterative Reasoning Preference Optimization**<br><sub>机构: FAIR at Meta, New York University<br>本文提出了一种迭代推理偏好优化方法，通过在推理任务上应用偏好优化，特别是针对CoT推理，并通过在迭代训练中引入NLL损失项来提升模型性能。实验证明，该方法在数次迭代后能够有效提升推理性能，最终达到性能饱和。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.19733v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.19733.md)  |
| <span style='display: inline-block; width: 42px;'>04-30</span> | **Better & Faster Large Language Models via Multi-token Prediction**<br><sub>机构: FAIR at Meta<br>论文提出了一种新的训练大型语言模型的方法，通过预测多个标记而不是单个来提高样本效率，并展示了如何提升生成任务中的性能并加快推理速度。实验证明了这种方法在提升大型模型性能和推理效率方面的显著优势。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.19737v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.19737.md)  |
| <span style='display: inline-block; width: 42px;'>04-29</span> | **Replacing Judges with Juries: Evaluating LLM Generations with a Panel of Diverse Models**<br><sub>机构: Cohere<br>该论文发展了一种以成员来自不同模型家族的小型模型组织成的“评审团”来评估LLM生成物的新方法，称为PoLL，显示出在不同任务中的适用性以及成本效率，减少了LLMs作为评判时存在的偏见问题。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.18796v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.18796.md)  |
| <span style='display: inline-block; width: 42px;'>04-29</span> | **LoRA Land: 310 Fine-tuned LLMs that Rival GPT-4, A Technical Report**<br><sub>机构: Predibase<br>本文提出通过LoRA对大型语言模型进行细化，可以明显提升模型的整体表现，降低在分类任务中出现的误差，且与开箱即用的GPT-4和GPT-3.5相比，有显著提高。同时，论文还考虑了成本限制，通过限制评估样本的数量来降低使用LLM API的财务负担。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.00732v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2405.00732.md)  |
| <span style='display: inline-block; width: 42px;'>04-26</span> | **When to Trust LLMs: Aligning Confidence with Response Quality**<br><sub>机构: Alibaba Group<br>本文提出了一个通过强化学习对齐信心和回答质量的方法（CONQORD）。该方法在没有客观实际标准的情况下通过自我评估来优化信心水平，并能够减少偏见，提升了模型预测的准确性和对齐性，但仍需对比绩效更高的方法进行改进。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.17287v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.17287.md)  |
| <span style='display: inline-block; width: 42px;'>04-26</span> | **A Comprehensive Evaluation on Event Reasoning of Large Language Models**<br><sub>机构: Peking University, Advanced Institute of Big Data, Beihang University<br>本文通过引入一个名为EV2的新基准测试来全面评估大型语言模型（LLMs）的事件推理能力。实验结果表明，虽然LLMs拥有事件推理能力，但与人类在运用事件模式知识方面并不一致，通过提供明确的指导，可以帮助模型更好地理解和执行事件推理任务。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.17513v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.17513.md)  |
| <span style='display: inline-block; width: 42px;'>04-25</span> | **Hippocrates: An Open-Source Framework for Advancing Large Language Models in Healthcare**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.16621v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.16621.md)  |
| <span style='display: inline-block; width: 42px;'>04-25</span> | **Layer Skip: Enabling Early Exit Inference and Self-Speculative Decoding**<br><sub>机构: Meta, University of Toronto, Carnegie Mellon University<br>LayerSkip是一个新颖的端到端解决方案，能够在不牺牲准确率的情况下显著加速大型语言模型的推理过程，具有实际应用价值和潜力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.16710v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.1671.md)  |
| <span style='display: inline-block; width: 42px;'>04-25</span> | **Continual Learning of Large Language Models: A Comprehensive Survey**<br><sub>机构: Rutgers University, Wuhan University, Huazhong University of Science and Technology<br>本综述为LLMs的持续学习提供了一个全面的视角，特别强调了连续预训练（CPT）和领域自适应预训练（DAP）的研究领域。强调社区需更多关注，特别是开发实用、易于获取且广泛认可的评估基准方面，以及需要针对新兴LLMs学习范式特别设计的方法论。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.16789v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.16789.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/Wang-ML-Lab/llm-continual-learning-survey)</div> |
| <span style='display: inline-block; width: 42px;'>04-25</span> | **How Far Are We to GPT-4V? Closing the Gap to Commercial Multimodal Models with Open-Source Suites**<br><sub>机构: Shanghai AI Laboratory, SenseTime Research, Tsinghua University<br>InternVL 1.5是一个强大的开源多模态语言模型，致力于弥补开源和商业模型在多模态理解方面的性能差距。该模型的优势包括改善视觉理解、处理动态高分辨率图像以及高质量的双语数据集的使用，这些它在多项任务中表现出色。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.16821v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.16821.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/OpenGVLab/InternVL)</div> |
| <span style='display: inline-block; width: 42px;'>04-24</span> | **Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs**<br><sub>机构: Shanghai Jiao Tong University, UC San Diego, Duke University<br>本文章是对大型语言模型（LLMs）中Chain-of-X (CoX) 方法的详尽调研，着重于将Chain-of-Thought (CoT) 的概念扩展至更广泛的应用，并为未来的研究提供了潜在的发展方向。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.15676v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.15676.md)  |
| <span style='display: inline-block; width: 42px;'>04-24</span> | **From Local to Global: A Graph RAG Approach to Query-Focused Summarization**<br><sub>机构: Microsoft Research, Microsoft Strategic Missions and Technologies, Microsoft Office of the CTO<br>这篇论文提出了Graph RAG方法，这是一种以图谱索引和LLM生成摘要为基础的查询聚焦摘要技术，旨在处理因语料量过大而超出大型语言模型处理能力的问题。通过社区检测算法的帮助，该方法能在处理全局性问题并实现大规模文本分析方面取得显著成效。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.16130v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.1613.md)  |
| <span style='display: inline-block; width: 42px;'>04-23</span> | **A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications**<br><sub>机构: Hong Kong Baptist University<br>本文是一个综述性研究，主要调查了在图数据上使用的LLMs研究，探讨了LLMs在图任务泛化方面的优势，并提出了在该领域进行研究的未来方向。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.14809v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.14809.md)  |
| <span style='display: inline-block; width: 42px;'>04-23</span> | **CultureBank: An Online Community-Driven Knowledge Base Towards Culturally Aware Language Technologies**<br><sub>机构: Stanford University, IBM Research<br>该论文提出了一个用于构建文化知识库的通用流水线，并使用该流水线创建了CultureBank，这是一个包含TikTok和Reddit上文化描述符的知识库。论文还通过这个知识库评估了LLMs在文化意识方面的表现，并用于训练更具文化意识的语言模型，以此促进未来语言技术的文化意识发展。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.15238v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.15238.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/SALT-NLP/CultureBank)</div> |
| <span style='display: inline-block; width: 42px;'>04-22</span> | **LLMs Know What They Need: Leveraging a Missing Information Guided Framework to Empower Retrieval-Augmented Generation**<br><sub>机构: Meituan<br>本文提出的MIGRES框架是通过Exploiting LLMs识别缺失信息的能力来增强RAG的能力。研究结果证明了MIGRES在多个公共数据集上具有优越性，应对了RAG在理解复杂查询和检索相关文档方面的挑战。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.14043v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.14043.md)  |
| <span style='display: inline-block; width: 42px;'>04-22</span> | **Beyond Scaling: Predicting Patent Approval with Domain-specific Fine-grained Claim Dependency Graph**<br><sub>机构: University of California San Diego, Carnegie Mellon University, University of Pennsylvania<br>研究者提出了一种新颖的用于构建细粒度主张依赖图(FLAN图)的算法，该算法在大规模上显著改善了现状，并对现代LLMs在专利批准预测上的应用进行了广泛实验和分析，发现了LLMs的局限性，并为未来LLM方案的开发提供了有价值的参考。源代码和数据集已公开发布以促进未来的研究。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.14372v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.14372.md)  |
| <span style='display: inline-block; width: 42px;'>04-22</span> | **A Survey on Efficient Inference for Large Language Models**<br><sub>机构: Tsinghua University<br>本文提供了一个全面的综述关于提高大型语言模型推理效率的文献，并提出了一个包含数据层、模型层和系统层优化的分类法。同时，通过实验对关键技术进行了量化比较，指出了研究的未来方向。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.14294v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.14294.md)  |
| <span style='display: inline-block; width: 42px;'>04-22</span> | **A Survey on Self-Evolution of Large Language Models**<br><sub>机构: Peking University, Alibaba Group, Nanyang Technological University<br>这篇综述文章提出并总结了LLMs的自我进化方法，为推动自我进化的研究提供了概念框架和未来方向的见解，旨在推动下一代自我进化LLMs的发展。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.14387v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.14387.md)  |
| <span style='display: inline-block; width: 42px;'>04-22</span> | **Information Re-Organization Improves Reasoning in Large Language Models**<br><sub>机构: Zhejiang University<br>本论文提出了一个新颖的信息重组方法（InfoRE），通过重组上下文内容来揭示逻辑关系，从而增强LLMs的推理能力。方法在零次射击设置下对LLMs进行上下文理解的多跳推理任务测试，取得了显著效果。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.13985v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.13985.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/hustcxx/InfoRE)</div> |
| <span style='display: inline-block; width: 42px;'>04-22</span> | **Tree of Reviews: A Tree-based Dynamic Iterative Retrieval Framework for Multi-hop Question Answering**<br><sub>机构: Tencent Inc., Harbin Institute of Technology<br>论文提出了一种新的迭代检索框架TOR，它采用树形结构减少错误累积，并引入优化策略提高检索效率和质量。在实验中，TOR框架在多个数据集上达到了最先进的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.14464v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.14464.md)  |
| <span style='display: inline-block; width: 42px;'>04-22</span> | **SnapKV: LLM Knows What You are Looking for Before Generation**<br><sub>机构: University of Illinois Urbana-Champaign, Cohere, Princeton University<br>该文章介绍了SnapKV，一种针对大型语言模型中关键值缓存问题的新方法。SnapKV通过智能压缩和选取重要的KV位置，有效地提升了长文本处理时的解码速度和内存效率，并在保持准确性的同时显著降低了计算成本。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.14469v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.14469.md)  |
| <span style='display: inline-block; width: 42px;'>04-21</span> | **AdvPrompter: Fast Adaptive Adversarial Prompting for LLMs**<br><sub>机构: Meta AI (FAIR), Max-Planck-Institute for Intelligent Systems<br>本文提出了一个新型的LLM，名为AdvPrompter，它利用新颖的算法，无需目标LLM的梯度信息，迅速生成人类可读的敌对提示，显著提升了生成速度并保持了提示的语义连贯性。此外，通过AdvPrompter的训练还能增强LLM面对越狱攻击的稳健性，而不牺牲性能表现。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.16873v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.16873.md)  |
| <span style='display: inline-block; width: 42px;'>04-19</span> | **Relevant or Random: Can LLMs Truly Perform Analogical Reasoning?**<br><sub>机构: Nanyang Technological University, Princeton University, Salesforce Research<br>本论文系统地评估了LLMs进行类比推理的能力，并提出了两种可以在显著降低推理成本的同时获得更好性能的方法。研究结果表明，与以前认为相关性至关重要的观点相反，自我生成的无关例子在某些任务上可以达到相当甚至更好的性能。希望本研究能刺激更多关于自我生成上下文设计的进一步研究。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.12728v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.12728.md)  |
| <span style='display: inline-block; width: 42px;'>04-19</span> | **LLM-R2: A Large Language Model Enhanced Rule-based Rewrite System for Boosting Query Efficiency**<br><sub>机构: Nanyang Technological University, DAMO Academy Alibaba Group, Singapore University of Technology and Design<br>LLM-R2是一种利用大型语言模型增强的查询重写系统，通过自动选择一组给定重写规则中的有效规则，有效地提升了查询重写的执行效率，解决了目前其他方法的局限性，并在多个数据集上取得了优越的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.12872v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.12872.md)  |
| <span style='display: inline-block; width: 42px;'>04-18</span> | **EVIT: Event-Oriented Instruction Tuning for Event Reasoning**<br><sub>机构: Key Laboratory of High Confidence Software Technologies (PKU), MOE, China, School of Computer Science, Peking University, Advanced Institute of Big Data<br>EVIT通过提出面向事件的指令调谐（Event-Oriented Instruction Tuning）和事件四元组的概念，解决了现有小型基于指令调谐模型在事件推理任务中的表现不足问题。实验结果表明，EVIT在事件推理任务上的表现优于其他模型。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.11978v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.11978.md)  |
| <span style='display: inline-block; width: 42px;'>04-18</span> | **Who Validates the Validators? Aligning LLM-Assisted Evaluation of LLM Outputs with Human Preferences**<br><sub>机构: UC Berkeley<br>这篇论文提出了一个与人类偏好相一致的LLM辅助评估界面EvalGen，通过混合主动式方法解决了LLM生成的评估功能评估质量受信任度的问题。论文还探讨了用户如何定义和使用评估标准的动态性，以及在实际应用中所面临的挑战。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.12272v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.12272.md)  |
| <span style='display: inline-block; width: 42px;'>04-18</span> | **Toward Self-Improvement of LLMs via Imagination, Searching, and Criticizing**<br><sub>该论文介绍了一种名为ALPHALLM的新型框架，通过蒙特卡洛树搜索（MCTS）和大型语言模型（LLMs）的结合，实现了LLMs的自我提高，无需额外的注解数据。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.12253v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.12253.md)  |
| <span style='display: inline-block; width: 42px;'>04-18</span> | **Generating Diverse Criteria On-the-Fly to Improve Point-wise LLM Rankers**<br><sub>机构: Westlake University, Alibaba Group, Zhejiang University<br>该论文提出了MCRanker模型，通过构建虚拟专业评注团队和生成多角度评估标准，有效提升了LLM排序器的一致性与全面性，可广泛适应于各类数据集，改进了排序性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.11960v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.1196.md)  |
| <span style='display: inline-block; width: 42px;'>04-18</span> | **RAGCache: Efficient Knowledge Caching for Retrieval-Augmented Generation**<br><sub>机构: Peking University, ByteDance Inc.<br>通过针对性的缓存系统设计和中间状态共享，RAGCache优化了RAG流程的性能，显著提升了处理速度并减少了计算资源的开销。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.12457v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.12457.md)  |
| <span style='display: inline-block; width: 42px;'>04-18</span> | **mABC: multi-Agent Blockchain-Inspired Collaboration for root cause analysis in micro-services architecture**<br><sub>机构:  Beihang University, Beijing Information Science and Technology University<br>mABC是一种创新的框架，利用了大语言模型（LLMs）及多代理合作，并由区块链启发式的决策过程促成，针对云原生技术中微服务架构的根本原因分析（RCA）。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.12135v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.12135.md)  |
| <span style='display: inline-block; width: 42px;'>04-17</span> | **Many-Shot In-Context Learning**<br><sub>机构: Google DeepMind<br>本论文主要贡献包括系统评估LLM在不同规模上下文样例的性能，导入reinforced ICL和unsupervised ICL以减少样例依赖，并发现MS-ICL可以克服预训练偏差学习高维数值预测任务。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.11018v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.11018.md)  |
| <span style='display: inline-block; width: 42px;'>04-17</span> | **Unifying Bias and Unfairness in Information Retrieval: A Survey of Challenges and Opportunities with Large Language Models**<br><sub>机构: Renmin University of China, Chinese Academy of Sciences, Huawei Technologies<br>这篇综述文章提供了一个新颖的视角来理解LLMs和IR系统中的偏见和不公平为分布失配问题，并归类了各种缓解策略。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.11457v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.11457.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/KID-22/LLM-IR-Bias-Fairness-Survey)</div> |
| <span style='display: inline-block; width: 42px;'>04-17</span> | **AgentKit: Flow Engineering with Graphs, not Coding**<br><sub>机构: Carnegie Mellon University, NVIDIA, Microsoft<br>论文引入了一种新型的 LLM 提示框架 AgentKit，针对多功能代理问题，通过模块化组件和直观设计支持构建和微调复杂的代理思维过程。AgentKit 显示出实现先进代理能力和降低用户参与门槛的潜力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.11483v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.11483.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/holmeswww/AgentKit)</div> |
| <span style='display: inline-block; width: 42px;'>04-17</span> | **A Deep Dive into Large Language Models for Automated Bug Localization and Repair**<br><sub>机构: University of Virginia, Purdue University, Amazon Web Services<br>这篇论文提出了一种名为Toggle的新方法，该方法使用token粒度的bug定位并修复，克服了现有行粒度方法的局限，通过输入设计和LLMs的微调，大幅提升了错误修复的准确性，并在多个数据集上取得优异的表现，为APR领域带来新的进展。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.11595v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.11595.md)  |
| <span style='display: inline-block; width: 42px;'>04-16</span> | **How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs' internal prior**<br><sub>机构: Stanford University<br>论文通过分析在RAG环境下LLMs内部知识与检索信息之间的张力，发现了LLMs倾向于遵循RAG信息的程度与模型在无上下文情况下的回答信心成反比。研究基于跨超过1200个问题的六个领域数据集，揭示了在模型的预训练知识与检索到的信息之间的固有冲突。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.10198v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.10198.md)  |
| <span style='display: inline-block; width: 42px;'>04-16</span> | **CoTAR: Chain-of-Thought Attribution Reasoning with Multi-level Granularity**<br><sub>机构: Intel Labs<br>本文提出的CoTAR方法针对LLMs在问答任务中倾向于生成不准确归因的问题。通过在输出生成前进行推理，并在不同的归因粒度级别上引导模型，显著提升了模型在答案质量和归因精确度上的表现。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.10513v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.10513.md)  |
| <span style='display: inline-block; width: 42px;'>04-16</span> | **Self-playing Adversarial Language Game Enhances LLM Reasoning**<br><sub>机构: Tencent AI Lab<br>本论文提出了一个名为SPAG的新型训练方案，通过自我对抗性语言游戏的自我播放，有效提升了LLMs的推理能力，并且其改进是可以通过迭代过程持续增强的。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.10642v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.10642.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/Linear95/SPAG)</div> |
| <span style='display: inline-block; width: 42px;'>04-15</span> | **Learn Your Reference Model for Real Good Alignment**<br><sub>机构: Tinkoff<br>本论文提出了一个名为Trust Region DPO (TR-DPO) 的新方法，该方法通过交互式地更新参考策略的参数，显著改进了语言模型的对齐问题。实验结果显示，TR-DPO在两个数据集上均优于DPO方法，有效提升了模型的多参数性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.09656v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.09656.md)  |
| <span style='display: inline-block; width: 42px;'>04-15</span> | **Compression Represents Intelligence Linearly**<br><sub>机构: The Hong Kong University of Science and Technology, Tencent<br>这篇论文通过实证研究，证明了LLMs在下游任务性能与它们的压缩效率之间存在着几乎线性的相关性，为“更好的压缩能力表明了更高的智能”这一长期信念提供了支持。同时，提出了使用压缩效率作为评估LLMs性能的无监督度量标准的建议。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.09937v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.09937.md)  |
| <span style='display: inline-block; width: 42px;'>04-14</span> | **Emerging Platforms Meet Emerging LLMs: A Year-Long Journey of Top-Down Development**<br><sub>本论文的研究主要集中在如何支持和优化新兴计算平台下的机器学习模型部署，并提出了一个框架TAPML，旨在通过顶层方法和通用运行时环境促进模型部署的广泛性、便利性和强大性，文中提供了实际部署案例作为发展ML系统的深入见解和最佳实践。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.09151v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.09151.md)  |
| <span style='display: inline-block; width: 42px;'>04-13</span> | **Intuition-aware Mixture-of-Rank-1-Experts for Parameter Efficient Finetuning**<br><sub>机构: Nanjing University, University of California<br>论文提出了一个新的用于大型语言模型多任务微调的框架Intuition-MoR1E，该框架借鉴人类认知神经科学原理，并利用排名1专家形式来管理直觉，显著提高了参数效率和多任务微调效果。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.08985v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.08985.md)  |
| <span style='display: inline-block; width: 42px;'>04-12</span> | **Megalodon: Efficient LLM Pretraining and Inference with Unlimited Context Length**<br><sub>机构: AI at Meta, University of Southern California, Carnegie Mellon University<br>这篇论文介绍了MEGALODON，一个高效处理无限上下文长度序列的神经网络架构。通过引入多项创新技术，MEGALODON在长序列模型任务中显示出比Transformer更高的效率和效能，同时在不同规模和模态的基准测试中都取得了稳健的改进。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.08801v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.08801.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/XuezheMax/megalodon)</div> |
| <span style='display: inline-block; width: 42px;'>04-11</span> | **Decomposing Label Space, Format and Discrimination: Rethinking How LLMs Respond and Solve Tasks via In-Context Learning**<br><sub>机构: Nanyang Technological University<br>本文研究了ICL在提升任务性能方面的生效机制，通过分解ICL的贡献因素，发现ICL通过精细调整标签空间和格式来显著提升性能，同时强调了选择合适演示示例的重要性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.07546v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.07546.md)  |
| <span style='display: inline-block; width: 42px;'>04-11</span> | **ChatGPT Can Predict the Future when it Tells Stories Set in the Future About the Past**<br><sub>机构: Baylor University<br>本研究通过分析ChatGPT-3.5和ChatGPT-4的预测能力，揭示了LLMs在推理方面的新潜力。研究证明了“未来叙事”提示能够显著提升预测的准确性，为LLMs在分析环境中的潜在应用提供了有益见解。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.07396v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.07396.md)  |
| <span style='display: inline-block; width: 42px;'>04-11</span> | **Rho-1: Not All Tokens Are What You Need**<br><sub>机构: Xiamen University, Tsinghua University, Microsoft<br>本文提出了RHO-1，这是一种利用选择性语言建模（SLM）的新型语言模型。该模型在预训练中专注于对有用的令牌进行训练，这种方法在数学领域的连续预训练中显示出卓越性能，能够更快地达到基线性能，并且在少量令牌的情况下达到最新的状态。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.07965v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.07965.md)  |
| <span style='display: inline-block; width: 42px;'>04-11</span> | **OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments**<br><sub>机构: The University of Hong Kong, CMU, Salesforce Research<br>OSWORLD提供了一个新的评估环境，解决了现有基准测试的局限性，为开发能在真实计算机环境中完成开放式任务的多模态代理提供了基础。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.07972v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.07972.md)  |
| <span style='display: inline-block; width: 42px;'>04-11</span> | **ControlNet++: Improving Conditional Controls with Efficient Consistency Feedback**<br><sub>机构: University of Central Florida, ByteDance Inc<br>ControlNet++通过优化生成图像与条件控制之间的像素级一致性，并通过高效的奖励微调策略减少了与图像采样相关的时间和内存成本，显著改善了在多种条件控制下的可控性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.07987v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.07987.md)  |
| <span style='display: inline-block; width: 42px;'>04-11</span> | **Interactive Prompt Debugging with Sequence Salience**<br><sub>这篇论文提出了一个名为序列显著性（Sequence Salience）的系统，它扩展了现有的输入显著性（IS）方法，以支持复杂的LLM提示调试。该工具提供实时交互式调试，并降低了实践者的认知负荷，支持根据显著性结果快速迭代提示，与开发者的思维模型更加对齐。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.07498v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.07498.md)  |
| <span style='display: inline-block; width: 42px;'>04-10</span> | **Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention**<br><sub>机构: Google<br>该研究提出一种全新的注意力机制Infini-attention，它通过将压缩记忆与标准的点积注意力相结合，并在设计上支持插拔式的持续预训练和长上下文调整，使得LLMs能以有界的内存和计算资源处理无限长的上下文。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.07143v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.07143.md)  |
| <span style='display: inline-block; width: 42px;'>04-10</span> | **"We Need Structured Output": Towards User-centered Constraints on Large Language Model Output**<br><sub>机构: Google Research<br>本论文探索如何为大型语言模型（LLM）输出实现用户中心的约束，通过调查行业专业人士来了解不同场景和需求。重点是提高开发者在开发、测试和整合LLM过程中的效率，并通过满足特定的输出格式和用户界面要求来增强最终用户的体验。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.07362v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.07362.md)  |
| <span style='display: inline-block; width: 42px;'>04-10</span> | **Superposition Prompting: Improving and Accelerating Retrieval-Augmented Generation**<br><sub>机构: Apple, Cupertino, CA, USA<br>该论文提出了一种新的检索增强生成（RAG）提示方法——“超级叠加提示”，用于处理大型语言模型处理长文本时遇到的问题，并在没有额外训练或微调的情况下显著提高了时间效率和准确性。这一方法在众多预训练模型上得到验证，并且作者计划发布一个开源代码实现。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.06910v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.0691.md)  |
| <span style='display: inline-block; width: 42px;'>04-10</span> | **Transferable and Efficient Non-Factual Content Detection via Probe Training with Offline Consistency Checking**<br><sub>机构: Renmin University of China, Tsinghua University<br>本论文提出了一种通过离线自我一致性检查训练探测模型的新方法PINOS，有效地解决了现有真实性检测方法的限制。PINOS提高了过程的转移能力和效率，并且在真实性检测和问答基准测试上取得了超越现有方法的结果。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.06742v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.06742.md)  |
| <span style='display: inline-block; width: 42px;'>04-09</span> | **RULER: What's the Real Context Size of Your Long-Context Language Models?**<br><sub>机构: NVIDIA  <br>本论文为长上下文LMs提出了新的评估工具RULER，并开源，用于测试LMs在复杂任务和长上下文理解能力上的表现，并在各种模型和任务复杂度上进行了分析，推动了长上下文LMs的未来研究。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.06654v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.06654.md)  |
| <span style='display: inline-block; width: 42px;'>04-09</span> | **Privacy Preserving Prompt Engineering: A Survey**<br><sub>机构: University of Arkansas<br>这篇调研论文为了在使用LLMs进行ICL和一般提示的过程中保护隐私，提供了一个关于在这一范畴下的隐私保护方法的系统性概述，有利于推动社区在隐私保护方面的进一步研究和探索。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.06001v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.06001.md)  |
| <span style='display: inline-block; width: 42px;'>04-09</span> | **Event-enhanced Retrieval in Real-time Search**<br><sub>机构: Tencent Search, Platform and Content Group<br>EER是一种新型方法，针对实时搜索中的“语义漂移”问题，通过改进EBR模型和加入对比学习及事件三元组生成任务提升检索性能。该方法通过实验验证了其有效性，并可能为信息检索领域提供新的视角。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.05989v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.05989.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/open-event-hub/Event-enhanced_Retrieval)</div> |
| <span style='display: inline-block; width: 42px;'>04-09</span> | **THOUGHTSCULPT: Reasoning with Intermediate Revision and Search**<br><sub>机构: UC Berkeley<br>THOUGHTSCULPT作为一个基于图的框架，通过内嵌的自我修正机制，能够让LLMs在生成新的思维节点的同时迭代地改进之前的输出，特别在需要持续修正和修改的任务中表现出卓越的能力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.05966v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.05966.md)  |
| <span style='display: inline-block; width: 42px;'>04-08</span> | **Evaluating Interventional Reasoning Capabilities of Large Language Models**<br><sub>机构: Université de Montréal, Google DeepMind, ServiceNow Research<br>本文对大型语言模型（LLMs）因果推理能力进行了评估。通过提出干预效果预测，它主要测试LLMs在干预实验后如何更新自己对事实的理解。结果显示GPT-4在某些条件下能够准确预测干预效果，但提示设计的微小变化会显著影响其表现。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.05545v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.05545.md)  |
| <span style='display: inline-block; width: 42px;'>04-08</span> | **Know When To Stop: A Study of Semantic Drift in Text Generation**<br><sub>机构: FAIR, Meta, Anthropic<br>本文为理解和测量语言模型在长文本生成中的语义漂移现象提供了工具。通过早停和重采样-重新排序等方法，显著提高了事实准确性，并为如何平衡信息量与事实准确性提供了可能的解决策略。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.05411v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.05411.md)  |
| <span style='display: inline-block; width: 42px;'>04-08</span> | **LayoutLLM: Layout Instruction Tuning with Large Language Models for Document Understanding**<br><sub>机构: Alibaba Group, Zhejiang University<br>该论文成功提出了LayoutLLM模型及其布局指导的调整策略，显著提高了模型对文档布局信息的理解和利用，尤其在零样本文档理解任务上表现出了卓越的效果。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.05225v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.05225.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/DocumentUnderstanding)</div> |
| <span style='display: inline-block; width: 42px;'>04-08</span> | **LLM-Augmented Retrieval: Enhancing Retrieval Models Through Language Models and Doc-Level Embedding**<br><sub>机构: Meta<br>该论文成功提出并验证了一个增强型文档级嵌入的LLM-augmented检索框架，不仅通过生成合成的相关查询和标题增加了文档嵌入的上下文信息，还改进了检索模型训练的关键步骤，从而提升检索模型的性能和鲁棒性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.05825v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.05825.md)  |
| <span style='display: inline-block; width: 42px;'>04-07</span> | **Radial Networks: Dynamic Layer Routing for High-Performance Large Language Models**<br><sub>机构: Cornell University<br>本论文提出了径向网络，这是一种新型神经网络结构，通过动态层稀疏性和一个经过训练的路由模块来实现令牌级的层间路由。这不仅提高了模型的性能，还显著降低了计算和服务成本，为大型语言模型的进一步扩展提供了可能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.04900v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.049.md)  |
| <span style='display: inline-block; width: 42px;'>04-07</span> | **Prompting Large Language Models for Zero-shot Essay Scoring via Multi-trait Specialization**<br><sub>机构: Peking University<br>该研究提出了一个零样本的大型语言模型作文评分框架（MTS），通过多轮对话来为作文的不同写作特质打分，并采用最小-最大缩放和异常值截断机制来得到最终得分。MTS在准确度上显著优于直接提示评分方法，并在小型化部署中优于ChatGPT，提供了监督学习之外的零样本作文评分方案。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.04941v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.04941.md)  |
| <span style='display: inline-block; width: 42px;'>04-04</span> | **Direct Nash Optimization: Teaching Language Models to Self-Improve with General Preferences**<br><sub>机构: Microsoft Research<br>这篇论文介绍了DNO——一种能够将对比学习的简洁性与从优化一般性偏好而来的理论普适性相结合的算法。DNO在后训练大型语言模型方面显著提升性能，它的成功实证了通过优化一般偏好来指导模型学习与人类价值观保持一致是可能的。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.03715v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.03715.md)  |
| <span style='display: inline-block; width: 42px;'>04-04</span> | **ReFT: Representation Finetuning for Language Models**<br><sub>机构: Stanford University, Pr(Ai)2R Group<br>这篇论文介绍了一种新的语言模型微调方法LoReFT，它在资源效率和模型控制能力方面显著优于现有的参数有效调整（PEFTs）方法。实验表明，该方法在多个NLP领域的任务上实现了新的最佳性能，同时保持了较少的参数需求和较高的可解释性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.03592v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.03592.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/stanfordnlp/pyreft)</div> |
| <span style='display: inline-block; width: 42px;'>04-04</span> | **AutoWebGLM: Bootstrap And Reinforce A Large Language Model-based Web Navigating Agent**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.03648v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.03648.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/THUDM/AutoWebGLM)</div> |
| <span style='display: inline-block; width: 42px;'>04-03</span> | **PromptRPA: Generating Robotic Process Automation on Smartphones from Textual Prompts**<br><sub>机构: Shanghai Jiao Tong University, CMU<br>文章介绍了PromptRPA系统，这是一个解决RPA在移动设备上应用受限的有效方案。通过利用多代理框架和在线教程，该系统能够解释各种文本提示，解决大范围的RPA任务。性能评估显示成功率显著提高，证明了文本驱动控制在RPA领域的可行性，并开辟了功能增强和适用性扩展的新方向。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.02475v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.02475.md)  |
| <span style='display: inline-block; width: 42px;'>04-02</span> | **Long-context LLMs Struggle with Long In-context Learning**<br><sub>机构: University of Waterloo, Carnegie Mellon University<br>这项研究为评估大型语言模型处理长上下文任务的能力提供了一个新的基准——LongICLBench，并显示了随着任务难度增加，LLMs的性能普遍下降，并且模型的长上下文学习能力受到提示中标签位置分布的影响。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.02060v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.0206.md)  |
| <span style='display: inline-block; width: 42px;'>04-02</span> | **Advancing LLM Reasoning Generalists with Preference Trees**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.02078v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.02078.md)  |
| <span style='display: inline-block; width: 42px;'>04-02</span> | **LLM-ABR: Designing Adaptive Bitrate Algorithms via Large Language Models**<br><sub>机构: Microsoft<br>论文探讨了大型语言模型（LLMs）如何辅助设计自适应比特率（ABR）算法，通过生成多样化的候选算法，并运用早停机制在网络模拟器中进行测试，从而有效地筛选出最有效的算法设计。评估显示在特定网络场景中，利用LLMs可以显著提高ABR算法的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.01617v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.01617.md)  |
| <span style='display: inline-block; width: 42px;'>04-02</span> | **Long-context LLMs Struggle with Long In-context Learning**<br><sub>机构: University of Waterloo, Carnegie Mellon University<br>这篇文章提出了一个新的评估基准，LongICLBench，用于评估LLMs在处理长输入任务时的性能，以及LLMs对输入序列中实例位置的敏感性。这一工作有助于更好地理解和改进大型语言模型在长文本处理方面的能力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.02060v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.0206.md)  |
| <span style='display: inline-block; width: 42px;'>04-02</span> | **CMAT: A Multi-Agent Collaboration Tuning Framework for Enhancing Small Language Models**<br><sub>机构: East China Jiaotong University, Guangdong University of Technology, University of Toronto<br>该论文的核心贡献是提出了CMAT框架，这是一种创新方法，可实现多智能体系统内部的动态、实时记忆更新，并设计了一种新型的角色扮演机制，用于精准的任务分配和提升代理间的通信，以此显著提高整体性能和合作效率。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.01663v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.01663.md)  |
| <span style='display: inline-block; width: 42px;'>04-02</span> | **Octopus v2: On-device language model for super agent**<br><sub>机构: Stanford University<br>这篇论文解决了边缘设备上LLM的部署和功能调用效率问题，通过引入特殊的训练方法和减少推理时需处理的上下文量，显著提高了在设备上进行函数调用的准确率和降低了延迟，实验结果表明其对提升函数调用任务的性能具有显著影响。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.01744v3)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.01744.md)  |
| <span style='display: inline-block; width: 42px;'>04-01</span> | **LLM-RadJudge: Achieving Radiologist-Level Evaluation for X-Ray Report Generation**<br><sub>机构: Microsoft Research Asia<br>这篇论文提出了一个基于大型语言模型的放射学报告评价新框架——LLM-RadJudge，能够有效提高放射学报告评价的临床相关性和一致性。并通过知识蒸馏技术实现了小型模型的开发，既降低了评价成本也提高了可访问性，为放射学报告生成研究和实际应用提供了有力的支撑。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.00998v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.00998.md)  |
| <span style='display: inline-block; width: 42px;'>04-01</span> | **Prompt-prompted Mixture of Experts for Efficient LLM Generation**<br><sub>机构: CMU<br>GRIFFIN是一个不需要训练的MoE系统，利用LLMs前馈块内的flocking现象在不同的激活函数下提高模型效率，保持性能的同时减少了计算成本。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.01365v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.01365.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/hdong920/GRIFFIN)</div> |
| <span style='display: inline-block; width: 42px;'>04-01</span> | **Efficiently Distilling LLMs for Edge Applications**<br><sub>机构: IBM Research  <br>本论文提供了一种新的针对边缘设备进行LLMs蒸馏的方法，允许LPFT同时显著减少模型尺寸和训练成本，尤其是优化了解码器模型的压缩抵抗和训练时长。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.01353v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.01353.md)  |
| <span style='display: inline-block; width: 42px;'>04-01</span> | **Mapping the Increasing Use of LLMs in Scientific Papers**<br><sub>机构: Stanford University, UC Santa Barbara<br>本文是首次进行的，跨arXiv、bioRxiv和Nature组合上发表的文章的系统性、大规模分析，采用的统计估计方法可以在群体层面上测量LLM修改内容的普及程度，为理解LLM在科学写作中的应用提供了宝贵的洞察。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.01268v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.01268.md)  |
| <span style='display: inline-block; width: 42px;'>04-01</span> | **AIOps Solutions for Incident Management: Technical Guidelines and A Comprehensive Literature Review**<br><sub>机构: University of Lyon, INSA Lyon, Infologic<br>本文提供了 AIOps 领域中事件管理的全面文献回顾，旨在通过提供结构化的知识、确定知识空白和为该领域的未来发展奠定基础。论文建立了 AIOps 的统一术语和分类法，揭示了现有的挑战，并提供了公开数据集，为未来的研究提供了方向和基础。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.01363v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.01363.md)  |

---

### 03月

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>03-28</span> | **sDPO: Don't Use Your Data All at Once**<br><sub>此论文提出了一个新的步骤化DPO（sDPO）方法，通过分步骤利用偏好数据集，并使用先前步骤中的对齐模型作为当前步骤的参考模型，有效提高了最终模型的性能与对齐度。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.19270v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.1927.md)  |
| <span style='display: inline-block; width: 42px;'>03-28</span> | **Jamba: A Hybrid Transformer-Mamba Language Model**<br><sub>机构: AI21 Labs<br>Jamba是基于混合Transformer-Mamba体系结构的新型大型语言模型，突破了处理长上下文的限制，并且通过应用专家混合（MoE）组件提高了模型吞吐量，同时保持了较小的内存足迹。此模型标志着在大型语言模型领域的一个新方向，并展示了高效训练与强大性能之间的可能平衡。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.19887v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.19887.md)  |
| <span style='display: inline-block; width: 42px;'>03-27</span> | **BLADE: Enhancing Black-box Large Language Models with Small Domain-Specific Models**<br><sub>机构: DCST Tsinghua University, Beijing Institute of Technology, Huawei Cloud BU<br>这项研究提出了一个新架构BLADE，可以通过小型领域特定模型增强黑盒大型语言模型，并解决了大型模型在特定领域应用中的知识不足问题。BLADE证明了其在性能和成本上都是一个有效的解决方案。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.18365v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.18365.md)  |
| <span style='display: inline-block; width: 42px;'>03-27</span> | **Rejection Improves Reliability: Training LLMs to Refuse Unknown Questions Using RL from Knowledge Feedback**<br><sub>这项工作通过提出RLKF框架并定义了新的模型可靠性评估指标，有效地解决了LLMs的幻觉问题，并提升了LLMs的诚实度和可靠性，显示出打造更值得信赖的AI系统的潜力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.18349v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.18349.md)  |
| <span style='display: inline-block; width: 42px;'>03-26</span> | **LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning**<br><sub>机构: The Hong Kong University of Science and Technology, University of Illinois Urbana-Champaign<br>这篇论文提出的LISA策略，通过分层权重重要性采样，实现了在保持类似于LoRA的内存效率的同时，提升了大型语言模型的微调效率和性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.17919v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.17919.md)  |
| <span style='display: inline-block; width: 42px;'>03-26</span> | **COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning**<br><sub>机构: Shenzhen Institute of Advanced Technology, CAS; M-A-P; Institute of Automation, CAS<br>本文提出了COIG-CQIA数据集，这是一个针对中文指令调优的高质量数据集，能够促进与人类交互的对齐。研究强调了高质量数据源在模型微调中的重要性，并通过实验展示了数据集创建策略和微调方法对模型性能的显著影响。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.18058v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.18058.md)  |
| <span style='display: inline-block; width: 42px;'>03-26</span> | **The Unreasonable Ineffectiveness of the Deeper Layers**<br><sub>机构: Meta FAIR, UMD<br>本论文针对流行的开权重预训练LLMs提出了一种简单的层剪枝策略，并展示了在删除大量层后LLMs对性能影响较小的实证研究。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.17887v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.17887.md)  |
| <span style='display: inline-block; width: 42px;'>03-25</span> | **AIOS: LLM Agent Operating System**<br><sub>机构: Rutgers University  <br>AIOS作为一个LLM代理操作系统，通过设计特定的内核和模块，克服了之前资源调度和上下文管理等领域的挑战，为LLM代理的性能和效率提供了改进，为AIOS生态系统的未来发展和部署铺平了道路。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.16971v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.16971.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/agiresearch/AIOS)</div> |
| <span style='display: inline-block; width: 42px;'>03-22</span> | **Can large language models explore in-context?**<br><sub>机构: Microsoft Research, Carnegie Mellon University<br>这篇论文调查了当代大型语言模型（LLMs）能否在上下文中从事探索的问题，特别是在没有训练干预的情况下。经过一系列实验，作者发现只有在特定的配置下LLMs才能稳健地进行探索。研究表明，没有适当的提示设计，即使是最先进的LLMs也可能无法在更复杂的环境中进行探索，而在这些环境中外部总结历史可能是一个非平凡的算法设计问题。这项工作提示了LLMs可能需要有针对性的算法干预才能在复杂环境中有效地工作。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.15371v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.15371.md)  |
| <span style='display: inline-block; width: 42px;'>03-20</span> | **Chain-of-Interaction: Enhancing Large Language Models for Psychiatric Behavior Understanding by Dyadic Contexts**<br><sub>机构: University of Memphis, San Francisco Veterans Affairs Health Care System, University of California San Francisco<br>本文通过引入互动链提示方法，有效地提升了大型语言模型在理解精神病行为方面的能力，特别是在动机面谈语境下的应用。通过结构化的提示和评估方法，能够模拟专业心理治疗人员的思维过程，对模型进行了有效的域知识教育，相比传统方法取得了更好的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.13786v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.13786.md)  |
| <span style='display: inline-block; width: 42px;'>03-19</span> | **Towards Robots That Know When They Need Help: Affordance-Based Uncertainty for Large Language Model Planners**<br><sub>机构: University of Maryland  <br>论文提出了一种新方法LAP，通过结合大型语言模型(LLMs)和场景可以供性来减少规划任务中的幻觉并实现不确定性对齐。通过在模拟和现实世界机器人操作任务的实验中表明，LAP可以显著提高成功率并减少对人类帮助的依赖，从而推动智能机器人领域的进步。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.13198v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.13198.md)  |
| <span style='display: inline-block; width: 42px;'>03-18</span> | **Decoding Compressed Trust: Scrutinizing the Trustworthiness of Efficient LLMs Under Compression**<br><sub>机构: University of Texas at Austin, Drexel University, MIT<br>本文首次对经过压缩的LLMs在多个信任维度上进行了全面评估，并提供了压缩时同时考虑效率和信任度的实用建议。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.15447v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.15447.md)  |
| <span style='display: inline-block; width: 42px;'>03-15</span> | **VideoAgent: Long-form Video Understanding with Large Language Model as Agent**<br><sub>机构: Stanford University<br>VideoAgent通过模仿人类的认知过程，在长视频理解方面迈出了重要的一步，强调了在长时间跨度内对视觉信息进行推理的重要性。此工作不仅为长视频理解设立了新的基准，也为未来该方向的研究提供了启示。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.10517v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.10517.md)  |
| <span style='display: inline-block; width: 42px;'>03-15</span> | **Uni-SMART: Universal Science Multimodal Analysis and Research Transformer**<br><sub>机构: DP Technology, AI for Science Institute Beijing<br>Uni-SMART 是一款创新的模型，旨在深入理解多模态科学文献，它在多个领域相对于其他顶尖文本焦点的 LLMs 显示出了更优越的性能，并有潜力改变我们与科学文献的互动方式。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.10301v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.10301.md)  |
| <span style='display: inline-block; width: 42px;'>03-15</span> | **RAFT: Adapting Language Model to Domain Specific RAG**<br><sub>机构: UC Berkeley<br>本论文提出的RAFT方法针对训练大型语言模型在特定领域内以“开卷”模式回答问题进行了创新，强化了模型的推理能力和对干扰文档的抵抗力，同时通过链式推理方式改进了模型生成解答的准确性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.10131v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.10131.md)  |
| <span style='display: inline-block; width: 42px;'>03-13</span> | **Steering LLMs Towards Unbiased Responses: A Causality-Guided Debiasing Framework**<br><sub>机构: ByteDance Research, University of Maryland College Park, Carnegie Mellon University<br>该论文成功提出了一个新的因果关系引导的去偏见框架，并通过实证研究验证了其有效性，既可以整合现有的基于提示的去偏见方法，也为诱导无偏见推理提出了新的途径。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.08743v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.08743.md)  |
| <span style='display: inline-block; width: 42px;'>03-13</span> | **Call Me When Necessary: LLMs can Efficiently and Faithfully Reason over Structured Environments**<br><sub>机构: Nanjing University, Microsoft<br>Readi框架提出了一种高效并真实地在大规模结构化环境中进行推理的方法，它充分发挥了LLMs的规划能力，并通过动态反馈优化推理路径，实现了在多跳推理任务中的显著改进。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.08593v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.08593.md)  |
| <span style='display: inline-block; width: 42px;'>03-13</span> | **Scaling Instructable Agents Across Many Simulated Worlds**<br><sub>此论文提出的SIMA项目旨在创建一个能够在各种模拟3D环境中根据任意语言指令进行操作的AI系统。该系统的设计致力于解决在感知和体化行动中具体化语言的挑战，以及在许多不同环境中实现通用性和可扩展性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.10179v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2404.10179.md)  |
| <span style='display: inline-block; width: 42px;'>03-12</span> | **Chronos: Learning the Language of Time Series**<br><sub>机构: Amazon Web Services, UC San Diego, University of Freiburg<br>Chronos作为一个预训练的时间序列预测模型框架，在零样本和标准预测任务中表现出色。它利用了数据增强策略和公共数据集的优势，证实了时间序列预测中语言模型架构通用性的潜力，为将来的时间序列模型提供了新的研究方向。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.07815v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.07815.md)  |
| <span style='display: inline-block; width: 42px;'>03-11</span> | **RA-ISF: Learning to Answer and Understand from Retrieval Augmentation via Iterative Self-Feedback**<br><sub>机构: Zhejiang University, Southeast University, Massachusetts Institute of Technology<br>RA-ISF是一个创新的检索增强框架，通过迭代问题分解和三个子模块的迭代处理来提高LLMs的问题解决能力，并有效降低不相关文本的干扰，显著提升知识检索的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.06840v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.0684.md)  |
| <span style='display: inline-block; width: 42px;'>03-11</span> | **ERA-CoT: Improving Chain-of-Thought through Entity Relationship Analysis**<br><sub>机构: Zhejiang University, Southeast University<br>该论文通过提出一种新的框架ERA-CoT，有效强化了大型语言模型在复杂实体场景中的推理和问题回答能力。该方法通过增强对实体关系的理解，实现了显著提升模型推理准确度，特别是在CoT推理过程中。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.06932v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.06932.md)  |
| <span style='display: inline-block; width: 42px;'>03-11</span> | **Stealing Part of a Production Language Model**<br><sub>机构: Google DeepMind, ETH Zurich, University of Washington<br>本文提出了一项对生产语言模型进行模型窃取的新攻击方法，该方法能够有效地提取Transformer模型的最后一层，并能用于解密黑盒模型的细节信息、参数和尺寸。文章还讨论了可能的防御措施，并指出了修改API以防止未来此类攻击的必要性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.06634v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.06634.md)  |
| <span style='display: inline-block; width: 42px;'>03-08</span> | **Overcoming Reward Overoptimization via Adversarial Policy Optimization with Lightweight Uncertainty Estimation**<br><sub>这篇论文介绍了Adversarial Policy Optimization (AdvPO)，它是解决基于人类反馈的强化学习过程中出现的奖励过优化问题的新方法，特别是在与人类偏好对齐的大型语言模型中。AdvPO有效地在没有带来高额计算成本的情况下缓解了奖励过优化。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.05171v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.05171.md)  |
| <span style='display: inline-block; width: 42px;'>03-08</span> | **Harnessing Multi-Role Capabilities of Large Language Models for Open-Domain Question Answering**<br><sub>机构: Gaoling School of Artificial Intelligence Renmin University of China, Nankai University, Beijing Academy of Artificial Intelligence<br>LLMQA是一个新的通用框架模型，通过结合检索和生成范式搜集更高质量的证据，并让LLMs在框架中发挥多重角色，提高了开放域问答系统的整体性能，实验结果也证明了其超越现有方法的有效性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.05217v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.05217.md)  |
| <span style='display: inline-block; width: 42px;'>03-08</span> | **Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context**<br><sub>机构: Google<br>Gemini 1.5 Pro在记忆与推理海量长上下文信息的能力上取得了显著突破，尤其是在超长文本、视频和音频处理方面。该模型不仅在效果上优于现有模型，也在计算效率上有显著提高。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.05530v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.0553.md)  |
| <span style='display: inline-block; width: 42px;'>03-07</span> | **Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference**<br><sub>机构: UC Berkeley, Stanford, UCSD<br>Chatbot Arena是一个基于用户偏好，用于评估大型语言模型的开放平台。它通过众包方式收集用户问题并进行匿名化的随机化对决，用于评估LLMs的表现，解决了现有静态数据集基准测试的局限性，并通过精心设计的统计方法确保了评估结果的可信度和效率。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.04132v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.04132.md)  |
| <span style='display: inline-block; width: 42px;'>03-07</span> | **Yi: Open Foundation Models by 01.AI**<br><sub>机构: 01.AI<br>该论文成功地提出了一个在性能和效率上都可与GPT-3.5相媲美的Yi-34B模型，并详细描述了在大型语言模型预训练及其指令微调方面的创新方法。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.04652v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.04652.md)  |
| <span style='display: inline-block; width: 42px;'>03-05</span> | **ChatCite: LLM Agent with Human Workflow Guidance for Comparative Literature Summary**<br><sub>机构: Tsinghua University<br>ChatCite系统是为了克服LLM在生成文献回顾时的挑战而设计的，它通过特定的模块使LLM代理可以更有效地理解、汇总和对比不同的研究工作，进而生成有组织、有比较性分析的文献回顾。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.02574v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.02574.md)  |
| <span style='display: inline-block; width: 42px;'>03-05</span> | **MathScale: Scaling Instruction Tuning for Mathematical Reasoning**<br><sub>机构: The Chinese University of Hong Kong Shenzhen, China; Microsoft Research Asia, Beijing, China; Shenzhen Research Institute of Big Data, Shenzhen, China<br>MathScale提出了一个可扩展的方法来创建高质量的数学推理数据，通过构建新的评估基准MWPBENCH全面地评价LLMs在数学推理上的能力，显著提升了模型解决数学问题的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.02884v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.02884.md)  |
| <span style='display: inline-block; width: 42px;'>03-05</span> | **Design2Code: How Far Are We From Automating Front-End Engineering?**<br><sub>机构: Stanford University, Georgia Tech, Microsoft<br>本文通过对Design2Code任务的形式化和基准测试，评估了当前多模态LLMs在将视觉设计转换为代码的能力，并发现GPT-4V表现最佳，为自动化前端开发提供了一种新的范式。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.03163v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.03163.md)  |

---

### 02月

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>02-29</span> | **SEED: Customize Large Language Models with Sample-Efficient Adaptation for Code Generation**<br><sub>机构: Peking University<br>本文提出了一个名为SEED的适应方法，它利用错误驱动学习来使LLMs更少样本地高效学习，针对代码生成任务实现了更佳的性能和泛化性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.00046v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2403.00046.md)  |
| <span style='display: inline-block; width: 42px;'>02-29</span> | **Beyond Language Models: Byte Models are Digital World Simulators**<br><sub>机构: Microsoft Research Asia<br>论文展现了bGPT在处理挑战性的字节级数据模拟任务中的潜力，特别强调了其在跨模态知识转移和数字世界模拟方面的能力。这揭示了字节模型在数字媒体数据处理和理解上的广泛适用性和灵活性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.19155v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.19155.md)  |
| <span style='display: inline-block; width: 42px;'>02-29</span> | **StarCoder 2 and The Stack v2: The Next Generation**<br><sub>机构: ServiceNow, Hugging Face  <br>本论文提出了The Stack v2和StarCoder2的发展过程，这是基于代码大规模预训练和指令微调的一项工作。研究人员通过整合多样化数据源和经过精心设计的训练过程，显著提高了代码LLMs的性能，特别是在处理低资源编程语言和需要代码推理的任务上。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.19173v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.19173.md)  |
| <span style='display: inline-block; width: 42px;'>02-29</span> | **Resonance RoPE: Improving Context Length Generalization of Large Language Models**<br><sub>机构: 1DIRO Université de Montréal, Mila - Quebec AI Institute, Huawei Noah’s Ark Lab<br>本论文提出了 Resonance Rope，这是一个改进的模型，它基于对 RoPE 位置嵌入特征波长的分析来提升模型在处理长文本时的性能。它还引入了 POSGEN 基准测试，以帮助研究和评估位置嵌入在长文本任务中的表现。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.00071v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2403.00071.md)  |
| <span style='display: inline-block; width: 42px;'>02-27</span> | **The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits**<br><sub>机构: Microsoft, University of Chinese Academy of Sciences<br>论文提出BitNet b1.58模型，这是一个1.58比特量化的大型语言模型，与传统的完整精度LLMs在性能上可比，而且更高效、更节省能源。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.17764v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.17764.md)  |
| <span style='display: inline-block; width: 42px;'>02-27</span> | **EMO: Emote Portrait Alive -- Generating Expressive Portrait Videos with Audio2Video Diffusion Model under Weak Conditions**<br><sub>机构: Alibaba Group  <br>EMO 框架通过直接的音频到视频合成方法提高了生成视频的真实感和表现力，显著优于现有技术，为视频合成领域提供了一个重要的进步。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.17485v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.17485.md)  |
| <span style='display: inline-block; width: 42px;'>02-27</span> | **When Scaling Meets LLM Finetuning: The Effect of Data, Model and Finetuning Method**<br><sub>机构: Google DeepMind<br>该论文提供了大型语言模型微调阶段不同因素如数据大小、模型大小以及微调方法对模型性能影响的深入洞见，定义了一种新的评估框架。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.17193v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.17193.md)  |
| <span style='display: inline-block; width: 42px;'>02-27</span> | **REAR: A Relevance-Aware Retrieval-Augmented Framework for Open-Domain Question Answering**<br><sub>机构: Gaoling School of Artificial Intelligence Renmin University of China, School of Information Renmin University of China<br>该论文提出了REAR框架，重点在于通过为LLMs加入文档相关性自我意识来增强其在QA任务中利用外部知识的能力，并证实该框架有效地超越了前述方法。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.17497v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.17497.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/RUCAIBox/REAR)</div> |
| <span style='display: inline-block; width: 42px;'>02-27</span> | **Agent-Pro: Learning to Evolve via Policy-Level Reflection and Optimization**<br><sub>机构: Zhejiang University, Institute of Software Chinese Academy of Sciences, Nanjing University of Posts and Telecommunications<br>Agent-Pro是一个新型的基于LLM的智能代理，能够通过政策级反思和优化在交互环境中学习和发展策略，解决了现有工作无法通过交互学习和适应的问题。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.17574v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.17574.md)  |
| <span style='display: inline-block; width: 42px;'>02-27</span> | **Sora: A Review on Background, Technology, Limitations, and Opportunities of Large Vision Models**<br><sub>机构: OpenAI<br>本文是一篇对Sora——一个大型视觉模型的综述。论文讨论了Sora的技术特征、创新点、以及当前应用领域的局限性和未来可能的发展机会。Sora的能力在多个维度上展现了大型视觉模型的进步，包括长视频生成和多样化视频格式的处理。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.17177v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.17177.md)  |
| <span style='display: inline-block; width: 42px;'>02-26</span> | **LLMArena: Assessing Capabilities of Large Language Models in Dynamic Multi-Agent Environments**<br><sub>研究介绍了LLMARENA基准，用以评估LLMs智能体在复杂多代理环境中的能力，指出了存在的问题并促进了未来的研究方向，包括多模态动态环境中的能力及利用外部工具的潜力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.16499v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.16499.md)  |
| <span style='display: inline-block; width: 42px;'>02-26</span> | **Improving LLM-based Machine Translation with Systematic Self-Correction**<br><sub>机构: Zhejiang University, Tencent, Angelalign Technology Inc.<br>论文成功提出了第一个基于LLMs的自我纠正翻译框架TER，并验证了其在多种语言对和不同模型间的翻译质量改进效果。它为机器翻译领域带来了新的视角，特别是在自我纠正在高资源、低资源语言和不同中心语言之间翻译的应用。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.16379v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.16379.md)  |
| <span style='display: inline-block; width: 42px;'>02-26</span> | **Do Large Language Models Latently Perform Multi-Hop Reasoning?**<br><sub>机构: Google DeepMind, UCL, Google Research<br>本文对LLMs是否能够进行潜在的多跳推理进行了研究，并通过实验提出了评估LLMs潜在多跳推理能力的新方法。研究提示LLMs对某些关系类型的提示有很强的多跳推理证据，但这种推理路径的运用在不同类型的提示中表现出高度的情境依赖性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.16837v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.16837.md)  |
| <span style='display: inline-block; width: 42px;'>02-25</span> | **ChatMusician: Understanding and Generating Music Intrinsically with LLM**<br><sub>机构: Hong Kong University of Science and Technology<br>本文通过创造首个针对语言模型的音乐预训练数据集和评估基准，提升了LLMs在音乐理解和生成方面的表现，并在这一未被深入研究的领域取得了实质性进展。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.16153v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.16153.md)  |
| <span style='display: inline-block; width: 42px;'>02-23</span> | **Genie: Generative Interactive Environments**<br><sub>机构: Google DeepMind, University of British Columbia<br>Genie是能够生成新视频并能通过用户输入控制视频内容的交互环境模型，弥补了传统视频生成技术与交互体验之间的差距。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.15391v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.15391.md)  |
| <span style='display: inline-block; width: 42px;'>02-23</span> | **ChunkAttention: Efficient Self-Attention with Prefix-Aware KV Cache and Two-Phase Partition**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.15220v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.1522.md)  |
| <span style='display: inline-block; width: 42px;'>02-22</span> | **Middleware for LLMs: Tools Are Instrumental for Language Agents in Complex Environments**<br><sub>通过为LLMs设计特定的工具和推理算法，研究开发了名为FUXI的新框架，有效提高了LLMs在复杂环境中的操作能</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.14672v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.14672.md)  |
| <span style='display: inline-block; width: 42px;'>02-22</span> | **CriticBench: Benchmarking LLMs for Critique-Correct Reasoning**<br><sub>机构: Tsinghua University, University of Hong Kong<br>该论文通过CRITICBENCH评估了LLMs的批判和纠正推理能力，并探究了影响这些能力的关键因子，旨在促进LLMs批判和自我改进能力的后续研究。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.14809v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.14809.md)  |
| <span style='display: inline-block; width: 42px;'>02-22</span> | **OpenCodeInterpreter: Integrating Code Generation with Execution and Refinement**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.14658v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.14658.md)  |
| <span style='display: inline-block; width: 42px;'>02-21</span> | **AgentScope: A Flexible yet Robust Multi-Agent Platform**<br><sub>机构: Alibaba Group<br>AgentScope是一个用于构建多代理应用的多功能平台，强调易用性与可定制性，特别适合不同技能水平的开发者使用。通过实现容错和支持多模态数据处理，以及优化分布式操作，AgentScope显著降低了多代理系统开发与部署的难度，鼓励更广泛的参与和创新。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.14034v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.14034.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/modelscope/agentscope)</div> |
| <span style='display: inline-block; width: 42px;'>02-21</span> | **User-LLM: Efficient LLM Contextualization with User Embeddings**<br><sub>USER-LLM是一个通过用户嵌入来上下文化LLM的框架。它能有效地解决用户数据的复杂性和长序列处理的问题，提升了LLM在个性化应用上的效能，同时也保证了计算效率。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.13598v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.13598.md)  |
| <span style='display: inline-block; width: 42px;'>02-20</span> | **Instruction-tuned Language Models are Better Knowledge Learners**<br><sub>机构: FAIR at Meta, Carnegie Mellon University, University of Washington<br>本文介绍了一种名为预指令微调（PIT）的方法，有效地提高了LLMs从文档中吸收知识的能力，解决了所谓的困惑度诅咒问题，并且在多域的知识获取中也取得了显著进展。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.12847v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.12847.md)  |
| <span style='display: inline-block; width: 42px;'>02-20</span> | **TofuEval: Evaluating Hallucinations of LLMs on Topic-Focused Dialogue Summarization**<br><sub>机构: AWS AI Labs, The University of Texas at Austin, KAIST<br>本论文提出了一个名为TOFUEVAL的新型评估基准，针对LLM在生成话题焦点对话摘要时的事实一致性进行了评估。研究发现，不同大小的LLM在对话领域生成的摘要中存在大量事实错误。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.13249v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.13249.md)  |
| <span style='display: inline-block; width: 42px;'>02-19</span> | **AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling**<br><sub>机构: Fudan University, Multimodal Art Projection Research Community, Shanghai AI Laboratory<br>AnyGPT 是一个多模态架构的语言模型，通过离散序列建模，能够实现不同模态间的无缝转换和统一处理，提供任意到任意模态之间的生成能力，同时不需要改变现有的 LLM 架构或训练范式。该模型通过在语义和感知水平进行建模，能有效处理和生成高质量的多模态内容，并且与专业模型相比具有可比较的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.12226v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.12226.md)  |
| <span style='display: inline-block; width: 42px;'>02-16</span> | **Speculative Streaming: Fast LLM Inference without Auxiliary Models**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.11131v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.11131.md)  |
| <span style='display: inline-block; width: 42px;'>02-16</span> | **FinTral: A Family of GPT-4 Level Multimodal Financial Large Language Models**<br><sub>机构: The University of British Columbia & Invertible AI<br>该论文提出了一个针对财务分析优化的多模态大型语言模型（LLM）套件FinTral。通过与现有模型的对比，展示了其在财务领域多任务环境下的先进性能，特别是在处理零样本任务和减少幻觉现象方面的能力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.10986v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.10986.md)  |
| <span style='display: inline-block; width: 42px;'>02-16</span> | **SPAR: Personalized Content-Based Recommendation via Long Engagement Attention**<br><sub>机构: The University of British Columbia, Meta<br>SPAR框架充分利用长期用户互动历史来提升个性化内容推荐的精度，并在多项性能指标上超越现有技术。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.10555v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.10555.md)  |
| <span style='display: inline-block; width: 42px;'>02-15</span> | **A Human-Inspired Reading Agent with Gist Memory of Very Long Contexts**<br><sub>机构: Google DeepMind, Google Research<br>ReadAgent 是一个受人类阅读方式启发的LLM代理系统，通过创建摘要记忆并根据需要检索信息来解决长文本任务，显著提高了模型的表现和伸缩性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.09727v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.09727.md)  |
| <span style='display: inline-block; width: 42px;'>02-15</span> | **How to Train Data-Efficient LLMs**<br><sub>机构: Google DeepMind, University of California San Diego, Texas A&M University<br>论文提出的ASK-LLM和DENSITY技术优化了大型语言模型的数据效率，有效提升了模型训练的速度和质量，并在资源限制下表现出色。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.09668v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.09668.md)  |
| <span style='display: inline-block; width: 42px;'>02-15</span> | **Chain-of-Thought Reasoning Without Prompting**<br><sub>机构: Google DeepMind<br>这项工作揭示了通过改变解码策略，可以有效地从预训练的LLMs中自然地引发推理，并且在预训练数据中频繁出现的任务上CoT路径更常见。提出的CoT解码方法无需手动引导，就能显著提高各种推理基准上的模型性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.10200v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.102.md)  |
| <span style='display: inline-block; width: 42px;'>02-14</span> | **Premise Order Matters in Reasoning with Large Language Models**<br><sub>机构: Google DeepMind<br>这篇论文关注于大型语言模型在处理推理任务时，前提顺序的影响，并通过创建R-GSM基准测试来评估这一现象。研究揭示了LLMs对前提顺序极为敏感，性能受顺序影响显著。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.08939v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.08939.md)  |
| <span style='display: inline-block; width: 42px;'>02-09</span> | **InternLM-Math: Open Math Large Language Models Toward Verifiable Reasoning**<br><sub>机构: Shanghai AI Laboratory, Tsinghua University, Fudan University School of Computer Science<br>InternLM-Math模型是一种基于LLMs的数学推理工具，它整合了多种能力并提供了监督学习以帮助模型在各种数学推理任务中实现最先进的性能，并开源其代码和数据。论文还探讨了利用程序语言LEAN在多任务学习设置中解决数学问题的新方法，彰显了LLMs在形式化和代码辅助推理中的潜能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.06332v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.06332.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/InternLM/InternLM-Math)</div> |
| <span style='display: inline-block; width: 42px;'>02-02</span> | **LimSim++: A Closed-Loop Platform for Deploying Multimodal LLMs in Autonomous Driving**<br><sub>机构: Shanghai Artificial Intelligence Laboratory, College of Control Science and Engineering Zhejiang University<br>LimSim++是首个专为(M)LLM支持的自动驾驶而开发的封闭循环评估平台。它解决了现有仿真平台的局限性，并通过实验验证了其在多种复杂交通场景中的有效性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.01246v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.01246.md)  |
| <span style='display: inline-block; width: 42px;'>02-02</span> | **Reasoning Capacity in Multi-Agent Systems: Limitations, Challenges and Human-Centered Solutions**<br><sub>机构: Megagon Labs, Carnegie Mellon University<br>本论文提出了多代理系统中的“推理能力”概念，以改善优化和评估，并探讨了利用人类反馈增强系统推理能力的可能性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.01108v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.01108.md)  |
| <span style='display: inline-block; width: 42px;'>02-02</span> | **AMOR: A Recipe for Building Adaptable Modular Knowledge Agents Through Process Feedback**<br><sub>机构: Tsinghua University, Ant Group<br>AMOR框架综合了基于有限状态机（FSM）的推理逻辑和过程反馈机制，展示了基于开源LLM的知识代理如何通过人类监督实现推理和适应性，提高了模型在完成知识密集任务中的能力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.01469v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.01469.md)  |
| <span style='display: inline-block; width: 42px;'>02-02</span> | **K-Level Reasoning with Large Language Models**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.01521v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.01521.md)  |
| <span style='display: inline-block; width: 42px;'>02-02</span> | **MAGDi: Structured Distillation of Multi-Agent Interaction Graphs Improves Reasoning in Smaller Language Models**<br><sub>机构: UNC Chapel Hill.<br>本论文介绍了名为MAGDI的新方法，它通过结构化蒸馏方式将多LLM之间的推理交互蒸馏到更小的模型中，显著提升小模型的推理能力和泛化能力，同时降低了成本。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.01620v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.0162.md)  |
| <span style='display: inline-block; width: 42px;'>02-01</span> | **Don't Hallucinate, Abstain: Identifying LLM Knowledge Gaps via Multi-LLM Collaboration**<br><sub>机构: University of Washington, University of California Berkeley, The Hong Kong University of Science and Technology<br>本文关注的是如何在大型语言模型(LLMs)中识别知识差距并在必要时放弃回答问题。研究提出了两种基于多LLM合作的新方法，通过对比实验显示它们能有效提高LLMs放弃生成低信心输出的能力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.00367v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.00367.md)  |
| <span style='display: inline-block; width: 42px;'>02-01</span> | **HR-MultiWOZ: A Task Oriented Dialogue (TOD) Dataset for HR LLM Agent**<br><sub>机构: Amazon, University of Milano-Bicocca<br>本文介绍了一个新的针对人力资源领域的大语言模型代理（HR LLM Agent）任务的对话数据集，HR-MultiWOZ。它不仅解决了当前在构建和评估HR领域LLM代理时缺乏高质量训练数据集的问题，还提供了一个经济高效的数据集生成方法，为同领域中的其他研究提供了宝贵的资源和参考。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.01018v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.01018.md)  |
| <span style='display: inline-block; width: 42px;'>02-01</span> | **Learning Planning-based Reasoning by Trajectories Collection and Process Reward Synthesizing**<br><sub>机构: Nanyang Technological University, Institute for Infocomm Research A*STAR, Salesforce Research<br>文章提出了一个新颖的离线训练框架，专注于改进大型语言模型在处理复杂推理任务时的可靠性和精确性，通过收集轨迹和基于结果监督的直接偏好优化，无需教师模型或人类标注。在两个逻辑推理基准测试上的结果证明了该方法的有效性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.00658v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.00658.md)  |
| <span style='display: inline-block; width: 42px;'>02-01</span> | **Can Large Language Models Understand Context?**<br><sub>机构: Georgetown University, Apple<br>本文提出了一个上下文理解基准，用以评估大型语言模型（LLMs）的上下文理解能力。该基准涵盖了对文档和对话基础上下文理解的要素，通过创新的测试方法和实验分析展示了LLMs在上下文理解方面的能力和局限性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.00858v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.00858.md)  |

---

### 01月

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>01-31</span> | **LongAlign: A Recipe for Long Context Alignment of Large Language Models**<br><sub>机构: Tsinghua University, Zhipu.AI<br>论文提出了一种新的长上下文对齐配方LongAlign，通过构建长指令数据集、采用新的训练策略并引入评估基准来提高LLMs处理长上下文的能力，且代码、数据和长对齐的模型已开源。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.18058v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.18058.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/THUDM/LongAlign)</div> |
| <span style='display: inline-block; width: 42px;'>01-30</span> | **Incoherent Probability Judgments in Large Language Models**<br><sub>机构: Princeton University<br>这篇论文探讨了大型语言模型在形成概率判断方面的连贯性问题，并发现这些模型在该领域表现出的偏差与人类认知中的系统性偏差相似。通过应用概率恒等式和重复判断的方法，研究人员量化了这些判断的不连贯性。研究还提出了一个假设，即LLMs在做出概率判断时的人类样偏差可能源自它们采用的自回归训练目标，这一假设得到了以贝叶斯取样器模型和LLMs中的自回归过程之间潜在联系为基础的支持。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.16646v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.16646.md)  |
| <span style='display: inline-block; width: 42px;'>01-30</span> | **Recovering Mental Representations from Large Language Models with Markov Chain Monte Carlo**<br><sub>机构: Princeton University, University of Warwick<br>本文通过将 LLMs 整合到采样算法中，并运用直接采样与 MCMC 的方式提取心理表征，有效提升了效率和性能，并探索了用 LLM 进行贝叶斯推断的潜力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.16657v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.16657.md)  |
| <span style='display: inline-block; width: 42px;'>01-30</span> | **Can Large Language Models be Trusted for Evaluation? Scalable Meta-Evaluation of LLMs as Evaluators via Agent Debate**<br><sub>机构: Shanghai Jiao Tong University, Carnegie Mellon University, Shanghai Artificial Intelligence Laboratory<br>SCALEEVAL 是一种新型的元评估框架，用于评估LLMs作为评估者的可靠性和效率。通过利用LLM代理间的辩论和最小化的人类监督，该框架在评估中引入灵活性和可扩展性，并在实验中显示出与纯人工评估高度一致的结果。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.16788v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.16788.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/GAIR-NLP/scaleeval)</div> |
| <span style='display: inline-block; width: 42px;'>01-30</span> | **Efficient Tool Use with Chain-of-Abstraction Reasoning**<br><sub>机构: Meta<br>本文提出了一种新的链式抽象推理方法，有效地提升了LLMs使用外部工具的能力，并加速了推理过程。实验结果证明了其在多步骤推理任务上的有效性和高效性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.17464v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.17464.md)  |
| <span style='display: inline-block; width: 42px;'>01-29</span> | **SelectLLM: Can LLMs Select Important Instructions to Annotate?**<br><sub>机构: University of Minnesota, Carnegie Mellon University<br>这项工作提出了一个利用LLMs选择未标记的高质量指令的新方法SELECTLLM，通过挑战传统的选择算法并在保持数据集的全局结构的同时提升选择效果。实验结果显示了其在指令调整基准测试上的优越性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.16553v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.16553.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/minnesotanlp/select-llm)</div> |
| <span style='display: inline-block; width: 42px;'>01-29</span> | **Beyond Direct Diagnosis: LLM-based Multi-Specialist Agent Consultation for Automatic Diagnosis**<br><sub>机构: Harbin Institute of Technology<br>本研究提出了一个基于LLM的自动诊断方法——多专家智能代理咨询模型（AMSC），它能更好地模拟现实世界中的诊断流程，并通过集成多个专家代理的预测来提升诊断的准确性和效率。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.16107v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.16107.md)  |
| <span style='display: inline-block; width: 42px;'>01-29</span> | **LLM4Vuln: A Unified Evaluation Framework for Decoupling and Enhancing LLMs' Vulnerability Reasoning**<br><sub>机构: Nanyang Technological University<br>LLM4Vuln是一个创新的框架，它通过提供漏洞知识的向量数据库、调用工具的功能、定制的CoT提示方案以及使用精通指令的模型来结构化输出，显著提高了LLMs在代码漏洞分析中的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.16185v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.16185.md)  |
| <span style='display: inline-block; width: 42px;'>01-28</span> | **PRE: A Peer Review Based Large Language Model Evaluator**<br><sub>这篇论文提出的PRE模型通过模拟学术界的同行评审机制，提供了一种全新的自动评估LLM的框架，它显著降低了成本，并且具有更高的通用性和可靠性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.15641v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.15641.md)  |
| <span style='display: inline-block; width: 42px;'>01-27</span> | **MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries**<br><sub>机构: Hong Kong University of Science and Technology<br>这篇论文开发了MultiHop-RAG数据集，以评估和改善现存的检索增强生成（RAG）系统在处理需要多步检索和推理的查询上的不足。研究还提供了一系列实验结果，揭示了目前RAG系统在此类任务上的局限性，并公开了数据集推动进一步的研究和开发。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.15391v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.15391.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/yixuantt/MultiHop-RAG)</div> |
| <span style='display: inline-block; width: 42px;'>01-26</span> | **EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty**<br><sub>机构: Peking University, Microsoft Research, University of Waterloo<br>文章提出了一个名为EAGLE的新框架，以提高大型语言模型（LLMs）自回归解码的速度，同时保证生成文本与原始LLMs的文本分布一致。EAGLE通过改进推测性采样方法，在减少时间开销和提高草稿的接受率方面取得了显著成效，对比Lookahead和Medusa实现了更快的加速效果，并且训练成本低，易于部署。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.15077v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.15077.md)  |
| <span style='display: inline-block; width: 42px;'>01-25</span> | **Towards Consistent Natural-Language Explanations via Explanation-Consistency Finetuning**<br><sub>机构: Columbia University, Microsoft Research, University of California Berkeley<br>EC-Finetuning方法成功地提高了LLMs生成解释的一致性，并且可以推广到未见过的数据集，表现出微调数据集上10.0%和分布外数据集上4.5%的解释一致性相对改善，同时也适度提升了预测准确度。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.13986v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.13986.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/yandachen/explanation-consistency-finetuning)</div> |
| <span style='display: inline-block; width: 42px;'>01-25</span> | **ConstraintChecker: A Plugin for Large Language Models to Reason on Commonsense Knowledge Bases**<br><sub>机构: HKUST<br>ConstraintChecker是一个能有效提升LLMs在CSKB推理任务中性能的独立插件工具。通过提供和检查显式约束的方式，它能够帮助LLMs在推理中取得更好的表现，且在经过验证后的指标上超过了其他的提示技术。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.14003v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.14003.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/HKUST-KnowComp/ConstraintChecker)</div> |
| <span style='display: inline-block; width: 42px;'>01-25</span> | **True Knowledge Comes from Practice: Aligning LLMs with Embodied Environments via Reinforcement Learning**<br><sub>机构: Nanyang Technological University, Zhejiang University<br>TWOSOME框架通过强化学习来有效地将大型语言模型（LLMs）与体现环境对齐，提高了样本效率和任务泛化能力，同时保留了LLMs的原始功能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.14151v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.14151.md)  |
| <span style='display: inline-block; width: 42px;'>01-24</span> | **AgentBoard: An Analytical Evaluation Board of Multi-turn LLM Agents**<br><sub>机构: The University of Hong Kong, Zhejiang University, Shanghai Jiao Tong University<br>研究人员提出了一个新的基准测试 AGENTBOARD，专门评估具有多轮交互能力的大语言模型代理，它提供了细粒度的进展率和交互式分析工具，以增进对 LLM 代理性能的深入理解。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.13178v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.13178.md)  |
| <span style='display: inline-block; width: 42px;'>01-24</span> | **Can AI Assistants Know What They Don't Know?**<br><sub>机构: Fudan University, Shanghai Artificial Intelligence Laboratory<br>这篇论文重点探究了AI助手识别自己知识边界的能力，并通过构建Idk数据集并对助手调整，实现了让AI助手识别并承认不知道的问题，以减少回答中的事实错误。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.13275v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.13275.md)  |
| <span style='display: inline-block; width: 42px;'>01-24</span> | **MM-LLMs: Recent Advances in MultiModal Large Language Models**<br><sub>机构: Tencent AI Lab, Kyoto University, Mohamed Bin Zayed University of Artificial Intelligence<br>本文是一项关于MM-LLMs的综合性调研，旨在进一步推动MM-LLMs领域的研究工作。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.13601v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.13601.md)  |
| <span style='display: inline-block; width: 42px;'>01-24</span> | **Consistency Guided Knowledge Retrieval and Denoising in LLMs for Zero-shot Document-level Relation Triplet Extraction**<br><sub>机构: Nanjing University of Science and Technology, Northeastern University, Singapore Institute of Technology<br>论文提出了一个新的Zero-shot Document-level Relation Triplet Extraction (ZeroDocRTE)框架，该框架通过从LLMs中检索和去噪知识生成带标签的数据，并通过一系列新方法显著提高了文档级关系三元组抽取的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.13598v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.13598.md)  |
| <span style='display: inline-block; width: 42px;'>01-24</span> | **Clue-Guided Path Exploration: An Efficient Knowledge Base Question-Answering Framework with Low Computational Resource Consumption**<br><sub>机构: Tsinghua University, Zhongguancun Laboratory, XinJiang University<br>论文提出的CGPE框架能有效支持LLMs在问答任务中的应用，通过线索引导的路径探索机制，降低了对LLMs能力的要求，并显著减少了计算资源消耗，对计算资源有限的个人和组织具有重要实际意义。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.13444v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.13444.md)  |
| <span style='display: inline-block; width: 42px;'>01-23</span> | **Large Language Models are Superpositions of All Characters: Attaining Arbitrary Role-play via Self-Alignment**<br><sub>机构: Alibaba Inc.<br>论文提出了一种名为DITTO的自对齐方法，能够通过知识增强和对话模拟增强LLMs的角色扮演能力。此外，它提供了一种客观、可复制、可解释且高效的角色扮演评估方法，并通过跨监督的实验了解角色扮演的分解，为LLMs构建角色扮演功能提供了深入的理解和见解。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.12474v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.12474.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/OFA-Sys/Ditto)</div> |
| <span style='display: inline-block; width: 42px;'>01-23</span> | **KAM-CoT: Knowledge Augmented Multimodal Chain-of-Thoughts Reasoning**<br><sub>机构: Samsung R&D Institute India - Bangalore<br>KAM-CoT是一个多模态CoT推理框架，整合了CoT推理、知识图谱和多种模态。它在具有较少可训练参数的情况下优于现有的最先进方法，展现出卓越的性能和成本效率。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.12863v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.12863.md)  |
| <span style='display: inline-block; width: 42px;'>01-23</span> | **CCA: Collaborative Competitive Agents for Image Editing**<br><sub>该论文提出了一种基于多个大语言模型(LLMs)的新型生成模型CCA，能够处理复杂的图像编辑任务并提升结果的质量和鲁棒性。通过鼓励代理的协作竞争，模型展示出优于传统方法的能力，尤其在管理复杂任务和从中间步骤中学习以改进结果方面。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.13011v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.13011.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/TiankaiHang/CCA)</div> |
| <span style='display: inline-block; width: 42px;'>01-23</span> | **AutoRT: Embodied Foundation Models for Large Scale Orchestration of Robotic Agents**<br><sub>机构: Google DeepMind<br>本论文描述了一个名为AutoRT的系统，它利用大型基础模型控制真实世界中的机器人，使它们能够自动导航并执行任务。这标志着第一次实现LLM控制的机器人在真实环境中进行自动操作、提出目标并实现这些目标。通过AutoRT收集到的数据不仅多样化且能够提高机器人学习模型的性能，并且可以与人类偏好保持一致。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.12963v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.12963.md)  |
| <span style='display: inline-block; width: 42px;'>01-22</span> | **Improving Small Language Models' Mathematical Reasoning via Mix Thoughts Distillation**<br><sub>机构: Institute of Information Engineering, Chinese Academy of Sciences<br>这篇论文通过介绍EoTD和MTD，表明了可以将LLMs的数学推理能力转化给参数数量少于一十亿个的SLMs。通过实验验证了这些方法不仅保留了SLMs的推理能力，还在一定程度上提升了该能力，使SLMs在推理任务上达到了最好水平。这一进展对于在资源受限的环境中推广SLMs的应用打开了大门，并缩小了对强大推理模型需求与计算资源限制之间的差距。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.11864v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.11864.md)  |
| <span style='display: inline-block; width: 42px;'>01-22</span> | **PsySafe: A Comprehensive Framework for Psychological-based Attack, Defense, and Evaluation of Multi-agent System Safety**<br><sub>机构: Shanghai Artificial Intelligence Laboratory, Dalian University of Technology<br>本文提出了一个针对多智能体系统安全性的综合性框架PsySafe，该框架结合了心理层面的攻击、防御与评估方法。研究的实验结果有助于更深入地理解和研究多智能体系统的安全问题。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.11880v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.1188.md)  |
| <span style='display: inline-block; width: 42px;'>01-22</span> | **CheXagent: Towards a Foundation Model for Chest X-Ray Interpretation**<br><sub>机构: Stanford University, Stability AI  <br>本论文致力于解决在自动化胸部X光解释方面存在的挑战，通过引入专为CXR解释设计的大型数据集、开发了新的基础模型以及创建了一个全面的评估基准，实现了在医学成像领域的应用，并证明了在多项评估任务中CheXagent的性能优于其他模型。同时也对模型中可能存在的偏差进行了检查，为未来的研究和应用提供了重要参考。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.12208v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.12208.md)  |
| <span style='display: inline-block; width: 42px;'>01-21</span> | **Interactive AI with Retrieval-Augmented Generation for Next Generation Networking**<br><sub>机构: Nanyang Technological University, Guangdong University of Technology, Institute for Infocomm Research, Agency for Science Technology and Research<br>本文研究了将交互式AI (IAI) 集成到下一代网络中的可能性，采用了检索增强型生成（RAG）和大型语言模型（LLM）来提升决策能力，并通过真实网络优化的案例研究证明了提出框架的有效性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.11391v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.11391.md)  |
| <span style='display: inline-block; width: 42px;'>01-20</span> | **BadChain: Backdoor Chain-of-Thought Prompting for Large Language Models**<br><sub>机构: University of Illinois Urbana-Champaign, University of Washington, Western Washington University<br>本文提出了BadChain，这是一种针对采用COT提示的LLMs的后门攻击，不仅不需要访问训练数据集或模型参数，而且计算开销低。该方法有效地揭示了COT提示下LLMs的安全漏洞，强调了进行后门攻击和设计有效防御的重要性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.12242v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.12242.md)  |
| <span style='display: inline-block; width: 42px;'>01-19</span> | **Pruning for Protection: Increasing Jailbreak Resistance in Aligned LLMs Without Fine-Tuning**<br><sub>机构: MIT<br>论文展示了通过Wanda剪枝方法，无需微调而提升LLMs从对齐安全性方面抵御“越狱”攻击的能力，并通过构建特定的数据集和评估体系验证模型表现。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.10862v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.10862.md)  |
| <span style='display: inline-block; width: 42px;'>01-19</span> | **Tool-LMM: A Large Multi-Modal Model for Tool Agent Learning**<br><sub>机构: ShanghaiTech University, Meituan, UniDT<br>Tool-LMM为首个致力于训练大型多模态模型以学习工具代理的系统，创新地整合了多模态输入与外部工具的正确选择，克服了文本模糊带来的问题，展现了在多模态指令下自动选择合适工具的能力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.10727v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.10727.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/Tool-LMM/Tool-LMM)</div> |
| <span style='display: inline-block; width: 42px;'>01-19</span> | **Mitigating Hallucinations of Large Language Models via Knowledge Consistent Alignment**<br><sub>机构: Sun Yat-sen University, Tencent AI Lab<br>这篇论文引入了一种新颖的KCA方法，通过减少外部知识和内在知识之间的不一致性，从而减轻LLMs在校准过程中产生的幻觉。研究提供了未来研究的几个见解，尤其是KCA方法在多种场景下的出色表现，以及其简单性与有效性的结合。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.10768v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.10768.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/fanqiwan/KCA)</div> |
| <span style='display: inline-block; width: 42px;'>01-19</span> | **Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads**<br><sub>机构: Princeton University, Together AI, University of Illinois Urbana-Champaign<br>文章提出了一个名为Medusa的LLM推理加速框架，通过增加额外的解码头并用树形注意力机制，并行生成多个token，有效减少解码步骤数量，实现了对大模型推理速度的显著提升。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.10774v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.10774.md)  |
| <span style='display: inline-block; width: 42px;'>01-18</span> | **ChatQA: Building GPT-4 Level Conversational QA Models**<br><sub>机构: NVIDIA<br>ChatQA模型通过两阶段的指令微调策略显著改进了多轮对话式问答的效果，尤其是在上下文理解和信息检索方面。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.10225v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.10225.md)  |
| <span style='display: inline-block; width: 42px;'>01-18</span> | **Self-Rewarding Language Models**<br><sub>机构: Meta, NYU  <br>本文提出了自奖励语言模型（Self-Rewarding Language Models），旨在通过自我训练来避免人类偏好数据的瓶颈，并提高模型的自奖励和执行指令的能力。实验结果表明，该模型表现出色，有望成为连续自我改进模型的开山之作。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.10020v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.1002.md)  |
| <span style='display: inline-block; width: 42px;'>01-18</span> | **Advancing Large Multi-modal Models with Explicit Chain-of-Reasoning and Visual Question Generation**<br><sub>机构: The University of Tokyo, RIKEN<br>这项研究通过创新地整合一个显性的推理过程和生成问题的能力到LMM中，以促进模型进行更可靠的推理。创建了一个新的数据集并利用它对模型进行培训，为今后LMM的进步设定了先例，并通过这种方式使模型在面临不确定性时能生成显性推理步骤和提问。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.10005v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.10005.md)  |
| <span style='display: inline-block; width: 42px;'>01-18</span> | **A Fast, Performant, Secure Distributed Training Framework For Large Language Model**<br><sub>机构: Ant Group China<br>本论文提出了一个基于模型切片的安全分布式训练框架，能在保证模型训练精度和高效率的同时，解决了服务端和客户端的模型参数及数据泄露问题。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.09796v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.09796.md)  |
| <span style='display: inline-block; width: 42px;'>01-17</span> | **ReFT: Reasoning with Reinforced Fine-Tuning**<br><sub>机构: ByteDance Research<br>ReFT通过利用强化学习优化非可微目标，显著提高了大型语言模型在数学问题求解任务中的性能和泛化能力。它超越了传统的监督式学习方法，展现了在更复杂推理任务中的潜力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.08967v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.08967.md)  |
| <span style='display: inline-block; width: 42px;'>01-17</span> | **LLMs for Relational Reasoning: How Far are We?**<br><sub>机构: Continental-NTU Corporate Lab, Nanyang Technological University, Singapore<br>本论文主要探讨了大型语言模型在关系推理方面的能力和局限性。通过全面的评估，包括新提出的测试方法和评估模块，发现LLMs虽然在某些关系推理任务上表现不错，但与专门为逻辑推理设计的模型相比，其性能相对较差。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.09042v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.09042.md)  |
| <span style='display: inline-block; width: 42px;'>01-17</span> | **Vlogger: Make Your Dream A Vlog**<br><sub>机构: Shanghai Jiao Tong University, Shanghai AI Laboratory, Shenzhen Institute of Advanced Technology Chinese Academy of Sciences<br>本论文通过介绍Vlogger系统，展示了一个创新的办法将LLMs应用于视频博客的生成过程中，从而克服了生成分钟级连贯视频内容的挑战，并取得了优异的实验结果。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.09414v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.09414.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/zhuangshaobin/Vlogger)</div> |
| <span style='display: inline-block; width: 42px;'>01-16</span> | **SpecGen: Automated Generation of Formal Program Specifications via Large Language Models**<br><sub>机构: Nanjing University, Nanyang Technological University, Singapore Management University<br>论文提出了 SpecGen，一个结合了大型语言模型和启发式选择策略的程序形式化规范自动生成技术。通过比较与现有工具和纯 LLM 方法，SpecGen 表现出更高效和准确的生成规范的能力，并且提出了数据集促进后续研究。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.08807v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.08807.md)  |
| <span style='display: inline-block; width: 42px;'>01-16</span> | **RAG vs Fine-tuning: Pipelines, Tradeoffs, and a Case Study on Agriculture**<br><sub>机构: Microsoft<br>本文研究了大型语言模型在农业数据上生成问答对的性能，并提出了一个新的生成管道，有效地使用了RAG和微调技术增强LLM的应用场景，拓展了LLM在特定行业的应用潜力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.08406v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.08406.md)  |
| <span style='display: inline-block; width: 42px;'>01-16</span> | **MARIO: MAth Reasoning with code Interpreter Output -- A Reproducible Pipeline**<br><sub>机构: Alibaba Group  <br>论文提出了一个新的数学推理数据集，该数据集与Python代码解释器相结合，通过改进数据集并实施特定微调流程显著提高了LLM在数学问题求解任务上的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.08190v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.0819.md)  |
| <span style='display: inline-block; width: 42px;'>01-16</span> | **Salute the Classic: Revisiting Challenges of Machine Translation in the Age of Large Language Models**<br><sub>机构: Tencent AI Lab<br>本文深入分析了LLMs在机器翻译任务中领域不匹配问题，并实验了不同数量的平行数据对LLMs翻译能力的影响，展现出LLMs在处理这些挑战中的潜力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.08350v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.0835.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/pangjh3/LLM4MT)</div> |
| <span style='display: inline-block; width: 42px;'>01-16</span> | **DoraemonGPT: Toward Understanding Dynamic Scenes with Large Language Models**<br><sub>机构:  Zhejiang University<br>DoraemonGPT是一个LLM驱动的智能体，通过符号记忆和工具集来理解并解答涉及动态视频的复杂问题。其采用了MCTS规划器优化回答的生成过程，能够在真实世界场景中处理更为复杂的任务。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.08392v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.08392.md)  |
| <span style='display: inline-block; width: 42px;'>01-16</span> | **Contrastive Preference Optimization: Pushing the Boundaries of LLM Performance in Machine Translation**<br><sub>机构: Johns Hopkins University, Microsoft<br>本论文提出了CPO，一个新的LLM微调方法，有效解决了SFT在机器翻译任务中存在的瓶颈，实现了在资源消耗极少的情况下显著提升中等规模LLM翻译模型的性能，最终与最先进的状态艺术翻译系统齐头并进。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.08417v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.08417.md)  |
| <span style='display: inline-block; width: 42px;'>01-15</span> | **MAPLE: Multilingual Evaluation of Parameter Efficient Finetuning of Large Language Models**<br><sub>机构: Microsoft Research India<br>这篇论文研究了大型语言模型在多语言任务上通过参数高效微调后的性能，特别是在低资源语言和英语任务上。研究展示了PEFT的潜力，同时指出了未来工作的一些可能方向。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.07598v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.07598.md)  |
| <span style='display: inline-block; width: 42px;'>01-15</span> | **The What, Why, and How of Context Length Extension Techniques in Large Language Models -- A Detailed Survey**<br><sub>机构: Technology Innovation Institute UAE, Islamic University of Technology Bangladesh, Stanford University, Amazon GenAI, AI Institute University of South Carolina<br>本论文是关于LLMs上下文长度扩展技术的详细调研。它为研究人员提供了该领域的现有策略和挑战的有组织概览，并鼓励了对未来发展的讨论。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.07872v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.07872.md)  |
| <span style='display: inline-block; width: 42px;'>01-15</span> | **A Study on Large Language Models' Limitations in Multiple-Choice Question Answering**<br><sub>机构: David R. Cheriton School of Computer Science<br>该论文针对LLMs在MCQ任务中的限制进行了研究，指出多数模型在此类任务中表现不佳。论文还发现模型的回答往往依赖于选项顺序，并提出了有效的评估方法来排除这些偏见。论文推荐在使用MCQ评估LLMs时要格外小心，并测试模型是否真正理解了任务。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.07955v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.07955.md)  |
| <span style='display: inline-block; width: 42px;'>01-14</span> | **Small LLMs Are Weak Tool Learners: A Multi-LLM Agent**<br><sub>机构: Sun Yat-sen University, Alibaba Group<br>研究表明小型LLM在作为工具学习者方面较为薄弱，通过引入α-UMi多LLM框架来构建性能更优的LLM代理，提出了必要的双阶段微调策略，并深入分析了数据规模法则。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.07324v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.07324.md)  |
| <span style='display: inline-block; width: 42px;'>01-13</span> | **Bridging the Preference Gap between Retrievers and LLMs**<br><sub>本论文介绍了BGM框架以解决检索器和LLMs之间的"偏好差"问题，通过一个序列到序列（seq2seq）的桥模型结合SL和RL的训练方案，优化了检索信息以满足LLMs的偏好，改进了多个下游任务的表现。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06954v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06954.md)  |
| <span style='display: inline-block; width: 42px;'>01-12</span> | **TestSpark: IntelliJ IDEA's Ultimate Test Generation Companion**<br><sub>机构: JetBrains Research, Delft University of Technology<br>论文提出了TestSpark插件，它结合了基于搜索的软件测试生成和基于语言模型的测试生成方法，在IntelliJ IDEA中提高了单元测试的生成和集成效率，同时解决了LLM生成测试用例可编译性的问题。插件的开源特性使其成为连接软件开发者和研究者的桥梁，有助于测试生成技术的实用性进步。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06580v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.0658.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/JetBrains-Research/TestSpark)</div> |
| <span style='display: inline-block; width: 42px;'>01-12</span> | **How Johnny Can Persuade LLMs to Jailbreak Them: Rethinking Persuasion to Challenge AI Safety by Humanizing LLMs**<br><sub>机构: Virginia Tech, Renmin University of China, UC Davis<br>本论文提出了将LLMs视为具备类人沟通能力的实体，利用了一个新的视角来研究AI安全问题。通过将十多年的社会科学研究应用于AI安全，制定了一个说服技巧分类法，并通过创建的工具自动生成了对抗性提示。结果表明，说服技巧可以有效地增强有风险行为被LLMs执行的可能性，同时揭示了当前防御手段在应对这类策略时的不足。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06373v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06373.md)  |
| <span style='display: inline-block; width: 42px;'>01-12</span> | **From Automation to Augmentation: Large Language Models Elevating Essay Scoring Landscape**<br><sub>机构: Tsinghua University, University of Maryland, Beijing Xicheng Educational Research Institute  <br>本文的研究展现了大型语言模型在教育领域中，特别是在AES系统中的潜力。LLMs不仅能够自动化评分过程，还能够通过生成反馈来增强人类评分者的表现。这不仅是技术上的进步，更为未来的人工智能辅助教育和人工智能与人类的高效协作提供了宝贵见解。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06431v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06431.md)  |
| <span style='display: inline-block; width: 42px;'>01-12</span> | **Kun: Answer Polishment for Chinese Self-Alignment with Instruction Back-Translation**<br><sub>机构: Tianyu Zheng, Shuyue Guo, Xingwei Qu, Jiawei Guo, Weixu Zhang, Xinrun Du, Chenghua Lin, Wenhao Huang, Wenhu Chen, Jie Fu, Ge Zhang<br>这篇论文提出了Kun策略，解决了中文大型语言模型指令微调中存在的数据一致性问题，通过AP过程和新的数据生成方法，减少了对人工标注的依赖。评估结果表明，Kun策略在创建高质量数据集方面具有明显优势。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06477v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06477.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/Zheng0428/COIG-Kun)</div> |
| <span style='display: inline-block; width: 42px;'>01-12</span> | **Teaching Code LLMs to Use Autocompletion Tools in Repository-Level Code Generation**<br><sub>机构: Nanyang Technological University, Fudan University<br>该论文成功提出了一种新方法TOOLGEN，通过集成自动完成工具到仓库级代码生成中的LLMs，解决了依赖性问题，提高了代码生成的质量和成功率。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06391v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06391.md)  |
| <span style='display: inline-block; width: 42px;'>01-12</span> | **An Experimental Design Framework for Label-Efficient Supervised Finetuning of Large Language Models**<br><sub>机构: University of Washington Seattle, University of Wisconsin-Madison, Stanford University<br>这篇论文提出了一个实验设计框架，为了提高大型语言模型在监督式微调（SFT）过程中的标签效率。它展示了实验设计技术可以在维持低计算成本的同时，大幅提高标签效率，在一些任务中与随机采样相比节省了50%的注释成本。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06692v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06692.md)  |
| <span style='display: inline-block; width: 42px;'>01-12</span> | **APAR: LLMs Can Do Auto-Parallel Auto-Regressive Decoding**<br><sub>机构: Tsinghua University, Zhipu AI<br>通过实施APAR，该研究成功提高了LLMs在内存受限场景和高吞吐率场景下的解码效率和生成速度，同时保持了生成质量，为大语言模型的部署提供了一种新的高效策略。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06761v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06761.md)  |
| <span style='display: inline-block; width: 42px;'>01-11</span> | **LLM-as-a-Coauthor: The Challenges of Detecting LLM-Human Mixcase**<br><sub>机构: LAIR Lab Lehigh University, Huazhong University of Science and Technology  <br>本文定义了混合场景中的混合文本（mixcase），构建了MIXSET数据集，并提出了通向解决混合文本检测问题的见解和方向。研究发现，现有的检测器在识别混合文本方面存在不足，这提出了制定更细粒度检测器的紧迫需求。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.05952v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.05952.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/Dongping-Chen/MixSet)</div> |
| <span style='display: inline-block; width: 42px;'>01-11</span> | **Risk Taxonomy, Mitigation, and Assessment Benchmarks of Large Language Model Systems**<br><sub>机构: Zhongguancun Laboratory, Tsinghua University, Institute of Information Engineering Chinese Academy of Sciences<br>本文为大语言模型系统中的风险分类、缓解措施以及评估标准提供了全面的概述，提出了一个新的系统化分类框架，帮助开发者更全面地理解和处理LLM系统的潜在风险。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.05778v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.05778.md)  |
| <span style='display: inline-block; width: 42px;'>01-11</span> | **Improving Large Language Models via Fine-grained Reinforcement Learning with Minimum Editing Constraint**<br><sub>机构: Gaoling School of Artificial Intelligence, Renmin University of China; School of Information, Renmin University of China; Kuaishou Technology, Beijing China.<br>本论文提出了一种新的RL方法，名为RLMEC，通过生成式奖励模型和最小编辑机制，使大型语言模型在RL训练过程中实现更精细的监督和训练的稳定性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06081v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06081.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/RUCAIBox/RLMEC)</div> |
| <span style='display: inline-block; width: 42px;'>01-11</span> | **EASYTOOL: Enhancing LLM-based Agents with Concise Tool Instruction**<br><sub>机构: Fudan University, Microsoft Research Asia, Zhejiang University<br>本文提出了一种名为EASYTOOL的方法，可以通过简化和统一工具文档的指令来提高LLM基础代理在工具使用方面的表现，解决了现有工具使用中的不一致性、冗余性和不完整性问题。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06201v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06201.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/microsoft/JARVIS)</div> |
| <span style='display: inline-block; width: 42px;'>01-11</span> | **The Benefits of a Concise Chain of Thought on Problem-Solving in Large Language Models**<br><sub>机构: Johns Hopkins University<br>此研究表明，通过使用简洁的思维链提示（CCoT），在大型语言模型中可以大幅减少文本输出的长度，而不会影响解决问题的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.05618v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.05618.md)  |
| <span style='display: inline-block; width: 42px;'>01-11</span> | **Chain of History: Learning and Forecasting with LLMs for Temporal Knowledge Graph Completion**<br><sub>机构: Tsinghua Shenzhen International Graduate School Tsinghua University, School of Computer Science Peking University, Baidu Inc.<br>本论文提出了一种使用大型语言模型进行时间知识图谱完成的方法，通过高效的微调方法和结合结构信息的历史数据增强，提高了模型的推理能力和性能。实验显示该方法有效地提升了时间知识图谱预测的精度，达到了最先进的结果。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06072v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06072.md)  |
| <span style='display: inline-block; width: 42px;'>01-11</span> | **Evidence to Generate (E2G): A Single-agent Two-step Prompting for Context Grounded and Retrieval Augmented Reasoning**<br><sub>机构: Qatar Computing Research Institute <br>本论文提出了一个新的、用于改善LLMs在上下文推理能力的单代理双步提示框架——Evidence to Generate (E2G)。通过要求LLMs在生成答案的同时提供证据与解释，E2G能够减少错误推理并提高模型在处理各种推理任务时的准确度。实验结果表明，E2G方法在多个情境密集型语言任务中表现出较CoT更好的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.05787v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.05787.md)  |
| <span style='display: inline-block; width: 42px;'>01-11</span> | **Patchscope: A Unifying Framework for Inspecting Hidden Representations of Language Models**<br><sub>机构: Google Research, Tel Aviv University<br>该论文提出了一个名为Patchscopes的框架，提供了一种新的方法去解释大型语言模型（LLMs）隐藏表示中编码的信息，并且能够纠正多步推理错误。Patchscopes作为一种通用的可配置框架，不仅统一了现有的解释工具，并解决了它们自身的一些不足，同时也开辟了新的研究和应用可能性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06102v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06102.md)  |
| <span style='display: inline-block; width: 42px;'>01-11</span> | **TOFU: A Task of Fictitious Unlearning for LLMs**<br><sub>机构: Carnegie Mellon University<br>文章为LLM遗忘问题提供了新的数据集和评估机制，TOFU任务展示了现有遗忘技术的不足，鼓励了相继而来的改进和研究工作。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06121v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06121.md)  |
| <span style='display: inline-block; width: 42px;'>01-10</span> | **CASA: Causality-driven Argument Sufficiency Assessment**<br><sub>机构: Peking University<br>本论文介绍了一个基于LLMs的零样本因果驱动论证充分性评估框架（CASA），成功应对了无观测数据下论证充分性量化和干预的难题，并在实际应用中展示了其有效性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.05249v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.05249.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/xxxiaol/CASA)</div> |
| <span style='display: inline-block; width: 42px;'>01-10</span> | **Attendre: Wait To Attend By Retrieval With Evicted Queries in Memory-Based Transformers for Long Context Processing**<br><sub>机构: Google Research<br>论文成功地提出了一个新的基于内存的转换器方法，通过存储驱逐策略和ATTENDRE层，有效地减少内存需求并支持双向注意力，在长序列处理上表现出与传统方法相当的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.04881v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.04881.md)  |
| <span style='display: inline-block; width: 42px;'>01-10</span> | **InfiAgent-DABench: Evaluating Agents on Data Analysis Tasks**<br><sub>InfiAgent-DABench提供了一个新颖的评估基准，这不仅有助于衡量智能代理在数据分析任务中的性能，同时也是探索如何改进和优化LLM在这一特定领域应用的重要一步。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.05507v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.05507.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/InfiAgent/InfiAgent)</div> |
| <span style='display: inline-block; width: 42px;'>01-10</span> | **Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security**<br><sub>机构: Tsinghua University, Xiaomi AI Lab<br>该论文作为一项调研工作，介绍了个人LLM代理的现状、挑战和未来趋势，并提出了一种通用的系统架构和智能水平定义。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.05459v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.05459.md)  |
| <span style='display: inline-block; width: 42px;'>01-10</span> | **Prompting Large Language Models for Recommender Systems: A Comprehensive Framework and Empirical Analysis**<br><sub>机构: Renmin University of China, Beijing Key Laboratory of Big Data Management and Analysis Methods, Meituan Group<br>这项工作提出了一个名为ProLLM4Rec的框架，系统地分析了利用大型语言模型(LLMs)作为推荐系统的基础模型，并通过实验测试了不同情况下对LLMs的影响。通过实证分析，总结了对未来研究的启发性发现。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.04997v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.04997.md)  |
| <span style='display: inline-block; width: 42px;'>01-10</span> | **Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk**<br><sub>机构: AWS AI Labs<br>论文提出了一种基于大型语言模型（LLMs）自我对话生成训练数据的新方法，该方法有潜力改进任务导向对话代理的性能。尽管存在一些限制，研究结果表明，当选择高质量对话作为训练数据时，可以有效提高模型的性能。这证明了在正确的设置下，通过自我生成数据进行微调的语言模型确实有潜力实现自我改进，并成为更好的任务导向对话代理。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.05033v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.05033.md)  |
| <span style='display: inline-block; width: 42px;'>01-10</span> | **AUTOACT: Automatic Agent Learning from Scratch via Self-Planning**<br><sub>机构: Zhejiang University, Alibaba Group<br>这项研究提出了一个名为AUTOACT的框架，它通过自我指导和自我规划实现语言代理的自动学习，以应对从零开始学习新任务的挑战。该框架的核心贡献在于有效的数据扩充方法和高效率的自动代理学习过程。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.05268v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.05268.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/zjunlp/AutoAct)</div> |
| <span style='display: inline-block; width: 42px;'>01-10</span> | **Leveraging Print Debugging to Improve Code Generation in Large Language Models**<br><sub>机构: Zhejiang University, ByteDance<br>本文提出了一种利用print debugging方法指导LLMs进行代码生成和调试的方法，并且在Leetcode问题集上验证了其有效性，特别是在简单和中等难度的问题上。尽管在高难度问题上效果有限，但这项工作仍然是LLMs在代码调试方面的一个重要进步。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.05319v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.05319.md)  |
| <span style='display: inline-block; width: 42px;'>01-09</span> | **Large Language Models for Robotics: Opportunities, Challenges, and Perspectives**<br><sub>机构: Northwestern Polytechnical University, University of Georgia, Shaanxi Normal University<br>论文提出的多模态GPT-4V框架，结合自然语言处理和视觉感知，有望解决LLMs在机器人任务规划中面对的挑战。这对于理解和实现更高级别的人机交互和人工智能的未来具有重要意义。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.04334v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.04334.md)  |
| <span style='display: inline-block; width: 42px;'>01-09</span> | **Agent Alignment in Evolving Social Norms**<br><sub>机构: Fudan University<br>此论文提出了一个EvoluationaryAgent框架，用于评估和增强大型智能代理在动态持续变化的社会规范中的自适应性和一致性。研究强调了代理在进化中与社会规范对齐的重要性，并通过实验验证了模型的可行性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.04620v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.0462.md)  |
| <span style='display: inline-block; width: 42px;'>01-09</span> | **The Critique of Critique**<br><sub>机构: The Hong Kong Polytechnic University, Shanghai Jiao Tong University, Shanghai Artificial Intelligence Laboratory<br>METACRITIQUE是首个针对自然语言批判进行评价的框架，其通过精确度和召回率的原则评估批判的质量，并实现了高度的可解释性和透明性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.04518v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.04518.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/GAIR-NLP/MetaCritique)</div> |
| <span style='display: inline-block; width: 42px;'>01-09</span> | **Rewriting the Code: A Simple Method for Large Language Model Augmented Code Search**<br><sub>机构: Nanyang Technological University Singapore<br>ReCo利用LLMs重写代码库中的代码，通过风格规范化显著提高了代码搜索的准确性，并通过新的评价指标CSSim量化了风格的差异，推动了代码样式标准化的研究。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.04514v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.04514.md)  |
| <span style='display: inline-block; width: 42px;'>01-09</span> | **Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding**<br><sub>机构: University of California San Diego, Google Cloud AI Research, Google Research<br>该论文提出了一个创新的CHAIN-OF-TABLE框架，通过将表格数据显式地用于推理链，动态地规划并更新操作过程，从而提高了LLMs在基于表格的推理任务中的准确性和可靠性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.04398v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.04398.md)  |
| <span style='display: inline-block; width: 42px;'>01-09</span> | **Know Your Needs Better: Towards Structured Understanding of Marketer Demands with Analogical Reasoning Augmented LLMs**<br><sub>机构: Zhejiang University, Ant Group<br>本文提出了一种名为ARALLM的新方法，该方法结合了类比推理和多任务模型提炼，有效促进了大型语言模型从自然语言中理解并转换为结构化的逻辑语言的能力。通过这种方法，非专业营销人员能够利用自然语言来选择目标用户，有望改变用户定位实践。这种能力的提升，不仅在营销场景中有实际的应用价值，同时也为大型语言模型的功能性和实用性做出了有益的探索。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.04319v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.04319.md)  |
| <span style='display: inline-block; width: 42px;'>01-08</span> | **MARG: Multi-Agent Review Generation for Scientific Papers**<br><sub>机构: Northwestern University, The Hebrew University of Jerusalem, Allen Institute for AI<br>本论文提出了一个创新的多代理评论生成方法（MARG），可以跨越基础模型的上下文大小限制，生成高质量的科学论文同行评审反馈。通过用户研究和自动化度量，MARG的反馈质量对比基线有显著提高，生成的有用评论数量提高了2.2倍，同时生成了更加具体的评论。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.04259v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.04259.md)  |
| <span style='display: inline-block; width: 42px;'>01-08</span> | **TTMs: Fast Multi-level Tiny Time Mixers for Improved Zero-shot and Few-shot Forecasting of Multivariate Time Series**<br><sub>机构: IBM Research<br>TTM展示了专门针对多样化时间序列数据训练的小型预训练模型在多变量时间序列零/少样本预测中的高效性和转移学习能力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.03955v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.03955.md)  |
| <span style='display: inline-block; width: 42px;'>01-08</span> | **SpeechAgents: Human-Communication Simulation with Multi-Modal Multi-Agent Systems**<br><sub>机构: Fudan University<br>论文提出了一个基于多模态大型语言模型的多代理系统——SpeechAgents，其能模拟包含多达 25 名代理人的人类交流场景，并展现出卓越的可扩展性。通过使用多模态信号作为代理间交流的媒介，系统不仅可以模拟具有正确内容、真实节奏和丰富情感的对话，而且还能应用于如戏剧创作和有声小说生成等任务。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.03945v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.03945.md)  |
| <span style='display: inline-block; width: 42px;'>01-07</span> | **Grimoire is All You Need for Enhancing Large Language Models**<br><sub>机构: Beihang University, Renmin University of China<br>该论文提出了一种名为SLEICL的方法，通过强语言模型学习示例技能并将其转移给弱语言模型，显著提高了弱模型的ICL能力。通过实验验证了该方法的有效性，展现了该技术在增强弱语言模型上下文学习能力方面的潜力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.03385v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.03385.md)  |
| <span style='display: inline-block; width: 42px;'>01-07</span> | **ChatGPT for Conversational Recommendation: Refining Recommendations by Reprompting with Feedback**<br><sub>机构: University of Louisville, Microsoft<br>该论文探索了ChatGPT作为对话推荐系统的有效性。通过构建围绕ChatGPT的流程，模拟用户实际使用情景，并对流行偏见进行了研究和缓解。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.03605v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.03605.md)  |
| <span style='display: inline-block; width: 42px;'>01-07</span> | **Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects**<br><sub>机构: The Chinese University of Hong Kong, DeepWisdom, Peking University<br>论文提出了一个用于指导未来研究与开发的基于LLM的智能代理系统的框架，并探讨了提高它们的计划能力和多模态信息处理能力的不同方法，以及如何解决LLM代理所面临的挑战，为未来的研究方向提供了清晰的指南。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.03428v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.03428.md)  |
| <span style='display: inline-block; width: 42px;'>01-07</span> | **Soaring from 4K to 400K: Extending LLM's Context with Activation Beacon**<br><sub>机构: Beijing Academy of Artificial Intelligence, Renmin University of China, Nankai University<br>这篇文章介绍了激活信标这一能够扩展大型语言模型上下文长度的新技术，使得模型能在有限上下文窗口内感知更广的上下文信息，同时保留对短上下文信息的处理能力。激活信标代表了一种有效、高效、兼容且训练成本低的方法，来扩展LLMs的上下文长度。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.03462v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.03462.md)  |
| <span style='display: inline-block; width: 42px;'>01-06</span> | **CogGPT: Unleashing the Power of Cognitive Dynamics on Large Language Models**<br><sub>机构: Harbin Institute of Technology, Kuaishou Technology<br>CogGPT通过引入迭代认知机制和记忆保持系统，有效地解决了大型语言模型在模仿人类认知动态方面的挑战，展示了在连续信息处理中的优秀表现。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.08438v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.08438.md)  |
| <span style='display: inline-block; width: 42px;'>01-06</span> | **Quartet Logic: A Four-Step Reasoning (QLFR) framework for advancing Short Text Classification**<br><sub>机构: Aerospace Information Research Institute Chinese Academy of Sciences, Key Laboratory of Target Cognition and Application Technology, University of Chinese Academy of Sciences<br>本研究提出了一个针对短文本分类任务的Quartet Logic: A Four-Step Reasoning (QLFR)框架，以及一个CoT驱动的多任务学习（QLFR-CML）方法，这两者都通过大语言模型的推理链来解决STC领域中的挑战。实验结果证明了这些方法的有效性和实用性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.03158v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.03158.md)  |
| <span style='display: inline-block; width: 42px;'>01-06</span> | **The Dawn After the Dark: An Empirical Study on Factuality Hallucination in Large Language Models**<br><sub>机构: Renmin University of China, Université de Montréal<br>本论文通过系统性实证研究，深入了解并探索大型语言模型中的幻觉问题，识别了幻觉的来源、检测方法和减轻策略，并提出了新的基准HaluEval 2.0和简单有效的幻觉检测框架。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.03205v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.03205.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/RUCAIBox/HaluEval-2.0)</div> |
| <span style='display: inline-block; width: 42px;'>01-05</span> | **From LLM to Conversational Agent: A Memory Enhanced Architecture with Fine-Tuning of Large Language Models**<br><sub>机构: Beike Inc.<br>本论文介绍了RAISE框架，通过增强记忆系统和结构化的代理构建过程，提高了LLMs在多轮对话中的表现，尤其是在房地产销售情境中。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.02777v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.02777.md)  |
| <span style='display: inline-block; width: 42px;'>01-05</span> | **Infinite-LLM: Efficient LLM Service for Long Context with DistAttention and Distributed KVCache**<br><sub>机构: Alibaba Group, Shanghai Jiao Tong University<br>文章提出了一个有效支持长上下文语言模型云服务的系统，通过分布式算法DistAttention，优化了注意力模块的处理和存储，并通过DistKV-LLM服务系统进行管理和协调，实现了在分布式环境中对资源的高效分配和管理，验证了其在性能上的明显提高。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.02669v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.02669.md)  |
| <span style='display: inline-block; width: 42px;'>01-04</span> | **ICE-GRT: Instruction Context Enhancement by Generative Reinforcement based Transformers**<br><sub>机构: Bytedance Inc.<br>本论文提出了针对大型语言模型在特定领域任务中深度与准确性提升的方法——ICE-GRT。通过结合人类反馈的强化学习，ICE-GRT 在不牺牲一般性能的前提下，显著提升了特定领域的能力，并在多项评估任务中达到了最先进的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.02072v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.02072.md)  |
| <span style='display: inline-block; width: 42px;'>01-04</span> | **Self-Contrast: Better Reflection Through Inconsistent Solving Perspectives**<br><sub>机构: Zhejiang University, OPPO Research Institute<br>本文提出了一种名为“自我对比”的新策略，用于改善大型语言模型（LLM）在反思和自我修正过程中存在的固执和不一致问题，通过创建多样化解决方案视角，对比不同解决方案的差异，并将差异总结为检查清单，进而提升了LLM的反思质量，并通过实验验证了该策略的效果和广泛适用性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.02009v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.02009.md)  |
| <span style='display: inline-block; width: 42px;'>01-04</span> | **SPEER: Sentence-Level Planning of Long Clinical Summa