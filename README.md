<h2 align='center'>AI4FM-paper 论文列表</h2>
<div align='center'>

[![Status](https://img.shields.io/badge/status-Update_07.31_10:00-success.svg)]() [![简体中文 badge](https://img.shields.io/badge/%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87-Simplified%20Chinese-blue)](./README.md) [![English badge](https://img.shields.io/badge/%E8%8B%B1%E6%96%87-English-blue)](./README_en.md) 

</div>

欢迎来到 **AI4FM-paper**! 本列表收集形式化方向、编程语言方向、软工方向、系统方向、安全方向的顶会顶刊中关于AI for FM的论文。



## 最新论文
### 形式化，编程语言，系统，安全（顶会）

| &nbsp;Conference/Year&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>07-29</span> | **SeaLLMs 3: Open Foundation and Chat Multilingual Large Language Models for Southeast Asian Languages**<br><sub>机构: DAMO Academy, Alibaba Group<br>SeaLLMs 3是专为东南亚多语言环境设计的大型语言模型，重点在于克服现有模型的局限性，通过高效的语言增强技术和安全可靠的机制，使之能够提供文化适宜的回应，同时减少幻觉现象。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2407.19672v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-07/2407.19672.md)  |
| <span style='display: inline-block; width: 42px;'>07-29</span> | **QAEA-DR: A Unified Text Augmentation Framework for Dense Retrieval**<br><sub>机构: Tsinghua University<br>QAEA-DR框架提出了一个针对密集检索的创新文本增强技术，通过集成事件提取和问题答案生成来提高文本生成的质量和健壮性，同时还可以与多种嵌入模型兼容，证明了其在实验中的有效性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2407.20207v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-07/2407.20207.md)  |

---

### 软件工程（顶会）

| &nbsp;Conference/Year&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>06-30</span> | **Step-Controlled DPO: Leveraging Stepwise Error for Enhanced Mathematical Reasoning**<br><sub>机构: Multimedia Laboratory (MMLab), The Chinese University of Hong Kong<br>本论文提出了一种新的数学推理优化方法——SCDPO，通过在特定步骤监督错误的方式，自动化地生成训练样本，显著提升了LLMs在数学问题求解方面的性能，证明了该方法的潜力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2407.00782v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2407.00782.md)  |
| <span style='display: inline-block; width: 42px;'>06-29</span> | **LiteSearch: Efficacious Tree Search for LLM**<br><sub>机构: Xiamen University, Tencent AI Lab<br>该论文通过提出一种效率更高的树搜索算法来降低在辅助大型语言模型解决复杂数学推理任务时的资源消耗，同时确保保持高性能水平。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2407.00320v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2407.0032.md)  |

---

### 系统，安全（顶刊）

| &nbsp;Journal/Year&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>05-31</span> | **Preemptive Answer "Attacks" on Chain-of-Thought Reasoning**<br><sub>机构: Tsinghua University<br>论文研究了预先答案对LLMs推理能力的负面影响，并提出了减轻其影响的策略。实验结果表明，这些策略不能完全抵消预先答案的影响，提示需要进一步增强CoT的鲁棒性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.20902v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.20902.md)  |
| <span style='display: inline-block; width: 42px;'>05-31</span> | **Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality**<br><sub>机构: Princeton University, Carnegie Mellon University<br>本论文展示了一个全新的状态空间对偶性（SSD）框架，连接了结构化的状态空间模型（SSMs）和注意力机制变体。论文的主要贡献包括将原本针对Transformers的算法和系统优化应用到SSMs上，以及开发了一种新的SSD算法，有效提高了模型训练和推理的效率。Mamba-2架构作为最终产品，实现了理想的性能表现，为未来的深度学习模型设计和优化提供了新的方向。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.21060v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.2106.md)  |

---

### 软件工程（顶刊）

| &nbsp;Journal/Year&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>04-30</span> | **Better & Faster Large Language Models via Multi-token Prediction**<br><sub>机构: FAIR at Meta<br>论文提出了一种新的训练大型语言模型的方法，通过预测多个标记而不是单个来提高样本效率，并展示了如何提升生成任务中的性能并加快推理速度。实验证明了这种方法在提升大型模型性能和推理效率方面的显著优势。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.19737v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.19737.md)  |
| <span style='display: inline-block; width: 42px;'>04-30</span> | **Multi-hop Question Answering over Knowledge Graphs using Large Language Models**<br><sub>机构: Microsoft<br>论文在多跳问答任务中提出针对不同的知识图谱数据集采用不同策略，展示了利用大型预训练语言模型在这些复杂问答任务中的强大能力。通过实验，验证了所提方法相比现有技术的优势。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.19234v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.19234.md)  |
| <span style='display: inline-block; width: 42px;'>04-30</span> | **Do Large Language Models Understand Conversational Implicature -- A case study with a chinese sitcom**<br><sub>机构: Shanghai Jiao Tong University<br>该研究通过创建一个新的中文多轮对话数据集SwordsmanImp评估LLMs理解言外之意的能力，特别是在涉及大量上下文和轮换的对话中，并揭示了LLMs在理解和解释非字面含义时的挑战和局限。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.19509v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.19509.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/sjtu-compling/llm-pragmatics)</div> |
| <span style='display: inline-block; width: 42px;'>04-30</span> | **Iterative Reasoning Preference Optimization**<br><sub>机构: FAIR at Meta, New York University<br>本文提出了一种迭代推理偏好优化方法，通过在推理任务上应用偏好优化，特别是针对CoT推理，并通过在迭代训练中引入NLL损失项来提升模型性能。实验证明，该方法在数次迭代后能够有效提升推理性能，最终达到性能饱和。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.19733v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.19733.md)  |
| <span style='display: inline-block; width: 42px;'>04-29</span> | **Replacing Judges with Juries: Evaluating LLM Generations with a Panel of Diverse Models**<br><sub>机构: Cohere<br>该论文发展了一种以成员来自不同模型家族的小型模型组织成的“评审团”来评估LLM生成物的新方法，称为PoLL，显示出在不同任务中的适用性以及成本效率，减少了LLMs作为评判时存在的偏见问题。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.18796v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.18796.md)  |
| <span style='display: inline-block; width: 42px;'>04-29</span> | **LoRA Land: 310 Fine-tuned LLMs that Rival GPT-4, A Technical Report**<br><sub>机构: Predibase<br>本文提出通过LoRA对大型语言模型进行细化，可以明显提升模型的整体表现，降低在分类任务中出现的误差，且与开箱即用的GPT-4和GPT-3.5相比，有显著提高。同时，论文还考虑了成本限制，通过限制评估样本的数量来降低使用LLM API的财务负担。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.00732v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2405.00732.md)  |
| <span style='display: inline-block; width: 42px;'>04-26</span> | **When to Trust LLMs: Aligning Confidence with Response Quality**<br><sub>机构: Alibaba Group<br>本文提出了一个通过强化学习对齐信心和回答质量的方法（CONQORD）。该方法在没有客观实际标准的情况下通过自我评估来优化信心水平，并能够减少偏见，提升了模型预测的准确性和对齐性，但仍需对比绩效更高的方法进行改进。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.17287v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.17287.md)  |
| <span style='display: inline-block; width: 42px;'>04-26</span> | **A Comprehensive Evaluation on Event Reasoning of Large Language Models**<br><sub>机构: Peking University, Advanced Institute of Big Data, Beihang University<br>本文通过引入一个名为EV2的新基准测试来全面评估大型语言模型（LLMs）的事件推理能力。实验结果表明，虽然LLMs拥有事件推理能力，但与人类在运用事件模式知识方面并不一致，通过提供明确的指导，可以帮助模型更好地理解和执行事件推理任务。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.17513v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.17513.md)  |
| <span style='display: inline-block; width: 42px;'>04-25</span> | **Continual Learning of Large Language Models: A Comprehensive Survey**<br><sub>机构: Rutgers University, Wuhan University, Huazhong University of Science and Technology<br>本综述为LLMs的持续学习提供了一个全面的视角，特别强调了连续预训练（CPT）和领域自适应预训练（DAP）的研究领域。强调社区需更多关注，特别是开发实用、易于获取且广泛认可的评估基准方面，以及需要针对新兴LLMs学习范式特别设计的方法论。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.16789v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.16789.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/Wang-ML-Lab/llm-continual-learning-survey)</div> |
| <span style='display: inline-block; width: 42px;'>04-25</span> | **How Far Are We to GPT-4V? Closing the Gap to Commercial Multimodal Models with Open-Source Suites**<br><sub>机构: Shanghai AI Laboratory, SenseTime Research, Tsinghua University<br>InternVL 1.5是一个强大的开源多模态语言模型，致力于弥补开源和商业模型在多模态理解方面的性能差距。该模型的优势包括改善视觉理解、处理动态高分辨率图像以及高质量的双语数据集的使用，这些它在多项任务中表现出色。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.16821v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.16821.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/OpenGVLab/InternVL)</div> |
| <span style='display: inline-block; width: 42px;'>04-25</span> | **Hippocrates: An Open-Source Framework for Advancing Large Language Models in Healthcare**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.16621v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.16621.md)  |
| <span style='display: inline-block; width: 42px;'>04-25</span> | **Layer Skip: Enabling Early Exit Inference and Self-Speculative Decoding**<br><sub>机构: Meta, University of Toronto, Carnegie Mellon University<br>LayerSkip是一个新颖的端到端解决方案，能够在不牺牲准确率的情况下显著加速大型语言模型的推理过程，具有实际应用价值和潜力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.16710v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.1671.md)  |
| <span style='display: inline-block; width: 42px;'>04-24</span> | **From Local to Global: A Graph RAG Approach to Query-Focused Summarization**<br><sub>机构: Microsoft Research, Microsoft Strategic Missions and Technologies, Microsoft Office of the CTO<br>这篇论文提出了Graph RAG方法，这是一种以图谱索引和LLM生成摘要为基础的查询聚焦摘要技术，旨在处理因语料量过大而超出大型语言模型处理能力的问题。通过社区检测算法的帮助，该方法能在处理全局性问题并实现大规模文本分析方面取得显著成效。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.16130v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.1613.md)  |
| <span style='display: inline-block; width: 42px;'>04-24</span> | **Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs**<br><sub>机构: Shanghai Jiao Tong University, UC San Diego, Duke University<br>本文章是对大型语言模型（LLMs）中Chain-of-X (CoX) 方法的详尽调研，着重于将Chain-of-Thought (CoT) 的概念扩展至更广泛的应用，并为未来的研究提供了潜在的发展方向。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.15676v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.15676.md)  |
| <span style='display: inline-block; width: 42px;'>04-23</span> | **A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications**<br><sub>机构: Hong Kong Baptist University<br>本文是一个综述性研究，主要调查了在图数据上使用的LLMs研究，探讨了LLMs在图任务泛化方面的优势，并提出了在该领域进行研究的未来方向。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.14809v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.14809.md)  |
| <span style='display: inline-block; width: 42px;'>04-23</span> | **CultureBank: An Online Community-Driven Knowledge Base Towards Culturally Aware Language Technologies**<br><sub>机构: Stanford University, IBM Research<br>该论文提出了一个用于构建文化知识库的通用流水线，并使用该流水线创建了CultureBank，这是一个包含TikTok和Reddit上文化描述符的知识库。论文还通过这个知识库评估了LLMs在文化意识方面的表现，并用于训练更具文化意识的语言模型，以此促进未来语言技术的文化意识发展。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.15238v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.15238.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/SALT-NLP/CultureBank)</div> |
| <span style='display: inline-block; width: 42px;'>04-22</span> | **Beyond Scaling: Predicting Patent Approval with Domain-specific Fine-grained Claim Dependency Graph**<br><sub>机构: University of California San Diego, Carnegie Mellon University, University of Pennsylvania<br>研究者提出了一种新颖的用于构建细粒度主张依赖图(FLAN图)的算法，该算法在大规模上显著改善了现状，并对现代LLMs在专利批准预测上的应用进行了广泛实验和分析，发现了LLMs的局限性，并为未来LLM方案的开发提供了有价值的参考。源代码和数据集已公开发布以促进未来的研究。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.14372v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.14372.md)  |
| <span style='display: inline-block; width: 42px;'>04-22</span> | **A Survey on Efficient Inference for Large Language Models**<br><sub>机构: Tsinghua University<br>本文提供了一个全面的综述关于提高大型语言模型推理效率的文献，并提出了一个包含数据层、模型层和系统层优化的分类法。同时，通过实验对关键技术进行了量化比较，指出了研究的未来方向。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.14294v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.14294.md)  |
| <span style='display: inline-block; width: 42px;'>04-22</span> | **A Survey on Self-Evolution of Large Language Models**<br><sub>机构: Peking University, Alibaba Group, Nanyang Technological University<br>这篇综述文章提出并总结了LLMs的自我进化方法，为推动自我进化的研究提供了概念框架和未来方向的见解，旨在推动下一代自我进化LLMs的发展。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.14387v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.14387.md)  |
| <span style='display: inline-block; width: 42px;'>04-22</span> | **SnapKV: LLM Knows What You are Looking for Before Generation**<br><sub>机构: University of Illinois Urbana-Champaign, Cohere, Princeton University<br>该文章介绍了SnapKV，一种针对大型语言模型中关键值缓存问题的新方法。SnapKV通过智能压缩和选取重要的KV位置，有效地提升了长文本处理时的解码速度和内存效率，并在保持准确性的同时显著降低了计算成本。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.14469v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.14469.md)  |
| <span style='display: inline-block; width: 42px;'>04-22</span> | **Tree of Reviews: A Tree-based Dynamic Iterative Retrieval Framework for Multi-hop Question Answering**<br><sub>机构: Tencent Inc., Harbin Institute of Technology<br>论文提出了一种新的迭代检索框架TOR，它采用树形结构减少错误累积，并引入优化策略提高检索效率和质量。在实验中，TOR框架在多个数据集上达到了最先进的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.14464v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.14464.md)  |
| <span style='display: inline-block; width: 42px;'>04-22</span> | **LLMs Know What They Need: Leveraging a Missing Information Guided Framework to Empower Retrieval-Augmented Generation**<br><sub>机构: Meituan<br>本文提出的MIGRES框架是通过Exploiting LLMs识别缺失信息的能力来增强RAG的能力。研究结果证明了MIGRES在多个公共数据集上具有优越性，应对了RAG在理解复杂查询和检索相关文档方面的挑战。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.14043v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.14043.md)  |
| <span style='display: inline-block; width: 42px;'>04-22</span> | **Information Re-Organization Improves Reasoning in Large Language Models**<br><sub>机构: Zhejiang University<br>本论文提出了一个新颖的信息重组方法（InfoRE），通过重组上下文内容来揭示逻辑关系，从而增强LLMs的推理能力。方法在零次射击设置下对LLMs进行上下文理解的多跳推理任务测试，取得了显著效果。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.13985v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.13985.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/hustcxx/InfoRE)</div> |
| <span style='display: inline-block; width: 42px;'>04-21</span> | **AdvPrompter: Fast Adaptive Adversarial Prompting for LLMs**<br><sub>机构: Meta AI (FAIR), Max-Planck-Institute for Intelligent Systems<br>本文提出了一个新型的LLM，名为AdvPrompter，它利用新颖的算法，无需目标LLM的梯度信息，迅速生成人类可读的敌对提示，显著提升了生成速度并保持了提示的语义连贯性。此外，通过AdvPrompter的训练还能增强LLM面对越狱攻击的稳健性，而不牺牲性能表现。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.16873v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.16873.md)  |
| <span style='display: inline-block; width: 42px;'>04-19</span> | **Relevant or Random: Can LLMs Truly Perform Analogical Reasoning?**<br><sub>机构: Nanyang Technological University, Princeton University, Salesforce Research<br>本论文系统地评估了LLMs进行类比推理的能力，并提出了两种可以在显著降低推理成本的同时获得更好性能的方法。研究结果表明，与以前认为相关性至关重要的观点相反，自我生成的无关例子在某些任务上可以达到相当甚至更好的性能。希望本研究能刺激更多关于自我生成上下文设计的进一步研究。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.12728v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.12728.md)  |
| <span style='display: inline-block; width: 42px;'>04-19</span> | **LLM-R2: A Large Language Model Enhanced Rule-based Rewrite System for Boosting Query Efficiency**<br><sub>机构: Nanyang Technological University, DAMO Academy Alibaba Group, Singapore University of Technology and Design<br>LLM-R2是一种利用大型语言模型增强的查询重写系统，通过自动选择一组给定重写规则中的有效规则，有效地提升了查询重写的执行效率，解决了目前其他方法的局限性，并在多个数据集上取得了优越的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.12872v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.12872.md)  |
| <span style='display: inline-block; width: 42px;'>04-18</span> | **mABC: multi-Agent Blockchain-Inspired Collaboration for root cause analysis in micro-services architecture**<br><sub>机构:  Beihang University, Beijing Information Science and Technology University<br>mABC是一种创新的框架，利用了大语言模型（LLMs）及多代理合作，并由区块链启发式的决策过程促成，针对云原生技术中微服务架构的根本原因分析（RCA）。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.12135v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.12135.md)  |
| <span style='display: inline-block; width: 42px;'>04-18</span> | **RAGCache: Efficient Knowledge Caching for Retrieval-Augmented Generation**<br><sub>机构: Peking University, ByteDance Inc.<br>通过针对性的缓存系统设计和中间状态共享，RAGCache优化了RAG流程的性能，显著提升了处理速度并减少了计算资源的开销。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.12457v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.12457.md)  |
| <span style='display: inline-block; width: 42px;'>04-18</span> | **Generating Diverse Criteria On-the-Fly to Improve Point-wise LLM Rankers**<br><sub>机构: Westlake University, Alibaba Group, Zhejiang University<br>该论文提出了MCRanker模型，通过构建虚拟专业评注团队和生成多角度评估标准，有效提升了LLM排序器的一致性与全面性，可广泛适应于各类数据集，改进了排序性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.11960v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.1196.md)  |
| <span style='display: inline-block; width: 42px;'>04-18</span> | **EVIT: Event-Oriented Instruction Tuning for Event Reasoning**<br><sub>机构: Key Laboratory of High Confidence Software Technologies (PKU), MOE, China, School of Computer Science, Peking University, Advanced Institute of Big Data<br>EVIT通过提出面向事件的指令调谐（Event-Oriented Instruction Tuning）和事件四元组的概念，解决了现有小型基于指令调谐模型在事件推理任务中的表现不足问题。实验结果表明，EVIT在事件推理任务上的表现优于其他模型。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.11978v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.11978.md)  |
| <span style='display: inline-block; width: 42px;'>04-18</span> | **Toward Self-Improvement of LLMs via Imagination, Searching, and Criticizing**<br><sub>该论文介绍了一种名为ALPHALLM的新型框架，通过蒙特卡洛树搜索（MCTS）和大型语言模型（LLMs）的结合，实现了LLMs的自我提高，无需额外的注解数据。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.12253v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.12253.md)  |
| <span style='display: inline-block; width: 42px;'>04-18</span> | **Who Validates the Validators? Aligning LLM-Assisted Evaluation of LLM Outputs with Human Preferences**<br><sub>机构: UC Berkeley<br>这篇论文提出了一个与人类偏好相一致的LLM辅助评估界面EvalGen，通过混合主动式方法解决了LLM生成的评估功能评估质量受信任度的问题。论文还探讨了用户如何定义和使用评估标准的动态性，以及在实际应用中所面临的挑战。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.12272v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.12272.md)  |
| <span style='display: inline-block; width: 42px;'>04-17</span> | **AgentKit: Flow Engineering with Graphs, not Coding**<br><sub>机构: Carnegie Mellon University, NVIDIA, Microsoft<br>论文引入了一种新型的 LLM 提示框架 AgentKit，针对多功能代理问题，通过模块化组件和直观设计支持构建和微调复杂的代理思维过程。AgentKit 显示出实现先进代理能力和降低用户参与门槛的潜力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.11483v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.11483.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/holmeswww/AgentKit)</div> |
| <span style='display: inline-block; width: 42px;'>04-17</span> | **Unifying Bias and Unfairness in Information Retrieval: A Survey of Challenges and Opportunities with Large Language Models**<br><sub>机构: Renmin University of China, Chinese Academy of Sciences, Huawei Technologies<br>这篇综述文章提供了一个新颖的视角来理解LLMs和IR系统中的偏见和不公平为分布失配问题，并归类了各种缓解策略。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.11457v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.11457.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/KID-22/LLM-IR-Bias-Fairness-Survey)</div> |
| <span style='display: inline-block; width: 42px;'>04-17</span> | **A Deep Dive into Large Language Models for Automated Bug Localization and Repair**<br><sub>机构: University of Virginia, Purdue University, Amazon Web Services<br>这篇论文提出了一种名为Toggle的新方法，该方法使用token粒度的bug定位并修复，克服了现有行粒度方法的局限，通过输入设计和LLMs的微调，大幅提升了错误修复的准确性，并在多个数据集上取得优异的表现，为APR领域带来新的进展。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.11595v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.11595.md)  |
| <span style='display: inline-block; width: 42px;'>04-17</span> | **Many-Shot In-Context Learning**<br><sub>机构: Google DeepMind<br>本论文主要贡献包括系统评估LLM在不同规模上下文样例的性能，导入reinforced ICL和unsupervised ICL以减少样例依赖，并发现MS-ICL可以克服预训练偏差学习高维数值预测任务。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.11018v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.11018.md)  |
| <span style='display: inline-block; width: 42px;'>04-16</span> | **How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs' internal prior**<br><sub>机构: Stanford University<br>论文通过分析在RAG环境下LLMs内部知识与检索信息之间的张力，发现了LLMs倾向于遵循RAG信息的程度与模型在无上下文情况下的回答信心成反比。研究基于跨超过1200个问题的六个领域数据集，揭示了在模型的预训练知识与检索到的信息之间的固有冲突。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.10198v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.10198.md)  |
| <span style='display: inline-block; width: 42px;'>04-16</span> | **CoTAR: Chain-of-Thought Attribution Reasoning with Multi-level Granularity**<br><sub>机构: Intel Labs<br>本文提出的CoTAR方法针对LLMs在问答任务中倾向于生成不准确归因的问题。通过在输出生成前进行推理，并在不同的归因粒度级别上引导模型，显著提升了模型在答案质量和归因精确度上的表现。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.10513v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.10513.md)  |
| <span style='display: inline-block; width: 42px;'>04-16</span> | **Self-playing Adversarial Language Game Enhances LLM Reasoning**<br><sub>机构: Tencent AI Lab<br>本论文提出了一个名为SPAG的新型训练方案，通过自我对抗性语言游戏的自我播放，有效提升了LLMs的推理能力，并且其改进是可以通过迭代过程持续增强的。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.10642v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.10642.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/Linear95/SPAG)</div> |
| <span style='display: inline-block; width: 42px;'>04-15</span> | **Learn Your Reference Model for Real Good Alignment**<br><sub>机构: Tinkoff<br>本论文提出了一个名为Trust Region DPO (TR-DPO) 的新方法，该方法通过交互式地更新参考策略的参数，显著改进了语言模型的对齐问题。实验结果显示，TR-DPO在两个数据集上均优于DPO方法，有效提升了模型的多参数性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.09656v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.09656.md)  |
| <span style='display: inline-block; width: 42px;'>04-15</span> | **Compression Represents Intelligence Linearly**<br><sub>机构: The Hong Kong University of Science and Technology, Tencent<br>这篇论文通过实证研究，证明了LLMs在下游任务性能与它们的压缩效率之间存在着几乎线性的相关性，为“更好的压缩能力表明了更高的智能”这一长期信念提供了支持。同时，提出了使用压缩效率作为评估LLMs性能的无监督度量标准的建议。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.09937v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.09937.md)  |
| <span style='display: inline-block; width: 42px;'>04-14</span> | **Emerging Platforms Meet Emerging LLMs: A Year-Long Journey of Top-Down Development**<br><sub>本论文的研究主要集中在如何支持和优化新兴计算平台下的机器学习模型部署，并提出了一个框架TAPML，旨在通过顶层方法和通用运行时环境促进模型部署的广泛性、便利性和强大性，文中提供了实际部署案例作为发展ML系统的深入见解和最佳实践。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.09151v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.09151.md)  |
| <span style='display: inline-block; width: 42px;'>04-13</span> | **Intuition-aware Mixture-of-Rank-1-Experts for Parameter Efficient Finetuning**<br><sub>机构: Nanjing University, University of California<br>论文提出了一个新的用于大型语言模型多任务微调的框架Intuition-MoR1E，该框架借鉴人类认知神经科学原理，并利用排名1专家形式来管理直觉，显著提高了参数效率和多任务微调效果。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.08985v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.08985.md)  |
| <span style='display: inline-block; width: 42px;'>04-12</span> | **Megalodon: Efficient LLM Pretraining and Inference with Unlimited Context Length**<br><sub>机构: AI at Meta, University of Southern California, Carnegie Mellon University<br>这篇论文介绍了MEGALODON，一个高效处理无限上下文长度序列的神经网络架构。通过引入多项创新技术，MEGALODON在长序列模型任务中显示出比Transformer更高的效率和效能，同时在不同规模和模态的基准测试中都取得了稳健的改进。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.08801v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.08801.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/XuezheMax/megalodon)</div> |
| <span style='display: inline-block; width: 42px;'>04-11</span> | **Rho-1: Not All Tokens Are What You Need**<br><sub>机构: Xiamen University, Tsinghua University, Microsoft<br>本文提出了RHO-1，这是一种利用选择性语言建模（SLM）的新型语言模型。该模型在预训练中专注于对有用的令牌进行训练，这种方法在数学领域的连续预训练中显示出卓越性能，能够更快地达到基线性能，并且在少量令牌的情况下达到最新的状态。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.07965v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.07965.md)  |
| <span style='display: inline-block; width: 42px;'>04-11</span> | **Interactive Prompt Debugging with Sequence Salience**<br><sub>这篇论文提出了一个名为序列显著性（Sequence Salience）的系统，它扩展了现有的输入显著性（IS）方法，以支持复杂的LLM提示调试。该工具提供实时交互式调试，并降低了实践者的认知负荷，支持根据显著性结果快速迭代提示，与开发者的思维模型更加对齐。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.07498v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.07498.md)  |
| <span style='display: inline-block; width: 42px;'>04-11</span> | **Decomposing Label Space, Format and Discrimination: Rethinking How LLMs Respond and Solve Tasks via In-Context Learning**<br><sub>机构: Nanyang Technological University<br>本文研究了ICL在提升任务性能方面的生效机制，通过分解ICL的贡献因素，发现ICL通过精细调整标签空间和格式来显著提升性能，同时强调了选择合适演示示例的重要性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.07546v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.07546.md)  |
| <span style='display: inline-block; width: 42px;'>04-11</span> | **ControlNet++: Improving Conditional Controls with Efficient Consistency Feedback**<br><sub>机构: University of Central Florida, ByteDance Inc<br>ControlNet++通过优化生成图像与条件控制之间的像素级一致性，并通过高效的奖励微调策略减少了与图像采样相关的时间和内存成本，显著改善了在多种条件控制下的可控性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.07987v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.07987.md)  |
| <span style='display: inline-block; width: 42px;'>04-11</span> | **ChatGPT Can Predict the Future when it Tells Stories Set in the Future About the Past**<br><sub>机构: Baylor University<br>本研究通过分析ChatGPT-3.5和ChatGPT-4的预测能力，揭示了LLMs在推理方面的新潜力。研究证明了“未来叙事”提示能够显著提升预测的准确性，为LLMs在分析环境中的潜在应用提供了有益见解。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.07396v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.07396.md)  |
| <span style='display: inline-block; width: 42px;'>04-11</span> | **OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments**<br><sub>机构: The University of Hong Kong, CMU, Salesforce Research<br>OSWORLD提供了一个新的评估环境，解决了现有基准测试的局限性，为开发能在真实计算机环境中完成开放式任务的多模态代理提供了基础。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.07972v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.07972.md)  |
| <span style='display: inline-block; width: 42px;'>04-10</span> | **Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention**<br><sub>机构: Google<br>该研究提出一种全新的注意力机制Infini-attention，它通过将压缩记忆与标准的点积注意力相结合，并在设计上支持插拔式的持续预训练和长上下文调整，使得LLMs能以有界的内存和计算资源处理无限长的上下文。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.07143v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.07143.md)  |
| <span style='display: inline-block; width: 42px;'>04-10</span> | **Superposition Prompting: Improving and Accelerating Retrieval-Augmented Generation**<br><sub>机构: Apple, Cupertino, CA, USA<br>该论文提出了一种新的检索增强生成（RAG）提示方法——“超级叠加提示”，用于处理大型语言模型处理长文本时遇到的问题，并在没有额外训练或微调的情况下显著提高了时间效率和准确性。这一方法在众多预训练模型上得到验证，并且作者计划发布一个开源代码实现。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.06910v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.0691.md)  |
| <span style='display: inline-block; width: 42px;'>04-10</span> | **Transferable and Efficient Non-Factual Content Detection via Probe Training with Offline Consistency Checking**<br><sub>机构: Renmin University of China, Tsinghua University<br>本论文提出了一种通过离线自我一致性检查训练探测模型的新方法PINOS，有效地解决了现有真实性检测方法的限制。PINOS提高了过程的转移能力和效率，并且在真实性检测和问答基准测试上取得了超越现有方法的结果。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.06742v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.06742.md)  |
| <span style='display: inline-block; width: 42px;'>04-10</span> | **"We Need Structured Output": Towards User-centered Constraints on Large Language Model Output**<br><sub>机构: Google Research<br>本论文探索如何为大型语言模型（LLM）输出实现用户中心的约束，通过调查行业专业人士来了解不同场景和需求。重点是提高开发者在开发、测试和整合LLM过程中的效率，并通过满足特定的输出格式和用户界面要求来增强最终用户的体验。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.07362v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.07362.md)  |
| <span style='display: inline-block; width: 42px;'>04-09</span> | **THOUGHTSCULPT: Reasoning with Intermediate Revision and Search**<br><sub>机构: UC Berkeley<br>THOUGHTSCULPT作为一个基于图的框架，通过内嵌的自我修正机制，能够让LLMs在生成新的思维节点的同时迭代地改进之前的输出，特别在需要持续修正和修改的任务中表现出卓越的能力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.05966v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.05966.md)  |
| <span style='display: inline-block; width: 42px;'>04-09</span> | **Event-enhanced Retrieval in Real-time Search**<br><sub>机构: Tencent Search, Platform and Content Group<br>EER是一种新型方法，针对实时搜索中的“语义漂移”问题，通过改进EBR模型和加入对比学习及事件三元组生成任务提升检索性能。该方法通过实验验证了其有效性，并可能为信息检索领域提供新的视角。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.05989v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.05989.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/open-event-hub/Event-enhanced_Retrieval)</div> |
| <span style='display: inline-block; width: 42px;'>04-09</span> | **RULER: What's the Real Context Size of Your Long-Context Language Models?**<br><sub>机构: NVIDIA  <br>本论文为长上下文LMs提出了新的评估工具RULER，并开源，用于测试LMs在复杂任务和长上下文理解能力上的表现，并在各种模型和任务复杂度上进行了分析，推动了长上下文LMs的未来研究。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.06654v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.06654.md)  |
| <span style='display: inline-block; width: 42px;'>04-09</span> | **Privacy Preserving Prompt Engineering: A Survey**<br><sub>机构: University of Arkansas<br>这篇调研论文为了在使用LLMs进行ICL和一般提示的过程中保护隐私，提供了一个关于在这一范畴下的隐私保护方法的系统性概述，有利于推动社区在隐私保护方面的进一步研究和探索。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.06001v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.06001.md)  |
| <span style='display: inline-block; width: 42px;'>04-08</span> | **LayoutLLM: Layout Instruction Tuning with Large Language Models for Document Understanding**<br><sub>机构: Alibaba Group, Zhejiang University<br>该论文成功提出了LayoutLLM模型及其布局指导的调整策略，显著提高了模型对文档布局信息的理解和利用，尤其在零样本文档理解任务上表现出了卓越的效果。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.05225v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.05225.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/DocumentUnderstanding)</div> |
| <span style='display: inline-block; width: 42px;'>04-08</span> | **Evaluating Interventional Reasoning Capabilities of Large Language Models**<br><sub>机构: Université de Montréal, Google DeepMind, ServiceNow Research<br>本文对大型语言模型（LLMs）因果推理能力进行了评估。通过提出干预效果预测，它主要测试LLMs在干预实验后如何更新自己对事实的理解。结果显示GPT-4在某些条件下能够准确预测干预效果，但提示设计的微小变化会显著影响其表现。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.05545v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.05545.md)  |
| <span style='display: inline-block; width: 42px;'>04-08</span> | **Know When To Stop: A Study of Semantic Drift in Text Generation**<br><sub>机构: FAIR, Meta, Anthropic<br>本文为理解和测量语言模型在长文本生成中的语义漂移现象提供了工具。通过早停和重采样-重新排序等方法，显著提高了事实准确性，并为如何平衡信息量与事实准确性提供了可能的解决策略。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.05411v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.05411.md)  |
| <span style='display: inline-block; width: 42px;'>04-08</span> | **LLM-Augmented Retrieval: Enhancing Retrieval Models Through Language Models and Doc-Level Embedding**<br><sub>机构: Meta<br>该论文成功提出并验证了一个增强型文档级嵌入的LLM-augmented检索框架，不仅通过生成合成的相关查询和标题增加了文档嵌入的上下文信息，还改进了检索模型训练的关键步骤，从而提升检索模型的性能和鲁棒性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.05825v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.05825.md)  |
| <span style='display: inline-block; width: 42px;'>04-07</span> | **Radial Networks: Dynamic Layer Routing for High-Performance Large Language Models**<br><sub>机构: Cornell University<br>本论文提出了径向网络，这是一种新型神经网络结构，通过动态层稀疏性和一个经过训练的路由模块来实现令牌级的层间路由。这不仅提高了模型的性能，还显著降低了计算和服务成本，为大型语言模型的进一步扩展提供了可能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.04900v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.049.md)  |
| <span style='display: inline-block; width: 42px;'>04-07</span> | **Prompting Large Language Models for Zero-shot Essay Scoring via Multi-trait Specialization**<br><sub>机构: Peking University<br>该研究提出了一个零样本的大型语言模型作文评分框架（MTS），通过多轮对话来为作文的不同写作特质打分，并采用最小-最大缩放和异常值截断机制来得到最终得分。MTS在准确度上显著优于直接提示评分方法，并在小型化部署中优于ChatGPT，提供了监督学习之外的零样本作文评分方案。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.04941v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.04941.md)  |
| <span style='display: inline-block; width: 42px;'>04-04</span> | **Direct Nash Optimization: Teaching Language Models to Self-Improve with General Preferences**<br><sub>机构: Microsoft Research<br>这篇论文介绍了DNO——一种能够将对比学习的简洁性与从优化一般性偏好而来的理论普适性相结合的算法。DNO在后训练大型语言模型方面显著提升性能，它的成功实证了通过优化一般偏好来指导模型学习与人类价值观保持一致是可能的。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.03715v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.03715.md)  |
| <span style='display: inline-block; width: 42px;'>04-04</span> | **ReFT: Representation Finetuning for Language Models**<br><sub>机构: Stanford University, Pr(Ai)2R Group<br>这篇论文介绍了一种新的语言模型微调方法LoReFT，它在资源效率和模型控制能力方面显著优于现有的参数有效调整（PEFTs）方法。实验表明，该方法在多个NLP领域的任务上实现了新的最佳性能，同时保持了较少的参数需求和较高的可解释性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.03592v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.03592.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/stanfordnlp/pyreft)</div> |
| <span style='display: inline-block; width: 42px;'>04-04</span> | **AutoWebGLM: Bootstrap And Reinforce A Large Language Model-based Web Navigating Agent**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.03648v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.03648.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/THUDM/AutoWebGLM)</div> |
| <span style='display: inline-block; width: 42px;'>04-03</span> | **PromptRPA: Generating Robotic Process Automation on Smartphones from Textual Prompts**<br><sub>机构: Shanghai Jiao Tong University, CMU<br>文章介绍了PromptRPA系统，这是一个解决RPA在移动设备上应用受限的有效方案。通过利用多代理框架和在线教程，该系统能够解释各种文本提示，解决大范围的RPA任务。性能评估显示成功率显著提高，证明了文本驱动控制在RPA领域的可行性，并开辟了功能增强和适用性扩展的新方向。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.02475v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.02475.md)  |
| <span style='display: inline-block; width: 42px;'>04-02</span> | **CMAT: A Multi-Agent Collaboration Tuning Framework for Enhancing Small Language Models**<br><sub>机构: East China Jiaotong University, Guangdong University of Technology, University of Toronto<br>该论文的核心贡献是提出了CMAT框架，这是一种创新方法，可实现多智能体系统内部的动态、实时记忆更新，并设计了一种新型的角色扮演机制，用于精准的任务分配和提升代理间的通信，以此显著提高整体性能和合作效率。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.01663v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.01663.md)  |
| <span style='display: inline-block; width: 42px;'>04-02</span> | **Octopus v2: On-device language model for super agent**<br><sub>机构: Stanford University<br>这篇论文解决了边缘设备上LLM的部署和功能调用效率问题，通过引入特殊的训练方法和减少推理时需处理的上下文量，显著提高了在设备上进行函数调用的准确率和降低了延迟，实验结果表明其对提升函数调用任务的性能具有显著影响。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.01744v3)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.01744.md)  |
| <span style='display: inline-block; width: 42px;'>04-02</span> | **Long-context LLMs Struggle with Long In-context Learning**<br><sub>机构: University of Waterloo, Carnegie Mellon University<br>这篇文章提出了一个新的评估基准，LongICLBench，用于评估LLMs在处理长输入任务时的性能，以及LLMs对输入序列中实例位置的敏感性。这一工作有助于更好地理解和改进大型语言模型在长文本处理方面的能力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.02060v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.0206.md)  |
| <span style='display: inline-block; width: 42px;'>04-02</span> | **LLM-ABR: Designing Adaptive Bitrate Algorithms via Large Language Models**<br><sub>机构: Microsoft<br>论文探讨了大型语言模型（LLMs）如何辅助设计自适应比特率（ABR）算法，通过生成多样化的候选算法，并运用早停机制在网络模拟器中进行测试，从而有效地筛选出最有效的算法设计。评估显示在特定网络场景中，利用LLMs可以显著提高ABR算法的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.01617v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.01617.md)  |
| <span style='display: inline-block; width: 42px;'>04-02</span> | **Advancing LLM Reasoning Generalists with Preference Trees**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.02078v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.02078.md)  |
| <span style='display: inline-block; width: 42px;'>04-02</span> | **Long-context LLMs Struggle with Long In-context Learning**<br><sub>机构: University of Waterloo, Carnegie Mellon University<br>这项研究为评估大型语言模型处理长上下文任务的能力提供了一个新的基准——LongICLBench，并显示了随着任务难度增加，LLMs的性能普遍下降，并且模型的长上下文学习能力受到提示中标签位置分布的影响。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.02060v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.0206.md)  |
| <span style='display: inline-block; width: 42px;'>04-01</span> | **AIOps Solutions for Incident Management: Technical Guidelines and A Comprehensive Literature Review**<br><sub>机构: University of Lyon, INSA Lyon, Infologic<br>本文提供了 AIOps 领域中事件管理的全面文献回顾，旨在通过提供结构化的知识、确定知识空白和为该领域的未来发展奠定基础。论文建立了 AIOps 的统一术语和分类法，揭示了现有的挑战，并提供了公开数据集，为未来的研究提供了方向和基础。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.01363v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.01363.md)  |
| <span style='display: inline-block; width: 42px;'>04-01</span> | **Mapping the Increasing Use of LLMs in Scientific Papers**<br><sub>机构: Stanford University, UC Santa Barbara<br>本文是首次进行的，跨arXiv、bioRxiv和Nature组合上发表的文章的系统性、大规模分析，采用的统计估计方法可以在群体层面上测量LLM修改内容的普及程度，为理解LLM在科学写作中的应用提供了宝贵的洞察。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.01268v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.01268.md)  |
| <span style='display: inline-block; width: 42px;'>04-01</span> | **Prompt-prompted Mixture of Experts for Efficient LLM Generation**<br><sub>机构: CMU<br>GRIFFIN是一个不需要训练的MoE系统，利用LLMs前馈块内的flocking现象在不同的激活函数下提高模型效率，保持性能的同时减少了计算成本。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.01365v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.01365.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/hdong920/GRIFFIN)</div> |
| <span style='display: inline-block; width: 42px;'>04-01</span> | **Efficiently Distilling LLMs for Edge Applications**<br><sub>机构: IBM Research  <br>本论文提供了一种新的针对边缘设备进行LLMs蒸馏的方法，允许LPFT同时显著减少模型尺寸和训练成本，尤其是优化了解码器模型的压缩抵抗和训练时长。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.01353v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.01353.md)  |
| <span style='display: inline-block; width: 42px;'>04-01</span> | **LLM-RadJudge: Achieving Radiologist-Level Evaluation for X-Ray Report Generation**<br><sub>机构: Microsoft Research Asia<br>这篇论文提出了一个基于大型语言模型的放射学报告评价新框架——LLM-RadJudge，能够有效提高放射学报告评价的临床相关性和一致性。并通过知识蒸馏技术实现了小型模型的开发，既降低了评价成本也提高了可访问性，为放射学报告生成研究和实际应用提供了有力的支撑。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.00998v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.00998.md)  |

---

### 03月

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>03-28</span> | **Jamba: A Hybrid Transformer-Mamba Language Model**<br><sub>机构: AI21 Labs<br>Jamba是基于混合Transformer-Mamba体系结构的新型大型语言模型，突破了处理长上下文的限制，并且通过应用专家混合（MoE）组件提高了模型吞吐量，同时保持了较小的内存足迹。此模型标志着在大型语言模型领域的一个新方向，并展示了高效训练与强大性能之间的可能平衡。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.19887v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.19887.md)  |
| <span style='display: inline-block; width: 42px;'>03-28</span> | **sDPO: Don't Use Your Data All at Once**<br><sub>此论文提出了一个新的步骤化DPO（sDPO）方法，通过分步骤利用偏好数据集，并使用先前步骤中的对齐模型作为当前步骤的参考模型，有效提高了最终模型的性能与对齐度。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.19270v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.1927.md)  |
| <span style='display: inline-block; width: 42px;'>03-27</span> | **Rejection Improves Reliability: Training LLMs to Refuse Unknown Questions Using RL from Knowledge Feedback**<br><sub>这项工作通过提出RLKF框架并定义了新的模型可靠性评估指标，有效地解决了LLMs的幻觉问题，并提升了LLMs的诚实度和可靠性，显示出打造更值得信赖的AI系统的潜力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.18349v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.18349.md)  |
| <span style='display: inline-block; width: 42px;'>03-27</span> | **BLADE: Enhancing Black-box Large Language Models with Small Domain-Specific Models**<br><sub>机构: DCST Tsinghua University, Beijing Institute of Technology, Huawei Cloud BU<br>这项研究提出了一个新架构BLADE，可以通过小型领域特定模型增强黑盒大型语言模型，并解决了大型模型在特定领域应用中的知识不足问题。BLADE证明了其在性能和成本上都是一个有效的解决方案。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.18365v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.18365.md)  |
| <span style='display: inline-block; width: 42px;'>03-26</span> | **COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning**<br><sub>机构: Shenzhen Institute of Advanced Technology, CAS; M-A-P; Institute of Automation, CAS<br>本文提出了COIG-CQIA数据集，这是一个针对中文指令调优的高质量数据集，能够促进与人类交互的对齐。研究强调了高质量数据源在模型微调中的重要性，并通过实验展示了数据集创建策略和微调方法对模型性能的显著影响。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.18058v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.18058.md)  |
| <span style='display: inline-block; width: 42px;'>03-26</span> | **LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning**<br><sub>机构: The Hong Kong University of Science and Technology, University of Illinois Urbana-Champaign<br>这篇论文提出的LISA策略，通过分层权重重要性采样，实现了在保持类似于LoRA的内存效率的同时，提升了大型语言模型的微调效率和性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.17919v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.17919.md)  |
| <span style='display: inline-block; width: 42px;'>03-26</span> | **The Unreasonable Ineffectiveness of the Deeper Layers**<br><sub>机构: Meta FAIR, UMD<br>本论文针对流行的开权重预训练LLMs提出了一种简单的层剪枝策略，并展示了在删除大量层后LLMs对性能影响较小的实证研究。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.17887v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.17887.md)  |
| <span style='display: inline-block; width: 42px;'>03-25</span> | **AIOS: LLM Agent Operating System**<br><sub>机构: Rutgers University  <br>AIOS作为一个LLM代理操作系统，通过设计特定的内核和模块，克服了之前资源调度和上下文管理等领域的挑战，为LLM代理的性能和效率提供了改进，为AIOS生态系统的未来发展和部署铺平了道路。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.16971v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.16971.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/agiresearch/AIOS)</div> |
| <span style='display: inline-block; width: 42px;'>03-22</span> | **Can large language models explore in-context?**<br><sub>机构: Microsoft Research, Carnegie Mellon University<br>这篇论文调查了当代大型语言模型（LLMs）能否在上下文中从事探索的问题，特别是在没有训练干预的情况下。经过一系列实验，作者发现只有在特定的配置下LLMs才能稳健地进行探索。研究表明，没有适当的提示设计，即使是最先进的LLMs也可能无法在更复杂的环境中进行探索，而在这些环境中外部总结历史可能是一个非平凡的算法设计问题。这项工作提示了LLMs可能需要有针对性的算法干预才能在复杂环境中有效地工作。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.15371v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.15371.md)  |
| <span style='display: inline-block; width: 42px;'>03-20</span> | **Chain-of-Interaction: Enhancing Large Language Models for Psychiatric Behavior Understanding by Dyadic Contexts**<br><sub>机构: University of Memphis, San Francisco Veterans Affairs Health Care System, University of California San Francisco<br>本文通过引入互动链提示方法，有效地提升了大型语言模型在理解精神病行为方面的能力，特别是在动机面谈语境下的应用。通过结构化的提示和评估方法，能够模拟专业心理治疗人员的思维过程，对模型进行了有效的域知识教育，相比传统方法取得了更好的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.13786v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.13786.md)  |
| <span style='display: inline-block; width: 42px;'>03-19</span> | **Towards Robots That Know When They Need Help: Affordance-Based Uncertainty for Large Language Model Planners**<br><sub>机构: University of Maryland  <br>论文提出了一种新方法LAP，通过结合大型语言模型(LLMs)和场景可以供性来减少规划任务中的幻觉并实现不确定性对齐。通过在模拟和现实世界机器人操作任务的实验中表明，LAP可以显著提高成功率并减少对人类帮助的依赖，从而推动智能机器人领域的进步。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.13198v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.13198.md)  |
| <span style='display: inline-block; width: 42px;'>03-18</span> | **Decoding Compressed Trust: Scrutinizing the Trustworthiness of Efficient LLMs Under Compression**<br><sub>机构: University of Texas at Austin, Drexel University, MIT<br>本文首次对经过压缩的LLMs在多个信任维度上进行了全面评估，并提供了压缩时同时考虑效率和信任度的实用建议。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.15447v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.15447.md)  |
| <span style='display: inline-block; width: 42px;'>03-15</span> | **Uni-SMART: Universal Science Multimodal Analysis and Research Transformer**<br><sub>机构: DP Technology, AI for Science Institute Beijing<br>Uni-SMART 是一款创新的模型，旨在深入理解多模态科学文献，它在多个领域相对于其他顶尖文本焦点的 LLMs 显示出了更优越的性能，并有潜力改变我们与科学文献的互动方式。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.10301v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.10301.md)  |
| <span style='display: inline-block; width: 42px;'>03-15</span> | **VideoAgent: Long-form Video Understanding with Large Language Model as Agent**<br><sub>机构: Stanford University<br>VideoAgent通过模仿人类的认知过程，在长视频理解方面迈出了重要的一步，强调了在长时间跨度内对视觉信息进行推理的重要性。此工作不仅为长视频理解设立了新的基准，也为未来该方向的研究提供了启示。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.10517v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.10517.md)  |
| <span style='display: inline-block; width: 42px;'>03-15</span> | **RAFT: Adapting Language Model to Domain Specific RAG**<br><sub>机构: UC Berkeley<br>本论文提出的RAFT方法针对训练大型语言模型在特定领域内以“开卷”模式回答问题进行了创新，强化了模型的推理能力和对干扰文档的抵抗力，同时通过链式推理方式改进了模型生成解答的准确性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.10131v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.10131.md)  |
| <span style='display: inline-block; width: 42px;'>03-13</span> | **Call Me When Necessary: LLMs can Efficiently and Faithfully Reason over Structured Environments**<br><sub>机构: Nanjing University, Microsoft<br>Readi框架提出了一种高效并真实地在大规模结构化环境中进行推理的方法，它充分发挥了LLMs的规划能力，并通过动态反馈优化推理路径，实现了在多跳推理任务中的显著改进。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.08593v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.08593.md)  |
| <span style='display: inline-block; width: 42px;'>03-13</span> | **Steering LLMs Towards Unbiased Responses: A Causality-Guided Debiasing Framework**<br><sub>机构: ByteDance Research, University of Maryland College Park, Carnegie Mellon University<br>该论文成功提出了一个新的因果关系引导的去偏见框架，并通过实证研究验证了其有效性，既可以整合现有的基于提示的去偏见方法，也为诱导无偏见推理提出了新的途径。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.08743v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.08743.md)  |
| <span style='display: inline-block; width: 42px;'>03-13</span> | **Scaling Instructable Agents Across Many Simulated Worlds**<br><sub>此论文提出的SIMA项目旨在创建一个能够在各种模拟3D环境中根据任意语言指令进行操作的AI系统。该系统的设计致力于解决在感知和体化行动中具体化语言的挑战，以及在许多不同环境中实现通用性和可扩展性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.10179v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2404.10179.md)  |
| <span style='display: inline-block; width: 42px;'>03-12</span> | **Chronos: Learning the Language of Time Series**<br><sub>机构: Amazon Web Services, UC San Diego, University of Freiburg<br>Chronos作为一个预训练的时间序列预测模型框架，在零样本和标准预测任务中表现出色。它利用了数据增强策略和公共数据集的优势，证实了时间序列预测中语言模型架构通用性的潜力，为将来的时间序列模型提供了新的研究方向。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.07815v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.07815.md)  |
| <span style='display: inline-block; width: 42px;'>03-11</span> | **RA-ISF: Learning to Answer and Understand from Retrieval Augmentation via Iterative Self-Feedback**<br><sub>机构: Zhejiang University, Southeast University, Massachusetts Institute of Technology<br>RA-ISF是一个创新的检索增强框架，通过迭代问题分解和三个子模块的迭代处理来提高LLMs的问题解决能力，并有效降低不相关文本的干扰，显著提升知识检索的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.06840v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.0684.md)  |
| <span style='display: inline-block; width: 42px;'>03-11</span> | **ERA-CoT: Improving Chain-of-Thought through Entity Relationship Analysis**<br><sub>机构: Zhejiang University, Southeast University<br>该论文通过提出一种新的框架ERA-CoT，有效强化了大型语言模型在复杂实体场景中的推理和问题回答能力。该方法通过增强对实体关系的理解，实现了显著提升模型推理准确度，特别是在CoT推理过程中。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.06932v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.06932.md)  |
| <span style='display: inline-block; width: 42px;'>03-11</span> | **Stealing Part of a Production Language Model**<br><sub>机构: Google DeepMind, ETH Zurich, University of Washington<br>本文提出了一项对生产语言模型进行模型窃取的新攻击方法，该方法能够有效地提取Transformer模型的最后一层，并能用于解密黑盒模型的细节信息、参数和尺寸。文章还讨论了可能的防御措施，并指出了修改API以防止未来此类攻击的必要性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.06634v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.06634.md)  |
| <span style='display: inline-block; width: 42px;'>03-08</span> | **Overcoming Reward Overoptimization via Adversarial Policy Optimization with Lightweight Uncertainty Estimation**<br><sub>这篇论文介绍了Adversarial Policy Optimization (AdvPO)，它是解决基于人类反馈的强化学习过程中出现的奖励过优化问题的新方法，特别是在与人类偏好对齐的大型语言模型中。AdvPO有效地在没有带来高额计算成本的情况下缓解了奖励过优化。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.05171v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.05171.md)  |
| <span style='display: inline-block; width: 42px;'>03-08</span> | **Harnessing Multi-Role Capabilities of Large Language Models for Open-Domain Question Answering**<br><sub>机构: Gaoling School of Artificial Intelligence Renmin University of China, Nankai University, Beijing Academy of Artificial Intelligence<br>LLMQA是一个新的通用框架模型，通过结合检索和生成范式搜集更高质量的证据，并让LLMs在框架中发挥多重角色，提高了开放域问答系统的整体性能，实验结果也证明了其超越现有方法的有效性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.05217v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.05217.md)  |
| <span style='display: inline-block; width: 42px;'>03-08</span> | **Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context**<br><sub>机构: Google<br>Gemini 1.5 Pro在记忆与推理海量长上下文信息的能力上取得了显著突破，尤其是在超长文本、视频和音频处理方面。该模型不仅在效果上优于现有模型，也在计算效率上有显著提高。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.05530v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.0553.md)  |
| <span style='display: inline-block; width: 42px;'>03-07</span> | **Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference**<br><sub>机构: UC Berkeley, Stanford, UCSD<br>Chatbot Arena是一个基于用户偏好，用于评估大型语言模型的开放平台。它通过众包方式收集用户问题并进行匿名化的随机化对决，用于评估LLMs的表现，解决了现有静态数据集基准测试的局限性，并通过精心设计的统计方法确保了评估结果的可信度和效率。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.04132v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.04132.md)  |
| <span style='display: inline-block; width: 42px;'>03-07</span> | **Yi: Open Foundation Models by 01.AI**<br><sub>机构: 01.AI<br>该论文成功地提出了一个在性能和效率上都可与GPT-3.5相媲美的Yi-34B模型，并详细描述了在大型语言模型预训练及其指令微调方面的创新方法。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.04652v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.04652.md)  |
| <span style='display: inline-block; width: 42px;'>03-05</span> | **Design2Code: How Far Are We From Automating Front-End Engineering?**<br><sub>机构: Stanford University, Georgia Tech, Microsoft<br>本文通过对Design2Code任务的形式化和基准测试，评估了当前多模态LLMs在将视觉设计转换为代码的能力，并发现GPT-4V表现最佳，为自动化前端开发提供了一种新的范式。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.03163v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.03163.md)  |
| <span style='display: inline-block; width: 42px;'>03-05</span> | **ChatCite: LLM Agent with Human Workflow Guidance for Comparative Literature Summary**<br><sub>机构: Tsinghua University<br>ChatCite系统是为了克服LLM在生成文献回顾时的挑战而设计的，它通过特定的模块使LLM代理可以更有效地理解、汇总和对比不同的研究工作，进而生成有组织、有比较性分析的文献回顾。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.02574v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.02574.md)  |
| <span style='display: inline-block; width: 42px;'>03-05</span> | **MathScale: Scaling Instruction Tuning for Mathematical Reasoning**<br><sub>机构: The Chinese University of Hong Kong Shenzhen, China; Microsoft Research Asia, Beijing, China; Shenzhen Research Institute of Big Data, Shenzhen, China<br>MathScale提出了一个可扩展的方法来创建高质量的数学推理数据，通过构建新的评估基准MWPBENCH全面地评价LLMs在数学推理上的能力，显著提升了模型解决数学问题的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.02884v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.02884.md)  |

---

### 02月

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>02-29</span> | **StarCoder 2 and The Stack v2: The Next Generation**<br><sub>机构: ServiceNow, Hugging Face  <br>本论文提出了The Stack v2和StarCoder2的发展过程，这是基于代码大规模预训练和指令微调的一项工作。研究人员通过整合多样化数据源和经过精心设计的训练过程，显著提高了代码LLMs的性能，特别是在处理低资源编程语言和需要代码推理的任务上。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.19173v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.19173.md)  |
| <span style='display: inline-block; width: 42px;'>02-29</span> | **SEED: Customize Large Language Models with Sample-Efficient Adaptation for Code Generation**<br><sub>机构: Peking University<br>本文提出了一个名为SEED的适应方法，它利用错误驱动学习来使LLMs更少样本地高效学习，针对代码生成任务实现了更佳的性能和泛化性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.00046v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2403.00046.md)  |
| <span style='display: inline-block; width: 42px;'>02-29</span> | **Beyond Language Models: Byte Models are Digital World Simulators**<br><sub>机构: Microsoft Research Asia<br>论文展现了bGPT在处理挑战性的字节级数据模拟任务中的潜力，特别强调了其在跨模态知识转移和数字世界模拟方面的能力。这揭示了字节模型在数字媒体数据处理和理解上的广泛适用性和灵活性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.19155v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.19155.md)  |
| <span style='display: inline-block; width: 42px;'>02-29</span> | **Resonance RoPE: Improving Context Length Generalization of Large Language Models**<br><sub>机构: 1DIRO Université de Montréal, Mila - Quebec AI Institute, Huawei Noah’s Ark Lab<br>本论文提出了 Resonance Rope，这是一个改进的模型，它基于对 RoPE 位置嵌入特征波长的分析来提升模型在处理长文本时的性能。它还引入了 POSGEN 基准测试，以帮助研究和评估位置嵌入在长文本任务中的表现。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.00071v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2403.00071.md)  |
| <span style='display: inline-block; width: 42px;'>02-27</span> | **EMO: Emote Portrait Alive -- Generating Expressive Portrait Videos with Audio2Video Diffusion Model under Weak Conditions**<br><sub>机构: Alibaba Group  <br>EMO 框架通过直接的音频到视频合成方法提高了生成视频的真实感和表现力，显著优于现有技术，为视频合成领域提供了一个重要的进步。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.17485v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.17485.md)  |
| <span style='display: inline-block; width: 42px;'>02-27</span> | **The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits**<br><sub>机构: Microsoft, University of Chinese Academy of Sciences<br>论文提出BitNet b1.58模型，这是一个1.58比特量化的大型语言模型，与传统的完整精度LLMs在性能上可比，而且更高效、更节省能源。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.17764v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.17764.md)  |
| <span style='display: inline-block; width: 42px;'>02-27</span> | **When Scaling Meets LLM Finetuning: The Effect of Data, Model and Finetuning Method**<br><sub>机构: Google DeepMind<br>该论文提供了大型语言模型微调阶段不同因素如数据大小、模型大小以及微调方法对模型性能影响的深入洞见，定义了一种新的评估框架。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.17193v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.17193.md)  |
| <span style='display: inline-block; width: 42px;'>02-27</span> | **REAR: A Relevance-Aware Retrieval-Augmented Framework for Open-Domain Question Answering**<br><sub>机构: Gaoling School of Artificial Intelligence Renmin University of China, School of Information Renmin University of China<br>该论文提出了REAR框架，重点在于通过为LLMs加入文档相关性自我意识来增强其在QA任务中利用外部知识的能力，并证实该框架有效地超越了前述方法。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.17497v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.17497.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/RUCAIBox/REAR)</div> |
| <span style='display: inline-block; width: 42px;'>02-27</span> | **Agent-Pro: Learning to Evolve via Policy-Level Reflection and Optimization**<br><sub>机构: Zhejiang University, Institute of Software Chinese Academy of Sciences, Nanjing University of Posts and Telecommunications<br>Agent-Pro是一个新型的基于LLM的智能代理，能够通过政策级反思和优化在交互环境中学习和发展策略，解决了现有工作无法通过交互学习和适应的问题。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.17574v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.17574.md)  |
| <span style='display: inline-block; width: 42px;'>02-27</span> | **Sora: A Review on Background, Technology, Limitations, and Opportunities of Large Vision Models**<br><sub>机构: OpenAI<br>本文是一篇对Sora——一个大型视觉模型的综述。论文讨论了Sora的技术特征、创新点、以及当前应用领域的局限性和未来可能的发展机会。Sora的能力在多个维度上展现了大型视觉模型的进步，包括长视频生成和多样化视频格式的处理。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.17177v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.17177.md)  |
| <span style='display: inline-block; width: 42px;'>02-26</span> | **Improving LLM-based Machine Translation with Systematic Self-Correction**<br><sub>机构: Zhejiang University, Tencent, Angelalign Technology Inc.<br>论文成功提出了第一个基于LLMs的自我纠正翻译框架TER，并验证了其在多种语言对和不同模型间的翻译质量改进效果。它为机器翻译领域带来了新的视角，特别是在自我纠正在高资源、低资源语言和不同中心语言之间翻译的应用。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.16379v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.16379.md)  |
| <span style='display: inline-block; width: 42px;'>02-26</span> | **Do Large Language Models Latently Perform Multi-Hop Reasoning?**<br><sub>机构: Google DeepMind, UCL, Google Research<br>本文对LLMs是否能够进行潜在的多跳推理进行了研究，并通过实验提出了评估LLMs潜在多跳推理能力的新方法。研究提示LLMs对某些关系类型的提示有很强的多跳推理证据，但这种推理路径的运用在不同类型的提示中表现出高度的情境依赖性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.16837v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.16837.md)  |
| <span style='display: inline-block; width: 42px;'>02-26</span> | **LLMArena: Assessing Capabilities of Large Language Models in Dynamic Multi-Agent Environments**<br><sub>研究介绍了LLMARENA基准，用以评估LLMs智能体在复杂多代理环境中的能力，指出了存在的问题并促进了未来的研究方向，包括多模态动态环境中的能力及利用外部工具的潜力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.16499v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.16499.md)  |
| <span style='display: inline-block; width: 42px;'>02-25</span> | **ChatMusician: Understanding and Generating Music Intrinsically with LLM**<br><sub>机构: Hong Kong University of Science and Technology<br>本文通过创造首个针对语言模型的音乐预训练数据集和评估基准，提升了LLMs在音乐理解和生成方面的表现，并在这一未被深入研究的领域取得了实质性进展。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.16153v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.16153.md)  |
| <span style='display: inline-block; width: 42px;'>02-23</span> | **ChunkAttention: Efficient Self-Attention with Prefix-Aware KV Cache and Two-Phase Partition**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.15220v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.1522.md)  |
| <span style='display: inline-block; width: 42px;'>02-23</span> | **Genie: Generative Interactive Environments**<br><sub>机构: Google DeepMind, University of British Columbia<br>Genie是能够生成新视频并能通过用户输入控制视频内容的交互环境模型，弥补了传统视频生成技术与交互体验之间的差距。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.15391v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.15391.md)  |
| <span style='display: inline-block; width: 42px;'>02-22</span> | **Automating psychological hypothesis generation with AI: when large language models meet causal graph**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.14424v3)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.14424.md)  |
| <span style='display: inline-block; width: 42px;'>02-22</span> | **Middleware for LLMs: Tools Are Instrumental for Language Agents in Complex Environments**<br><sub>通过为LLMs设计特定的工具和推理算法，研究开发了名为FUXI的新框架，有效提高了LLMs在复杂环境中的操作能</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.14672v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.14672.md)  |
| <span style='display: inline-block; width: 42px;'>02-22</span> | **CriticBench: Benchmarking LLMs for Critique-Correct Reasoning**<br><sub>机构: Tsinghua University, University of Hong Kong<br>该论文通过CRITICBENCH评估了LLMs的批判和纠正推理能力，并探究了影响这些能力的关键因子，旨在促进LLMs批判和自我改进能力的后续研究。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.14809v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.14809.md)  |
| <span style='display: inline-block; width: 42px;'>02-22</span> | **OpenCodeInterpreter: Integrating Code Generation with Execution and Refinement**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.14658v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.14658.md)  |
| <span style='display: inline-block; width: 42px;'>02-21</span> | **User-LLM: Efficient LLM Contextualization with User Embeddings**<br><sub>USER-LLM是一个通过用户嵌入来上下文化LLM的框架。它能有效地解决用户数据的复杂性和长序列处理的问题，提升了LLM在个性化应用上的效能，同时也保证了计算效率。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.13598v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.13598.md)  |
| <span style='display: inline-block; width: 42px;'>02-21</span> | **AgentScope: A Flexible yet Robust Multi-Agent Platform**<br><sub>机构: Alibaba Group<br>AgentScope是一个用于构建多代理应用的多功能平台，强调易用性与可定制性，特别适合不同技能水平的开发者使用。通过实现容错和支持多模态数据处理，以及优化分布式操作，AgentScope显著降低了多代理系统开发与部署的难度，鼓励更广泛的参与和创新。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.14034v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.14034.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/modelscope/agentscope)</div> |
| <span style='display: inline-block; width: 42px;'>02-20</span> | **TofuEval: Evaluating Hallucinations of LLMs on Topic-Focused Dialogue Summarization**<br><sub>机构: AWS AI Labs, The University of Texas at Austin, KAIST<br>本论文提出了一个名为TOFUEVAL的新型评估基准，针对LLM在生成话题焦点对话摘要时的事实一致性进行了评估。研究发现，不同大小的LLM在对话领域生成的摘要中存在大量事实错误。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.13249v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.13249.md)  |
| <span style='display: inline-block; width: 42px;'>02-20</span> | **Instruction-tuned Language Models are Better Knowledge Learners**<br><sub>机构: FAIR at Meta, Carnegie Mellon University, University of Washington<br>本文介绍了一种名为预指令微调（PIT）的方法，有效地提高了LLMs从文档中吸收知识的能力，解决了所谓的困惑度诅咒问题，并且在多域的知识获取中也取得了显著进展。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.12847v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.12847.md)  |
| <span style='display: inline-block; width: 42px;'>02-19</span> | **AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling**<br><sub>机构: Fudan University, Multimodal Art Projection Research Community, Shanghai AI Laboratory<br>AnyGPT 是一个多模态架构的语言模型，通过离散序列建模，能够实现不同模态间的无缝转换和统一处理，提供任意到任意模态之间的生成能力，同时不需要改变现有的 LLM 架构或训练范式。该模型通过在语义和感知水平进行建模，能有效处理和生成高质量的多模态内容，并且与专业模型相比具有可比较的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.12226v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.12226.md)  |
| <span style='display: inline-block; width: 42px;'>02-16</span> | **SPAR: Personalized Content-Based Recommendation via Long Engagement Attention**<br><sub>机构: The University of British Columbia, Meta<br>SPAR框架充分利用长期用户互动历史来提升个性化内容推荐的精度，并在多项性能指标上超越现有技术。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.10555v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.10555.md)  |
| <span style='display: inline-block; width: 42px;'>02-16</span> | **FinTral: A Family of GPT-4 Level Multimodal Financial Large Language Models**<br><sub>机构: The University of British Columbia & Invertible AI<br>该论文提出了一个针对财务分析优化的多模态大型语言模型（LLM）套件FinTral。通过与现有模型的对比，展示了其在财务领域多任务环境下的先进性能，特别是在处理零样本任务和减少幻觉现象方面的能力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.10986v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.10986.md)  |
| <span style='display: inline-block; width: 42px;'>02-16</span> | **Speculative Streaming: Fast LLM Inference without Auxiliary Models**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.11131v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.11131.md)  |
| <span style='display: inline-block; width: 42px;'>02-15</span> | **How to Train Data-Efficient LLMs**<br><sub>机构: Google DeepMind, University of California San Diego, Texas A&M University<br>论文提出的ASK-LLM和DENSITY技术优化了大型语言模型的数据效率，有效提升了模型训练的速度和质量，并在资源限制下表现出色。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.09668v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.09668.md)  |
| <span style='display: inline-block; width: 42px;'>02-15</span> | **A Human-Inspired Reading Agent with Gist Memory of Very Long Contexts**<br><sub>机构: Google DeepMind, Google Research<br>ReadAgent 是一个受人类阅读方式启发的LLM代理系统，通过创建摘要记忆并根据需要检索信息来解决长文本任务，显著提高了模型的表现和伸缩性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.09727v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.09727.md)  |
| <span style='display: inline-block; width: 42px;'>02-15</span> | **Chain-of-Thought Reasoning Without Prompting**<br><sub>机构: Google DeepMind<br>这项工作揭示了通过改变解码策略，可以有效地从预训练的LLMs中自然地引发推理，并且在预训练数据中频繁出现的任务上CoT路径更常见。提出的CoT解码方法无需手动引导，就能显著提高各种推理基准上的模型性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.10200v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.102.md)  |
| <span style='display: inline-block; width: 42px;'>02-14</span> | **Premise Order Matters in Reasoning with Large Language Models**<br><sub>机构: Google DeepMind<br>这篇论文关注于大型语言模型在处理推理任务时，前提顺序的影响，并通过创建R-GSM基准测试来评估这一现象。研究揭示了LLMs对前提顺序极为敏感，性能受顺序影响显著。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.08939v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.08939.md)  |
| <span style='display: inline-block; width: 42px;'>02-09</span> | **InternLM-Math: Open Math Large Language Models Toward Verifiable Reasoning**<br><sub>机构: Shanghai AI Laboratory, Tsinghua University, Fudan University School of Computer Science<br>InternLM-Math模型是一种基于LLMs的数学推理工具，它整合了多种能力并提供了监督学习以帮助模型在各种数学推理任务中实现最先进的性能，并开源其代码和数据。论文还探讨了利用程序语言LEAN在多任务学习设置中解决数学问题的新方法，彰显了LLMs在形式化和代码辅助推理中的潜能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.06332v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.06332.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/InternLM/InternLM-Math)</div> |
| <span style='display: inline-block; width: 42px;'>02-02</span> | **Reasoning Capacity in Multi-Agent Systems: Limitations, Challenges and Human-Centered Solutions**<br><sub>机构: Megagon Labs, Carnegie Mellon University<br>本论文提出了多代理系统中的“推理能力”概念，以改善优化和评估，并探讨了利用人类反馈增强系统推理能力的可能性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.01108v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.01108.md)  |
| <span style='display: inline-block; width: 42px;'>02-02</span> | **LimSim++: A Closed-Loop Platform for Deploying Multimodal LLMs in Autonomous Driving**<br><sub>机构: Shanghai Artificial Intelligence Laboratory, College of Control Science and Engineering Zhejiang University<br>LimSim++是首个专为(M)LLM支持的自动驾驶而开发的封闭循环评估平台。它解决了现有仿真平台的局限性，并通过实验验证了其在多种复杂交通场景中的有效性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.01246v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.01246.md)  |
| <span style='display: inline-block; width: 42px;'>02-02</span> | **AMOR: A Recipe for Building Adaptable Modular Knowledge Agents Through Process Feedback**<br><sub>机构: Tsinghua University, Ant Group<br>AMOR框架综合了基于有限状态机（FSM）的推理逻辑和过程反馈机制，展示了基于开源LLM的知识代理如何通过人类监督实现推理和适应性，提高了模型在完成知识密集任务中的能力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.01469v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.01469.md)  |
| <span style='display: inline-block; width: 42px;'>02-02</span> | **K-Level Reasoning with Large Language Models**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.01521v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.01521.md)  |
| <span style='display: inline-block; width: 42px;'>02-02</span> | **MAGDi: Structured Distillation of Multi-Agent Interaction Graphs Improves Reasoning in Smaller Language Models**<br><sub>机构: UNC Chapel Hill.<br>本论文介绍了名为MAGDI的新方法，它通过结构化蒸馏方式将多LLM之间的推理交互蒸馏到更小的模型中，显著提升小模型的推理能力和泛化能力，同时降低了成本。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.01620v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.0162.md)  |
| <span style='display: inline-block; width: 42px;'>02-01</span> | **Don't Hallucinate, Abstain: Identifying LLM Knowledge Gaps via Multi-LLM Collaboration**<br><sub>机构: University of Washington, University of California Berkeley, The Hong Kong University of Science and Technology<br>本文关注的是如何在大型语言模型(LLMs)中识别知识差距并在必要时放弃回答问题。研究提出了两种基于多LLM合作的新方法，通过对比实验显示它们能有效提高LLMs放弃生成低信心输出的能力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.00367v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.00367.md)  |
| <span style='display: inline-block; width: 42px;'>02-01</span> | **HR-MultiWOZ: A Task Oriented Dialogue (TOD) Dataset for HR LLM Agent**<br><sub>机构: Amazon, University of Milano-Bicocca<br>本文介绍了一个新的针对人力资源领域的大语言模型代理（HR LLM Agent）任务的对话数据集，HR-MultiWOZ。它不仅解决了当前在构建和评估HR领域LLM代理时缺乏高质量训练数据集的问题，还提供了一个经济高效的数据集生成方法，为同领域中的其他研究提供了宝贵的资源和参考。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.01018v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.01018.md)  |
| <span style='display: inline-block; width: 42px;'>02-01</span> | **Learning Planning-based Reasoning by Trajectories Collection and Process Reward Synthesizing**<br><sub>机构: Nanyang Technological University, Institute for Infocomm Research A*STAR, Salesforce Research<br>文章提出了一个新颖的离线训练框架，专注于改进大型语言模型在处理复杂推理任务时的可靠性和精确性，通过收集轨迹和基于结果监督的直接偏好优化，无需教师模型或人类标注。在两个逻辑推理基准测试上的结果证明了该方法的有效性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.00658v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.00658.md)  |
| <span style='display: inline-block; width: 42px;'>02-01</span> | **Can Large Language Models Understand Context?**<br><sub>机构: Georgetown University, Apple<br>本文提出了一个上下文理解基准，用以评估大型语言模型（LLMs）的上下文理解能力。该基准涵盖了对文档和对话基础上下文理解的要素，通过创新的测试方法和实验分析展示了LLMs在上下文理解方面的能力和局限性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.00858v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.00858.md)  |

---

### 01月

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>01-31</span> | **LongAlign: A Recipe for Long Context Alignment of Large Language Models**<br><sub>机构: Tsinghua University, Zhipu.AI<br>论文提出了一种新的长上下文对齐配方LongAlign，通过构建长指令数据集、采用新的训练策略并引入评估基准来提高LLMs处理长上下文的能力，且代码、数据和长对齐的模型已开源。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.18058v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.18058.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/THUDM/LongAlign)</div> |
| <span style='display: inline-block; width: 42px;'>01-30</span> | **Efficient Tool Use with Chain-of-Abstraction Reasoning**<br><sub>机构: Meta<br>本文提出了一种新的链式抽象推理方法，有效地提升了LLMs使用外部工具的能力，并加速了推理过程。实验结果证明了其在多步骤推理任务上的有效性和高效性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.17464v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.17464.md)  |
| <span style='display: inline-block; width: 42px;'>01-30</span> | **Can Large Language Models be Trusted for Evaluation? Scalable Meta-Evaluation of LLMs as Evaluators via Agent Debate**<br><sub>机构: Shanghai Jiao Tong University, Carnegie Mellon University, Shanghai Artificial Intelligence Laboratory<br>SCALEEVAL 是一种新型的元评估框架，用于评估LLMs作为评估者的可靠性和效率。通过利用LLM代理间的辩论和最小化的人类监督，该框架在评估中引入灵活性和可扩展性，并在实验中显示出与纯人工评估高度一致的结果。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.16788v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.16788.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/GAIR-NLP/scaleeval)</div> |
| <span style='display: inline-block; width: 42px;'>01-30</span> | **Recovering Mental Representations from Large Language Models with Markov Chain Monte Carlo**<br><sub>机构: Princeton University, University of Warwick<br>本文通过将 LLMs 整合到采样算法中，并运用直接采样与 MCMC 的方式提取心理表征，有效提升了效率和性能，并探索了用 LLM 进行贝叶斯推断的潜力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.16657v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.16657.md)  |
| <span style='display: inline-block; width: 42px;'>01-30</span> | **Incoherent Probability Judgments in Large Language Models**<br><sub>机构: Princeton University<br>这篇论文探讨了大型语言模型在形成概率判断方面的连贯性问题，并发现这些模型在该领域表现出的偏差与人类认知中的系统性偏差相似。通过应用概率恒等式和重复判断的方法，研究人员量化了这些判断的不连贯性。研究还提出了一个假设，即LLMs在做出概率判断时的人类样偏差可能源自它们采用的自回归训练目标，这一假设得到了以贝叶斯取样器模型和LLMs中的自回归过程之间潜在联系为基础的支持。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.16646v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.16646.md)  |
| <span style='display: inline-block; width: 42px;'>01-29</span> | **Beyond Direct Diagnosis: LLM-based Multi-Specialist Agent Consultation for Automatic Diagnosis**<br><sub>机构: Harbin Institute of Technology<br>本研究提出了一个基于LLM的自动诊断方法——多专家智能代理咨询模型（AMSC），它能更好地模拟现实世界中的诊断流程，并通过集成多个专家代理的预测来提升诊断的准确性和效率。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.16107v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.16107.md)  |
| <span style='display: inline-block; width: 42px;'>01-29</span> | **LLM4Vuln: A Unified Evaluation Framework for Decoupling and Enhancing LLMs' Vulnerability Reasoning**<br><sub>机构: Nanyang Technological University<br>LLM4Vuln是一个创新的框架，它通过提供漏洞知识的向量数据库、调用工具的功能、定制的CoT提示方案以及使用精通指令的模型来结构化输出，显著提高了LLMs在代码漏洞分析中的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.16185v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.16185.md)  |
| <span style='display: inline-block; width: 42px;'>01-29</span> | **SelectLLM: Can LLMs Select Important Instructions to Annotate?**<br><sub>机构: University of Minnesota, Carnegie Mellon University<br>这项工作提出了一个利用LLMs选择未标记的高质量指令的新方法SELECTLLM，通过挑战传统的选择算法并在保持数据集的全局结构的同时提升选择效果。实验结果显示了其在指令调整基准测试上的优越性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.16553v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.16553.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/minnesotanlp/select-llm)</div> |
| <span style='display: inline-block; width: 42px;'>01-28</span> | **PRE: A Peer Review Based Large Language Model Evaluator**<br><sub>这篇论文提出的PRE模型通过模拟学术界的同行评审机制，提供了一种全新的自动评估LLM的框架，它显著降低了成本，并且具有更高的通用性和可靠性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.15641v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.15641.md)  |
| <span style='display: inline-block; width: 42px;'>01-27</span> | **MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries**<br><sub>机构: Hong Kong University of Science and Technology<br>这篇论文开发了MultiHop-RAG数据集，以评估和改善现存的检索增强生成（RAG）系统在处理需要多步检索和推理的查询上的不足。研究还提供了一系列实验结果，揭示了目前RAG系统在此类任务上的局限性，并公开了数据集推动进一步的研究和开发。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.15391v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.15391.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/yixuantt/MultiHop-RAG)</div> |
| <span style='display: inline-block; width: 42px;'>01-26</span> | **EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty**<br><sub>机构: Peking University, Microsoft Research, University of Waterloo<br>文章提出了一个名为EAGLE的新框架，以提高大型语言模型（LLMs）自回归解码的速度，同时保证生成文本与原始LLMs的文本分布一致。EAGLE通过改进推测性采样方法，在减少时间开销和提高草稿的接受率方面取得了显著成效，对比Lookahead和Medusa实现了更快的加速效果，并且训练成本低，易于部署。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.15077v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.15077.md)  |
| <span style='display: inline-block; width: 42px;'>01-25</span> | **Towards Consistent Natural-Language Explanations via Explanation-Consistency Finetuning**<br><sub>机构: Columbia University, Microsoft Research, University of California Berkeley<br>EC-Finetuning方法成功地提高了LLMs生成解释的一致性，并且可以推广到未见过的数据集，表现出微调数据集上10.0%和分布外数据集上4.5%的解释一致性相对改善，同时也适度提升了预测准确度。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.13986v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.13986.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/yandachen/explanation-consistency-finetuning)</div> |
| <span style='display: inline-block; width: 42px;'>01-25</span> | **ConstraintChecker: A Plugin for Large Language Models to Reason on Commonsense Knowledge Bases**<br><sub>机构: HKUST<br>ConstraintChecker是一个能有效提升LLMs在CSKB推理任务中性能的独立插件工具。通过提供和检查显式约束的方式，它能够帮助LLMs在推理中取得更好的表现，且在经过验证后的指标上超过了其他的提示技术。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.14003v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.14003.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/HKUST-KnowComp/ConstraintChecker)</div> |
| <span style='display: inline-block; width: 42px;'>01-25</span> | **True Knowledge Comes from Practice: Aligning LLMs with Embodied Environments via Reinforcement Learning**<br><sub>机构: Nanyang Technological University, Zhejiang University<br>TWOSOME框架通过强化学习来有效地将大型语言模型（LLMs）与体现环境对齐，提高了样本效率和任务泛化能力，同时保留了LLMs的原始功能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.14151v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.14151.md)  |
| <span style='display: inline-block; width: 42px;'>01-24</span> | **Can AI Assistants Know What They Don't Know?**<br><sub>机构: Fudan University, Shanghai Artificial Intelligence Laboratory<br>这篇论文重点探究了AI助手识别自己知识边界的能力，并通过构建Idk数据集并对助手调整，实现了让AI助手识别并承认不知道的问题，以减少回答中的事实错误。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.13275v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.13275.md)  |
| <span style='display: inline-block; width: 42px;'>01-24</span> | **MM-LLMs: Recent Advances in MultiModal Large Language Models**<br><sub>机构: Tencent AI Lab, Kyoto University, Mohamed Bin Zayed University of Artificial Intelligence<br>本文是一项关于MM-LLMs的综合性调研，旨在进一步推动MM-LLMs领域的研究工作。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.13601v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.13601.md)  |
| <span style='display: inline-block; width: 42px;'>01-24</span> | **Consistency Guided Knowledge Retrieval and Denoising in LLMs for Zero-shot Document-level Relation Triplet Extraction**<br><sub>机构: Nanjing University of Science and Technology, Northeastern University, Singapore Institute of Technology<br>论文提出了一个新的Zero-shot Document-level Relation Triplet Extraction (ZeroDocRTE)框架，该框架通过从LLMs中检索和去噪知识生成带标签的数据，并通过一系列新方法显著提高了文档级关系三元组抽取的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.13598v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.13598.md)  |
| <span style='display: inline-block; width: 42px;'>01-24</span> | **Clue-Guided Path Exploration: An Efficient Knowledge Base Question-Answering Framework with Low Computational Resource Consumption**<br><sub>机构: Tsinghua University, Zhongguancun Laboratory, XinJiang University<br>论文提出的CGPE框架能有效支持LLMs在问答任务中的应用，通过线索引导的路径探索机制，降低了对LLMs能力的要求，并显著减少了计算资源消耗，对计算资源有限的个人和组织具有重要实际意义。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.13444v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.13444.md)  |
| <span style='display: inline-block; width: 42px;'>01-24</span> | **AgentBoard: An Analytical Evaluation Board of Multi-turn LLM Agents**<br><sub>机构: The University of Hong Kong, Zhejiang University, Shanghai Jiao Tong University<br>研究人员提出了一个新的基准测试 AGENTBOARD，专门评估具有多轮交互能力的大语言模型代理，它提供了细粒度的进展率和交互式分析工具，以增进对 LLM 代理性能的深入理解。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.13178v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.13178.md)  |
| <span style='display: inline-block; width: 42px;'>01-23</span> | **AutoRT: Embodied Foundation Models for Large Scale Orchestration of Robotic Agents**<br><sub>机构: Google DeepMind<br>本论文描述了一个名为AutoRT的系统，它利用大型基础模型控制真实世界中的机器人，使它们能够自动导航并执行任务。这标志着第一次实现LLM控制的机器人在真实环境中进行自动操作、提出目标并实现这些目标。通过AutoRT收集到的数据不仅多样化且能够提高机器人学习模型的性能，并且可以与人类偏好保持一致。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.12963v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.12963.md)  |
| <span style='display: inline-block; width: 42px;'>01-23</span> | **KAM-CoT: Knowledge Augmented Multimodal Chain-of-Thoughts Reasoning**<br><sub>机构: Samsung R&D Institute India - Bangalore<br>KAM-CoT是一个多模态CoT推理框架，整合了CoT推理、知识图谱和多种模态。它在具有较少可训练参数的情况下优于现有的最先进方法，展现出卓越的性能和成本效率。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.12863v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.12863.md)  |
| <span style='display: inline-block; width: 42px;'>01-23</span> | **Large Language Models are Superpositions of All Characters: Attaining Arbitrary Role-play via Self-Alignment**<br><sub>机构: Alibaba Inc.<br>论文提出了一种名为DITTO的自对齐方法，能够通过知识增强和对话模拟增强LLMs的角色扮演能力。此外，它提供了一种客观、可复制、可解释且高效的角色扮演评估方法，并通过跨监督的实验了解角色扮演的分解，为LLMs构建角色扮演功能提供了深入的理解和见解。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.12474v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.12474.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/OFA-Sys/Ditto)</div> |
| <span style='display: inline-block; width: 42px;'>01-23</span> | **CCA: Collaborative Competitive Agents for Image Editing**<br><sub>该论文提出了一种基于多个大语言模型(LLMs)的新型生成模型CCA，能够处理复杂的图像编辑任务并提升结果的质量和鲁棒性。通过鼓励代理的协作竞争，模型展示出优于传统方法的能力，尤其在管理复杂任务和从中间步骤中学习以改进结果方面。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.13011v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.13011.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/TiankaiHang/CCA)</div> |
| <span style='display: inline-block; width: 42px;'>01-22</span> | **Improving Small Language Models' Mathematical Reasoning via Mix Thoughts Distillation**<br><sub>机构: Institute of Information Engineering, Chinese Academy of Sciences<br>这篇论文通过介绍EoTD和MTD，表明了可以将LLMs的数学推理能力转化给参数数量少于一十亿个的SLMs。通过实验验证了这些方法不仅保留了SLMs的推理能力，还在一定程度上提升了该能力，使SLMs在推理任务上达到了最好水平。这一进展对于在资源受限的环境中推广SLMs的应用打开了大门，并缩小了对强大推理模型需求与计算资源限制之间的差距。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.11864v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.11864.md)  |
| <span style='display: inline-block; width: 42px;'>01-22</span> | **PsySafe: A Comprehensive Framework for Psychological-based Attack, Defense, and Evaluation of Multi-agent System Safety**<br><sub>机构: Shanghai Artificial Intelligence Laboratory, Dalian University of Technology<br>本文提出了一个针对多智能体系统安全性的综合性框架PsySafe，该框架结合了心理层面的攻击、防御与评估方法。研究的实验结果有助于更深入地理解和研究多智能体系统的安全问题。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.11880v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.1188.md)  |
| <span style='display: inline-block; width: 42px;'>01-22</span> | **CheXagent: Towards a Foundation Model for Chest X-Ray Interpretation**<br><sub>机构: Stanford University, Stability AI  <br>本论文致力于解决在自动化胸部X光解释方面存在的挑战，通过引入专为CXR解释设计的大型数据集、开发了新的基础模型以及创建了一个全面的评估基准，实现了在医学成像领域的应用，并证明了在多项评估任务中CheXagent的性能优于其他模型。同时也对模型中可能存在的偏差进行了检查，为未来的研究和应用提供了重要参考。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.12208v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.12208.md)  |
| <span style='display: inline-block; width: 42px;'>01-21</span> | **Interactive AI with Retrieval-Augmented Generation for Next Generation Networking**<br><sub>机构: Nanyang Technological University, Guangdong University of Technology, Institute for Infocomm Research, Agency for Science Technology and Research<br>本文研究了将交互式AI (IAI) 集成到下一代网络中的可能性，采用了检索增强型生成（RAG）和大型语言模型（LLM）来提升决策能力，并通过真实网络优化的案例研究证明了提出框架的有效性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.11391v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.11391.md)  |
| <span style='display: inline-block; width: 42px;'>01-20</span> | **BadChain: Backdoor Chain-of-Thought Prompting for Large Language Models**<br><sub>机构: University of Illinois Urbana-Champaign, University of Washington, Western Washington University<br>本文提出了BadChain，这是一种针对采用COT提示的LLMs的后门攻击，不仅不需要访问训练数据集或模型参数，而且计算开销低。该方法有效地揭示了COT提示下LLMs的安全漏洞，强调了进行后门攻击和设计有效防御的重要性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.12242v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.12242.md)  |
| <span style='display: inline-block; width: 42px;'>01-19</span> | **Mitigating Hallucinations of Large Language Models via Knowledge Consistent Alignment**<br><sub>机构: Sun Yat-sen University, Tencent AI Lab<br>这篇论文引入了一种新颖的KCA方法，通过减少外部知识和内在知识之间的不一致性，从而减轻LLMs在校准过程中产生的幻觉。研究提供了未来研究的几个见解，尤其是KCA方法在多种场景下的出色表现，以及其简单性与有效性的结合。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.10768v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.10768.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/fanqiwan/KCA)</div> |
| <span style='display: inline-block; width: 42px;'>01-19</span> | **Pruning for Protection: Increasing Jailbreak Resistance in Aligned LLMs Without Fine-Tuning**<br><sub>机构: MIT<br>论文展示了通过Wanda剪枝方法，无需微调而提升LLMs从对齐安全性方面抵御“越狱”攻击的能力，并通过构建特定的数据集和评估体系验证模型表现。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.10862v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.10862.md)  |
| <span style='display: inline-block; width: 42px;'>01-19</span> | **Tool-LMM: A Large Multi-Modal Model for Tool Agent Learning**<br><sub>机构: ShanghaiTech University, Meituan, UniDT<br>Tool-LMM为首个致力于训练大型多模态模型以学习工具代理的系统，创新地整合了多模态输入与外部工具的正确选择，克服了文本模糊带来的问题，展现了在多模态指令下自动选择合适工具的能力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.10727v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.10727.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/Tool-LMM/Tool-LMM)</div> |
| <span style='display: inline-block; width: 42px;'>01-19</span> | **Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads**<br><sub>机构: Princeton University, Together AI, University of Illinois Urbana-Champaign<br>文章提出了一个名为Medusa的LLM推理加速框架，通过增加额外的解码头并用树形注意力机制，并行生成多个token，有效减少解码步骤数量，实现了对大模型推理速度的显著提升。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.10774v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.10774.md)  |
| <span style='display: inline-block; width: 42px;'>01-18</span> | **Advancing Large Multi-modal Models with Explicit Chain-of-Reasoning and Visual Question Generation**<br><sub>机构: The University of Tokyo, RIKEN<br>这项研究通过创新地整合一个显性的推理过程和生成问题的能力到LMM中，以促进模型进行更可靠的推理。创建了一个新的数据集并利用它对模型进行培训，为今后LMM的进步设定了先例，并通过这种方式使模型在面临不确定性时能生成显性推理步骤和提问。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.10005v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.10005.md)  |
| <span style='display: inline-block; width: 42px;'>01-18</span> | **A Fast, Performant, Secure Distributed Training Framework For Large Language Model**<br><sub>机构: Ant Group China<br>本论文提出了一个基于模型切片的安全分布式训练框架，能在保证模型训练精度和高效率的同时，解决了服务端和客户端的模型参数及数据泄露问题。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.09796v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.09796.md)  |
| <span style='display: inline-block; width: 42px;'>01-18</span> | **ChatQA: Building GPT-4 Level Conversational QA Models**<br><sub>机构: NVIDIA<br>ChatQA模型通过两阶段的指令微调策略显著改进了多轮对话式问答的效果，尤其是在上下文理解和信息检索方面。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.10225v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.10225.md)  |
| <span style='display: inline-block; width: 42px;'>01-18</span> | **Self-Rewarding Language Models**<br><sub>机构: Meta, NYU  <br>本文提出了自奖励语言模型（Self-Rewarding Language Models），旨在通过自我训练来避免人类偏好数据的瓶颈，并提高模型的自奖励和执行指令的能力。实验结果表明，该模型表现出色，有望成为连续自我改进模型的开山之作。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.10020v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.1002.md)  |
| <span style='display: inline-block; width: 42px;'>01-17</span> | **Vlogger: Make Your Dream A Vlog**<br><sub>机构: Shanghai Jiao Tong University, Shanghai AI Laboratory, Shenzhen Institute of Advanced Technology Chinese Academy of Sciences<br>本论文通过介绍Vlogger系统，展示了一个创新的办法将LLMs应用于视频博客的生成过程中，从而克服了生成分钟级连贯视频内容的挑战，并取得了优异的实验结果。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.09414v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.09414.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/zhuangshaobin/Vlogger)</div> |
| <span style='display: inline-block; width: 42px;'>01-17</span> | **LLMs for Relational Reasoning: How Far are We?**<br><sub>机构: Continental-NTU Corporate Lab, Nanyang Technological University, Singapore<br>本论文主要探讨了大型语言模型在关系推理方面的能力和局限性。通过全面的评估，包括新提出的测试方法和评估模块，发现LLMs虽然在某些关系推理任务上表现不错，但与专门为逻辑推理设计的模型相比，其性能相对较差。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.09042v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.09042.md)  |
| <span style='display: inline-block; width: 42px;'>01-17</span> | **ReFT: Reasoning with Reinforced Fine-Tuning**<br><sub>机构: ByteDance Research<br>ReFT通过利用强化学习优化非可微目标，显著提高了大型语言模型在数学问题求解任务中的性能和泛化能力。它超越了传统的监督式学习方法，展现了在更复杂推理任务中的潜力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.08967v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.08967.md)  |
| <span style='display: inline-block; width: 42px;'>01-16</span> | **RAG vs Fine-tuning: Pipelines, Tradeoffs, and a Case Study on Agriculture**<br><sub>机构: Microsoft<br>本文研究了大型语言模型在农业数据上生成问答对的性能，并提出了一个新的生成管道，有效地使用了RAG和微调技术增强LLM的应用场景，拓展了LLM在特定行业的应用潜力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.08406v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.08406.md)  |
| <span style='display: inline-block; width: 42px;'>01-16</span> | **MARIO: MAth Reasoning with code Interpreter Output -- A Reproducible Pipeline**<br><sub>机构: Alibaba Group  <br>论文提出了一个新的数学推理数据集，该数据集与Python代码解释器相结合，通过改进数据集并实施特定微调流程显著提高了LLM在数学问题求解任务上的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.08190v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.0819.md)  |
| <span style='display: inline-block; width: 42px;'>01-16</span> | **Contrastive Preference Optimization: Pushing the Boundaries of LLM Performance in Machine Translation**<br><sub>机构: Johns Hopkins University, Microsoft<br>本论文提出了CPO，一个新的LLM微调方法，有效解决了SFT在机器翻译任务中存在的瓶颈，实现了在资源消耗极少的情况下显著提升中等规模LLM翻译模型的性能，最终与最先进的状态艺术翻译系统齐头并进。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.08417v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.08417.md)  |
| <span style='display: inline-block; width: 42px;'>01-16</span> | **SpecGen: Automated Generation of Formal Program Specifications via Large Language Models**<br><sub>机构: Nanjing University, Nanyang Technological University, Singapore Management University<br>论文提出了 SpecGen，一个结合了大型语言模型和启发式选择策略的程序形式化规范自动生成技术。通过比较与现有工具和纯 LLM 方法，SpecGen 表现出更高效和准确的生成规范的能力，并且提出了数据集促进后续研究。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.08807v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.08807.md)  |
| <span style='display: inline-block; width: 42px;'>01-16</span> | **Salute the Classic: Revisiting Challenges of Machine Translation in the Age of Large Language Models**<br><sub>机构: Tencent AI Lab<br>本文深入分析了LLMs在机器翻译任务中领域不匹配问题，并实验了不同数量的平行数据对LLMs翻译能力的影响，展现出LLMs在处理这些挑战中的潜力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.08350v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.0835.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/pangjh3/LLM4MT)</div> |
| <span style='display: inline-block; width: 42px;'>01-16</span> | **DoraemonGPT: Toward Understanding Dynamic Scenes with Large Language Models**<br><sub>机构:  Zhejiang University<br>DoraemonGPT是一个LLM驱动的智能体，通过符号记忆和工具集来理解并解答涉及动态视频的复杂问题。其采用了MCTS规划器优化回答的生成过程，能够在真实世界场景中处理更为复杂的任务。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.08392v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.08392.md)  |
| <span style='display: inline-block; width: 42px;'>01-15</span> | **A Study on Large Language Models' Limitations in Multiple-Choice Question Answering**<br><sub>机构: David R. Cheriton School of Computer Science<br>该论文针对LLMs在MCQ任务中的限制进行了研究，指出多数模型在此类任务中表现不佳。论文还发现模型的回答往往依赖于选项顺序，并提出了有效的评估方法来排除这些偏见。论文推荐在使用MCQ评估LLMs时要格外小心，并测试模型是否真正理解了任务。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.07955v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.07955.md)  |
| <span style='display: inline-block; width: 42px;'>01-15</span> | **MAPLE: Multilingual Evaluation of Parameter Efficient Finetuning of Large Language Models**<br><sub>机构: Microsoft Research India<br>这篇论文研究了大型语言模型在多语言任务上通过参数高效微调后的性能，特别是在低资源语言和英语任务上。研究展示了PEFT的潜力，同时指出了未来工作的一些可能方向。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.07598v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.07598.md)  |
| <span style='display: inline-block; width: 42px;'>01-15</span> | **The What, Why, and How of Context Length Extension Techniques in Large Language Models -- A Detailed Survey**<br><sub>机构: Technology Innovation Institute UAE, Islamic University of Technology Bangladesh, Stanford University, Amazon GenAI, AI Institute University of South Carolina<br>本论文是关于LLMs上下文长度扩展技术的详细调研。它为研究人员提供了该领域的现有策略和挑战的有组织概览，并鼓励了对未来发展的讨论。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.07872v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.07872.md)  |
| <span style='display: inline-block; width: 42px;'>01-14</span> | **Small LLMs Are Weak Tool Learners: A Multi-LLM Agent**<br><sub>机构: Sun Yat-sen University, Alibaba Group<br>研究表明小型LLM在作为工具学习者方面较为薄弱，通过引入α-UMi多LLM框架来构建性能更优的LLM代理，提出了必要的双阶段微调策略，并深入分析了数据规模法则。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.07324v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.07324.md)  |
| <span style='display: inline-block; width: 42px;'>01-13</span> | **Bridging the Preference Gap between Retrievers and LLMs**<br><sub>本论文介绍了BGM框架以解决检索器和LLMs之间的"偏好差"问题，通过一个序列到序列（seq2seq）的桥模型结合SL和RL的训练方案，优化了检索信息以满足LLMs的偏好，改进了多个下游任务的表现。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06954v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06954.md)  |
| <span style='display: inline-block; width: 42px;'>01-12</span> | **From Automation to Augmentation: Large Language Models Elevating Essay Scoring Landscape**<br><sub>机构: Tsinghua University, University of Maryland, Beijing Xicheng Educational Research Institute  <br>本文的研究展现了大型语言模型在教育领域中，特别是在AES系统中的潜力。LLMs不仅能够自动化评分过程，还能够通过生成反馈来增强人类评分者的表现。这不仅是技术上的进步，更为未来的人工智能辅助教育和人工智能与人类的高效协作提供了宝贵见解。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06431v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06431.md)  |
| <span style='display: inline-block; width: 42px;'>01-12</span> | **TestSpark: IntelliJ IDEA's Ultimate Test Generation Companion**<br><sub>机构: JetBrains Research, Delft University of Technology<br>论文提出了TestSpark插件，它结合了基于搜索的软件测试生成和基于语言模型的测试生成方法，在IntelliJ IDEA中提高了单元测试的生成和集成效率，同时解决了LLM生成测试用例可编译性的问题。插件的开源特性使其成为连接软件开发者和研究者的桥梁，有助于测试生成技术的实用性进步。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06580v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.0658.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/JetBrains-Research/TestSpark)</div> |
| <span style='display: inline-block; width: 42px;'>01-12</span> | **An Experimental Design Framework for Label-Efficient Supervised Finetuning of Large Language Models**<br><sub>机构: University of Washington Seattle, University of Wisconsin-Madison, Stanford University<br>这篇论文提出了一个实验设计框架，为了提高大型语言模型在监督式微调（SFT）过程中的标签效率。它展示了实验设计技术可以在维持低计算成本的同时，大幅提高标签效率，在一些任务中与随机采样相比节省了50%的注释成本。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06692v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06692.md)  |
| <span style='display: inline-block; width: 42px;'>01-12</span> | **APAR: LLMs Can Do Auto-Parallel Auto-Regressive Decoding**<br><sub>机构: Tsinghua University, Zhipu AI<br>通过实施APAR，该研究成功提高了LLMs在内存受限场景和高吞吐率场景下的解码效率和生成速度，同时保持了生成质量，为大语言模型的部署提供了一种新的高效策略。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06761v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06761.md)  |
| <span style='display: inline-block; width: 42px;'>01-12</span> | **Kun: Answer Polishment for Chinese Self-Alignment with Instruction Back-Translation**<br><sub>机构: Tianyu Zheng, Shuyue Guo, Xingwei Qu, Jiawei Guo, Weixu Zhang, Xinrun Du, Chenghua Lin, Wenhao Huang, Wenhu Chen, Jie Fu, Ge Zhang<br>这篇论文提出了Kun策略，解决了中文大型语言模型指令微调中存在的数据一致性问题，通过AP过程和新的数据生成方法，减少了对人工标注的依赖。评估结果表明，Kun策略在创建高质量数据集方面具有明显优势。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06477v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06477.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/Zheng0428/COIG-Kun)</div> |
| <span style='display: inline-block; width: 42px;'>01-12</span> | **How Johnny Can Persuade LLMs to Jailbreak Them: Rethinking Persuasion to Challenge AI Safety by Humanizing LLMs**<br><sub>机构: Virginia Tech, Renmin University of China, UC Davis<br>本论文提出了将LLMs视为具备类人沟通能力的实体，利用了一个新的视角来研究AI安全问题。通过将十多年的社会科学研究应用于AI安全，制定了一个说服技巧分类法，并通过创建的工具自动生成了对抗性提示。结果表明，说服技巧可以有效地增强有风险行为被LLMs执行的可能性，同时揭示了当前防御手段在应对这类策略时的不足。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06373v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06373.md)  |
| <span style='display: inline-block; width: 42px;'>01-12</span> | **Teaching Code LLMs to Use Autocompletion Tools in Repository-Level Code Generation**<br><sub>机构: Nanyang Technological University, Fudan University<br>该论文成功提出了一种新方法TOOLGEN，通过集成自动完成工具到仓库级代码生成中的LLMs，解决了依赖性问题，提高了代码生成的质量和成功率。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06391v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06391.md)  |
| <span style='display: inline-block; width: 42px;'>01-11</span> | **Improving Large Language Models via Fine-grained Reinforcement Learning with Minimum Editing Constraint**<br><sub>机构: Gaoling School of Artificial Intelligence, Renmin University of China; School of Information, Renmin University of China; Kuaishou Technology, Beijing China.<br>本论文提出了一种新的RL方法，名为RLMEC，通过生成式奖励模型和最小编辑机制，使大型语言模型在RL训练过程中实现更精细的监督和训练的稳定性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06081v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06081.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/RUCAIBox/RLMEC)</div> |
| <span style='display: inline-block; width: 42px;'>01-11</span> | **Chain of History: Learning and Forecasting with LLMs for Temporal Knowledge Graph Completion**<br><sub>机构: Tsinghua Shenzhen International Graduate School Tsinghua University, School of Computer Science Peking University, Baidu Inc.<br>本论文提出了一种使用大型语言模型进行时间知识图谱完成的方法，通过高效的微调方法和结合结构信息的历史数据增强，提高了模型的推理能力和性能。实验显示该方法有效地提升了时间知识图谱预测的精度，达到了最先进的结果。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06072v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06072.md)  |
| <span style='display: inline-block; width: 42px;'>01-11</span> | **Risk Taxonomy, Mitigation, and Assessment Benchmarks of Large Language Model Systems**<br><sub>机构: Zhongguancun Laboratory, Tsinghua University, Institute of Information Engineering Chinese Academy of Sciences<br>本文为大语言模型系统中的风险分类、缓解措施以及评估标准提供了全面的概述，提出了一个新的系统化分类框架，帮助开发者更全面地理解和处理LLM系统的潜在风险。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.05778v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.05778.md)  |
| <span style='display: inline-block; width: 42px;'>01-11</span> | **Patchscope: A Unifying Framework for Inspecting Hidden Representations of Language Models**<br><sub>机构: Google Research, Tel Aviv University<br>该论文提出了一个名为Patchscopes的框架，提供了一种新的方法去解释大型语言模型（LLMs）隐藏表示中编码的信息，并且能够纠正多步推理错误。Patchscopes作为一种通用的可配置框架，不仅统一了现有的解释工具，并解决了它们自身的一些不足，同时也开辟了新的研究和应用可能性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06102v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06102.md)  |
| <span style='display: inline-block; width: 42px;'>01-11</span> | **TOFU: A Task of Fictitious Unlearning for LLMs**<br><sub>机构: Carnegie Mellon University<br>文章为LLM遗忘问题提供了新的数据集和评估机制，TOFU任务展示了现有遗忘技术的不足，鼓励了相继而来的改进和研究工作。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06121v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06121.md)  |
| <span style='display: inline-block; width: 42px;'>01-11</span> | **LLM-as-a-Coauthor: The Challenges of Detecting LLM-Human Mixcase**<br><sub>机构: LAIR Lab Lehigh University, Huazhong University of Science and Technology  <br>本文定义了混合场景中的混合文本（mixcase），构建了MIXSET数据集，并提出了通向解决混合文本检测问题的见解和方向。研究发现，现有的检测器在识别混合文本方面存在不足，这提出了制定更细粒度检测器的紧迫需求。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.05952v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.05952.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/Dongping-Chen/MixSet)</div> |
| <span style='display: inline-block; width: 42px;'>01-11</span> | **Evidence to Generate (E2G): A Single-agent Two-step Prompting for Context Grounded and Retrieval Augmented Reasoning**<br><sub>机构: Qatar Computing Research Institute <br>本论文提出了一个新的、用于改善LLMs在上下文推理能力的单代理双步提示框架——Evidence to Generate (E2G)。通过要求LLMs在生成答案的同时提供证据与解释，E2G能够减少错误推理并提高模型在处理各种推理任务时的准确度。实验结果表明，E2G方法在多个情境密集型语言任务中表现出较CoT更好的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.05787v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.05787.md)  |
| <span style='display: inline-block; width: 42px;'>01-11</span> | **EASYTOOL: Enhancing LLM-based Agents with Concise Tool Instruction**<br><sub>机构: Fudan University, Microsoft Research Asia, Zhejiang University<br>本文提出了一种名为EASYTOOL的方法，可以通过简化和统一工具文档的指令来提高LLM基础代理在工具使用方面的表现，解决了现有工具使用中的不一致性、冗余性和不完整性问题。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06201v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06201.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/microsoft/JARVIS)</div> |
| <span style='display: inline-block; width: 42px;'>01-11</span> | **The Benefits of a Concise Chain of Thought on Problem-Solving in Large Language Models**<br><sub>机构: Johns Hopkins University<br>此研究表明，通过使用简洁的思维链提示（CCoT），在大型语言模型中可以大幅减少文本输出的长度，而不会影响解决问题的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.05618v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.05618.md)  |
| <span style='display: inline-block; width: 42px;'>01-10</span> | **InfiAgent-DABench: Evaluating Agents on Data Analysis Tasks**<br><sub>InfiAgent-DABench提供了一个新颖的评估基准，这不仅有助于衡量智能代理在数据分析任务中的性能，同时也是探索如何改进和优化LLM在这一特定领域应用的重要一步。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.05507v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.05507.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/InfiAgent/InfiAgent)</div> |
| <span style='display: inline-block; width: 42px;'>01-10</span> | **CASA: Causality-driven Argument Sufficiency Assessment**<br><sub>机构: Peking University<br>本论文介绍了一个基于LLMs的零样本因果驱动论证充分性评估框架（CASA），成功应对了无观测数据下论证充分性量化和干预的难题，并在实际应用中展示了其有效性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.05249v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.05249.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/xxxiaol/CASA)</div> |
| <span style='display: inline-block; width: 42px;'>01-10</span> | **Leveraging Print Debugging to Improve Code Generation in Large Language Models**<br><sub>机构: Zhejiang University, ByteDance<br>本文提出了一种利用print debugging方法指导LLMs进行代码生成和调试的方法，并且在Leetcode问题集上验证了其有效性，特别是在简单和中等难度的问题上。尽管在高难度问题上效果有限，但这项工作仍然是LLMs在代码调试方面的一个重要进步。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.05319v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.05319.md)  |
| <span style='display: inline-block; width: 42px;'>01-10</span> | **AUTOACT: Automatic Agent Learning from Scratch via Self-Planning**<br><sub>机构: Zhejiang University, Alibaba Group<br>这项研究提出了一个名为AUTOACT的框架，它通过自我指导和自我规划实现语言代理的自动学习，以应对从零开始学习新任务的挑战。该框架的核心贡献在于有效的数据扩充方法和高效率的自动代理学习过程。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.05268v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.05268.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/zjunlp/AutoAct)</div> |
| <span style='display: inline-block; width: 42px;'>01-10</span> | **Prompting Large Language Models for Recommender Systems: A Comprehensive Framework and Empirical Analysis**<br><sub>机构: Renmin University of China, Beijing Key Laboratory of Big Data Management and Analysis Methods, Meituan Group<br>这项工作提出了一个名为ProLLM4Rec的框架，系统地分析了利用大型语言模型(LLMs)作为推荐系统的基础模型，并通过实验测试了不同情况下对LLMs的影响。通过实证分析，总结了对未来研究的启发性发现。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.04997v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.04997.md)  |
| <span style='display: inline-block; width: 42px;'>01-10</span> | **Attendre: Wait To Attend By Retrieval With Evicted Queries in Memory-Based Transformers for Long Context Processing**<br><sub>机构: Google Research<br>论文成功地提出了一个新的基于内存的转换器方法，通过存储驱逐策略和ATTENDRE层，有效地减少内存需求并支持双向注意力，在长序列处理上表现出与传统方法相当的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.04881v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.04881.md)  |
| <span style='display: inline-block; width: 42px;'>01-10</span> | **Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk**<br><sub>机构: AWS AI Labs<br>论文提出了一种基于大型语言模型（LLMs）自我对话生成训练数据的新方法，该方法有潜力改进任务导向对话代理的性能。尽管存在一些限制，研究结果表明，当选择高质量对话作为训练数据时，可以有效提高模型的性能。这证明了在正确的设置下，通过自我生成数据进行微调的语言模型确实有潜力实现自我改进，并成为更好的任务导向对话代理。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.05033v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.05033.md)  |
| <span style='display: inline-block; width: 42px;'>01-10</span> | **Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security**<br><sub>机构: Tsinghua University, Xiaomi AI Lab<br>该论文作为一项调研工作，介绍了个人LLM代理的现状、挑战和未来趋势，并提出了一种通用的系统架构和智能水平定义。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.05459v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.05459.md)  |
| <span style='display: inline-block; width: 42px;'>01-09</span> | **Know Your Needs Better: Towards Structured Understanding of Marketer Demands with Analogical Reasoning Augmented LLMs**<br><sub>机构: Zhejiang University, Ant Group<br>本文提出了一种名为ARALLM的新方法，该方法结合了类比推理和多任务模型提炼，有效促进了大型语言模型从自然语言中理解并转换为结构化的逻辑语言的能力。通过这种方法，非专业营销人员能够利用自然语言来选择目标用户，有望改变用户定位实践。这种能力的提升，不仅在营销场景中有实际的应用价值，同时也为大型语言模型的功能性和实用性做出了有益的探索。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.04319v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.04319.md)  |
| <span style='display: inline-block; width: 42px;'>01-09</span> | **Large Language Models for Robotics: Opportunities, Challenges, and Perspectives**<br><sub>机构: Northwestern Polytechnical University, University of Georgia, Shaanxi Normal University<br>论文提出的多模态GPT-4V框架，结合自然语言处理和视觉感知，有望解决LLMs在机器人任务规划中面对的挑战。这对于理解和实现更高级别的人机交互和人工智能的未来具有重要意义。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.04334v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.04334.md)  |
| <span style='display: inline-block; width: 42px;'>01-09</span> | **Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding**<br><sub>机构: University of California San Diego, Google Cloud AI Research, Google Research<br>该论文提出了一个创新的CHAIN-OF-TABLE框架，通过将表格数据显式地用于推理链，动态地规划并更新操作过程，从而提高了LLMs在基于表格的推理任务中的准确性和可靠性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.04398v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.04398.md)  |
| <span style='display: inline-block; width: 42px;'>01-09</span> | **Rewriting the Code: A Simple Method for Large Language Model Augmented Code Search**<br><sub>机构: Nanyang Technological University Singapore<br>ReCo利用LLMs重写代码库中的代码，通过风格规范化显著提高了代码搜索的准确性，并通过新的评价指标CSSim量化了风格的差异，推动了代码样式标准化的研究。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.04514v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.04514.md)  |
| <span style='display: inline-block; width: 42px;'>01-09</span> | **The Critique of Critique**<br><sub>机构: The Hong Kong Polytechnic University, Shanghai Jiao Tong University, Shanghai Artificial Intelligence Laboratory<br>METACRITIQUE是首个针对自然语言批判进行评价的框架，其通过精确度和召回率的原则评估批判的质量，并实现了高度的可解释性和透明性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.04518v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.04518.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/GAIR-NLP/MetaCritique)</div> |
| <span style='display: inline-block; width: 42px;'>01-09</span> | **Agent Alignment in Evolving Social Norms**<br><sub>机构: Fudan University<br>此论文提出了一个EvoluationaryAgent框架，用于评估和增强大型智能代理在动态持续变化的社会规范中的自适应性和一致性。研究强调了代理在进化中与社会规范对齐的重要性，并通过实验验证了模型的可行性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.04620v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.0462.md)  |
| <span style='display: inline-block; width: 42px;'>01-08</span> | **TTMs: Fast Multi-level Tiny Time Mixers for Improved Zero-shot and Few-shot Forecasting of Multivariate Time Series**<br><sub>机构: IBM Research<br>TTM展示了专门针对多样化时间序列数据训练的小型预训练模型在多变量时间序列零/少样本预测中的高效性和转移学习能力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.03955v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.03955.md)  |
| <span style='display: inline-block; width: 42px;'>01-08</span> | **SpeechAgents: Human-Communication Simulation with Multi-Modal Multi-Agent Systems**<br><sub>机构: Fudan University<br>论文提出了一个基于多模态大型语言模型的多代理系统——SpeechAgents，其能模拟包含多达 25 名代理人的人类交流场景，并展现出卓越的可扩展性。通过使用多模态信号作为代理间交流的媒介，系统不仅可以模拟具有正确内容、真实节奏和丰富情感的对话，而且还能应用于如戏剧创作和有声小说生成等任务。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.03945v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.03945.md)  |
| <span style='display: inline-block; width: 42px;'>01-08</span> | **MARG: Multi-Agent Review Generation for Scientific Papers**<br><sub>机构: Northwestern University, The Hebrew University of Jerusalem, Allen Institute for AI<br>本论文提出了一个创新的多代理评论生成方法（MARG），可以跨越基础模型的上下文大小限制，生成高质量的科学论文同行评审反馈。通过用户研究和自动化度量，MARG的反馈质量对比基线有显著提高，生成的有用评论数量提高了2.2倍，同时生成了更加具体的评论。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.04259v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.04259.md)  |
| <span style='display: inline-block; width: 42px;'>01-07</span> | **Soaring from 4K to 400K: Extending LLM's Context with Activation Beacon**<br><sub>机构: Beijing Academy of Artificial Intelligence, Renmin University of China, Nankai University<br>这篇文章介绍了激活信标这一能够扩展大型语言模型上下文长度的新技术，使得模型能在有限上下文窗口内感知更广的上下文信息，同时保留对短上下文信息的处理能力。激活信标代表了一种有效、高效、兼容且训练成本低的方法，来扩展LLMs的上下文长度。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.03462v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.03462.md)  |
| <span style='display: inline-block; width: 42px;'>01-07</span> | **ChatGPT for Conversational Recommendation: Refining Recommendations by Reprompting with Feedback**<br><sub>机构: University of Louisville, Microsoft<br>该论文探索了ChatGPT作为对话推荐系统的有效性。通过构建围绕ChatGPT的流程，模拟用户实际使用情景，并对流行偏见进行了研究和缓解。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.03605v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.03605.md)  |
| <span style='display: inline-block; width: 42px;'>01-07</span> | **Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects**<br><sub>机构: The Chinese University of Hong Kong, DeepWisdom, Peking University<br>论文提出了一个用于指导未来研究与开发的基于LLM的智能代理系统的框架，并探讨了提高它们的计划能力和多模态信息处理能力的不同方法，以及如何解决LLM代理所面临的挑战，为未来的研究方向提供了清晰的指南。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.03428v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.03428.md)  |
| <span style='display: inline-block; width: 42px;'>01-07</span> | **Grimoire is All You Need for Enhancing Large Language Models**<br><sub>机构: Beihang University, Renmin University of China<br>该论文提出了一种名为SLEICL的方法，通过强语言模型学习示例技能并将其转移给弱语言模型，显著提高了弱模型的ICL能力。通过实验验证了该方法的有效性，展现了该技术在增强弱语言模型上下文学习能力方面的潜力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.03385v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.03385.md)  |
| <span style='display: inline-block; width: 42px;'>01-06</span> | **The Dawn After the Dark: An Empirical Study on Factuality Hallucination in Large Language Models**<br><sub>机构: Renmin University of China, Université de Montréal<br>本论文通过系统性实证研究，深入了解并探索大型语言模型中的幻觉问题，识别了幻觉的来源、检测方法和减轻策略，并提出了新的基准HaluEval 2.0和简单有效的幻觉检测框架。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.03205v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.03205.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/RUCAIBox/HaluEval-2.0)</div> |
| <span style='display: inline-block; width: 42px;'>01-06</span> | **Quartet Logic: A Four-Step Reasoning (QLFR) framework for advancing Short Text Classification**<br><sub>机构: Aerospace Information Research Institute Chinese Academy of Sciences, Key Laboratory of Target Cognition and Application Technology, University of Chinese Academy of Sciences<br>本研究提出了一个针对短文本分类任务的Quartet Logic: A Four-Step Reasoning (QLFR)框架，以及一个CoT驱动的多任务学习（QLFR-CML）方法，这两者都通过大语言模型的推理链来解决STC领域中的挑战。实验结果证明了这些方法的有效性和实用性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.03158v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.03158.md)  |
| <span style='display: inline-block; width: 42px;'>01-06</span> | **CogGPT: Unleashing the Power of Cognitive Dynamics on Large Language Models**<br><sub>机构: Harbin Institute of Technology, Kuaishou Technology<br>CogGPT通过引入迭代认知机制和记忆保持系统，有效地解决了大型语言模型在模仿人类认知动态方面的挑战，展示了在连续信息处理中的优秀表现。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.08438v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.08438.md)  |
| <span style='display: inline-block; width: 42px;'>01-05</span> | **Infinite-LLM: Efficient LLM Service for Long Context with DistAttention and Distributed KVCache**<br><sub>机构: Alibaba Group, Shanghai Jiao Tong University<br>文章提出了一个有效支持长上下文语言模型云服务的系统，通过分布式算法DistAttention，优化了注意力模块的处理和存储，并通过DistKV-LLM服务系统进行管理和协调，实现了在分布式环境中对资源的高效分配和管理，验证了其在性能上的明显提高。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.02669v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.02669.md)  |
| <span style='display: inline-block; width: 42px;'>01-05</span> | **From LLM to Conversational Agent: A Memory Enhanced Architecture with Fine-Tuning of Large Language Models**<br><sub>机构: Beike Inc.<br>本论文介绍了RAISE框架，通过增强记忆系统和结构化的代理构建过程，提高了LLMs在多轮对话中的表现，尤其是在房地产销售情境中。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.02777v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.02777.md)  |
| <span style='display: inline-block; width: 42px;'>01-04</span> | **Using LLM to select the right SQL Query from candidates**<br><sub>机构: Peking University<br>本文提出了一种借助大型语言模型自动生成text-to-SQL测试用例的方法，并设计了三步重新排序过程，实验显示该方法能显著提高现有text-to-SQL模型的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.02115v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.02115.md)  |
| <span style='display: inline-block; width: 42px;'>01-04</span> | **SPEER: Sentence-Level Planning of Long Clinical Summaries via Embedded Entity Retrieval**<br><sub>机构: Columbia University<br>本论文针对医院出院总结的长篇文档任务，提出了一个基于嵌入式实体检索的句子级规划方法SPEER，通过引导大型语言模型LLMs更好地覆盖关键实体，生成更完整和可信的临床总结。研究证明了SPEER方法在实际应用中可以提高文档的覆盖度和准确性，减轻临床医生的文档负担。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.02369v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.02369.md)  |
| <span style='display: inline-block; width: 42px;'>01-04</span> | **On the Prospects of Incorporating Large Language Models (LLMs) in Automated Planning and Scheduling (APS)**<br><sub>机构: University of South Carolina, New Mexico State University, IBM Research<br>本文是对大型语言模型在自动规划和调度领域的应用进行了综述，提出了将领先的 LLMs 如 GPT-4 和 BERT 与经典规划方法结合的前景，以及在八个不同的规划问题类别中应用 LLMs 的潜力，以期发展更先进、更智能的规划系统。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.02500v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.025.md)  |
| <span style='display: inline-block; width: 42px;'>01-04</span> | **On the Prospects of Incorporating Large Language Models (LLMs) in Automated Planning and Scheduling (APS)**<br><sub>机构: University of South Carolina, New Mexico State University, IBM Research<br>本论文在理解大型语言模型（LLMs）与自动规划和调度（APS）的整合前景，突破了传统系统对上下文的适应性局限性，为实现更动态、上下文敏感的规划途径提供了可能性，并为进一步的应用和研究奠定了基础。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.02500v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.025.md)  |
| <span style='display: inline-block; width: 42px;'>01-04</span> | **Self-Contrast: Better Reflection Through Inconsistent Solving Perspectives**<br><sub>机构: Zhejiang University, OPPO Research Institute<br>本文提出了一种名为“自我对比”的新策略，用于改善大型语言模型（LLM）在反思和自我修正过程中存在的固执和不一致问题，通过创建多样化解决方案视角，对比不同解决方案的差异，并将差异总结为检查清单，进而提升了LLM的反思质量，并通过实验验证了该策略的效果和广泛适用性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.02009v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.02009.md)  |
| <span style='display: inline-block; width: 42px;'>01-04</span> | **ICE-GRT: Instruction Context Enhancement by Generative Reinforcement based Transformers**<br><sub>机构: Bytedance Inc.<br>本论文提出了针对大型语言模型在特定领域任务中深度与准确性提升的方法——ICE-GRT。通过结合人类反馈的强化学习，ICE-GRT 在不牺牲一般性能的前提下，显著提升了特定领域的能力，并在多项评估任务中达到了最先进的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.02072v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.02072.md)  |
| <span style='display: inline-block; width: 42px;'>01-04</span> | **LLM Augmented LLMs: Expanding Capabilities through Composition**<br><sub>机构: Google Research, Google DeepMind<br>该论文提出了一个新的模型扩展框架 —— CALM，有效整合了两个大型语言模型以实现新的任务，且在多个实验中证明了其有效性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.02412v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.02412.md)  |
| <span style='display: inline-block; width: 42px;'>01-03</span> | **Social Media Ready Caption Generation for Brands**<br><sub>机构: Adobe Research India<br>本论文提出了一个新的框架，旨在帮助品牌在社交媒体上创造与品牌形象和个性相符的吸引人的标题。框架分为两部分，成功应对了生成与品牌相关性强且吸引眼球的社交媒体标题的挑战。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.01637v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.01637.md)  |
| <span style='display: inline-block; width: 42px;'>01-03</span> | **MedSumm: A Multimodal Approach to Summarizing Code-Mixed Hindi-English Clinical Queries**<br><sub>机构: Indian Institute of Technology Patna, Stanford University, Amazon GenAI<br>MedSumm是一个新颖的多模态医疗问题总结框架，它能够通过整合文本和视觉信息生成医学细节丰富的总结，有潜力提高医疗决策的质量并加深对患者问题的理解。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.01596v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.01596.md)  |
| <span style='display: inline-block; width: 42px;'>01-02</span> | **A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models**<br><sub>机构: Islamic University of Technology Bangladesh, University of South Carolina, Stanford University<br>本文是对LLM幻觉减轻技术的全面综述，提出了分类框架和系统化的反馈和理由方法，并评估了这些技术的有效性和影响。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.01313v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.01313.md)  |
| <span style='display: inline-block; width: 42px;'>01-02</span> | **LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning**<br><sub>这篇论文成功展示了一种无需fine-tuning即可扩展LLMs上下文窗口的方法，这对于在计算资源受限情况下提升大型语言模型处理长文本的能力具有重要意义。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.01325v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.01325.md)  |
| <span style='display: inline-block; width: 42px;'>01-01</span> | **A & B == B & A: Triggering Logical Reasoning Failures in Large Language Models**<br><sub>机构: The Chinese University of Hong Kong, Tencent AI Lab<br>本论文针对LLMs的逻辑推理能力的评估和改进问题，提出了一个名为LogicAsker的方法，能够全面评估LLMs的推理能力，并通过问题生成和上下文学习有效提升这些能力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.00757v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.00757.md)  |
| <span style='display: inline-block; width: 42px;'>01-01</span> | **The Earth is Flat? Unveiling Factual Errors in Large Language Models**<br><sub>机构: The Chinese University of Hong Kong, Tencent AI Lab<br>本文介绍的FactChecker提供了针对大型语言模型的事实错误自动测试新框架，通过构建知识图谱并生成测试问题，揭示并减少了模型的事实错误。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.00761v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.00761.md)  |
| <span style='display: inline-block; width: 42px;'>01-01</span> | **From Prompt Engineering to Prompt Science With Human in the Loop**<br><sub>机构: University of Washington<br>文章展示了如何将LLMs的提示工程转化为更为科学和系统的提示科学。通过引入人在环中的质性编码方法，确保了LLM生成的响应的质量和一致性，同时消除了个体主观性和随意性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.04122v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.04122.md)  |

---

### 12月

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>12-31</span> | **BatchEval: Towards Human-like Text Evaluation**<br><sub>机构: Beijing Institute of Technology, Xiaohongshu Inc  <br>论文提出了一种新的LLM评估范式——BATCHEVAL，解决了自动文本评估在鲁棒性和与人类判断一致性方面的问题。通过批量评估和迭代处理，BATCHEVAL在准确性和成本效率方面显著超越了现有方法。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.00437v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2401.00437.md)  |
| <span style='display: inline-block; width: 42px;'>12-31</span> | **Improving Text Embeddings with Large Language Models**<br><sub>机构: Microsoft Corporation<br>本文采用最新的大型语言模型和合成数据，提出一种新颖的文本嵌入方法，能够在无需人工标注数据且训练步骤少于1千的情况下，达到与竞争性基准相匹配的性能，为进一步提升文本嵌入技术提供了有力证据。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.00368v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2401.00368.md)  |
| <span style='display: inline-block; width: 42px;'>12-29</span> | **DB-GPT: Empowering Database Interactions with Private Large Language Models**<br><sub>机构: Alibaba Group<br>本文提出了名为DB-GPT的创新项目，该项目集成了LLMs及数据库系统，以提升用户体验和无障碍性。DB-GPT展现了层次化设计，有效处理了隐私和安全保护等问题，同时通过多源RAG和自适应ICL提升了系统的整体性能和效率。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.17449v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.17449.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/eosphoros-ai/DB-GPT)</div> |
| <span style='display: inline-block; width: 42px;'>12-29</span> | **Building Efficient Universal Classifiers with Natural Language Inference**<br><sub>机构: Vrije Universiteit Amsterdam, University of London Royal Holloway, Hugging Face<br>这篇论文提供了一种利用自然语言推断进行通用文本分类的新方法，并且提供了实现该方法的详细步骤和工具，能够在不牺牲性能的前提下显著提高模型的效率。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.17543v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.17543.md)  |
| <span style='display: inline-block; width: 42px;'>12-29</span> | **Enhancing Quantitative Reasoning Skills of Large Language Models through Dimension Perception**<br><sub>机构: **Institution:** Shanghai Key Laboratory of Data Science School of Computer Science Fudan University, School of Data Science Fudan University, DataGrand Co. LTD<br>本文的研究通过建立维度单位知识库和定制化基准测试，显著提升了LLMs的定量推理能力。这为理解文本中重要的量值信息并进行高准确度的推理任务提供了新的途径。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.17532v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.17532.md)  |
| <span style='display: inline-block; width: 42px;'>12-29</span> | **The Right Prompts for the Job: Repair Code-Review Defects with Large Language Model**<br><sub>机构: Ant Group, Nanjing University<br>研究探讨了LLMs在代码审查缺陷修复中的应用，提出了一个有效的半自动APR范例，分析了9种流行模型的性能，并设计了有效的提示以指导代码修复过程。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.17485v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.17485.md)  |
| <span style='display: inline-block; width: 42px;'>12-29</span> | **Truth Forest: Toward Multi-Scale Truthfulness in Large Language Models through Intervention without Tuning**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.17484v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.17484.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/jongjyh/trfr)</div> |
| <span style='display: inline-block; width: 42px;'>12-28</span> | **Experiential Co-Learning of Software-Developing Agents**<br><sub>机构: Tsinghua University,Dalian University of Technology,Beijing University of Posts and Telecommunications<br>本文提出了一种新的框架，称为经验共同学习（Experiential Co-Learning），通过共同追踪、共同记忆和共同推理模块的顺序实现，使得LLM驱动的智能代理能够更有效地从历史轨迹中学习，并利用历史经验来相互推理解决新任务。展示了明显优于现有技术的绩效改进。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.17025v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.17025.md)  |
| <span style='display: inline-block; width: 42px;'>12-28</span> | **Challenge LLMs to Reason About Reasoning: A Benchmark to Unveil Cognitive Depth in LLMs**<br><sub>机构: Chinese University of Hong Kong, Tencent AI Lab<br>这篇论文提出了一个创新的评估模型，要求LLMs不仅要解决问题，还要进行元推理——即评估推理过程本身。这种方法有望揭示由于以往以结果为导向的评估方法而忽略的模型认知缺陷，为未来LLMs的评估和训练提供了新的方向。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.17080v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.1708.md)  |
| <span style='display: inline-block; width: 42px;'>12-28</span> | **Structured Packing in LLM Training Improves Long Context Utilization**<br><sub>机构: University of Warsaw, Google DeepMind, Polish Academy of Sciences<br>这篇论文通过提出SPLICE方法来改进长距离上下文的利用，验证了其在提高大规模语言模型上下文利用率和改进长上下文任务性能方面的有效性。SPLICE特别适用于在缺乏额外结构化信息的训练数据上构造训练示例。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.17296v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.17296.md)  |
| <span style='display: inline-block; width: 42px;'>12-28</span> | **GitAgent: Facilitating Autonomous Agent with GitHub by Tool Extension**<br><sub>机构: Tsinghua University, Renmin University of China<br>文章主要介绍了一个名为GITAGENT的自主代理，它可以自主从GitHub扩展工具，以满足用户查询的多种需求。GITAGENT通过解决非标准化挑战，能够自主学习基于GitHub Issues/PRs的人类经验，以解决工具扩展过程中的问题，并且展示了在自主集成工具以完成跨专业领域任务方面的有效性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.17294v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.17294.md)  |
| <span style='display: inline-block; width: 42px;'>12-28</span> | **Grounding-Prompter: Prompting LLM with Multimodal Information for Temporal Sentence Grounding in Long Videos**<br><sub>机构: Tsinghua University<br>本论文提出了Grounding-Prompter方法，针对长视频中的TSG问题，将LLM与时序推理和多模态信息结合起来，证明了通过多模态提示LLM的有效性，并通过实验验证了其在长视频TSG任务中的优越性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.17117v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.17117.md)  |
| <span style='display: inline-block; width: 42px;'>12-28</span> | **Challenge LLMs to Reason About Reasoning: A Benchmark to Unveil Cognitive Depth in LLMs**<br><sub>机构: Chinese University of Hong Kong, Tencent AI Lab<br>这篇论文提出了一个挑战LLMs进行元推理的新评估范式，并开发了配套的公开基准DiagGSM8K，这为评估LLMs的认知能力增加了一个新维度。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.17080v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.1708.md)  |
| <span style='display: inline-block; width: 42px;'>12-28</span> | **DrugAssist: A Large Language Model for Molecule Optimization**<br><sub>机构: Tencent AI Lab, Department of Computer Science Hunan University<br>DrugAssist是一个通过人机交互进行分子优化的模型，它突破了LLMs在药物发现过程中互动性不足的局限，并在多属性分子优化领域展现了出色的性能和转移能力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.10334v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2401.10334.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/blazerye/DrugAssist)</div> |
| <span style='display: inline-block; width: 42px;'>12-28</span> | **Improving In-context Learning via Bidirectional Alignment**<br><sub>机构: Nanyang Technological University, Princeton University, Salesforce Research USA<br>本文通过引入新颖的排名损失以及对输出分布的对齐，提出了双向对齐(BiAlign)，有效提高了小型模型的 ICL 能力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.17055v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.17055.md)  |
| <span style='display: inline-block; width: 42px;'>12-27</span> | **Conversational Question Answering with Reformulations over Knowledge Graph**<br><sub>机构: University of Illinois at Urbana-Champaign, Amazon<br>CoRnNet 是一种新型RL模型，用于在知识图谱上进行会话式问题回答并结合LLM生成的改写，展现了比其他先进模型更出色的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.17269v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.17269.md)  |
| <span style='display: inline-block; width: 42px;'>12-27</span> | **Adapting Large Language Models for Education: Foundational Capabilities, Potentials, and Challenges**<br><sub>机构: Shanghai Jiao Tong University (SJTU)<br>本论文是一个关于如何适配大型语言模型于教育系统的综述，它提供了对LLMs在教育相关能力方面的发展情况的概述，并探讨了构建这样系统的潜力与挑战，为未来的相关研究提供了洞见。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.08664v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2401.08664.md)  |
| <span style='display: inline-block; width: 42px;'>12-27</span> | **How Robust are LLMs to In-Context Majority Label Bias?**<br><sub>机构: Amazon<br>本文对LLMs在面对ICL中多数类标签偏差时的鲁棒性进行了全面研究，通过实验发现某些模型在处理这种偏差时显示出显著的稳定性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.16549v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.16549.md)  |
| <span style='display: inline-block; width: 42px;'>12-27</span> | **Rethinking Tabular Data Understanding with Large Language Models**<br><sub>机构: UC San Diego, USC, UC Davis  <br>这篇论文深入探讨了LLMs对表格数据的理解和推理能力，对表格结构的鲁棒性、文本与符号推理的比较，以及多推理路径聚合对模型性能提升的影响做出了贡献。所提出的表格结构标准化方法和混合自一致性机制对提高LLMs在表格数据推理上的性能具有重要意义。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.16702v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.16702.md)  |
| <span style='display: inline-block; width: 42px;'>12-26</span> | **Think and Retrieval: A Hypothesis Knowledge Graph Enhanced Medical Large Language Models**<br><sub>机构: Key Laboratory of High Confidence Software Technologies (Peking University), Ministry of Education; School of Computer Science Peking University, Beijing China<br>HyKGE框架有效解决了大型语言模型在面对医疗领域复杂问题时的准确性和解释性挑战，具有在医疗领域中的潜在应用并且在实际场景中展示出了很大的优越性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.15883v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.15883.md)  |
| <span style='display: inline-block; width: 42px;'>12-26</span> | **Scaling Down, LiTting Up: Efficient Zero-Shot Listwise Reranking with Seq2seq Encoder-Decoder Models**<br><sub>机构: University of Waterloo<br>这篇论文提出了LiT5-Distill和LiT5-Score两种序列到序列的编码器-解码器模型，用于有效的零样本列表级重新排序。这些方法不仅在模型效果上竞争力强，并且解决了传统依赖于大型LLM和外部相关性标签的问题，展示了在这一领域的优化和进步。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.16098v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.16098.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/castorini/LiT5)</div> |
| <span style='display: inline-block; width: 42px;'>12-26</span> | **Align on the Fly: Adapting Chatbot Behavior to Established Norms**<br><sub>机构: Shanghai Jiao Tong University, Shanghai Artificial Intelligence Laboratory, The Hong Kong Polytechnic University<br>该工作提出了一个动态的OPO方法，通过收集法律和道德规则作为外部存储器来限制LLMs的行为，无需进一步训练，并通过一个可扩展的评估模块来应对潜在的基准测试泄漏问题及扩大测试规则的范围。尽管该方法在推理效率方面存在局限性并且检索模型仍可进一步优化，但在多个评估数据集上的广泛实验表明了该方法的有效性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.15907v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.15907.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/GAIR-NLP/OPO)</div> |
| <span style='display: inline-block; width: 42px;'>12-26</span> | **Supervised Knowledge Makes Large Language Models Better In-context Learners**<br><sub>机构: School of Engineering Westlake University, Westlake Institute for Advanced Study, Peking University<br>论文提出的SuperContext框架通过利用特定任务微调的SLMs的监督知识，显著提高了LLMs在自然语言理解和问答任务中的泛化能力和事实性。它代表了将小型模型的强大功能融入LLMs，以处理分布外数据和最小化幻觉现象的一种创新做法。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.15918v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.15918.md)  |
| <span style='display: inline-block; width: 42px;'>12-26</span> | **KnowledgeNavigator: Leveraging Large Language Models for Enhanced Reasoning over Knowledge Graph**<br><sub>机构: Northeastern University, Neusoft AI Magic Technology Research, Neusoft Institute of Intelligent Medical Research<br>这篇论文介绍了一个新型框架KnowledgeNavigator，它通过改善知识图谱上的推理过程，解决了LLM在复杂推理任务上的性能局限问题。实验结果证实了其有效性，并有望在高风险和高敏感领域推广LLM的应用。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.15880v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.1588.md)  |
| <span style='display: inline-block; width: 42px;'>12-26</span> | **RecRanker: Instruction Tuning Large Language Model as Ranker for Top-k Recommendation**<br><sub>机构: City University of Hong Kong, The Chinese University of Hong Kong, Hangdian University<br>该论文提出了RecRanker这一新型框架，它通过指令调整的方式优化了LLMs在top-k推荐任务中的性能，并有效地融合了传统推荐系统的信号，改善了模型在推荐场景中的应用表现。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.16018v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.16018.md)  |
| <span style='display: inline-block; width: 42px;'>12-26</span> | **A Prompt Learning Framework for Source Code Summarization**<br><sub>机构: Nanyang Technological University, Tencent Inc., Nanjing University<br>本论文提出了一个新颖的PromptCS框架，用于源代码摘要，能够生成高质量的摘要，减少了训练成本，并提供了代码以供他人研究。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.16066v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.16066.md)  |
| <span style='display: inline-block; width: 42px;'>12-26</span> | **Aligning Large Language Models with Human Preferences through Representation Engineering**<br><sub>机构: Fudan University  <br>本论文提出了一个新颖的方法RAHF，通过表示工程技术操纵内部模型表示来对齐LLMs与人类偏好，这种方法在计算上高效且容易实现，并展示了处理多种人类偏好或价值的潜力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.15997v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.15997.md)  |
| <span style='display: inline-block; width: 42px;'>12-25</span> | **Alleviating Hallucinations of Large Language Models through Induced Hallucinations**<br><sub>机构: Soochow University, Tencent AI Lab<br>论文提出一个新颖的减少LLMs幻觉的方法，通过构建一个事实上较弱的LLM并在生成过程中减去其知识，改进了模型在生成事实性内容方面的表现。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.15710v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.1571.md)  |
| <span style='display: inline-block; width: 42px;'>12-25</span> | **ESGReveal: An LLM-based approach for extracting structured data from ESG reports**<br><sub>机构: Alibaba Cloud, Tsinghua University, Sun Yat-Sen University<br>ESGReveal代表了在处理ESG数据中的一大步进，旨在通过大型语言模型和相关技术来提高从公司报告中提取结构化数据的一致性和准确性，并推动了ESG实践和透明度的改进。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.17264v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.17264.md)  |
| <span style='display: inline-block; width: 42px;'>12-22</span> | **Reasons to Reject? Aligning Language Models with Judgments**<br><sub>机构: Tencent AI Lab, The Chinese University of Hong Kong<br>论文提出了一个新的通过直接利用语言反馈来对齐LLMs的框架Contrastive Unlikelihood Training（CUT），并且证明了其在多种场景下的有效性，包括离线对齐和在线对齐，以及从未对齐的模型（冷启动）和已对齐的模型（热启动）进行进一步优化。研究显示，与奖励相比，评判性反馈在对齐LLMs方面具有更大的潜力，值得进行进一步研究。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.14591v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.14591.md)  |
| <span style='display: inline-block; width: 42px;'>12-22</span> | **VIEScore: Towards Explainable Metrics for Conditional Image Synthesis Evaluation**<br><sub>机构: University of Waterloo, IN.AI Research<br>该论文提出了一个名为VIEScore的评估框架，旨在提供对条件图像生成任务的可解释性评价。VIEScore克服了现有自动化度量无法解释评分理由的挑战，并能够适应各种任务需求。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.14867v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.14867.md)  |
| <span style='display: inline-block; width: 42px;'>12-22</span> | **A Survey of Reinforcement Learning from Human Feedback**<br><sub>机构: LMU Munich, Duke Kunshan University<br>这篇文章是对RLHF的综述，分析了它在人工智能和人机交互交叉点中的应用，并探讨了与LLMs相关的最新研究趋势。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.14925v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.14925.md)  |
| <span style='display: inline-block; width: 42px;'>12-22</span> | **Generative AI Beyond LLMs: System Implications of Multi-Modal Generation**<br><sub>该论文是针对跨文本、图像和视频生成模型的系统性能特征化的首次工作，它揭示了不同于传统LLMs的独特系统属性，并提出了对于TTI/TTV模型而言，传统的优化技术需要重新考虑的挑战和机会。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.14385v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.14385.md)  |
| <span style='display: inline-block; width: 42px;'>12-22</span> | **Large Language Model (LLM) Bias Index -- LLMBI**<br><sub>机构: University of Oxford, University Canada West, Amazon Web Services (AWS)<br>引入LLMBI是在创建公平可靠的LLMs方面迈出的重要一步。它为系统工程师和研究人员提供了一种定量衡量偏见的工具，引导他们持续改进这些强大的模型，确保它们反映社会的多样性和不断进化的结构。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.14769v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.14769.md)  |
| <span style='display: inline-block; width: 42px;'>12-22</span> | **Plan, Posture and Go: Towards Open-World Text-to-Motion Generation**<br><sub>机构: Tsinghua University, Microsoft Research Asia<br>研究者们提出了一个名为PRO-Motion的新框架，以克服传统文本到动作生成方法的局限性，并成功在开放世界场景中生成更多样和真实的动作。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.14828v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.14828.md)  |
| <span style='display: inline-block; width: 42px;'>12-22</span> | **YAYI 2: Multilingual Open-Source Large Language Models**<br><sub>机构: Beijing Wenge Technology Co. Ltd., Institute of Automation Chinese Academy of Sciences<br>该论文提出了YAYI 2，一个针对多语言场景优化的大型语言模型，通过在大规模语料库上进行预训练，并通过多种方法与人类价值观对齐，显著提升了模型在多种任务中的表现，特别是在中文相关任务上。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.14862v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.14862.md)  |
| <span style='display: inline-block; width: 42px;'>12-22</span> | **Pangu-Agent: A Fine-Tunable Generalist Agent with Structured Reasoning**<br><sub>机构: Huawei Noah's Ark Lab, University College London, University of Oxford<br>本论文提出了Pangu-Agent框架，目标是解决标准RL方法在多任务环境中所面临的挑战。Pangu-Agent通过内在函数引入结构性推理，并通过监督学习和RL实现智能体的微调，提高了智能体适应多环境交互的能力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.14878v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.14878.md)  |
| <span style='display: inline-block; width: 42px;'>12-22</span> | **NPHardEval: Dynamic Benchmark on Reasoning Ability of Large Language Models via Complexity Classes**<br><sub>机构: University of Michigan, Rutgers University<br>本论文通过NPHardEval基准测试提供了一种新的评估LLMs推理能力的方法。该基准测试广泛涵盖了从多项式时间到NP-Hard复杂性级别的问题，并设计了动态数据更新机制以防止模型过拟合，从而确保了评估结果的可靠性和真实性。这些发现极大地促进了对LLMs当前能力的理解，并为提高这些模型的推理能力铺平了道路。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.14890v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.1489.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/casmlab/NPHardEval)</div> |
| <span style='display: inline-block; width: 42px;'>12-21</span> | **The Truth is in There: Improving Reasoning in Language Models with Layer-Selective Rank Reduction**<br><sub>机构: MIT, Microsoft Research NYC<br>该论文提出了LASER，一种在模型训练完成后对Transformer模型的特定层进行裁剪以提升性能的方法。作者表明，这种策略不仅有效，而且是首次发现可以通过精心选择的剪枝来增强Transformer模型的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.13558v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.13558.md)  |
| <span style='display: inline-block; width: 42px;'>12-21</span> | **On Task Performance and Model Calibration with Supervised and Self-Ensembled In-Context Learning**<br><sub>机构: Language Technology Lab University of Cambridge<br>本文提供了在资源有限的情况下不同学习方法的性能和校准的全面分析。这表明虽然提高性能和校准同时达成是困难的，但通过自组装技术能够在不影响性能的前提下增强模型的校准，对于未来LLMs的应用提供了重要的实践指导。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.13772v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.13772.md)  |
| <span style='display: inline-block; width: 42px;'>12-21</span> | **AppAgent: Multimodal Agents as Smartphone Users**<br><sub>机构: Tencent  <br>这项研究提出了一个创新的多模态代理框架，它允许代理像人类用户一样操作任何智能手机应用，并通过自动探索和观察人类演示来学习新应用的使用方法。研究结果证实了该框架在执行多样化高级任务时的效率和适应性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.13771v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.13771.md)  |
| <span style='display: inline-block; width: 42px;'>12-21</span> | **De novo Drug Design using Reinforcement Learning with Multiple GPT Agents**<br><sub>机构: Tsinghua University, Microsoft Research AI<br>这篇论文推出了一个结合多个GPT代理的强化学习算法用于药物分子的生成，并在GuacaMol基准测试和SARS-CoV-2蛋白靶标抑制剂设计中显示出良好的性能和实用性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06155v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2401.06155.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/HXYfighter/MolRL-MGPT)</div> |
| <span style='display: inline-block; width: 42px;'>12-20</span> | **Time is Encoded in the Weights of Finetuned Language Models**<br><sub>这项研究通过时间向量的概念表明了时间变化可以在一定程度上通过语言模型的权重空间来编码，并且权重插值可以帮助定制模型以适应新的时间段。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.13401v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.13401.md)  |
| <span style='display: inline-block; width: 42px;'>12-20</span> | **Lampr: Boosting the Effectiveness of Language-Generic Program Reduction via Large Language Models**<br><sub>机构: University of Waterloo, The Hong Kong University of Science and Technology, Concordia University<br>Lampr是第一个整合LLMs于程序缩减过程的算法。它通过多层次提示方法和LLMs的辅助，取得了跨语言通用性和特定语言语义意识之间的平衡，并且在实验中证明了其优越性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.13064v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.13064.md)  |
| <span style='display: inline-block; width: 42px;'>12-20</span> | **AgentCoder: Multi-Agent-based Code Generation with Iterative Testing and Optimisation**<br><sub>机构: The University of Hong Kong, Shanghai Jiao Tong University, King’s College London<br>本论文提出了一个新颖的基于多智能体的代码生成解决方案AgentCoder，通过特定的智能体聚焦于代码生成、测试设计和测试执行，有效地解决了代码生成与测试之间的平衡问题，并实现了优于现有SOTA方法的代码生成质量。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.13010v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.1301.md)  |
| <span style='display: inline-block; width: 42px;'>12-20</span> | **Mini-GPTs: Efficient Large Language Models through Contextual Pruning**<br><sub>机构: Massachusetts Institute of Technology<br>这篇论文展示了通过上下文剪枝开发小型但高效的GPT模型，即Mini-GPTs的过程和结果。通过这种方法，研究人员在不同领域特定的数据集上成功减少了LLMs的尺寸并且保持了性能，展现了剪枝技术不仅理论上可行，而且在开发资源高效的领域特定LLMs中实践上具有实用价值。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.12682v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.12682.md)  |
| <span style='display: inline-block; width: 42px;'>12-20</span> | **Lookahead: An Inference Acceleration Framework for Large Language Model with Lossless Generation Accuracy**<br><sub>机构: Ant Group<br>本论文提出了名为Lookahead的推理加速框架，它通过使用基于Trie树的多分支推理策略，在提高LLMs推理速度的同时，保持了生成准确性。框架通过广泛的实验验证了其性能，并在支付宝的实际使用场景中得到了部署。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.12728v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.12728.md)  |
| <span style='display: inline-block; width: 42px;'>12-20</span> | **Generative Multimodal Models are In-Context Learners**<br><sub>机构: Beijing Academy of Artificial Intelligence, Tsinghua University, Peking University<br>本论文通过扩大模型规模，成功提升了多模态生成模型 Emu2 在上下文学习能力上的表现，并在一系列多模态理解任务中取得了突破性的效果，尤其在基于指令微调后的视觉问答和可控视觉生成方面。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.13286v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.13286.md)  |
| <span style='display: inline-block; width: 42px;'>12-20</span> | **AgentCoder: Multi-Agent-based Code Generation with Iterative Testing and Optimisation**<br><sub>机构: The University of Hong Kong, Shanghai Jiao Tong University<br>AgentCoder是一种新型的多代理框架，它在自动代码生成中通过进行迭代测试和优化，明显提高了代码生成的质量和准确性，尤其是在面对挑战性更大的增强型数据集时表现出其优势。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.13010v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.1301.md)  |
| <span style='display: inline-block; width: 42px;'>12-19</span> | **A Revisit of Fake News Dataset with Augmented Fact-checking by ChatGPT**<br><sub>本文提出了首个结合人类核实与ChatGPT辅助的假新闻检测公共基准数据集ChatGPT-FC，并通过定量分析对比了人类记者与LLM进行事实核查的差异。研究发现ChatGPT可以增强新闻事实核查过程的客观性和可靠性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.11870v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.1187.md)  |
| <span style='display: inline-block; width: 42px;'>12-19</span> | **Text-Conditioned Resampler For Long Form Video Understanding**<br><sub>机构: University of Oxford, Google, Google DeepMind<br>本论文提出了一个名为TCR的新型架构及预训练方法，能够处理与文本条件相结合的长视频。它有效地桥接了预训练的视觉编码器和LLM，实现了长期视频理解的问题，并在多个评估任务上取得了最佳性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.11897v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.11897.md)  |
| <span style='display: inline-block; width: 42px;'>12-19</span> | **Active Preference Inference using Language Models and Probabilistic Reasoning**<br><sub>机构: Cornell University, Cornell Tech<br>本研究提出了一个实时算法，通过生成信息丰富的问题来加快LLMs对用户偏好的推断，并在网购场景中验证了其减少用户交互并提高任务性能的能力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.12009v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.12009.md)  |
| <span style='display: inline-block; width: 42px;'>12-19</span> | **Curated LLM: Synergy of LLMs and Data Curation for tabular augmentation in ultra low-data regimes**<br><sub>机构: University of Cambridge<br>本文介绍了CLLM，这是一种结合了大型语言模型的先验知识和强大的数据中心方法来进行数据增强的新方法，旨在为资料匮乏的领域和地区的机器学习提供了新的途径。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.12112v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.12112.md)  |
| <span style='display: inline-block; width: 42px;'>12-18</span> | **From Google Gemini to OpenAI Q-Star: A Survey of Reshaping the Generative Artificial Intelligence (AI) Research Landscape**<br><sub>机构: Cyberstronomy Pty Ltd, Academies Australasia Polytechnic, Massey University<br>这项综述详尽地分析了生成型AI领域的发展及其对研究景观的重塑效应，尤其关注了MoE多模态学习和AGI的前景。研究涵盖了从AI模型结构和培训技术到应用领域和伦理考虑的全面分类。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.10868v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.10868.md)  |
| <span style='display: inline-block; width: 42px;'>12-18</span> | **G-LLaVA: Solving Geometric Problem with Multi-Modal Large Language Model**<br><sub>机构: Huawei Noah's Ark Lab, The University of Hong Kong, The Hong Kong University of Science and Technology<br>这篇论文通过构建 Geo170K 数据集和开发基于它的 G-LLaVA 模型，克服了多模态大型语言模型在解决几何问题上的限制，并实现了比现有最先端模型更好的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.11370v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.1137.md)  |
| <span style='display: inline-block; width: 42px;'>12-18</span> | **Generalized Category Discovery with Large Language Models in the Loop**<br><sub>本论文提出了一个端到端的主动学习框架，该框架通过引入大型语言模型进入训练循环，有效地提升了模型在泛化类别发现任务上的性能，并能自动生成类别名称。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.10897v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.10897.md)  |
| <span style='display: inline-block; width: 42px;'>12-18</span> | **Social Learning: Towards Collaborative Learning with Large Language Models**<br><sub>机构: Google, EPFL<br>本文提出了在LLMs中实现知识传递的新框架—社交学习，并提供了保护隐私的解决方案。该框架通过自然语言在模型间交换知识，同时避免敏感信息泄露，并通过实验验证了其有效性和隐私保护能力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.11441v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.11441.md)  |
| <span style='display: inline-block; width: 42px;'>12-18</span> | **MAC-SQL: Multi-Agent Collaboration for Text-to-SQL**<br><sub>机构: Beihang University, Tencent Cloud AI<br>总体而言，MAC-SQL 框架通过联合智能代理，解决了 Text-to-SQL 任务中的一些关键挑战，如处理大型数据库、复杂查询以及SQL验证和修正问题。还发布了一个开源模型SQL-Llama，该模型展示了鼓励性的结果，并具备与收费模型如GPT-4相媲美的潜力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.11242v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.11242.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/wbbeyourself/MAC-SQL)</div> |
| <span style='display: inline-block; width: 42px;'>12-18</span> | **"Paraphrasing The Original Text" Makes High Accuracy Long-Context QA**<br><sub>机构: Tsinghua University  <br>论文主要通过理论证明和实验验证，提出了一种低成本且高效的方法，通过原文释义任务和有效的指令微调数据扩展现有语言模型处理长文本的能力，显著提高了长文本问答的准确性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.11193v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.11193.md)  |
| <span style='display: inline-block; width: 42px;'>12-18</span> | **Retrieval-Augmented Generation for Large Language Models: A Survey**<br><sub>机构: Shanghai Research Institute for Intelligent Autonomous Systems, Tongji University, Fudan University<br>这篇论文为RAG领域提供了一个全面和系统的技术概览，强调了提升LLMs检索和生成能力的重要性，指出了现有挑战，展望了未来的研究方向。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.10997v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.10997.md)  |
| <span style='display: inline-block; width: 42px;'>12-18</span> | **NoMIRACL: Knowing When You Don't Know for Robust Multilingual Retrieval-Augmented Generation**<br><sub>机构: University of Waterloo, Huawei Noah’s Ark Lab, FEEC-Unicamp Brazil<br>这项工作通过引入NoMIRACL数据集，为评估LLM在检索式增强生成中的稳健性提供了一个多语言的评估工具，并通过建立GPT-4基线模型展示了LLM在识别相关与非相关检索结果中存在的挑战，突出了未来研究提高LLM稳健性的必要性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.11361v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.11361.md)  |
| <span style='display: inline-block; width: 42px;'>12-18</span> | **Agent-based Learning of Materials Datasets from Scientific Literature**<br><sub>机构: University of Toronto  <br>本论文展示了一个以大型语言模型为基础的智能代理在自动学习和提取科学文献中材料相关数据集方面的能力。Eunomia展示了在没有任何微调的情况下在提取实体和关系方面的有效性，且可以增强其在处理复杂任务时避免错误的能力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.11690v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.1169.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/AI4ChemS/Eunomia)</div> |
| <span style='display: inline-block; width: 42px;'>12-18</span> | **Designing LLM Chains by Adapting Techniques from Crowdsourcing Workflows**<br><sub>机构: University of Washington, Stanford University, Allen Institute for AI<br>本文提出了一个设计空间概念框架以及通过转换众包工作流到LLM链的三个案例研究，为未来LLM链的设计和开发提供了实践指导和理论见解。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.11681v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.11681.md)  |
| <span style='display: inline-block; width: 42px;'>12-18</span> | **Towards Better Serialization of Tabular Data for Few-shot Classification with Large Language Models**<br><sub>机构: Carnegie Mellon University<br>论文成功地展示了在表格数据分类中应用LLMs的创新实践，并以LaTeX序列化框架为特点，提出了有效处理领域特定数据集的新型序列化方法。研究还对LLMs在解读复杂数据关系方面的能力进行了深入的探索。论文的LaTeX序列化方法不仅提升了LLMs在分类任务中的表现，还显著提高了内存的使用效率和计算效率。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.12464v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.12464.md)  |
| <span style='display: inline-block; width: 42px;'>12-17</span> | **Distinguishing Translations by Human, NMT, and ChatGPT: A Linguistic and Statistical Approach**<br><sub>机构: Shanghai Jiao Tong University<br>本研究为ChatGPT作为NMT之外的另一种翻译工具的可能性提供了初步答案，并展示了ChatGPT与NMT和HT相比的独特特性。这些新认识有助于未来更人性化、更符合语境的翻译系统的开发，并为如何有效使用AI生成的翻译提供洞见。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.10750v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.1075.md)  |
| <span style='display: inline-block; width: 42px;'>12-17</span> | **Mixed Distillation Helps Smaller Language Model Better Reasoning**<br><sub>机构: Zhejiang University, Dalian Medical University<br>Mixed Distillation框架通过整合LLMs中的PoT和CoT能力到更小的模型中，显著改善了它们的高级推理能力，特别是在数学推理任务上的表现。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.10730v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.1073.md)  |
| <span style='display: inline-block; width: 42px;'>12-16</span> | **RIGHT: Retrieval-augmented Generation for Mainstream Hashtag Recommendation**<br><sub>机构: CAS Key Lab of Network Data Science and Technology ICT CAS, University of Chinese Academy of Sciences Beijing China<br>本文提出了一种新的检索增强型生成主流标签推荐系统（RIGHT），通过结合检索器、选择器和生成器的优势，克服了现有方法在理解新信息和识别主流标签方面的限制，并在实验中取得显著成效。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.10466v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.10466.md)  |
| <span style='display: inline-block; width: 42px;'>12-16</span> | **A Survey on Robotic Manipulation of Deformable Objects: Recent Advances, Open Challenges and New Frontiers**<br><sub>机构: Tongji University, National Natural Science Foundation of China, Shanghai Municipal Science and Technology Major Project<br>本综述归纳了机器人操作可变形对象（DOM）领域的近期进展、存在的挑战和新前沿。特别强调了大型语言模型（LLMs）在机器人操纵中的初始进展，并指出这一领域值得进一步研究的重要方向。尽管综述了大量的文献并指出了未来研究方向，但实际的部署示例和定量评估是有限的。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.10419v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.10419.md)  |
| <span style='display: inline-block; width: 42px;'>12-16</span> | **ProTIP: Progressive Tool Retrieval Improves Planning**<br><sub>机构: Apple  <br>这篇论文提出了 ProTIP，为大型语言模型在复杂规划任务中的工具检索和使用提供了一种进步的策略。ProTIP 的核心在于渐进式检索、有效利用执行历史和实现子任务与工具功能的对齐。实验结果展示出 ProTIP 明显超过传统方法，降低了工具虚构，并提高了规划效率。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.10332v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.10332.md)  |
| <span style='display: inline-block; width: 42px;'>12-16</span> | **CoAScore: Chain-of-Aspects Prompting for NLG Evaluation**<br><sub>机构: GSAI Renmin University of China<br>CoAScore 是一个新颖的评估指标，它通过“方面链”的方法提升了对于 NLG 任务的评估精度，并且该效果获得了实验的证实。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.10355v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.10355.md)  |
| <span style='display: inline-block; width: 42px;'>12-16</span> | **RecPrompt: A Prompt Tuning Framework for News Recommendation Using Large Language Models**<br><sub>机构: Science Foundation Ireland (SFI), JSPS KAKENHI<br>这篇论文提出了RecPrompt模型，利用LLM对新闻推荐进行优化。通过手动和LLM自动生成的提示模板的迭代优化过程，显著提高了新闻推荐性能，尤其是在使用GPT-4进行自动生成的提示模板下。然而，这种方法并非总是能超越传统的推荐方法，且推荐效果受到LLM选择的显著影响。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.10463v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.10463.md)  |
| <span style='display: inline-block; width: 42px;'>12-15</span> | **ProCoT: Stimulating Critical Thinking and Writing of Students through Engagement with Large Language Models (LLMs)**<br><sub>机构: Luleå University of Technology Sweden<br>本文通过引入ProCoT方法，展示了如何利用LLM促进学生批判性思维与写作，同时防止作弊。这种方法有助于教育者更好地利用这些技术工具，并培养学生成为更好的批判性思维者。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.09801v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.09801.md)  |
| <span style='display: inline-block; width: 42px;'>12-15</span> | **Challenges with unsupervised LLM knowledge discovery**<br><sub>机构: Google DeepMind, Google Research<br>本文通过理论证明和实验验证，挑战了现有无监督方法在探索LLMs中隐性知识的能力，并提出了未来评估知识启发方法时应考虑的理智检查。总体上，作者认为未来的无监督方法很可能会遇到类似的问题，即难以准确区分模型知识和其他特征。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.10029v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.10029.md)  |
| <span style='display: inline-block; width: 42px;'>12-15</span> | **Faithful Persona-based Conversational Dataset Generation with Large Language Models**<br><sub>机构: University of Southern California, Google, Information Sciences Institute<br>本论文提出了一种基于LLMs的框架，用于生成、扩展和更新大型的个性化对话数据集，并且通过Generator-Critic架构和信实性标准来提高对话的质量，有效地建立了Synthetic-Persona-Chat数据集。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.10007v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.10007.md)  |
| <span style='display: inline-block; width: 42px;'>12-15</span> | **ReST meets ReAct: Self-Improvement for Multi-Step Reasoning LLM Agent**<br><sub>机构: Google<br>本论文通过定义一个能够进行推理和外部知识互动的LLM代理，并采用自我改进算法，实现了在合成问答基准测试中小型模型与大型模型相媲美的表现。提出的方法不仅提高了模型的推理能力，也大大减小了模型所需的参数数量。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.10003v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.10003.md)  |
| <span style='display: inline-block; width: 42px;'>12-15</span> | **The Art of Balancing: Revolutionizing Mixture of Experts for Maintaining World Knowledge in Language Model Alignment**<br><sub>机构: NLP Group Fudan University, Hikvision Inc  <br>本论文提出了一个名为LoRAMoE的模型，用于解决大规模微调数据导致的语言模型中的世界知识遗忘问题，并在多任务学习中表现出潜力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.09979v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.09979.md)  |
| <span style='display: inline-block; width: 42px;'>12-15</span> | **Generative Context-aware Fine-tuning of Self-supervised Speech Models**<br><sub>机构: ASAPP, Carnegie Mellon University, Toyota Technological Institute at Chicago<br>论文介绍了一种新的自监督语音模型微调方法，它使用大型语言模型生成的文本信息作为上下文，以提高任务执行的表现力，同时在不牺牲性能的情况下减少对额外大型语言模型的依赖和减少推理时的资源消耗。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.09895v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.09895.md)  |
| <span style='display: inline-block; width: 42px;'>12-15</span> | **WEAK-TO-STRONG GENERALIZATION: ELICITING STRONG CAPABILITIES WITH WEAK SUPERVISION**<br><sub>机构: OpenAI<br></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](https://cdn.openai.com/papers/weak-to-strong-generalization.pdf)</div><div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/openai/weak-to-strong)</div><div style='min-width:85px;'>[![Blog](https://img.shields.io/badge/Blog-Posts-yellow?logo=rss)](https://mp.weixin.qq.com/s/f6YW-CxnLhnfMWTLg4M4Cw)</div> |
| <span style='display: inline-block; width: 42px;'>12-15</span> | **No-Skim: Towards Efficiency Robustness Evaluation on Skimming-based Language Models**<br><sub>机构: Fudan University<br>本论文首次系统地研究了从效率角度出发，基于"错过"的语言模型的脆弱性，并提出了一个有效和通用的效率鲁棒性评估框架No-Skim，以生成增加计算复杂度的对抗性输入。同时，该框架还通过不同的插件模块进行了模块化设计，这些模块在不同的实际情景下工作，评估可以在三种不同的知识水平下进行。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.09494v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.09494.md)  |
| <span style='display: inline-block; width: 42px;'>12-15</span> | **GSVA: Generalized Segmentation via Multimodal Large Language Models**<br><sub>机构: Tsinghua University<br>论文提出的GSVA方法通过学习预测多个[SEG]标记和创新性地生成[REJ]标记以解决GRES任务中存在的多目标和空目标挑战，相较于现有技术，展现了显著优势。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.10103v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.10103.md)  |
| <span style='display: inline-block; width: 42px;'>12-15</span> | **KGLens: A Parameterized Knowledge Graph Solution to Assess What an LLM Does and Doesn't Know**<br><sub>机构: Apple<br>本文提出了一种新的名为KGLens的框架，用于评估LLM中的事实知识。KGLens利用KG结构生成自然语言问题并进行评估，OD辅以参数化的KG和图指导的QG策略以提高自然问题的生成质量和评估过程的效率。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.11539v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.11539.md)  |
| <span style='display: inline-block; width: 42px;'>12-14</span> | **Zebra: Extending Context Window with Layerwise Grouped Local-Global Attention**<br><sub>机构: Tencent AI Lab Seattle<br>本文提出的Zebra模型通过使用分组的局部-全局注意力层，有效地降低了计算和内存需求，并在长短序列处理上展示了卓越的性能。研究团队通过一系列实验验证了模型的效果，证明了Zebra架构的优势。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.08618v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.08618.md)  |
| <span style='display: inline-block; width: 42px;'>12-14</span> | **Towards Verifiable Text Generation with Evolving Memory and Self-Reflection**<br><sub>机构: Peking University, Chinese Academy of Sciences, Baidu Inc<br>VTG通过演化的长短期记忆和自我反思的方法来提升LLMs生成文本时的可靠性和验证性，对复杂的注意力转移问题和文档检索的挑战有着有效的应对策略，并且通过实验获得了验证。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.09075v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.09075.md)  |
| <span style='display: inline-block; width: 42px;'>12-14</span> | **The Earth is Flat because...: Investigating LLMs' Belief towards Misinformation via Persuasive Conversation**<br><sub>机构: Tsinghua University, Stanford University, Nanyang Technological University<br>本论文为首次全面研究LLMs面对事实错误信息在劝说性对话设置中的鲁棒性，并揭示了LLMs对劝说性错误信息的易感性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.09085v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.09085.md)  |
| <span style='display: inline-block; width: 42px;'>12-14</span> | **Auto MC-Reward: Automated Dense Reward Design with Large Language Models for Minecraft**<br><sub>机构: CUHK-SenseTime Joint Laboratory, Shanghai AI Laboratory, Tsinghua University<br>Auto MC-Reward是一种先进的学习系统，利用LLMs以自动方式设计针对Minecraft任务的密集型奖励，通过LLMs的理解和经验总结能力，有效地提高了代理在复杂环境中学习新行为和完成长期任务的能力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.09238v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.09238.md)  |
| <span style='display: inline-block; width: 42px;'>12-14</span> | **Entity-Augmented Code Generation**<br><sub>机构: JetBrains<br>论文为解决利用外部实体进行代码生成的任务提出了一个新颖的架构。该架构能在不牺牲性能的前提下扩展，通过将实体检索器注入到解码器而非编码器中，模型可以一次性查看所有实体并直接使用它们。新架构不仅解决了现有模型的限制，还在多个实验场景中展示了其优越性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.08976v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.08976.md)  |
| <span style='display: inline-block; width: 42px;'>12-14</span> | **Math-Shepherd: A Label-Free Step-by-Step Verifier for LLMs in Mathematical Reasoning**<br><sub>机构: Peking University, DeepSeek-AI, The University of Hong Kong<br>MATH-SHEPHERD通过自动生成监督数据训练LLMs，来解决高成本人力标注的问题，并提高了LLMs在复杂数学问题上的准确性。这一成果为LLMs的进步和实际应用开辟了新的可能性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.08935v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.08935.md)  |
| <span style='display: inline-block; width: 42px;'>12-14</span> | **Modeling Complex Mathematical Reasoning via Large Language Model based MathAgent**<br><sub>机构: Shanghai Jiao Tong University<br>论文建议通过MathAgent框架，即Planner-Reasoner-Executor-Reflector (PRER)，提升LLMs解决复杂数学问题的能力。通过将问题分解为多个阶段并模拟人类解题过程，MathAgent能显著提高对挑战性数学数据集的解决能力，尤其是在估算和综合能力要求较高的领域。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.08926v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.08926.md)  |
| <span style='display: inline-block; width: 42px;'>12-14</span> | **Boosting LLM Reasoning: Push the Limits of Few-shot Learning with Reinforced In-Context Pruning**<br><sub>机构: Hong Kong University of Science and Technology, Microsoft Research<br>这篇论文提出了CoT-Max，一个通过粗到细的剪枝技术来增强LLMs数学推理能力的方法，有效地提高了少样本学习在数学推理任务中的效果。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.08901v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.08901.md)  |
| <span style='display: inline-block; width: 42px;'>12-14</span> | **Forbidden Facts: An Investigation of Competing Objectives in Llama-2**<br><sub>机构: MIT<br>这篇论文通过研究模型在禁止事实任务下的行为，解析了Llama-2-chat模型如何处理相互竞争的目标，并对它的分析提出了新的手法。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.08793v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.08793.md)  |
| <span style='display: inline-block; width: 42px;'>12-14</span> | **TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning**<br><sub>机构: National University of Singapore, University of Illinois Urbana-Champaign, Microsoft  <br>本文中提出的TAP4LLM框架通过采样、增强和打包半结构化数据，显著提升了大型语言模型在表格推理任务中的性能，并且可以作为插件提供给不同组件，用于增强LLMs对于结构化数据的理解。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.09039v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.09039.md)  |
| <span style='display: inline-block; width: 42px;'>12-14</span> | **Self-Evaluation Improves Selective Generation in Large Language Models**<br><sub>机构: Google DeepMind, Google Research<br>论文提出了一种新的方法，通过指导LLM进行自我评估，以提高其在选择性生成场景中输出内容质量的校准。实验证明，该方法可以提高LLM生成内容的准确性和整体质量。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.09300v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.093.md)  |
| <span style='display: inline-block; width: 42px;'>12-14</span> | **StemGen: A music generation model that listens**<br><sub>机构: SAMI, ByteDance Inc.<br>该论文提出了一个新的非自回归的语言模型方法用于音乐生成，优化了多声道的处理和音乐与上下文信息的一致性，并通过客观和主观评估证明了模型生成的音乐质量和与上下文信息的契合程度。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.08723v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.08723.md)  |
| <span style='display: inline-block; width: 42px;'>12-14</span> | **CogAgent: A Visual Language Model for GUI Agents**<br><sub>机构: Tsinghua University, Zhipu AI<br>CogAgent 打破了纯文本输入方式的局限性，通过结合高低分辨率的影像编码器和视觉语言模型，高效地解决了在图形用户界面（GUI）中理解和导航的挑战，同时在九个视觉问答基准测试中取得国际领先水平，推动了VLM在AI代理研究和应用方面的未来发展。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.08914v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.08914.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/THUDM/CogVLM)</div> |
| <span style='display: inline-block; width: 42px;'>12-14</span> | **TinyGSM: achieving >80% on GSM8k with small language models**<br><sub>机构: Carnegie Mellon University, Microsoft Research  <br>这篇论文通过创建一个合成的数学问题数据集TinyGSM及其对应的Python解决方案，成功使小型语言模型在GSM8K数学问题推理基准测试上的准确率超过了80%，展示了通过高质量数据集和验证器策略显著提高了小型模型性能的可行性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.09241v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.09241.md)  |
| <span style='display: inline-block; width: 42px;'>12-14</span> | **Weight subcloning: direct initialization of transformers using larger pretrained ones**<br><sub>机构: Apple<br>本论文提出了一种有效的权重子克隆（weight subcloning）技术，用以从较大的预训练模型初始化较小的变换器模型，显著提高了训练速度，并使得全新的模型即使在低计算资源条件下也能得到高效训练。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.09299v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.09299.md)  |
| <span style='display: inline-block; width: 42px;'>12-13</span> | **E&V: Prompting Large Language Models to Perform Static Analysis by Pseudo-code Execution and Verification**<br><sub>机构: UC Riverside, Microsoft Research<br>本论文通过提出E&V方法，展示了LLMs在执行伪代码静态分析和自我验证中的潜力。该方法不仅提高了静态分析的灵活性和精准度，还减少了编写静态分析工具需要的人力和专业知识。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.08477v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.08477.md)  |
| <span style='display: inline-block; width: 42px;'>12-13</span> | **LDM$^2$: A Large Decision Model Imitating Human Cognition with Dynamic Memory Enhancement**<br><sub>机构: University of Chinese Academy of Sciences<br>该论文提出了LDM2模型，它使用动态内存机制和树探索策略来增强LLMs的决策能力，使其能够适应更复杂和未知的环境，并实现动态学习能力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.08402v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.08402.md)  |
| <span style='display: inline-block; width: 42px;'>12-13</span> | **SwitchHead: Accelerating Transformers with Mixture-of-Experts Attention**<br><sub>机构: The Swiss AI Lab IDSIA USI & SUPSI, AI Initiative KAUST, Center for Brain Science Harvard University<br>SwitchHead是一种新颖的方法，它通过优化多头自注意力结构中的资源使用，实现了资源消耗的降低同时保持了模型性能。该方法具有实际应用潜力，尤其对于资源有限的研究人员和机构而言。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.07987v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.07987.md)  |
| <span style='display: inline-block; width: 42px;'>12-13</span> | **Efficient Toxic Content Detection by Bootstrapping and Distilling Large Language Models**<br><sub>机构: University of Southern California, Amazon.com Inc.<br>文章针对现有的网络有害内容自动探测面临的问题，提出了一个称为BD-LLM的新方法，它通过一个新的方法DToT来提升LLMs在有害内容检测任务中的效能和转移性，并将优化模型压缩以便更有效地部署。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.08303v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.08303.md)  |
| <span style='display: inline-block; width: 42px;'>12-13</span> | **Knowledge-Aware Artifact Image Synthesis with LLM-Enhanced Prompting and Multi-Source Supervision**<br><sub>机构: Peking University<br>本文提出了一个结合LLMs增强提示和多源监督的知识感知古代文物图像合成方法，解决了现有文本到图像合成方法在考古领域应用时缺乏领域知识的问题，并在质量和历史知识对齐方面取得了显著进步。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.08056v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.08056.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/danielwusg/artifact_diffusion)</div> |
| <span style='display: inline-block; width: 42px;'>12-12</span> | **Alignment for Honesty**<br><sub>机构: Shanghai Jiao Tong University, Shanghai Artificial Intelligence Laboratory, Fudan University<br>论文提出了与人类的诚实性对齐的概念，并在此基础上提出了挑战和解决方法。通过正式定义问题、提出新方法和建立评估框架，论文为大型语言模型中的诚实性对齐提供了全面的解决方案。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.07000v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.07.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/GAIR-NLP/alignment-for-honesty)</div> |
| <span style='display: inline-block; width: 42px;'>12-12</span> | **Efficient Few-Shot Clinical Task Adaptation with Large Language Models**<br><sub>本文提出了一个在少样本的医学图像分类中通过冷冻一部分网络层进行高效的微调方法，并且引入了大型语言模型来上下文化标签，以提供有效的语义指导。方法在挑战赛中取得了优异的成绩，表明在处理少样本场景下自然图像模型到医学图像任务的适配问题时具有很高的有效性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.07125v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.07125.md)  |
| <span style='display: inline-block; width: 42px;'>12-12</span> | **VILA: On Pre-training for Visual Language Models**<br><sub>机构: NVIDIA, MIT  <br>VILA利用改进的预训练策略，在多种视觉语言任务中显示出卓越的性能，为未来视觉语言模型的设计提供了实用指南。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.07533v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.07533.md)  |
| <span style='display: inline-block; width: 42px;'>12-12</span> | **Comparable Demonstrations are Important in In-Context Learning: A Novel Perspective on Demonstration Selection**<br><sub>机构: Shanghai Jiao Tong University<br>本文从示例间关系的角度研究ICL，提出通过最小化编辑文本以构造Comparable Demonstrations（CDs）来减轻潜在的示例偏倚，实验证明了其在OOD情形下的性能增益，表明了CDs在简化任务中尤其必要，并展示了其相对于示例数的稳健性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.07476v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.07476.md)  |
| <span style='display: inline-block; width: 42px;'>12-12</span> | **LLMEval: A Preliminary Study on How to Evaluate Large Language Models**<br><sub>机构: Fudan University, Shanghai Jiaotong University  <br>论文针对如何评估大型语言模型（LLMs），对多种评估标准、不同类型的评估者、评分方法和排名系统进行了比较和分析，提出了新的评估数据集LLMEval，对20个LLMs进行了评估，生成了大量的手动和自动评估结果。该研究为未来的LLM评估提供了有益的洞见和结论。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.07398v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.07398.md)  |
| <span style='display: inline-block; width: 42px;'>12-12</span> | **diff History for Long-Context Language Agents**<br><sub>机构: New York University<br>论文提出并验证了使用diff历史来提高对长交互历史的模型处理能力。这一方法显著提升了模型在复杂决策任务中的表现，并能有效扩大模型可处理的历史长度，为长时间序列决策代理的设计提供了新思路。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.07540v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.0754.md)  |
| <span style='display: inline-block; width: 42px;'>12-12</span> | **Tell, don't show: Declarative facts influence how LLMs generalize**<br><sub>机构: Apollo Research, University of Oxford<br>本文研究了培训数据中声明性陈述与统计模式或“程序”示例相冲突时模型的泛化情况。所得结果对于AI风险（关于“背叛转折”）和公平性有重要影响。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.07779v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.07779.md)  |
| <span style='display: inline-block; width: 42px;'>12-12</span> | **LLM in a flash: Efficient Large Language Model Inference with Limited Memory**<br><sub>机构: Apple<br>这份研究提供了一个创新且实用的解决方案，不仅能有效降低在内存受限设备上运行大型语言模型时的数据负载，还能显著提升推理速度，在实际应用中具有重要意义。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.11514v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.11514.md)  |
| <span style='display: inline-block; width: 42px;'>12-11</span> | **Honeybee: Locality-enhanced Projector for Multimodal LLM**<br><sub>机构: Kakao Brain<br>论文提出了一种新型的局部性增强投影器设计，解决了现有方法在处理视觉特征局部性上的不足，并有效利用了多面向指令数据集，最终使得Honeybee模型在多个MLLM基准测试中取得了显著的性能提升。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.06742v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.06742.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/kakaobrain/honeybee)</div> |
| <span style='display: inline-block; width: 42px;'>12-11</span> | **Dense X Retrieval: What Retrieval Granularity Should We Use?**<br><sub>机构: University of Washington, Tencent AI Lab<br>本文提出命题作为一种新型稠密检索单元，其在减少所检索文本中无关信息的同时，提高了下游问答任务的性能和跨任务泛化能力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.06648v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.06648.md)  |
| <span style='display: inline-block; width: 42px;'>12-11</span> | **Federated Full-Parameter Tuning of Billion-Sized Language Models with Communication Cost under 18 Kilobytes**<br><sub>机构: Zhejiang University, Alibaba Group<br>论文提出了一种新颖的联邦全参数微调方法——FedKSeed，通过ZOO与有限组种子结合，显著降低了数十亿大小LLMs全参数微调所需的通信开销，同时实现了较高的模型精确度和计算效率。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.06353v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.06353.md)  |
| <span style='display: inline-block; width: 42px;'>12-11</span> | **Unlocking Anticipatory Text Generation: A Constrained Approach for Faithful Decoding with Large Language Models**<br><sub>机构: Salesforce AI Research<br>本文提出了一种通过考虑未来约束满足来改善大型语言模型解码方法的新途径。提出的正式方法和评分机制通过与LLMs的基准测试，可以显著提高文本生成的质量和控制。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.06149v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.06149.md)  |
| <span style='display: inline-block; width: 42px;'>12-11</span> | **"What's important here?": Opportunities and Challenges of Using LLMs in Retrieving Information from Web Interfaces**<br><sub>机构: Carnegie Mellon University<br>本文研究了LLMs在从Web界面检索信息中的应用潜力和面临的挑战。通过一系列实验，揭示了模型性能的关键因素及其限制，并为未来工作指明了方向。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.06147v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.06147.md)  |
| <span style='display: inline-block; width: 42px;'>12-11</span> | **MMICT: Boosting Multi-Modal Fine-Tuning with In-Context Examples**<br><sub>机构: Xiamen University, Tencent YouTu Lab<br>这项工作通过提出MMICT，展示了在大型多模态语言模型上运用上下文学习能力以增强微调性能的新范式。通过设计M-Hub这一多功能模块并通过各种上下文示范实验，研究揭示了上下文学习在改善多模态任务性能中的潜力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.06363v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.06363.md)  |
| <span style='display: inline-block; width: 42px;'>12-11</span> | **Oracle-based Protocol Testing with Eywa**<br><sub>机构: Microsoft Research<br>本文介绍了基于神谕的测试方法，充分利用LLMs建立了丰富的协议行为模型，并通过符号执行和传统测试生成方法相结合，提升了网络协议测试用例的自动生成和覆盖面。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.06875v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.06875.md)  |
| <span style='display: inline-block; width: 42px;'>12-11</span> | **On Meta-Prompting**<br><sub>机构: Microsoft  <br>这篇论文提出了一个基于范畴论的理论框架来概括和描绘自动化提示方法，通过在构想力和创造力这两个领域的实验，展示了meta-prompting比传统固定提示方法更能生成用户偏好的输出。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.06562v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.06562.md)  |
| <span style='display: inline-block; width: 42px;'>12-11</span> | **Extracting Self-Consistent Causal Insights from Users Feedback with LLMs and In-context Learning**<br><sub>机构: Microsoft, Microsoft Research<br>该研究提出了一种新框架，使用LLMs和ICL从用户反馈中提取自洽的因果见解，以支持微软Feedback Hub的分析。该框架采用创新的自洽性和提示集合技术以抑制LLMs的幻觉和错误推理，并提出了两种启发式方法来评估反馈的信息丰富度。实验显示，该方法能有效地提取因果见解和新的bug，并有助于微软工程师优先处理信息量丰富的反馈。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.06820v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.0682.md)  |
| <span style='display: inline-block; width: 42px;'>12-10</span> | **Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs**<br><sub>机构: Microsoft Israel<br>这项研究的核心贡献在于它对比了细化训练和RAG两种方法对于LLMs知识注入能力的影响，并发现RAG在注入新的和已有的知识方面表现更佳。研究使用了创新的数据集和评估方法，确保了理论发现的实用性和可行性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.05934v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.05934.md)  |
| <span style='display: inline-block; width: 42px;'>12-09</span> | **Context Tuning for Retrieval Augmented Generation**<br><sub>机构: Apple  <br>本论文通过引入上下文调优这一新颖组件，提高了基于检索的增强计划（RAG-based planning）的效果，使其能处理不完整或不明确的查询，同时还降低了幻觉性错误的产生。研究对比了不同的检索方法在轻量模型和LLMs中的应用，并展示了新方法在提高上下文理解上的有效性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.05708v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.05708.md)  |
| <span style='display: inline-block; width: 42px;'>12-09</span> | **Can Large Language Models Serve as Rational Players in Game Theory? A Systematic Analysis**<br><sub>机构: Shanghai Jiao Tong University<br>本研究系统地探索了LLMs在游戏理论背景下的能力边界，并从三个角度出发，提供了将LLMs在社会科学研究中使用的进一步指导。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.05488v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.05488.md)  |
| <span style='display: inline-block; width: 42px;'>12-09</span> | **NLLG Quarterly arXiv Report 09/23: What are the most influential current AI Papers?**<br><sub>机构: University of Mannheim, University of Bielefeld<br>该论文通过分析在特定时间内arXiv上引用最多的论文，提供了AI研究领域的最新趋势和影响力分析，特别强调了大型语言模型在其中的重要性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.05688v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.05688.md)  |
| <span style='display: inline-block; width: 42px;'>12-09</span> | **Sim-GPT: Text Similarity via GPT Annotated Data**<br><sub>机构: Shannon.AI, Zhejiang University, Bytedance<br>Sim-GPT是一个利用GPT-4生成数据标签来训练STS模型的框架。它在生成数据时仅产生一次性成本，速度较快，模型在多个STS基准上性能优越。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.05603v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.05603.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/ShuheWang1998/Sim-GPT)</div> |
| <span style='display: inline-block; width: 42px;'>12-09</span> | **Agile-Quant: Activation-Guided Quantization for Faster Inference of LLMs on the Edge**<br><sub>机构: Northeastern University, Oracle<br>本文提出了一个名为Agile-Quant的激活引导量化框架，以加速大型语言模型的边缘设备推理。Agile-Quant克服了激活值异常的挑战和边缘设备上的硬件实施问题，并实现了与仅权重量化方法相当的任务性能，同时在实际设备上获得了显著的推理速度提升。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.05693v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.05693.md)  |
| <span style='display: inline-block; width: 42px;'>12-08</span> | **PaperQA: Retrieval-Augmented Generative Agent for Scientific Research**<br><sub>机构: RAND Corporation, Carnegie Mellon University, LangChain<br>该论文提出了PaperQA，一个基于检索的生成型代理，用于科学研究。PaperQA可以准确回答基于最新科学文献的问题，并且与人类专家的回答相当，甚至在某些方面表现更好。论文展示了PaperQA的有效性，并通过与人类专家和其他商业工具的对比，证明了其优越性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.07559v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.07559.md)  |
| <span style='display: inline-block; width: 42px;'>12-08</span> | **Using Program Knowledge Graph to Uncover Software Vulnerabilities**<br><sub>论文通过结合程序图和安全数据，提出了程序知识图谱，并利用大型语言模型的提示调整来自动生成检测软件代码中漏洞的查询。该方法旨在克服传统漏洞检测方法的局限性，提高漏洞检测的自动化程度和有效性，尤其是在静态分析中的应用。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.04818v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.04818.md)  |
| <span style='display: inline-block; width: 42px;'>12-07</span> | **Beyond Surface: Probing LLaMA Across Scales and Layers**<br><sub>机构: Hong Kong University of Science and Technology<br>本研究的核心贡献在于提出了一系列评估大型语言模型高阶能力的探针任务，这些任务围绕着计算能力、数学推理、逻辑推理和真实性检测。研究揭示了LLM的表现如何随着模型规模和层次结构的变化。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.04333v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.04333.md)  |
| <span style='display: inline-block; width: 42px;'>12-07</span> | **Fortify the Shortest Stave in Attention: Enhancing Context Awareness of Large Language Models for Effective Tool Use**<br><sub>机构: Gaoling School of Artificial Intelligence, Renmin University of China, Alibaba Group<br>该论文针对LLMs在工具使用时对上下文认知的不足提出了Attention Buckets方法，通过处理不同的RoPE角度基础来强化对上下文的关注，显著提升了LLMs在工具使用任务的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.04455v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.04455.md)  |
| <span style='display: inline-block; width: 42px;'>12-07</span> | **Generating Illustrated Instructions**<br><sub>机构: GenAI Meta, Columbia University<br>本论文介绍了一种名为StackedDiffusion的新方法，用于生成插图说明，这是一种将文本和图像结合起来描述如何实现某一目标的任务。该方法通过结合大型语言模型和文本到图像扩散模型，并引入一些新颖的建模技巧，解决了现有T2I模型无法直接从用户查询中生成视觉效果的问题，并在人类评估中超越了现有技术水平。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.04552v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.04552.md)  |
| <span style='display: inline-block; width: 42px;'>12-07</span> | **CLadder: A Benchmark to Assess Causal Reasoning Capabilities of Language Models**<br><sub>机构: MPI for Intelligent Systems, University of Washington<br>此研究为测试和分析大型语言模型（LLMs）在正规因果推理上的能力提出了CLADDER数据集和CAUSALCOT思维路径提示策略，通过实验突显了LLMs的局限并为未来研究提出了方向。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.04350v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.0435.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/causalNLP/cladder)</div> |
| <span style='display: inline-block; width: 42px;'>12-07</span> | **A Study on the Calibration of In-context Learning**<br><sub>机构: Harvard University<br>该论文深入研究了上下文内学习(ICL)在语言模型(LMs)中的校准准确性问题，并提出了评估和分析方法。它揭示了校准误差与模型大小和微调过程中的变化关系，以及校准在推理任务生成中的降低。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.04021v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.04021.md)  |
| <span style='display: inline-block; width: 42px;'>12-07</span> | **Cost-Effective In-Context Learning for Entity Resolution: A Design Space Exploration**<br><sub>机构: Renmin University of China, Beijing Institute of Technology, HKUST (GZ)<br>这篇论文提供了一个全面的研究，旨在探索如何开发一种成本效益的批量提示方法来进行实体解析。主要贡献是介绍 BATCHER 框架并提出基于覆盖的演示选择策略。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03987v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03987.md)  |
| <span style='display: inline-block; width: 42px;'>12-07</span> | **Chain of Code: Reasoning with a Language Model-Augmented Code Emulator**<br><sub>机构: Google DeepMind, Stanford University, University of California Berkeley  <br>Chain of Code (CoC)为语言模型增加了通过编写代码和模拟代码执行来改善推理能力的新维度。它在数字和语义推理任务中均实现了突破性的性能，对LLMs的应用范围进行了扩展，并有潜力应用于更广泛的问题。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.04474v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.04474.md)  |
| <span style='display: inline-block; width: 42px;'>12-07</span> | **An LLM Compiler for Parallel Function Calling**<br><sub>机构: UC Berkeley, ICSI, LBNL<br>论文提出了一个名为LLMCompiler的系统，解决了大型语言模型在执行多功能调用时的高延迟成本和效率低下的问题，通过并行化函数调用和优化协调来提高速度，节省成本并提升准确率。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.04511v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.04511.md)  |
| <span style='display: inline-block; width: 42px;'>12-06</span> | **OneLLM: One Framework to Align All Modalities with Language**<br><sub>机构: MMLab The Chinese University of Hong Kong, Shanghai Artificial Intelligence Laboratory<br>OneLLM通过其统一的多模态编码框架和渐进式对齐管道，在推理和利用方面展示了强大的多模态理解和处理能力，并成功地处理了扩展多模态LLMs的挑战。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03700v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.037.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/csuhan/OneLLM)</div> |
| <span style='display: inline-block; width: 42px;'>12-06</span> | **Generative agent-based modeling with actions grounded in physical, social, or digital space using Concordia**<br><sub>机构: Google DeepMind, Google Research<br>本论文提出了利用生成式大型语言模型增强基于代理的模型的方法，通过Concordia库实现了在社会、物理和数字空间中模拟代理的交互。该模型旨在提供逼真的社会模拟，并探索模型的有效性验证。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03664v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03664.md)  |
| <span style='display: inline-block; width: 42px;'>12-06</span> | **Holmes: Towards Distributed Training Across Clusters with Heterogeneous NIC Environment**<br><sub>机构: Zhejiang Lab<br>文章成功介绍了一个能在网络接口卡异构环境中进行大型语言模型训练的框架——Holmes。通过实证研究其性能，Holmes被证明可在异构环境中实现与同构RDMA NICs相当的性能水平，从而使LLM训练更加普及并扩大了有效扩展的可能性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03549v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03549.md)  |
| <span style='display: inline-block; width: 42px;'>12-06</span> | **AnimateZero: Video Diffusion Models are Zero-Shot Image Animators**<br><sub>机构: Peking University, Tencent AI Lab, HKUST<br>AnimateZero为T2V生成提供解耦和精确的外观和动作控制，通过空间外观控制和时间一致性控制，实现了从T2I到I2V的步骤式视频生成，同时维护良好的域一致性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03793v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03793.md)  |
| <span style='display: inline-block; width: 42px;'>12-06</span> | **Efficient Large Language Models: A Survey**<br><sub>机构: The Ohio State University, Google Research, Amazon AWS AI<br>论文综述了大型语言模型中对于稀疏激活方法的最新进展，特别是混合专家系统（MoE）及其在长文本处理方面的应用。它总结了MoE模型优化的各种方法，包括算法级别的改进和系统级别的加速框架。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03863v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03863.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/AIoT-MLSys-Lab/EfficientLLMs)</div> |
| <span style='display: inline-block; width: 42px;'>12-06</span> | **Controllable Human-Object Interaction Synthesis**<br><sub>机构: Stanford University, FAIR Meta<br>本文提出了一种新的交互合成方法CHOIS，它能在受语言描述指导的条件下，生成符合三维场景几何约束的人与物体的同步运动。该方法通过集成到一个系统中，展示了其在合成连续、逼真和环境感知的人物互动方面的有效性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03913v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03913.md)  |
| <span style='display: inline-block; width: 42px;'>12-05</span> | **Rank-without-GPT: Building GPT-Independent Listwise Rerankers on Open-Source Large Language Models**<br><sub>机构: University of Waterloo, 2Cohere, Comcast Applied AI<br>本文的核心成果是演示了如何构建一种不依赖GPT模型的有效列表重排序器，能显著超越现有基于GPT的重排序器，并呼吁研究社区开发更高质量的列表排序训练数据，以提升模型的表现。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.02969v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.02969.md)  |
| <span style='display: inline-block; width: 42px;'>12-05</span> | **A Comparative Study of AI-Generated (GPT-4) and Human-crafted MCQs in Programming Education**<br><sub>机构: Carnegie Mellon University  <br>本文的主要贡献是开发了一个基于GPT-4的自动化MCQ生成系统，通过专门的弹性构架和精确的LO对齐机制，成功生成与高等教育Python课程LO一致的MCQs。研究结果表明，自动生成的MCQ在大多数情况下与LO保持良好的一致性，质量接近人工设计的MCQ，但在拥有单一正确答案和高质量干扰项方面略显欠缺，未来工作应该集中在减轻这些问题上。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03173v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03173.md)  |
| <span style='display: inline-block; width: 42px;'>12-05</span> | **Beyond Isolation: Multi-Agent Synergy for Improving Knowledge Graph Construction**<br><sub>机构: Zhejiang Lab, Ant Group<br>通过在KGC中引入多智能体合作的方法，cooperKGC框架提升了智能体解决实体、关系和事件提取任务中的精确度，并有望为AI的协作意识化未来奠定了基础。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03022v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03022.md)  |
| <span style='display: inline-block; width: 42px;'>12-05</span> | **Let's Think Outside the Box: Exploring Leap-of-Thought in Large Language Models with Creative Humor Generation**<br><sub>机构: Sea AI Lab, Sun Yat-sen University, Harvard University  <br>本论文提出了一种旨在提升大型语言模型创造性思维能力的Creative Leap-of-Thought (CLoT)范式，并验证了其在多种任务中的有效性和概括能力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.02439v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.02439.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/sail-sg/CLoT)</div> |
| <span style='display: inline-block; width: 42px;'>12-05</span> | **RankZephyr: Effective and Robust Zero-Shot Listwise Reranking is a Breeze!**<br><sub>机构: University of Waterloo<br>RankZephyr是一款新型开源LLM，特别优化了零样本列表重新排序任务。它提供了与大型专有模型相当或更优的重新排序效果，同时强调了数据增强对于提升模型鲁棒性的重要性，并通过实验证明了其有效性和在现实场景中的应用潜力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.02724v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.02724.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/castorini/rank_llm)</div> |
| <span style='display: inline-block; width: 42px;'>12-05</span> | **Large Knowledge Model: Perspectives and Challenges**<br><sub>机构: Zhejiang University<br>本文提出了一种大型知识模型（LKM）的概念，旨在更有效地管理和解读知识表示的多样性。研究指出了从现有的大型语言模型到LKM转变的挑战，强调了结构化知识在预训练中的重要性，并提出了一套LKM的设计原则。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.02706v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.02706.md)  |
| <span style='display: inline-block; width: 42px;'>12-05</span> | **A Hardware Evaluation Framework for Large Language Model Inference**<br><sub>机构: Princeton University<br>LLMCompass 作为一种硬件评估框架，成功地应对了设计LLM推理硬件时面临的挑战。它不仅快速精准，而且具有架构描述性和成本意识，已经在商业硬件上进行了验证且显示出优异的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03134v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03134.md)  |
| <span style='display: inline-block; width: 42px;'>12-05</span> | **Prompt Optimization via Adversarial In-Context Learning**<br><sub>机构: National University of Singapore, Hong Kong University of Science and Technology, Institute for Infocomm Research (I2R) A*STAR<br>论文介绍了一个新颖的Adversarial In-Context Learning（adv-ICL）方法，用于优化大型模型中prompt的选择，以此提高模型性能。它可以实现对抗训练目标，克服数据和计算资源限制，通过优化prompt而不是模型参数来提升性能，且实验结果在多个任务上显著优于现有技术。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.02614v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.02614.md)  |
| <span style='display: inline-block; width: 42px;'>12-05</span> | **Inherent limitations of LLMs regarding spatial information**<br><sub>机构: ProtagoLabs, International Monetary Fund, NetMind.ai  <br>论文为GPT-4等大型语言模型在处理空间信息方面的能力提供了新的评估框架和专门设计的数据集，并分析了GPT-4在处理空间信息方面的能力和局限性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03042v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03042.md)  |
| <span style='display: inline-block; width: 42px;'>12-05</span> | **How should the advent of large language models affect the practice of science?**<br><sub>机构: Max Planck Institute for Biological Cybernetics, University of Tübingen, University of Washington  <br>本文讨论了LLMs对科学实践的影响，并建议对其使用持审慎态度，同时强调了保护科学的规范和认识论方面的重要性。虽然LLMs可能提升某些科研任务的效率，但作为工具，其使用应该谨慎并确保符合科学规范。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03759v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03759.md)  |
| <span style='display: inline-block; width: 42px;'>12-04</span> | **Exchange-of-Thought: Enhancing Large Language Model Capabilities through Cross-Model Communication**<br><sub>机构: Fudan University, National University of Singapore, Shanghai AI Laboratory  <br>本文提出的Exchange-of-Thought（EoT）框架通过模型间交流提升LLMs的推理能力，凭借四种通信范例和信心评估机制，在多个推理任务上取得了显著成效，并证明了外部思维在增强模型性能中的作用。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01823v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01823.md)  |
| <span style='display: inline-block; width: 42px;'>12-04</span> | **Competition-Level Problems are Effective LLM Evaluators**<br><sub>机构: Microsoft Research Asia, Xiamen University, Microsoft Azure AI<br>本研究通过评估大型语言模型在处理竞赛级编程问题上的表现，揭示了GPT-4等模型在真实推理能力上的不足，并提出了一些提升表现的方法。这些发现突显了这类问题作为评估LLMs的有效工具的重要性，并促进了对于提高LLMs复杂推理能力的进一步研究。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.02143v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.02143.md)  |
| <span style='display: inline-block; width: 42px;'>12-04</span> | **The Unlocking Spell on Base LLMs: Rethinking Alignment via In-Context Learning**<br><sub>机构: Allen Institute for Artificial Intelligence, University of Washington<br>本论文提出了一个通过上下文学习实现LLMs对齐的简单无须调整方法（URIAL），表现出与传统调整对齐方法相匹配甚至更好的效果。这一发现对未来LLMs研究具有重要的启示，说明了在LLMs对齐上更深入的分析和理论理解的重要性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01552v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01552.md)  |
| <span style='display: inline-block; width: 42px;'>12-04</span> | **On the Effectiveness of Large Language Models in Domain-Specific Code Generation**<br><sub>机构: Shanghai Jiao Tong University, Chongqing University, East China Normal University<br>这项研究表明，通过有效地整合领域知识到代码生成过程中，可以增强LLMs在特定领域内的代码生成能力。DomCoder作为一个新的代码生成方法，利用了不同策略以整合领域知识，并在特定设置下提升了代码生成的实际效果。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01639v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01639.md)  |
| <span style='display: inline-block; width: 42px;'>12-04</span> | **ChatGPT as a Math Questioner? Evaluating ChatGPT on Generating Pre-university Math Questions**<br><sub>机构: Nanyang Technological University, National University of Singapore<br>该研究提出了第一个系统的评估ChatGPT在生成前大学数学问题潜力的研究。通过两种主要场景：给定上下文和未给定上下文的生成问题，并为教育工作者提供实用的洞察。研究的结果有可能促进现代AI技术在教育领域的应用，并提高自动化数学问题生成的实用性和效率。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01661v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01661.md)  |
| <span style='display: inline-block; width: 42px;'>12-04</span> | **Data Management For Large Language Models: A Survey**<br><sub>机构: Peking University, Huawei Noah’s Ark Lab<br>这篇综述研究了在LLMs的预训练和监督式微调阶段，数据管理的研究现状以及数据管理策略的设计。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01700v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.017.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/ZigeW/data_management_LLM)</div> |
| <span style='display: inline-block; width: 42px;'>12-04</span> | **Retrieval-augmented Multi-modal Chain-of-Thoughts Reasoning for Large Language Models**<br><sub>机构: Xiamen University, MBZUAI, Tencent AI Lab<br>文章通过引入动态自动检索机制和分层抽样方法，成功提升了多模态任务中LLMs的CoT推理能力。提出的方法不仅提高了模型性能，而且通过多样化示例选择进一步细化了推理过程，为多模态推理领域树立了新的性能标杆。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01714v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01714.md)  |
| <span style='display: inline-block; width: 42px;'>12-04</span> | **A Survey on Large Language Model (LLM) Security and Privacy: The Good, the Bad, and the Ugly**<br><sub>机构: Elsevier<br>这篇论文总结了大型语言模型（LLMs）在安全性和隐私保护中的应用及相关挑战，指出LLMs在这些领域的好处、坏处和丑陋之处，同时强调了其在数据保护方面的潜力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.02003v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.02003.md)  |
| <span style='display: inline-block; width: 42px;'>12-04</span> | **LLMs Accelerate Annotation for Medical Information Extraction**<br><sub>机构: Google Research<br>本论文展示了一个利用大型语言模型，特别是Google的PaLM 2，来提升医学信息抽取任务中注释速度的方法。这个基于LLM的注释流程提高了效率且不需要对模型进行复杂的调参，使其成为一个有潜力的工具来加速医疗领域的数据注释工作。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.02296v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.02296.md)  |
| <span style='display: inline-block; width: 42px;'>12-03</span> | **Running cognitive evaluations on large language models: The do's and the don'ts**<br><sub>机构: Massachusetts Institute of Technology<br>这篇论文为大型语言模型的认知评估研究方法提供了指导性的建议，探讨了在方法论上如何避免在运行认知评估时可能出现的问题。论文的目标是贡献于AI心理学领域最佳实践的更广泛讨论。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01276v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01276.md)  |
| <span style='display: inline-block; width: 42px;'>12-03</span> | **TextGenSHAP: Scalable Post-hoc Explanations in Text Generation with Long Documents**<br><sub>机构: University of Southern California, Google Cloud AI<br>TextGenSHAP是一个为大型语言模型设计的高效后验解释性方法，通过改进解释生成的速度，并展示了如何利用这些解释改进长文档问答和文档检索系统。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01279v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01279.md)  |
| <span style='display: inline-block; width: 42px;'>12-03</span> | **D-Bot: Database Diagnosis System using Large Language Models**<br><sub>机构: Tsinghua University, Pigsty, ModelBest<br>D-Bot是一个基于大型语言模型的数据库诊断系统，它通过文档中的知识提取和生成有效的诊断报告来提高数据库诊断的效率和准确性，解决了区域专家在数据库诊断中遇到的挑战。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01454v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01454.md)  |
| <span style='display: inline-block; width: 42px;'>12-02</span> | **Large Language Models Are Zero-Shot Text Classifiers**<br><sub>机构: Florida Atlantic University<br>论文展示了LLMs可以有效作为零样本文本分类器的能力，这对于需要快速部署文本分类器的小团队或小企业来说特别有益。研究结果表明，在所有四个数据集中，GPT-4一致超过了传统ML算法。文章还建议未来的研究方向包括优化提示以获得更高的精度或引入评论代理以评估和提升LLM的结果。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01044v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01044.md)  |
| <span style='display: inline-block; width: 42px;'>12-02</span> | **Exploring and Improving the Spatial Reasoning Abilities of Large Language Models**<br><sub>机构: Stanford University  <br>论文提高了对LLMs在空间推理和序列标注方面能力的理解，提出了一种改进LLMs处理3D轨迹识别任务的方法，具有显著的性能提升。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01054v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01054.md)  |
| <span style='display: inline-block; width: 42px;'>12-02</span> | **Just-in-Time Security Patch Detection -- LLM At the Rescue for Data Augmentation**<br><sub>机构: University of Luxembourg, Windows Copilot Microsoft, Singapore Management University<br>论文提出了一种新颖的安全补丁检测框架 LLMDA，使用大型语言模型进行补丁分析和数据增强，并对多模态输入进行对齐。这使系统能够从补丁和代码的联合上下文中提取更丰富的信息，提升检测准确性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01241v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01241.md)  |
| <span style='display: inline-block; width: 42px;'>12-02</span> | **Axiomatic Preference Modeling for Longform Question Answering**<br><sub>本文提出的基于公理的框架为长篇问答偏好模型提供了一种新方法，通过细致审视人类偏好，并优化了偏好打分的准确性与效率。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.02206v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.02206.md)  |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **On Exploring the Reasoning Capability of Large Language Models with Knowledge Graphs**<br><sub>机构: Singapore Management University, National Sun Yat-sen University<br>研究结果显示，LLMs能够通过其内部知识图成功处理知识图推理任务，并能从上下文中推断出知识图关系，展示了LLMs在知识图推理中的潜力及应用价值。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00353v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.00353.md)  |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **Learning from One Continuous Video Stream**<br><sub>该论文介绍了一个框架，用于从单一连续视频流中进行在线学习，这一框架侧重于适应性与泛化的评估，并提出了一系列未来预测任务进行预训练。研究显示，在这种学习环境下，优化策略需要调整，通过减少动量和调整权重更新频率可以改善模型的适应性和泛化能力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00598v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.00598.md)  |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **Leveraging Large Language Models to Improve REST API Testing**<br><sub>机构: Georgia Institute of Technology, IBM Research<br>RESTGPT通过利用LLMs，特别是GPT-3.5 Turbo的高效准确性和少量示例学习的精准性，解决了现有方法在提取自然语言描述中规则和生成有效值时的限制，显著提升了REST API测试的质量和准确度。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00894v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.00894.md)  |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **The Cost of Compression: Investigating the Impact of Compression on Parametric Knowledge in Language Models**<br><sub>机构: University of Wisconsin - Madison<br>这项研究首次大规模考察了LLMs的压缩技术对模型参数知识的影响，并为实际应用提供了重要见解，特别是在关于修剪和量化技术相关的决策方面。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00960v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.0096.md)  |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **The Cost of Compression: Investigating the Impact of Compression on Parametric Knowledge in Language Models**<br><sub>机构: University of Wisconsin - Madison<br>本论文通过对大型语言模型（LLMs）进行压缩技术（剪枝和量化）的全面研究，揭示了这些技术对模型参数知识保留的影响，为实践者提供了关于模型压缩的有价值见解。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00960v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.0096.md)  |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **Improve Supervised Representation Learning with Masked Image Modeling**<br><sub>机构: Google Research, OpenAI  <br>这篇论文提出了一种融合监督表示学习和MIM的新训练设置，该设置在不增加显著的训练或推理开销的前提下，显著提高了下游任务如分类、图像检索和语义分割的表示学习质量。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00950v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.0095.md)  |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **Nash Learning from Human Feedback**<br><sub>机构: Google DeepMind<br>这篇文章提出了一种全新的调节大型语言模型以通过纳什均衡与人类偏好对齐的方法，展示了其在复杂任务中的潜能，并通过实验证明了其效果。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00886v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.00886.md)  |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **RLHF-V: Towards Trustworthy MLLMs via Behavior Alignment from Fine-grained Correctional Human Feedback**<br><sub>RLHF-V是一个通过细粒度校正型人类反馈校正MLLM行为的新框架，通过收集高质量的人类偏好数据为MLLMs提供人类对齐的学习信号，并通过全面的实验验证了该框架的有效性。该研究可能在提高大型多模态语言模型在各种任务中的可靠性和实用性方面取得重要进展。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00849v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.00849.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/RLHF-V/RLHF-V)</div> |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **Beyond ChatBots: ExploreLLM for Structured Thoughts and Personalized Model Responses**<br><sub>机构: Google<br>本文介绍了探索LLM系统ExploreLLM，它通过结合基于提示的任务分解方法和全新的类似图式的图形用户界面（UI），在用户和LLM助手之间提供了一种全新的交互模式。该系统通过在结构化和交互式界面中表示生成子任务，旨在减轻用户完成复杂任务时的认知负担，同时提高个性化响应的水平。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00763v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.00763.md)  |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **Deciphering Digital Detectives: Understanding LLM Behaviors and Capabilities in Multi-Agent Mystery Games**<br><sub>机构: Quebec AI Institute<br>这篇论文贡献了适应JuBensha游戏复杂性和新挑战的评估方法，并创建了一个能够评估交互式环境中LLM智能体能力的新框架ThinkThrice，推动了AI在多玩家角色扮演游戏中的应用。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00746v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.00746.md)  |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **Instruction-tuning Aligns LLMs to the Human Brain**<br><sub>机构: EPFL<br>本研究表明，通过指令调整训练的大型语言模型在世界知识表示方面以及与人脑活动的对齐程度上表现更佳。这为未来LLMs的发展提供了将世界知识集成到模型中的重要视角。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00575v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.00575.md)  |

---

### 11月

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>11-30</span> | **TaskBench: Benchmarking Large Language Models for Task Automation**<br><sub>机构: Zhejiang University<br>该文献提出了TaskBench基准测试和TASKEVAL评估系统，通过数据生成和量化评估系统，有效地解决了在任务自动化领域对LLMs的评估问题。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.18760v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.1876.md)  |
| <span style='display: inline-block; width: 42px;'>11-30</span> | **Unnatural Error Correction: GPT-4 Can Almost Perfectly Handle Unnatural Scrambled Text**<br><sub>机构: The University of Tokyo<br>研究展示了GPT-4处理混淆文本的强大能力，设置了两项新指标RR和RPG，并通过它们验证了GPT-4在不同混淆场景和比率下的稳定表现。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.18805v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.18805.md)  |
| <span style='display: inline-block; width: 42px;'>11-30</span> | **IAG: Induction-Augmented Generation Framework for Answering Reasoning Questions**<br><sub>机构: Huawei Poisson Lab<br>IAG框架通过归纳提示法加强知识陈述的真实性，并且优化了知识融合机制和学生归纳模型，以解决现有基于检索的方法在隐性推理问答任务上的不足。研究成果表明，IAG在回答涉及隐性推理的问答任务上表现更优。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.18397v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.18397.md)  |
| <span style='display: inline-block; width: 42px;'>11-30</span> | **Autonomous Agents in Software Development: A Vision Paper**<br><sub>机构: Tampere University<br>本论文提出了一个关于利用多个 GPT 代理来自动执行软件工程任务的愿景，并演示了在简单软件任务上所取得的初步成功。这项工作有可能彻底改变软件开发的方式，并缩短开发时间。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.18440v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.1844.md)  |
| <span style='display: inline-block; width: 42px;'>11-30</span> | **Applying Large Language Models and Chain-of-Thought for Automatic Scoring**<br><sub>机构: University of Georgia<br>本文展示了LLMs在促进自动评分方面的潜力，并强调CoT在配合项茎和评分标准使用时能显著增强评分的准确度。通过结合LLMs和CoT的方法，可以降低自动评分模型构建的复杂性和人力成本，并可能提供更接近人类评分结果的评分。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03748v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2312.03748.md)  |
| <span style='display: inline-block; width: 42px;'>11-30</span> | **MicroCinema: A Divide-and-Conquer Approach for Text-to-Video Generation**<br><sub>机构: University of Science and Technology of China, Microsoft Research Asia<br>MicroCinema以其创新的文本到视频生成两阶段流程和有效的Appearance Injection Network及Appearance Noise Prior机制，在视频生成质量上实现了新的突破，为后续工作提供了可借鉴的范例。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.18829v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.18829.md)  |
| <span style='display: inline-block; width: 42px;'>11-30</span> | **CoDi-2: In-Context, Interleaved, and Interactive Any-to-Any Generation**<br><sub>机构: UC Berkeley, Microsoft Azure AI, ZOOM<br>CoDi-2是一种具有前沿能力的多模态生成模型，可以处理复杂的多模态输入、在上下文中指导生成、通过多轮交互与用户互动，并实现了优秀的零样本和少样本性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.18775v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.18775.md)  |
| <span style='display: inline-block; width: 42px;'>11-30</span> | **PoseGPT: Chatting about 3D Human Pose**<br><sub>机构: Max Planck Institute for Intelligent Systems, Meshcapade<br>PoseGPT是一个新型框架，它通过在LLM中嵌入SMPL姿态标记，使模型可以直接从文本和视觉输入生成三维人体姿态，并在解释三维人体姿态方面实现了一定程度的创新。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.18836v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.18836.md)  |
| <span style='display: inline-block; width: 42px;'>11-30</span> | **What Do Llamas Really Think? Revealing Preference Biases in Language Model Representations**<br><sub>机构: Comcast Applied AI, University of Waterloo<br>作者们提出了一个新型探针来检测LLMs表示中的内隐关联偏见，并通过实验在偏好检测中达到了最新水平。研究还发现了多个指令遵循型和“传统”的LLMs中的显著偏见，这些偏见存在于国籍、政治、宗教和性别等方面，尽管LLMs已经经过明确的安全指导调整。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.18812v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.18812.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/castorini/biasprobe)</div> |
| <span style='display: inline-block; width: 42px;'>11-29</span> | **TimeBench: A Comprehensive Evaluation of Temporal Reasoning Abilities in Large Language Models**<br><sub>机构: Harbin Institute of Technology<br>TIMEBENCH基准的提出是对大型语言模型时间推理能力综合评估的重要步骤，它展示了当前模型与人类在这方面的差距，并为未来的研究提供了指引。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.17667v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.17667.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/zchuz/TimeBench)</div> |
| <span style='display: inline-block; width: 42px;'>11-29</span> | **Large Language Models for Networking: Applications, Enabling Techniques, and Challenges**<br><sub>机构: BUPT<br>该论文提出了一个整合大型语言模型与网络技术的新框架ChatNet，并探究了它在网络规划中的应用。研究表明，ChatNet可以有效提升网络任务的自动化和智能化水平，尽管在部署前仍需解决多模态数据整合和插件开发等挑战。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.17474v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.17474.md)  |
| <span style='display: inline-block; width: 42px;'>11-29</span> | **Are Large Language Models Good Fact Checkers: A Preliminary Study**<br><sub>机构: Chinese Academy of Sciences<br>这篇文章通过系统评估LLMs在整个事实核查流程中的潜力，发现尽管LLMs在某些方面表现出潜力，但依然需要更多研究和尝试来提升它们在事实核查任务上的表现。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.17355v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.17355.md)  |
| <span style='display: inline-block; width: 42px;'>11-29</span> | **Zero-shot Conversational Summarization Evaluations with small Large Language Models**<br><sub>机构: Intel labs<br>文章以大型语言模型在会话摘要任务中的应用作为焦点，深入探讨了不同指令对模型执行效果的影响，并研究了在有限硬件下使用压缩模型的优化方法。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.18041v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.18041.md)  |
| <span style='display: inline-block; width: 42px;'>11-29</span> | **Understanding and Improving In-Context Learning on Vision-language Models**<br><sub>机构: LMU Munich, University of Oxford<br>本文提出了一个用于视觉-语言模型在背景学习中选择示范的新方法MMICES，并通过一系列实验展示了其在不同模型和数据集上的良好性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.18021v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.18021.md)  |
| <span style='display: inline-block; width: 42px;'>11-29</span> | **Towards Top-Down Reasoning: An Explainable Multi-Agent Approach for Visual Question Answering**<br><sub>机构: Sun Yat-Sen University<br>这项工作通过创新性地结合三个代理来模拟人类认知中的自顶向下推理过程，并引入了多视角知识库的概念，显著提升了VQA模型的表现力和解释能力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.17331v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.17331.md)  |
| <span style='display: inline-block; width: 42px;'>11-29</span> | **How to Build an AI Tutor that Can Adapt to Any Course and Provide Accurate Answers Using Large Language Model and Retrieval-Augmented Generation**<br><sub>机构: The Education University of Hong Kong<br>这篇论文代表了一次开创性的尝试，构建了一个可以适应任何学科并提供高质量的定制化教育支持的AI导师系统。这不仅能促进AI教育技术的应用，而且为AI教学系统的发展开辟了新路径。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.17696v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.17696.md)  |
| <span style='display: inline-block; width: 42px;'>11-29</span> | **TaskWeaver: A Code-First Agent Framework**<br><sub>机构: Microsoft<br>TaskWeaver是为构建基于LLM的自治代理而设计的代码优先框架，实现了对复杂数据的高效处理以及插件的灵活使用，并将特定域知识成功整合入系统中。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.17541v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.17541.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/microsoft/TaskWeaver)</div> |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case Study in Medicine**<br><sub>机构: Microsoft<br>本文通过系统的提示工程方法探讨了在无需专家监督的情况下，如何指导通用的基础模型在专业任务上发挥专家级别的能力，具体以医学领域为案例研究。所提出的Medprompt策略证明了其在增强基础模型专业能力方面的显著优势，并展示了广泛适用于多个学科的可能性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.16452v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.16452.md)  |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **Beyond Hallucinations: Enhancing LVLMs through Hallucination-Aware Direct Preference Optimization**<br><sub>机构: Shanghai AI Laboratory<br>文章提出了一个新颖的策略来优化LVLMs并减少幻觉现象，同时介绍了一种新的评估方法来更全面地衡量幻觉现象，并通过实验验证了所提方法的有效性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.16839v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.16839.md)  |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **Graph Prompt Learning: A Comprehensive Survey and Beyond**<br><sub>机构: The Chinese University of Hong Kong, Hong Kong University of Science and Technology, Fudan University  <br>论文是关于图提示学习的综合性调研，涵盖了AGI在图数据处理方面面临的挑战以及如何通过图提示学习来实现AGI技术的跨模态、跨域和跨任务适用性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.16534v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.16534.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/WxxShirley/Awesome-Graph-Prompt)</div> |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **ChatGPT's One-year Anniversary: Are Open-Source Large Language Models Catching up?**<br><sub>机构: Nanyang Technological University<br>这篇综述文章提供了对开源LLMs在多任务领域相较ChatGPT的性能评估的考察，突出了目前开源LLMs的强项和潜在问题，并为未来的研究和开发提供了启示。此外，文章还总结了众多的最佳实践和挑战，显示出开源领域在一定程度上有望缩小与商业模型之间的差距。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.16989v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.16989.md)  |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **Animate Anyone: Consistent and Controllable Image-to-Video Synthesis for Character Animation**<br><sub>机构: Alibaba Group<br>本文提出了一个利用扩散模型进行角色动画的新框架“Animate Anyone”。该框架通过ReferenceNet保持外观一致性，并通过姿态引导器与时间层确保动画的可控性与连续性，取得了先进的角色动画生成结果。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.17117v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.17117.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/HumanAIGC/AnimateAnyone)</div><div style='min-width:85px;'>[![Blog](https://img.shields.io/badge/Blog-Posts-yellow?logo=rss)](https://humanaigc.github.io/animate-anyone/)</div> |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **LLaFS: When Large-Language Models Meet Few-Shot Segmentation**<br><sub>机构: Singapore University of Technology and Design, Zhejiang University <br>本文提出了一个基于大型语言模型（LLM）的小样本图像分割框架，并解决了让LLMs理解和执行视觉任务的核心挑战。通过定制指导和细粒度上下文指导相结合的方法，实现了高质量的小样本分割。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.16926v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.16926.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/lanyunzhu99/LLaFS)</div> |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **Prompting in Autoregressive Large Language Models**<br><sub>机构: George Mason University<br>本论文为自回归大型语言模型的提示技术领域提供了一个紧凑的文献综述，并指出了一些尚未解决的挑战和开放性问题，为未来研究提供了方向。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03740v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2312.0374.md)  |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **Training Chain-of-Thought via Latent-Variable Inference**<br><sub>机构: Google<br>本论文开发了一种基于MCMC-EM的微调策略，通过平均理由帮助LLMs生成正确的答案，具有潜在的推广应用的潜力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.02179v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2312.02179.md)  |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **RELIC: Investigating Large Language Model Responses using Self-Consistency**<br><sub>机构: ETH Zurich<br>RELIC是一个交互式系统，它通过多样本的事实一致性检验，帮助用户验证和指导LLMs生成的文本。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.16842v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.16842.md)  |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **RankingGPT: Empowering Large Language Models in Text Ranking with Progressive Enhancement**<br><sub>机构: Alibaba Group<br>本研究提出了一种用于文本排序的二阶段训练模型，结合了弱监督预训练和监督细化训练，通过在不损害预训练益处的基础上增强模型细化训练性能，完成了从预训练到细化训练的平滑过渡，并在实验中显著优于现有技术。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.16720v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.1672.md)  |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **AvatarGPT: All-in-One Framework for Motion Understanding, Planning, Generation and Beyond**<br><sub>研究提出了一个创新的，一体化的框架AvatarGPT，用于处理理解、规划以及生成人类动作相关的高级和低级任务，展现出长时间运动合成的能力和减少手动干预的可能性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.16468v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.16468.md)  |
| <span style='display: inline-block; width: 42px;'>11-27</span> | **RoboGPT: an intelligent agent of making embodied long-term decisions for daily instruction tasks**<br><sub>机构: Chinese Academy of Sciences, Peking University<br>文章提出了一个名为RoboGPT的智能体，该智能体用于制定执行日常指令任务的长期决策。该智能体通过一项新的机器人数据集，结合了LLMs的通用知识和机器人领域的专业知识，并引入了Re-Plan模块和RoboSkill模块以增强任务规划的逻辑性和适应性。在ALFRED基准测试和泛化任务上，RoboGPT优于现有的先进方法。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.15649v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.15649.md)  |
| <span style='display: inline-block; width: 42px;'>11-25</span> | **Faster Minimum Bayes Risk Decoding with Confidence-based Pruning**<br><sub>机构: University of Cambridge<br>论文提出了一个用于MBR解码的算法，该算法通过在样本估计中逐渐增加样本数量并使用置信度剪枝来减少用户函数调用。在保持准确度的同时，该算法显著降低了计算成本，并通过三种语言对的NMT实验得到了验证。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.14919v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.14919.md)  |
| <span style='display: inline-block; width: 42px;'>11-24</span> | **Calibrated Language Models Must Hallucinate**<br><sub>机构: Microsoft Research<br>该文章展示了预训练语言模型在充分校准的条件下，必然产生幻觉的统计根源，并介绍了预测性能良好的模型固有的幻觉产生机制。同时，文章还提供了幻觉产生率的下界估算，并探讨了不同类型事实产生幻觉的可能性，指出了未来减轻特定类型幻觉的可能方向。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.14648v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.14648.md)  |
| <span style='display: inline-block; width: 42px;'>11-24</span> | **Data-Efficient Alignment of Large Language Models with Human Feedback Through Natural Language**<br><sub>机构: Amazon<br>文章提出了一个有效的CnR方法，它能够通过使用自然语言的精细反馈和响应修正，高效地校准LLMs以符合人类预期。通过相对较少的人类反馈数据，此方法可以显著改善即使是顶尖LLMs的响应质量，如ChatGPT。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.14543v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.14543.md)  |
| <span style='display: inline-block; width: 42px;'>11-23</span> | **Controlling Large Language Model-based Agents for Large-Scale Decision-Making: An Actor-Critic Approach**<br><sub>机构: Chinese Academy of Sciences<br>LLaMAC框架展示了基于LLM的多智能体系统在长期规划、数学推理、优化问题和空间推理方面的卓越表现，并且减少了大规模多智能体协作的访问成本。随着LLM的进一步提升和更多协作框架的出现，多智能体协作领域将迎来新的发展机遇。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13884v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.13884.md)  |
| <span style='display: inline-block; width: 42px;'>11-23</span> | **ZipLoRA: Any Subject in Any Style by Effectively Merging LoRAs**<br><sub>机构: Google Research<br>文章提出了一种名为ZipLoRA的新策略，旨在通过一个优化过程有效地合并独立训练的主题和风格LoRAs，从而能够生成任何用户提供的主题风格的组合。ZipLoRA对生成任何特定主题和风格的图像这一开放性研究问题提供了创新的解决方案，且由于其无需手动超参数调整，使用起来更加简便高效。实验证明该方法在保持主题和风格真实性的同时，相比于现有方法和其他基本方法而言，具有更好的生成质量和鲁棒性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13600v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.136.md)  |
| <span style='display: inline-block; width: 42px;'>11-23</span> | **Diffusion Model Alignment Using Direct Preference Optimization**<br><sub>机构: Nikhil Naik, Stanford University<br>本文提出了一个名为Diffusion-DPO的方法，其通过直接优化基于人类比较数据的模型来实现对扩散模型与人类偏好的对齐。此外，文章也探索了基于AI反馈的训练，取得了与基于人类偏好训练相媲美的成绩。这明显提升了模型在视觉吸引力和文本对齐方面的性能，为利用AI反馈扩展扩散模型对齐方法提供了新的途径。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12908v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12908.md)  |
| <span style='display: inline-block; width: 42px;'>11-23</span> | **LucidDreamer: Domain-free Generation of 3D Gaussian Splatting Scenes**<br><sub>机构: ASRI<br>LucidDreamer是一个能够用于生成逼真而且分辨率更高的3D场景的模型。它优于现有的场景生成模型，因为它不依赖特定的训练数据集，并能够适应多种输入样式。LucidDreamer通过约束点云的移动和使用插值算法，克服了形状扭曲和点云与图像错位的问题，从而在操纵3D空间中的点云时保持了场景的真实感和一致性。在实验中明显展示了其优越性和高泛化能力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13384v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.13384.md)  |
| <span style='display: inline-block; width: 42px;'>11-23</span> | **FusionFrames: Efficient Architectural Aspects for Text-to-Video Generation Pipeline**<br><sub>机构: Sber AI<br>总体而言，该论文提出了一个新型两阶段潜在扩散的文本到视频生成架构，解决了关键帧合成和插值帧生成中存在的问题，通过使用独立的时域块和有效的插值架构，减少了计算成本，并在多个质量指标上取得了优于现有技术的表现。此外，论文还针对视频解码器设计了不同的架构选项，进一步优化了视频的一致性和整体质量。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13073v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.13073.md)  |
| <span style='display: inline-block; width: 42px;'>11-23</span> | **GAIA: a benchmark for General AI Assistants**<br><sub>机构: FAIR, Meta<br>GAIA 是一项针对通用人工智能助理的基准测试，其目的在于提出真实世界的挑战性问题，并避开传统 LLMs 评价中的许多陷阱。该基准测试强调任务对人类简单而对AI难度较大，以此来评估AI的执行复杂行动序列的准确能力，这些任务在设计上无法简单地通过暴力方法得以解决。GAIA 还考虑了如何扩展基准测试，并探讨了一些最先进的助理的成功与短板，展示了增强 LLMs 的潜力。最终，文章旨在设立一个开发者问题集，为人工智能研究提供一个可扩展的基准测试平台。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12983v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12983.md)  |
| <span style='display: inline-block; width: 42px;'>11-23</span> | **Probabilistic Tree-of-thought Reasoning for Answering Knowledge-intensive Complex Questions**<br><sub>机构: Tsinghua University<br>文章提出了一种新颖的概率树状推理（ProbTree）方法，通过探索LLM在回答知识密集型复杂问题时的能力，并将不确定性引入推理过程，在统一框架中整合了外部和参数知识。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13982v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.13982.md)  |
| <span style='display: inline-block; width: 42px;'>11-22</span> | **Visual In-Context Prompting**<br><sub>机构: HKUST, Microsoft Research<br>本论文提出了DINOv，一个新的视觉上下文内提示框架，能够有效处理多样化的视觉提示，使用无标签数据，并在多个任务中达到很好的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13601v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.13601.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/UX-Decoder/DINOv)</div> |
| <span style='display: inline-block; width: 42px;'>11-22</span> | **AlignedCoT: Prompting Large Language Models via Native-Speaking Demonstrations**<br><sub>机构: The Hong Kong University of Science and Technology (Guangzhou), The Hong Kong University of Science and Technology, University of California, Los Angeles<br>本文提出的AlignedCoT技术，旨在通过对齐LLMs的CoT文本风格与其“本土风格”，来提高LLMs的推理能力，并通过实验证明了其有效性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13538v4)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.13538.md)  |
| <span style='display: inline-block; width: 42px;'>11-22</span> | **Enhancing Summarization Performance through Transformer-Based Prompt Engineering in Automated Medical Reporting**<br><sub>机构: Utrecht University<br>这项研究验证了在自动化医疗报告中应用基于转换器的提示工程可以提高摘要性能。尽管存在一些局限性，但研究提出的方法证明了在提示制定时加入示例和上下文信息的效用，并且指出了未来工作的方向。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13274v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.13274.md)  |
| <span style='display: inline-block; width: 42px;'>11-22</span> | **LIMIT: Less Is More for Instruction Tuning Across Evaluation Paradigms**<br><sub>机构: Princeton University<br>本论文的主要贡献包括：在开源模型上微调不同大小和风格的指令数据集，评估微调模型在不同的评估范式下的表现，并且发现较少的样本（特别是当这些样本结合了不同来源和风格时）足以在不同类型的评估中获得良好的性能。这表明在培养LLMs的指令遵从能力时，“少即是多”，且通过精心选择微调样本，可以使模型在执行指令能力上得到显著提升。这一发现对于如何有效地微调LLMs以及如何评估它们的实用性具有重要意义。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13133v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.13133.md)  |
| <span style='display: inline-block; width: 42px;'>11-22</span> | **XAGen: 3D Expressive Human Avatars Generation**<br><sub>机构: National University of Singapore, ByteDance<br>研究提出了XAGen模型，它是首个能够生成全面可控3D人类化身的GAN模型。XAGen在细粒度属性控制上具有独立的能力，并通过多尺度和多部分的3D表示与渲染技术提升了面部和手部的生成质量。实验结果证明XAGen在外观质量、控制能力和数据利用率方面都超过了现有最先进的方法，推进了3D虚拟化身生成技术的发展。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13574v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.13574.md)  |
| <span style='display: inline-block; width: 42px;'>11-21</span> | **AcademicGPT: Empowering Academic Research**<br><sub>机构: International Digital Economy Academy<br>AcademicGPT针对学术研究的特定需求进行了优化，通过结合针对性强的训练数据和多方面的应用开发，为学术领域提供了实质性的支持和工具。它标志着大型语言模型个性化与专业化发展的一个重要步骤，并有望对学术社区产生深远的影响。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12315v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12315.md)  |
| <span style='display: inline-block; width: 42px;'>11-21</span> | **Do Smaller Language Models Answer Contextualised Questions Through Memorisation Or Generalisation?**<br><sub>机构: University of Auckland<br>本论文提出了一种新方法以评价小型语言模型在问答任务中答案的生成是否为记忆或概括能力的结果。通过语义相似度分析，确定了不太可能被模型记住答案的评估样本，并用增加额外训练数据集的方式，针对特定评估子集进行了模型性能的优化。最终，研究结果显示增加了数据集的模型在特定评估数据集上有了显著提升，并推断这种改善与模型的泛化能力有关。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12337v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12337.md)  |
| <span style='display: inline-block; width: 42px;'>11-21</span> | **A Survey on Multimodal Large Language Models for Autonomous Driving**<br><sub>机构: Purdue University<br>该论文全面回顾了MLLMs在自动驾驶领域的应用，表明MLLMs具备解析非文本数据和融合多种模态（如视觉、语言）的能力，这些能力对于行为预测和动作规划尤为重要。通过在不同的自动驾驶环节中部署MLLMs（如理解交通场景、规划控制、模式生成），可以改善决策流程，并实现类似人类的驾驶直觉和决策模式，同时提高车辆导航和规划的效率和安全性。此外，模型通过为多个任务的预训练提供了一种新的可能性，这可能会推动把智能系统推向人工普遍智能（AGI）的发展路径。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12320v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.1232.md)  |
| <span style='display: inline-block; width: 42px;'>11-21</span> | **Oasis: Data Curation and Assessment System for Pretraining of Large Language Models**<br><sub>机构: Chinese Academy of Sciences<br>本文提出的Oasis系统是针对大型语言模型预训练的数据整理和评估问题的解决方案。Oasis通过其交互式的自定义数据整理模块、针对偏差的模型过滤器和全面的数据评估系统，旨在提高数据集的质量和多样性，同时降低内存需求和资源消耗。系统的实现立足于提升数据处理的灵活性和评估的准确性，填补了现有工作在全面性和多维度评估方面的空白。通过综合使用人类评估、启发式度量和最新的大型语言模型如GPT-4进行质量评估，Oasis展现了对预训练数据集进行全方位优化的能力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12537v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12537.md)  |
| <span style='display: inline-block; width: 42px;'>11-21</span> | **Mechanistically analyzing the effects of fine-tuning on procedurally defined tasks**<br><sub>机构: University of Cambridge<br>本文针对微调对预定义能力的影响开展了一项全面的分析和评估。通过Tracr编译式的能力设计和基于PCFG的学习式能力设计，文章详细探讨了微调过程中嵌入特征的相关性，提出了reFT来强化分析微调影响的深度。本研究的发现改进了对微调影响机理的理解，并为后续的模型设计和微调策略提供了实证支持。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12786v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12786.md)  |
| <span style='display: inline-block; width: 42px;'>11-21</span> | **How Capable Can a Transformer Become? A Study on Synthetic, Interpretable Tasks**<br><sub>机构: University of Pennsylvania, MIT<br>本文通过设计合成数据生成过程和系统性实验，以评估和理解自回归Transformer模型在组合其原始能力方面的潜力。研究结果突显了模型学习组合结构的能力，揭示了训练数据对此能力的影响以及模型内部注意力层在组合学习过程中的重要性。这或许为评估和提高现代神经网络对真实世界数据的理解和应用，特别是在其可能面临前所未见的任务时，提供了新的见解。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12997v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12997.md)  |
| <span style='display: inline-block; width: 42px;'>11-21</span> | **Latent Lab: Large Language Models for Knowledge Exploration**<br><sub>机构: Department of Electrical Engineering and Computer Science, MIT<br>Latent Lab作为一种探索大型数据集中相互联系关系的创新和强大工具，通过利用LLMs和视觉引人注目的接口，它超越了常规搜索的局限性，提供了一个语义上有意义和情境感知的体验。强调探索的价值和迭代设计，在直观地访问大量相互连接的信息方面实现了信息技术专家的长期追求，并通过AI辅助探索将这一愿景变为现实，为未来人工智能共创系统的发展奠定了基础，并促进了更直观和高效的合作，有能力产生新颖和有影响力的创造物。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13051v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.13051.md)  |
| <span style='display: inline-block; width: 42px;'>11-21</span> | **Prompting Frameworks for Large Language Models: A Survey**<br><sub>机构: Zhejiang University<br>这项研究提供了一个框架，它通过实现新的技术手段来增强与LLMs的交互，包括改善与编程语言的兼容性，使能LLMs使用外部工具，并维护历史交互信息，并以此指导未来的研究方向。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12785v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12785.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/lxx0628/Prompting-Framework-Survey)</div> |
| <span style='display: inline-block; width: 42px;'>11-21</span> | **Advancing Transformer Architecture in Long-Context Large Language Models: A Comprehensive Survey**<br><sub>机构: Nanjing University<br>文章为了解决LLMs在应对长上下文时的挑战，提出了一系列方法和综合分类体系，提高了LLMs在注意力机制、记忆效率和最大长度处理上的性能。通过综合回顾和分类学界最近的进展，本文为未来的LLMs架构设计和优化提供了清晰的指导方向。。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12351v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12351.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/Strivin0311/long-llms-learning)</div> |
| <span style='display: inline-block; width: 42px;'>11-20</span> | **GPQA: A Graduate-Level Google-Proof Q&A Benchmark**<br><sub>机构: New York University<br>GPQA 数据集提供了一个用于测试 AI 系统在处理需深度理解和推理能力的复杂问题上的能力的基准。通过严格的问题质量控制和专家级别的难度，它可能促进人类专家与 AI 系统合作的方法发展，并推动 AI 系统设计的进步。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12022v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12022.md)  |
| <span style='display: inline-block; width: 42px;'>11-20</span> | **Igniting Language Intelligence: The Hitchhiker's Guide From Chain-of-Thought Reasoning to Language Agents**<br><sub>机构: Shanghai Jiao Tong University<br>本文作为首篇系统性探讨CoT基步机制、范式转变，以及CoT与代理间复杂交互的工作，提供了一些关键见解。文章揭示了CoT在特定条件下显示出的有效性，指出了使CoT工作的多个条件，以及理论和实证研究为其成功提供了何种解释。文章还对CoT理论进行了深入分析，提出了CoT对于LLMs在多个领域的优化和革新可能具有重要的贡献，并指出尽管LLMs、CoT推理和语言代理快速发展，但仍存在未解决的挑战，如对未见领域的泛化、提高交互效率、代理定制化、代理扩展及代理安全性等【10†源】。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.11797v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.11797.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/Zoeyyao27/CoT-Igniting-Agent)</div> |
| <span style='display: inline-block; width: 42px;'>11-20</span> | **Continual Learning: Applications and the Road Forward**<br><sub>机构: KU Leuven<br>论文综述了当前的持续学习研究现状，指出了其在记忆限制条件下研究较多而忽视计算成本的问题，并提出了四个有前途的研究方向。这些方向包括：1) 真实世界数据处理的挑战，2) 计算成本的考虑，以及其他如何获取数据和理论理解方面的关注点。论文主张未来的CL算法应在减少对完全标记和封闭世界假设的依赖上做出实质性的进展，以使CL成为解决实际机器学习问题的一个有效工具。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.11908v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.11908.md)  |
| <span style='display: inline-block; width: 42px;'>11-20</span> | **Assessing Prompt Injection Risks in 200+ Custom GPTs**<br><sub>机构: Northwestern University<br>该论文着重研究了自定义GPT模型中的安全风险，尤其是提示注入攻击。研究者们提出了一个包含扫描、注入敌意提示和提取目标信息三个步骤的攻击方法，并通过实施评估发现自定义GPT模型存在严重的系统提示提取和文件泄露漏洞。这些发现突出了自定义GPT模型中的关键安全缺陷，并指出了提升这些模型安全性结构的必要性。此外，红队评估清楚地显示出，现有防护措施并不足够强大，甚至有时候明确指出不应该分享的信息也能被提取出来，这表明亟需进一步加强对抗提示注入攻击的防御机制。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.11538v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.11538.md)  |
| <span style='display: inline-block; width: 42px;'>11-19</span> | **TPTU-v2: Boosting Task Planning and Tool Usage of Large Language Model-based Agents in Real-world Systems**<br><sub>机构: SenseTime Researc<br></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.11315v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.11315.md)  |
| <span style='display: inline-block; width: 42px;'>11-18</span> | **An Embodied Generalist Agent in 3D World**<br><sub>机构: Beijing Institute for General Artificial Intelligence <br>LEO是一个新型的身体化、多模态、多任务的通用型智能体，专注于在3D世界中的感知、基础、推理、规划和行动。通过对3D视觉-语言对齐和视觉-语言-动作指令调优的训练，LEO能在3D世界中执行一系列任务。文章通过一系列严格实验和消融实验的结果，证实了LEO在一系列任务上的高效性能，并为未来身体化通用型智能体的发展提供了宝贵洞见。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12871v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12871.md)  |
| <span style='display: inline-block; width: 42px;'>11-18</span> | **Adapters: A Unified Library for Parameter-Efficient and Modular Transfer Learning**<br><sub>机构: Technical University of Darmstadt, University of Cambridge<br>论文提出了一个统一的库——Adapters，它整合并扩展了参数高效和模块化迁移学习方法，实现了与Transformers库的紧密整合，通过多个NLP任务的对比实验，展示了其有效性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.11077v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.11077.md)  |
| <span style='display: inline-block; width: 42px;'>11-18</span> | **Orca 2: Teaching Small Language Models How to Reason**<br><sub>机构: Microsoft Research<br>文章通过介绍一个新的小型语言模型Orca 2，并展示其在多种推理任务上能够与更大的模型相匹敌或超越它们的性能，对当前小型语言模型在复杂推理任务中表现不佳的问题提出了有效的解决方案。Orca 2的开发依赖于对训练数据和训练策略的精心设计，证明了即使是小型模型，也可以通过改进训练方法来增强其理解和推理能力。文章还提供了Orca 2在各种标准测试中的卓越性能结果，验证了其方法论在实际应用中的有效性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.11045v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.11045.md)  |
| <span style='display: inline-block; width: 42px;'>11-18</span> | **RecExplainer: Aligning Large Language Models for Recommendation Model Interpretability**<br><sub>机构: University of Science and Technology of China<br>文章针对推荐模型解释性的研究提出了一种新型的方法，即通过大型语言模型进行对齐，以提高解释的质量和准确性。文章介绍了三种不同的对齐方法，并通过一系列任务训练LLM以模仿推荐模型的逻辑。论文采用了多种评估策略和评分体系，包括使用最新的GPT-4模型和人类评分来验证所提出方法的有效性，并在三个不同的数据集上进行了测试，显示出其在提高推荐模型解释性方面的潜力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.10947v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.10947.md)  |
| <span style='display: inline-block; width: 42px;'>11-17</span> | **Camels in a Changing Climate: Enhancing LM Adaptation with Tulu 2**<br><sub>机构: Allen Institute for AI <br>TÜLU 2通过采用新的基础模型和调整策略，在多个性能指标上实现了突破，对进一步理解和改进预训练语言模型的适配具有重要意义。通过引入新的数据混合物和先进的训练方法（如DPO），TÜLU 2提高了模型在各种推理和知识探测任务上的性能，并在开放式生成指标上取得了显著的提升。此外，研究者们通过公开相关模型、数据和代码，推动了语言模型适配方法的开放研究和发展。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.10702v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.10702.md)  |
| <span style='display: inline-block; width: 42px;'>11-17</span> | **Exploring the Relationship between In-Context Learning and Instruction Tuning**<br><sub>机构: HKUST<br>论文提供了ICL与IT之间密切相关的实证证据，即使ICL中不更改模型参数，二者所使用的指令和示例都驱动模型朝着收敛的隐藏状态前进。这一发现对于如何设计高效的数据集和任务以推进基础模型在下游应用的发展和对齐具有启示作用。研究结果还可以帮助理解示例在ICL和IT中的作用，以及如何利用这些见解来设计有效的示例任务和数据集，从而提升LLM的性能。论文中申明将会提供实验代码以供复现。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.10367v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.10367.md)  |
| <span style='display: inline-block; width: 42px;'>11-16</span> | **MacGyver: Are Large Language Models Creative Problem Solvers?**<br><sub>机构: University of California, Princeton University<br>本研究通过创造MACGYVER数据集，探索了LLMs在解决非传统问题上的能力，并通过人类评估员对GPT-4的表现进行了评价。研究结果展示了LLMs在这类任务上的局限性，同时提出了提高其表现的新方法。研究强调了创造性问题解决能力在日常生活中的重要性，并尝试通过LLMs补充人类的创造性思维，以期提高解决问题的能力和效率。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.09682v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.09682.md)  |
| <span style='display: inline-block; width: 42px;'>11-16</span> | **Crafting In-context Examples according to LMs' Parametric Knowledge**<br><sub>机构: The University of Texas at Austin<br>本文的重点研究是如何根据LM的参数知识有效地创建上下文示例：选择最优的示例（已知与未知的比较）以及在上下文示例中如何排序答案。实验结果支持了半已知示例的有效性以及基于参数知识的答案排序方法，这些发现为提高大型语言模型在多答案生成任务中的性能提供了可行的技术途径。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.09579v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.09579.md)  |
| <span style='display: inline-block; width: 42px;'>11-16</span> | **Predictive Minds: LLMs As Atypical Active Inference Agents**<br><sub>机构: Charles University<br>本论文将活动推断的概念应用于大型语言模型（LLMs），从一个新的视角分析了LLMs的行为和学习机制。论文提出，尽管LLMs在物理上无法直接与环境互动，但它们通过生成文本在虚拟环境中的“行动”间接影响世界，并有可能将这些影响反馈到模型的训练中。研究指出，增强LLMs与用户交互的反馈循环，将有助于提升模型的自我意识，让其更好地适应和响应环境变化，这将带来重大的社会影响和潜在的风险。论文为理解和改进LLMs在实际部署时的行为提供了重要的理论基础，预测了这些系统未来可能的发展方向。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.10215v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.10215.md)  |
| <span style='display: inline-block; width: 42px;'>11-16</span> | **Automatic Engineering of Long Prompts**<br><sub>机构: Google<br>本文针对语言模型长指令工程中存在的问题，提出了一种新的算法框架，并解决了贪婪算法易陷入局部最优和遗传算法初期收敛慢的问题。通过对指令的每个句子进行语义保持重述，并利用波束搜索来维护和优化候选指令集合，使算法在有限训练数据上表现出良好的性能和较快的收敛速度。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.10117v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.10117.md)  |
| <span style='display: inline-block; width: 42px;'>11-15</span> | **Contrastive Chain-of-Thought Prompting**<br><sub>机构: DAMO Academy, Alibaba Group<br>本论文提出了对比式链式思维方法，以解决传统链式思维中存在的问题，即缺乏对错误避免的指导以及实现推理效果的不确定性。通过提供有效和无效的推理示例，新方法旨在引导模型减少推理错误并一步步推理，同时该方法提供了自动化构建对比示例的技术以便泛化到各种任务。实验结果证实，该方法能够作为一种通用增强手段，显著提升链式思维的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.09277v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.09277.md)  |
| <span style='display: inline-block; width: 42px;'>11-15</span> | **Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language Models**<br><sub>机构: Tecent AI Lab<br>论文提出的CHAIN-OF-NOTE（CON）框架旨在提高RALMs的鲁棒性，主要通过引入结构化的阅读笔记过程来批判性地评估检索到的文档。实验结果表明，该框架提高了模型在噪声数据和未知情况下的健壮性，改善了整体QA性能，并在检索文档失败还是成功时均提高了模型的性能。CON框架通过生成读取笔记和最终回答，提高了模型对噪声的鲁棒性，并在缺乏信息时能够给出“未知”的回答，增强了模型的适应性和可靠性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.09210v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.0921.md)  |
| <span style='display: inline-block; width: 42px;'>11-15</span> | **Exponentially Faster Language Modelling**<br><sub>机构: ETH Zurich<br>本文介绍了UltraFastBERT，这是一个大规模语言模型的变种，它显著减少了在推理时需要使用的神经元数量，并通过使用快速前馈网络来提高计算效率。尽管不具备原生的高效实现，但该模型提供了一个能够显著加速推理过程的CPU代码实现，并在标准下游任务中表现良好。这一工作展示了条件神经执行在语言建模领域巨大的潜力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.10770v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.1077.md)  |
| <span style='display: inline-block; width: 42px;'>11-15</span> | **ToolTalk: Evaluating Tool-Usage in a Conversational Setting**<br><sub>机构: Microsoft Corporation<br>ToolTalk 是一个致力于评估和提高 LLM 在对话环境中使用多步骤外部工具性能的基准。它通过创新的评估方法和真实场景模拟，挑战和扩展了现有 LLMs 的能力边界，并为未来的研究指出了方向。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.10775v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.10775.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/microsoft/ToolTalk)</div> |
| <span style='display: inline-block; width: 42px;'>11-15</span> | **Memory Augmented Language Models through Mixture of Word Experts**<br><sub>机构: Google Research<br>本论文提出了一个称为MoWE的新型架构，它通过融合稀疏模型的效率和大型语言模型的性能，出色地处理了性能与计算成本之间的平衡。通过采取创新的设计原则，并且在NLP多种任务中验证了其超越传统模型如T5和MoE的性能，MoWE展示了在学术和实际应用领域的潜力，尤其是在处理知识密集型任务时。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.10768v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.10768.md)  |
| <span style='display: inline-block; width: 42px;'>11-14</span> | **Instruction-Following Evaluation for Large Language Models**<br><sub>机构: Google, Yale University<br>本文提出了一种评估大型语言模型的指令遵循能力的新方法——IFEval，它通过合成逻辑一致的指令和计算指令遵循准确性的新准则来解决评估过程中的挑战。此方法为自动化且无偏见，它通过多步骤过程避免指令间的潜在冲突，并引入了严格和宽松的准确性评价标准来减少误判，同时认为未来可以通过增加多样化和使用多模态指令来改进该方法。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.07911v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.07911.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/google-research/google-research/tree/master/instruction_following_eval)</div> |
| <span style='display: inline-block; width: 42px;'>11-14</span> | **Learning to Filter Context for Retrieval-Augmented Generation**<br><sub>机构: Carnegie Mellon University<br>本文提出的FILCO方法针对开放领域问答和事实验证等知识密集型任务，通过改善提供给生成模型的上下文质量来解决生成输出时面临的问题。通过结合词汇和信息论方法来识别有用上下文，并训练模型以在测试时过滤检索上下文，很好地解决了以前方法的局限性。实验结果显示，相比传统方法，FILCO在多个知识密集型任务上都取得了显著的性能改进，并且在上下文过滤训练上显示出其有效性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.08377v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.08377.md)  |
| <span style='display: inline-block; width: 42px;'>11-14</span> | **KTRL+F: Knowledge-Augmented In-Document Search**<br><sub>机构: KAIST AI, Samsung Research<br>文章提出了一个新的问题——KTRL+F，以解决文献搜索中的实时、准确性、引入外部知识的需求。通过分析现有基线，文章发现它们存在局限性，在此基础上提出了Knowledge-Augmented Phrase Retrieval模型。该模型有效地在短语检索中整合了外部知识，通过简单的扩展保持了快速响应，无需额外训练。通过用户研究，证明了该模型能够提升用户搜索体验，减少搜索时间和外部信息检索量。作者鼓励研究社区关注KTRL+F这一独特挑战，提高文献信息访问的效率和效果。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.08329v3)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.08329.md)  |
| <span style='display: inline-block; width: 42px;'>11-13</span> | **Can LLMs Patch Security Issues?**<br><sub>机构: School of Computer Science Atlanta<br>本文介绍了一种新型的代码修正方法FDSS，通过与静态代码分析工具Bandit集成，能显著提高LLMs解决代码中安全问题的能力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00024v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2312.00024.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/Kamel773/LLM-code-refine)</div> |
| <span style='display: inline-block; width: 42px;'>11-13</span> | **In-context Learning Generalizes, But Not Always Robustly: The Case of Syntax**<br><sub>机构: NYU, Microsoft<br>本论文揭示了大型语言模型在理解和泛化句法结构时可能存在的局限性，这对于改进语言模型处理复杂语法任务的方式具有重要意义。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.07811v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.07811.md)  |
| <span style='display: inline-block; width: 42px;'>11-11</span> | **In-context Vectors: Making In Context Learning More Effective and Controllable Through Latent Space Steering**<br><sub>机构: Stanford University<br>本论文提出的ICV方法为大型语言模型的上下文学习提供了一种新颖且更加有效的替代方案。通过将演示示例的关键信息集成到一个可以控制的向量中，ICV方法提高了任务指导的精确度和效果，并显著优于现有的方法。实验结果表明，ICV在多项任务中展现了较高的性能，包括在不同的LLMs上进行语言模型解毒、风格转换和角色扮演。ICV方法的计算开销低，并且易于控制，有助于提升语言模型在实际应用中的适用性和弹性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.06668v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.06668.md)  |
| <span style='display: inline-block; width: 42px;'>11-10</span> | **Making LLMs Worth Every Penny: Resource-Limited Text Classification in Banking**<br><sub>机构: Helvia.ai<br>论文首次将多种在资源受限环境下的方法进行了全面评估，包括成本分析、RAG方法和利用GPT-4的数据增强，为金融行业提供了新的方法用以应对数据和预算限制的挑战。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.06102v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.06102.md)  |
| <span style='display: inline-block; width: 42px;'>11-05</span> | **ChaTA: Towards an Intelligent Question-Answer Teaching Assistant using Open-Source LLMs**<br><sub>机构: Cornell University, Microsoft Research<br>本文提供了一个使用开源LLMs增强在线教育QA平台的新方案，并对其进行了广泛的评估和测试。通过将RAG、SFT和DPO等技术结合应用，确保了回答质量的显著提升和数据隐私的保护，对于开发智能QA助手具有重要的意义。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.02775v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.02775.md)  |
| <span style='display: inline-block; width: 42px;'>11-01</span> | **LLMRec: Large Language Models with Graph Augmentation for Recommendation**<br><sub>机构: University of Hong Kong, Baidu<br>LLMRec作为开创性的工作，它引入LLMs来增强图推荐系统，成功地解决了交互数据的稀疏性和低质量侧信息的问题，并通过强化用户-项目交互边、项目节点属性以及用户画像等手段提升了推荐系统的性能，确保了推荐质量的同时降低了数据噪声的影响。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.00423v5)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.00423.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/HKUDS/LLMRec.git)</div> |

---

### 10月

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>10-20</span> | **The History and Risks of Reinforcement Learning and Human Feedback**<br><sub>机构: Berkeley<br></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2310.13595v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-10/2310.13595.md)  |
| <span style='display: inline-block; width: 42px;'>10-17</span> | **Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection**<br><sub>机构: University of Washington<br>论文推出了SELF-RAG，这是一种新的框架，通过按需检索和自我反思来增加LLMs的质量和事实性。它通过生成反思标记让LM在推理阶段变得可控，可以满足多样化的任务要求。SELF-RAG在多个任务上显著超越了现有LLMs和RAG模型，并通过定制的解码算法和反思标记，为模型自我评估和定制提供了新的方案。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2310.11511v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-10/2310.11511.md)  |
| <span style='display: inline-block; width: 42px;'>10-11</span> | **OpsEval: A Comprehensive Task-Oriented AIOps Benchmark for Large Language Models**<br><sub>机构: Tsinghua University, Chinese Academy of Sciences<br>OpsEval 作为一个全面的 AIOps 任务导向型基准测试，不仅评估了大型语言模型的综合性能、推理和实际应用能力，还可能改变未来大规模质量评估中使用的评价指标。它提供了一个用于持续研究和优化AIOps领域大型语言模型的坚实基础。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2310.07637v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-10/2310.07637.md)  |
| <span style='display: inline-block; width: 42px;'>10-10</span> | **GPT-4 as an Agronomist Assistant? Answering Agriculture Exams Using Large Language Models**<br><sub>机构: Microsoft Research<br>本研究展示了在农业领域使用LLMs进行问题回答的新方法，特别是通过Ensemble Refinement策略，大幅提升了LLMs在多选题目上的表现，并显示出在处理专业领域问题时的广泛潜力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2310.06225v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-10/2310.06225.md)  |

---

### 09月

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>09-04</span> | **Benchmarking Large Language Models in Retrieval-Augmented Generation**<br><sub>机构: Chinese Information Processing Laboratory <br>本论文提出了一种新的基于实际新闻文章的检索增强生成基准测试，用以彻底评估大型语言模型在复杂信息环境中的多项能力，并通过实验结果展现了现有LLMs在这些方面的局限性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2309.01431v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-09/2309.01431.md)  |

---

### 08月

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>08-18</span> | **Learning Representations on Logs for AIOps**<br><sub>机构: IBM Research<br>本文提出的BERTOps模型通过使用LLMs中的通用表示，并结合专门针对AIOps日志数据的预训练，有效地提高了自动化日志分析任务的性能，并展示了显著的改进。BERTOps不仅优于现有模型，在多个下游任务中也表现出卓越的性能，有助于加速AIOps的实践应用。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2308.11526v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-08/2308.11526.md)  |

---

### 07月

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>07-11</span> | **Towards Understanding In-Context Learning with Contrastive Demonstrations and Saliency Maps**<br><sub>机构: UNIVERSITY OF MARYLAND<br>本研究使用对比示例和显著图分析法来探究大型语言模型中上下文学习的内在机制，揭示了标签翻转、输入变化、和补充性解释对预测的不同影响，并为实践者提供了如何策划示例的洞见。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2307.05052v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-07/2307.05052.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/paihengxu/XICL)</div> |

---

### 06月

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>06-07</span> | **PromptRobust: Towards Evaluating the Robustness of Large Language Models on Adversarial Prompts**<br><sub>机构: Microsoft Research<br>PromptRobust是一个全新的、开放性的基准测试，旨在评估LLMs如何对待可能在现实世界中自然发生的输入错误，如错别字和同义词替换。这一工具的开源将有助于未来的稳健性研究。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2306.04528v5)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-06/2306.04528.md)  |

---

### 05月

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>05-24</span> | **In-Context Demonstration Selection with Cross Entropy Difference**<br><sub>机构: Microsoft Cognitive Service Research<br>文章提出了一种新的基于交叉熵差异（CED）的上下文示例选择方法，并提供了理论上的解释，实现了对不同大小和类型的大型语言模型性能的提升。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2305.14726v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-05/2305.14726.md)  |
| <span style='display: inline-block; width: 42px;'>05-23</span> | **Label Words are Anchors: An Information Flow Perspective for Understanding In-Context Learning**<br><sub>机构: Lean Wang, Lei Li, Damai Dai, Deli Chen, Hao Zhou, Fandong Meng, Jie Zhou, Xu Sun<br>本论文通过信息流视角研究了大型语言模型进行上下文学习（ICL）的内部机制，发现了标签词在信息流中作为锚点的现象，提出了新假设，并通过实验验证了其有效性。此外，使用所得洞见提出了提高ICL性能的方法，为未来相关研究提供了理论基础和实践指导。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2305.14160v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-05/2305.1416.md)  |
| <span style='display: inline-block; width: 42px;'>05-19</span> | **How to Prompt LLMs for Text-to-SQL: A Study in Zero-shot, Single-domain, and Cross-domain Settings**<br><sub>机构: The Ohio State University<br>本研究揭示出有效提示构造的关键数据库知识和最优表述，为LLMs在text-to-SQL任务中的应用提供指导，并指出在跨域设置中对于提示长度存在一个“甜蜜点”。本研究的发现可能对于特定数据库不总是适用，特别是如果该数据库与Spider数据库显著不同。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2305.11853v3)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-05/2305.11853.md)  |

---

### 03月

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>03-31</span> | **A Survey of Large Language Models**<br><sub>机构: Renmin University of China<br>总的来说，这篇综述文章介绍了LLMs领域的最新进展，特别是OpenAI推出的ChatGPT和GPT-4模型，并强调了这些产品对人工智能研究的重大影响，特别指出了它们在人机交流、多模态理解和生成、以及人工智能对齐和安全性方面的突破。同时，文章认识到尽管取得了巨大的技术进展，但在安全性、生成质量和多模态性功能方面仍面临挑战，并提出了一系列的技术和策略来缓解这些问题。通过这篇文章，我们可以更好地理解LLMs的发展方向以及对未来人工智能应用和研究的潜在影响。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2303.18223v13)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-03/2303.18223.md)  |

---

### 02月

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>02-08</span> | **A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity**<br><sub>机构: Centre for Artificial Intelligence Research<br>文章通过更细粒度的方式评估了ChatGPT的推理能力，并且找到了LLMs中的一个关键问题，即在非文本语义理解方面的不足。这一发现对于未来LLMs的改进和推理能力的研究提供了重要的方向。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2302.04023v4)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-02/2302.04023.md)  |

---


## Star History
<picture>
<source
    media="(prefers-color-scheme: dark)"
    srcset="
    https://api.star-history.com/svg?repos=xianshang33/llm-paper-daily&type=Date&theme=dark
    "
/>
<source
    media="(prefers-color-scheme: light)"
    srcset="
    https://api.star-history.com/svg?repos=xianshang33/llm-paper-daily&type=Date
    "
/>
<img
    alt="Star History Chart"
    src="https://api.star-history.com/svg?repos=xianshang33/llm-paper-daily&type=Date"
/>
</picture>
            
